[
  {
    "command": "chgrp",
    "description": " The chgrp utility shall set the group ID of the file named by each file operand to the group ID specified by the group operand. For each file operand, or, if the -R option is used, each file encountered while walking the directory trees specified by the file operands, the chgrp utility shall perform actions equivalent to the chown() function defined in the System Interfaces volume of POSIX.1\u20102017, called with the following arguments: * The file operand shall be used as the path argument. * The user ID of the file shall be used as the owner argument. * The specified group ID shall be used as the group argument. Unless chgrp is invoked by a process with appropriate privileges, the set-user-ID and set-group-ID bits of a regular file shall be cleared upon successful completion; the set-user-ID and set- group-ID bits of other file types may be cleared. The chgrp utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported by the implementation: -h For each file operand that names a file of type symbolic link, chgrp shall attempt to set the group ID of the symbolic link instead of the file referenced by the symbolic link. -H If the -R option is specified and a symbolic link referencing a file of type directory is specified on the command line, chgrp shall change the group of the directory referenced by the symbolic link and all files in the file hierarchy below it. -L If the -R option is specified and a symbolic link referencing a file of type directory is specified on the command line or encountered during the traversal of a file hierarchy, chgrp shall change the group of the directory referenced by the symbolic link and all files in the file hierarchy below it. -P If the -R option is specified and a symbolic link is specified on the command line or encountered during the traversal of a file hierarchy, chgrp shall change the group ID of the symbolic link. The chgrp utility shall not follow the symbolic link to any other part of the file hierarchy. -R Recursively change file group IDs. For each file operand that names a directory, chgrp shall change the group of the directory and all files in the file hierarchy below it. Unless a -H, -L, or -P option is specified, it is unspecified which of these options will be used as the default. Specifying more than one of the mutually-exclusive options -H, -L, and -P shall not be considered an error. The last option specified shall determine the behavior of the utility. "
  },
  {
    "command": "more",
    "description": " more is a filter for paging through text one screenful at a time. This version is especially primitive. Users should realize that less(1) provides more(1) emulation plus extensive enhancements. Options are also taken from the environment variable MORE (make sure to precede them with a dash (-)) but command-line options will override those. -d, --silent Prompt with \"[Press space to continue, 'q' to quit.]\", and display \"[Press 'h' for instructions.]\" instead of ringing the bell when an illegal key is pressed. -l, --logical Do not pause after any line containing a ^L (form feed). -e, --exit-on-eof Exit on End-Of-File, enabled by default if POSIXLY_CORRECT environment variable is not set or if not executed on terminal. -f, --no-pause Count logical lines, rather than screen lines (i.e., long lines are not folded). -p, --print-over Do not scroll. Instead, clear the whole screen and then display the text. Notice that this option is switched on automatically if the executable is named page. -c, --clean-print Do not scroll. Instead, paint each screen from the top, clearing the remainder of each line as it is displayed. -s, --squeeze Squeeze multiple blank lines into one. -u, --plain Suppress underlining. This option is silently ignored as backwards compatibility. -n, --lines number Specify the number of lines per screenful. The number argument is a positive decimal integer. The --lines option shall override any values obtained from any other source, such as number of lines reported by terminal. -number A numeric option means the same as --lines option argument. +number Start displaying each file at line number. +/string The string to be searched in each file before starting to display it. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "git-hash-object",
    "description": " Computes the object ID value for an object with specified type with the contents of the named file (which can be outside of the work tree), and optionally writes the resulting object into the object database. Reports its object ID to its standard output. When <type> is not specified, it defaults to \"blob\". -t <type> Specify the type (default: \"blob\"). -w Actually write the object into the object database. --stdin Read the object from standard input instead of from a file. --stdin-paths Read file names from the standard input, one per line, instead of from the command-line. --path Hash object as it were located at the given path. The location of file does not directly influence on the hash value, but path is used to determine what Git filters should be applied to the object before it can be placed to the object database, and, as result of applying filters, the actual blob put into the object database may differ from the given file. This option is mainly useful for hashing temporary files located outside of the working directory or files read from stdin. --no-filters Hash the contents as is, ignoring any input filter that would have been chosen by the attributes mechanism, including the end-of-line conversion. If the file is read from standard input then this is always implied, unless the --path option is given. --literally Allow --stdin to hash any garbage into a loose object which might not otherwise pass standard object parsing or git-fsck checks. Useful for stress-testing Git itself or reproducing characteristics of corrupt or bogus objects encountered in the wild. "
  },
  {
    "command": "id",
    "description": " If no user operand is provided, the id utility shall write the user and group IDs and the corresponding user and group names of the invoking process to standard output. If the effective and real IDs do not match, both shall be written. If multiple groups are supported by the underlying system (see the description of {NGROUPS_MAX} in the System Interfaces volume of POSIX.1\u20102017), the supplementary group affiliations of the invoking process shall also be written. If a user operand is provided and the process has appropriate privileges, the user and group IDs of the selected user shall be written. In this case, effective IDs shall be assumed to be identical to real IDs. If the selected user has more than one allowable group membership listed in the group database, these shall be written in the same manner as the supplementary groups described in the preceding paragraph. The id utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -G Output all different group IDs (effective, real, and supplementary) only, using the format \"%u\\n\". If there is more than one distinct group affiliation, output each such affiliation, using the format \" %u\", before the <newline> is output. -g Output only the effective group ID, using the format \"%u\\n\". -n Output the name in the format \"%s\" instead of the numeric ID using the format \"%u\". -r Output the real ID instead of the effective ID. -u Output only the effective user ID, using the format \"%u\\n\". "
  },
  {
    "command": "nl",
    "description": " Write each FILE to standard output, with line numbers added. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -b, --body-numbering=STYLE use STYLE for numbering body lines -d, --section-delimiter=CC use CC for logical page delimiters -f, --footer-numbering=STYLE use STYLE for numbering footer lines -h, --header-numbering=STYLE use STYLE for numbering header lines -i, --line-increment=NUMBER line number increment at each line -l, --join-blank-lines=NUMBER group of NUMBER empty lines counted as one -n, --number-format=FORMAT insert line numbers according to FORMAT -p, --no-renumber do not reset line numbers for each section -s, --number-separator=STRING add STRING after (possible) line number -v, --starting-line-number=NUMBER first line number for each section -w, --number-width=NUMBER use NUMBER columns for line numbers --help display this help and exit --version output version information and exit Default options are: -bt -d'\\:' -fn -hn -i1 -l1 -n'rn' -s<TAB> -v1 -w6 CC are two delimiter characters used to construct logical page delimiters; a missing second character implies ':'. As a GNU extension one can specify more than two characters, and also specifying the empty string (-d '') disables section matching. STYLE is one of: a number all lines t number only nonempty lines n number no lines pBRE number only lines that contain a match for the basic regular expression, BRE FORMAT is one of: ln left justified, no leading zeros rn right justified, no leading zeros rz right justified, leading zeros "
  },
  {
    "command": "git-check-ignore",
    "description": " For each pathname given via the command-line or from a file via --stdin, check whether the file is excluded by .gitignore (or other input files to the exclude mechanism) and output the path if it is excluded. By default, tracked files are not shown at all since they are not subject to exclude rules; but see \u2018--no-index\u2019. -q, --quiet Don\u2019t output anything, just set exit status. This is only valid with a single pathname. -v, --verbose Instead of printing the paths that are excluded, for each path that matches an exclude pattern, print the exclude pattern together with the path. (Matching an exclude pattern usually means the path is excluded, but if the pattern begins with \"!\" then it is a negated pattern and matching it means the path is NOT excluded.) For precedence rules within and between exclude sources, see gitignore(5). --stdin Read pathnames from the standard input, one per line, instead of from the command-line. -z The output format is modified to be machine-parsable (see below). If --stdin is also given, input paths are separated with a NUL character instead of a linefeed character. -n, --non-matching Show given paths which don\u2019t match any pattern. This only makes sense when --verbose is enabled, otherwise it would not be possible to distinguish between paths which match a pattern and those which don\u2019t. --no-index Don\u2019t look in the index when undertaking the checks. This can be used to debug why a path became tracked by e.g. git add . and was not ignored by the rules as expected by the user or when developing patterns including negation to match a path previously added with git add -f. "
  },
  {
    "command": "tcpdump",
    "description": " Tcpdump prints out a description of the contents of packets on a network interface that match the Boolean expression (see pcap-filter(@MAN_MISC_INFO@) for the expression syntax); the description is preceded by a time stamp, printed, by default, as hours, minutes, seconds, and fractions of a second since midnight. It can also be run with the -w flag, which causes it to save the packet data to a file for later analysis, and/or with the -r flag, which causes it to read from a saved packet file rather than to read packets from a network interface. It can also be run with the -V flag, which causes it to read a list of saved packet files. In all cases, only packets that match expression will be processed by tcpdump. Tcpdump will, if not run with the -c flag, continue capturing packets until it is interrupted by a SIGINT signal (generated, for example, by typing your interrupt character, typically control-C) or a SIGTERM signal (typically generated with the kill(1) command); if run with the -c flag, it will capture packets until it is interrupted by a SIGINT or SIGTERM signal or the specified number of packets have been processed. When tcpdump finishes capturing packets, it will report counts of: packets ``captured'' (this is the number of packets that tcpdump has received and processed); packets ``received by filter'' (the meaning of this depends on the OS on which you're running tcpdump, and possibly on the way the OS was configured - if a filter was specified on the command line, on some OSes it counts packets regardless of whether they were matched by the filter expression and, even if they were matched by the filter expression, regardless of whether tcpdump has read and processed them yet, on other OSes it counts only packets that were matched by the filter expression regardless of whether tcpdump has read and processed them yet, and on other OSes it counts only packets that were matched by the filter expression and were processed by tcpdump); packets ``dropped by kernel'' (this is the number of packets that were dropped, due to a lack of buffer space, by the packet capture mechanism in the OS on which tcpdump is running, if the OS reports that information to applications; if not, it will be reported as 0). On platforms that support the SIGINFO signal, such as most BSDs (including macOS) and Digital/Tru64 UNIX, it will report those counts when it receives a SIGINFO signal (generated, for example, by typing your ``status'' character, typically control-T, although on some platforms, such as macOS, the ``status'' character is not set by default, so you must set it with stty(1) in order to use it) and will continue capturing packets. On platforms that do not support the SIGINFO signal, the same can be achieved by using the SIGUSR1 signal. Using the SIGUSR2 signal along with the -w flag will forcibly flush the packet buffer into the output file. Reading packets from a network interface may require that you have special privileges; see the pcap(3PCAP) man page for details. Reading a saved packet file doesn't require special privileges. -A Print each packet (minus its link level header) in ASCII. Handy for capturing web pages. -b Print the AS number in BGP packets in ASDOT notation rather than ASPLAIN notation. -B buffer_size --buffer-size=buffer_size Set the operating system capture buffer size to buffer_size, in units of KiB (1024 bytes). -c count Exit after receiving count packets. --count Print only on stdout the packet count when reading capture file(s) instead of parsing/printing the packets. If a filter is specified on the command line, tcpdump counts only packets that were matched by the filter expression. -C file_size Before writing a raw packet to a savefile, check whether the file is currently larger than file_size and, if so, close the current savefile and open a new one. Savefiles after the first savefile will have the name specified with the -w flag, with a number after it, starting at 1 and continuing upward. The default unit of file_size is millions of bytes (1,000,000 bytes, not 1,048,576 bytes). By adding a suffix of k/K, m/M or g/G to the value, the unit can be changed to 1,024 (KiB), 1,048,576 (MiB), or 1,073,741,824 (GiB) respectively. -d Dump the compiled packet-matching code in a human readable form to standard output and stop. Please mind that although code compilation is always DLT- specific, typically it is impossible (and unnecessary) to specify which DLT to use for the dump because tcpdump uses either the DLT of the input pcap file specified with -r, or the default DLT of the network interface specified with -i, or the particular DLT of the network interface specified with -y and -i respectively. In these cases the dump shows the same exact code that would filter the input file or the network interface without -d. However, when neither -r nor -i is specified, specifying -d prevents tcpdump from guessing a suitable network interface (see -i). In this case the DLT defaults to EN10MB and can be set to another valid value manually with -y. -dd Dump packet-matching code as a C program fragment. -ddd Dump packet-matching code as decimal numbers (preceded with a count). -D --list-interfaces Print the list of the network interfaces available on the system and on which tcpdump can capture packets. For each network interface, a number and an interface name, possibly followed by a text description of the interface, are printed. The interface name or the number can be supplied to the -i flag to specify an interface on which to capture. This can be useful on systems that don't have a command to list them (e.g., Windows systems, or UNIX systems lacking ifconfig -a); the number can be useful on Windows 2000 and later systems, where the interface name is a somewhat complex string. The -D flag will not be supported if tcpdump was built with an older version of libpcap that lacks the pcap_findalldevs(3PCAP) function. -e Print the link-level header on each dump line. This can be used, for example, to print MAC layer addresses for protocols such as Ethernet and IEEE 802.11. -E Use spi@ipaddr algo:secret for decrypting IPsec ESP packets that are addressed to addr and contain Security Parameter Index value spi. This combination may be repeated with comma or newline separation. Note that setting the secret for IPv4 ESP packets is supported at this time. Algorithms may be des-cbc, 3des-cbc, blowfish-cbc, rc3-cbc, cast128-cbc, or none. The default is des-cbc. The ability to decrypt packets is only present if tcpdump was compiled with cryptography enabled. secret is the ASCII text for ESP secret key. If preceded by 0x, then a hex value will be read. The option assumes RFC 2406 ESP, not RFC 1827 ESP. The option is only for debugging purposes, and the use of this option with a true `secret' key is discouraged. By presenting IPsec secret key onto command line you make it visible to others, via ps(1) and other occasions. In addition to the above syntax, the syntax file name may be used to have tcpdump read the provided file in. The file is opened upon receiving the first ESP packet, so any special permissions that tcpdump may have been given should already have been given up. -f Print `foreign' IPv4 addresses numerically rather than symbolically (this option is intended to get around serious brain damage in Sun's NIS server \u2014 usually it hangs forever translating non-local internet numbers). The test for `foreign' IPv4 addresses is done using the IPv4 address and netmask of the interface on that capture is being done. If that address or netmask are not available, either because the interface on that capture is being done has no address or netmask or because it is the \"any\" pseudo-interface, which is available in Linux and in recent versions of macOS and Solaris, and which can capture on more than one interface, this option will not work correctly. -F file Use file as input for the filter expression. An additional expression given on the command line is ignored. -G rotate_seconds If specified, rotates the dump file specified with the -w option every rotate_seconds seconds. Savefiles will have the name specified by -w which should include a time format as defined by strftime(3). If no time format is specified, each new file will overwrite the previous. Whenever a generated filename is not unique, tcpdump will overwrite the pre-existing data; providing a time specification that is coarser than the capture period is therefore not advised. If used in conjunction with the -C option, filenames will take the form of `file<count>'. -h --help Print the tcpdump and libpcap version strings, print a usage message, and exit. --version Print the tcpdump and libpcap version strings and exit. -H Attempt to detect 802.11s draft mesh headers. -i interface --interface=interface Listen, report the list of link-layer types, report the list of time stamp types, or report the results of compiling a filter expression on interface. If unspecified and if the -d flag is not given, tcpdump searches the system interface list for the lowest numbered, configured up interface (excluding loopback), which may turn out to be, for example, ``eth0''. On Linux systems with 2.2 or later kernels and on recent versions of macOS and Solaris, an interface argument of ``any'' can be used to capture packets from all interfaces. Note that captures on the ``any'' pseudo- interface will not be done in promiscuous mode. If the -D flag is supported, an interface number as printed by that flag can be used as the interface argument, if no interface on the system has that number as a name. -I --monitor-mode Put the interface in \"monitor mode\"; this is supported only on IEEE 802.11 Wi-Fi interfaces, and supported only on some operating systems. Note that in monitor mode the adapter might disassociate from the network with which it's associated, so that you will not be able to use any wireless networks with that adapter. This could prevent accessing files on a network server, or resolving host names or network addresses, if you are capturing in monitor mode and are not connected to another network with another adapter. This flag will affect the output of the -L flag. If -I isn't specified, only those link-layer types available when not in monitor mode will be shown; if -I is specified, only those link-layer types available when in monitor mode will be shown. --immediate-mode Capture in \"immediate mode\". In this mode, packets are delivered to tcpdump as soon as they arrive, rather than being buffered for efficiency. This is the default when printing packets rather than saving packets to a ``savefile'' if the packets are being printed to a terminal rather than to a file or pipe. -j tstamp_type --time-stamp-type=tstamp_type Set the time stamp type for the capture to tstamp_type. The names to use for the time stamp types are given in pcap-tstamp(@MAN_MISC_INFO@); not all the types listed there will necessarily be valid for any given interface. -J --list-time-stamp-types List the supported time stamp types for the interface and exit. If the time stamp type cannot be set for the interface, no time stamp types are listed. --time-stamp-precision=tstamp_precision When capturing, set the time stamp precision for the capture to tstamp_precision. Note that availability of high precision time stamps (nanoseconds) and their actual accuracy is platform and hardware dependent. Also note that when writing captures made with nanosecond accuracy to a savefile, the time stamps are written with nanosecond resolution, and the file is written with a different magic number, to indicate that the time stamps are in seconds and nanoseconds; not all programs that read pcap savefiles will be able to read those captures. When reading a savefile, convert time stamps to the precision specified by timestamp_precision, and display them with that resolution. If the precision specified is less than the precision of time stamps in the file, the conversion will lose precision. The supported values for timestamp_precision are micro for microsecond resolution and nano for nanosecond resolution. The default is microsecond resolution. --micro --nano Shorthands for --time-stamp-precision=micro or --time-stamp-precision=nano, adjusting the time stamp precision accordingly. When reading packets from a savefile, using --micro truncates time stamps if the savefile was created with nanosecond precision. In contrast, a savefile created with microsecond precision will have trailing zeroes added to the time stamp when --nano is used. -K --dont-verify-checksums Don't attempt to verify IP, TCP, or UDP checksums. This is useful for interfaces that perform some or all of those checksum calculation in hardware; otherwise, all outgoing TCP checksums will be flagged as bad. -l Make stdout line buffered. Useful if you want to see the data while capturing it. E.g., tcpdump -l | tee dat or tcpdump -l > dat & tail -f dat Note that on Windows,``line buffered'' means ``unbuffered'', so that WinDump will write each character individually if -l is specified. -U is similar to -l in its behavior, but it will cause output to be ``packet-buffered'', so that the output is written to stdout at the end of each packet rather than at the end of each line; this is buffered on all platforms, including Windows. -L --list-data-link-types List the known data link types for the interface, in the specified mode, and exit. The list of known data link types may be dependent on the specified mode; for example, on some platforms, a Wi-Fi interface might support one set of data link types when not in monitor mode (for example, it might support only fake Ethernet headers, or might support 802.11 headers but not support 802.11 headers with radio information) and another set of data link types when in monitor mode (for example, it might support 802.11 headers, or 802.11 headers with radio information, only in monitor mode). -m module Load SMI MIB module definitions from file module. This option can be used several times to load several MIB modules into tcpdump. -M secret Use secret as a shared secret for validating the digests found in TCP segments with the TCP-MD5 option (RFC 2385), if present. -n Don't convert addresses (i.e., host addresses, port numbers, etc.) to names. -N Don't print domain name qualification of host names. E.g., if you give this flag then tcpdump will print ``nic'' instead of ``nic.ddn.mil''. -# --number Print an optional packet number at the beginning of the line. -O --no-optimize Do not run the packet-matching code optimizer. This is useful only if you suspect a bug in the optimizer. -p --no-promiscuous-mode Don't put the interface into promiscuous mode. Note that the interface might be in promiscuous mode for some other reason; hence, `-p' cannot be used as an abbreviation for `ether host {local-hw-addr} or ether broadcast'. --print Print parsed packet output, even if the raw packets are being saved to a file with the -w flag. --print-sampling=nth Print every nth packet. This option enables the --print flag. Unprinted packets are not parsed, which decreases processing time. Setting nth to 100 for example, will (counting from 1) parse and print the 100th packet, 200th packet, 300th packet, and so on. This option also enables the -S flag, as relative TCP sequence numbers are not tracked for unprinted packets. -Q direction --direction=direction Choose send/receive direction direction for which packets should be captured. Possible values are `in', `out' and `inout'. Not available on all platforms. -q Quick (quiet?) output. Print less protocol information so output lines are shorter. -r file Read packets from file (which was created with the -w option or by other tools that write pcap or pcapng files). Standard input is used if file is ``-''. -S --absolute-tcp-sequence-numbers Print absolute, rather than relative, TCP sequence numbers. -s snaplen --snapshot-length=snaplen Snarf snaplen bytes of data from each packet rather than the default of 262144 bytes. Packets truncated because of a limited snapshot are indicated in the output with ``[|proto]'', where proto is the name of the protocol level at which the truncation has occurred. Note that taking larger snapshots both increases the amount of time it takes to process packets and, effectively, decreases the amount of packet buffering. This may cause packets to be lost. Note also that taking smaller snapshots will discard data from protocols above the transport layer, which loses information that may be important. NFS and AFS requests and replies, for example, are very large, and much of the detail won't be available if a too-short snapshot length is selected. If you need to reduce the snapshot size below the default, you should limit snaplen to the smallest number that will capture the protocol information you're interested in. Setting snaplen to 0 sets it to the default of 262144, for backwards compatibility with recent older versions of tcpdump. -T type Force packets selected by \"expression\" to be interpreted the specified type. Currently known types are aodv (Ad- hoc On-demand Distance Vector protocol), carp (Common Address Redundancy Protocol), cnfp (Cisco NetFlow protocol), domain (Domain Name System), lmp (Link Management Protocol), pgm (Pragmatic General Multicast), pgm_zmtp1 (ZMTP/1.0 inside PGM/EPGM), ptp (Precision Time Protocol), quic (QUIC), radius (RADIUS), resp (REdis Serialization Protocol), rpc (Remote Procedure Call), rtcp (Real-Time Applications control protocol), rtp (Real-Time Applications protocol), snmp (Simple Network Management Protocol), someip (SOME/IP), tftp (Trivial File Transfer Protocol), vat (Visual Audio Tool), vxlan (Virtual eXtensible Local Area Network), wb (distributed White Board) and zmtp1 (ZeroMQ Message Transport Protocol 1.0). Note that the pgm type above affects UDP interpretation only, the native PGM is always recognised as IP protocol 113 regardless. UDP-encapsulated PGM is often called \"EPGM\" or \"PGM/UDP\". Note that the pgm_zmtp1 type above affects interpretation of both native PGM and UDP at once. During the native PGM decoding the application data of an ODATA/RDATA packet would be decoded as a ZeroMQ datagram with ZMTP/1.0 frames. During the UDP decoding in addition to that any UDP packet would be treated as an encapsulated PGM packet. -t Don't print a timestamp on each dump line. -tt Print the timestamp, as seconds since January 1, 1970, 00:00:00, UTC, and fractions of a second since that time, on each dump line. -ttt Print a delta (microsecond or nanosecond resolution depending on the --time-stamp-precision option) between current and previous line on each dump line. The default is microsecond resolution. -tttt Print a timestamp, as hours, minutes, seconds, and fractions of a second since midnight, preceded by the date, on each dump line. -ttttt Print a delta (microsecond or nanosecond resolution depending on the --time-stamp-precision option) between current and first line on each dump line. The default is microsecond resolution. -u Print undecoded NFS handles. -U --packet-buffered If the -w option is not specified, or if it is specified but the --print flag is also specified, make the printed packet output ``packet-buffered''; i.e., as the description of the contents of each packet is printed, it will be written to the standard output, rather than, when not writing to a terminal, being written only when the output buffer fills. If the -w option is specified, make the saved raw packet output ``packet-buffered''; i.e., as each packet is saved, it will be written to the output file, rather than being written only when the output buffer fills. The -U flag will not be supported if tcpdump was built with an older version of libpcap that lacks the pcap_dump_flush(3PCAP) function. -v When parsing and printing, produce (slightly more) verbose output. For example, the time to live, identification, total length and options in an IP packet are printed. Also enables additional packet integrity checks such as verifying the IP and ICMP header checksum. When writing to a file with the -w option and at the same time not reading from a file with the -r option, report to stderr, once per second, the number of packets captured. In Solaris, FreeBSD and possibly other operating systems this periodic update currently can cause loss of captured packets on their way from the kernel to tcpdump. -vv Even more verbose output. For example, additional fields are printed from NFS reply packets, and SMB packets are fully decoded. -vvv Even more verbose output. For example, telnet SB ... SE options are printed in full. With -X Telnet options are printed in hex as well. -V file Read a list of filenames from file. Standard input is used if file is ``-''. -w file Write the raw packets to file rather than parsing and printing them out. They can later be printed with the -r option. Standard output is used if file is ``-''. This output will be buffered if written to a file or pipe, so a program reading from the file or pipe may not see packets for an arbitrary amount of time after they are received. Use the -U flag to cause packets to be written as soon as they are received. The MIME type application/vnd.tcpdump.pcap has been registered with IANA for pcap files. The filename extension .pcap appears to be the most commonly used along with .cap and .dmp. Tcpdump itself doesn't check the extension when reading capture files and doesn't add an extension when writing them (it uses magic numbers in the file header instead). However, many operating systems and applications will use the extension if it is present and adding one (e.g. .pcap) is recommended. See pcap-savefile(@MAN_FILE_FORMATS@) for a description of the file format. -W filecount Used in conjunction with the -C option, this will limit the number of files created to the specified number, and begin overwriting files from the beginning, thus creating a 'rotating' buffer. In addition, it will name the files with enough leading 0s to support the maximum number of files, allowing them to sort correctly. Used in conjunction with the -G option, this will limit the number of rotated dump files that get created, exiting with status 0 when reaching the limit. If used in conjunction with both -C and -G, the -W option will currently be ignored, and will only affect the file name. -x When parsing and printing, in addition to printing the headers of each packet, print the data of each packet (minus its link level header) in hex. The smaller of the entire packet or snaplen bytes will be printed. Note that this is the entire link-layer packet, so for link layers that pad (e.g. Ethernet), the padding bytes will also be printed when the higher layer packet is shorter than the required padding. In the current implementation this flag may have the same effect as -xx if the packet is truncated. -xx When parsing and printing, in addition to printing the headers of each packet, print the data of each packet, including its link level header, in hex. -X When parsing and printing, in addition to printing the headers of each packet, print the data of each packet (minus its link level header) in hex and ASCII. This is very handy for analysing new protocols. In the current implementation this flag may have the same effect as -XX if the packet is truncated. -XX When parsing and printing, in addition to printing the headers of each packet, print the data of each packet, including its link level header, in hex and ASCII. -y datalinktype --linktype=datalinktype Set the data link type to use while capturing packets (see -L) or just compiling and dumping packet-matching code (see -d) to datalinktype. -z postrotate-command Used in conjunction with the -C or -G options, this will make tcpdump run \" postrotate-command file \" where file is the savefile being closed after each rotation. For example, specifying -z gzip or -z bzip2 will compress each savefile using gzip or bzip2. Note that tcpdump will run the command in parallel to the capture, using the lowest priority so that this doesn't disturb the capture process. And in case you would like to use a command that itself takes flags or different arguments, you can always write a shell script that will take the savefile name as the only argument, make the flags & arguments arrangements and execute the command that you want. -Z user --relinquish-privileges=user If tcpdump is running as root, after opening the capture device or input savefile, but before opening any savefiles for output, change the user ID to user and the group ID to the primary group of user. This behavior can also be enabled by default at compile time. expression selects which packets will be dumped. If no expression is given, all packets on the net will be dumped. Otherwise, only packets for which expression is `true' will be dumped. For the expression syntax, see pcap-filter(@MAN_MISC_INFO@). The expression argument can be passed to tcpdump as either a single Shell argument, or as multiple Shell arguments, whichever is more convenient. Generally, if the expression contains Shell metacharacters, such as backslashes used to escape protocol names, it is easier to pass it as a single, quoted argument rather than to escape the Shell metacharacters. Multiple arguments are concatenated with spaces before being parsed. "
  },
  {
    "command": "users",
    "description": " Output who is currently logged in according to FILE. If FILE is not specified, use /var/run/utmp. /var/log/wtmp as FILE is common. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "git-rev-list",
    "description": " List commits that are reachable by following the parent links from the given commit(s), but exclude commits that are reachable from the one(s) given with a ^ in front of them. The output is given in reverse chronological order by default. You can think of this as a set operation. Commits reachable from any of the commits given on the command line form a set, and then commits reachable from any of the ones given with ^ in front are subtracted from that set. The remaining commits are what comes out in the command\u2019s output. Various other options and paths parameters can be used to further limit the result. Thus, the following command: $ git rev-list foo bar ^baz means \"list all the commits which are reachable from foo or bar, but not from baz\". A special notation \"<commit1>..<commit2>\" can be used as a short-hand for \"^<commit1> <commit2>\". For example, either of the following may be used interchangeably: $ git rev-list origin..HEAD $ git rev-list HEAD ^origin Another special notation is \"<commit1>...<commit2>\" which is useful for merges. The resulting set of commits is the symmetric difference between the two operands. The following two commands are equivalent: $ git rev-list A B --not $(git merge-base --all A B) $ git rev-list A...B rev-list is a very essential Git command, since it provides the ability to build and traverse commit ancestry graphs. For this reason, it has a lot of different options that enables it to be used by commands as different as git bisect and git repack. Commit Limiting Besides specifying a range of commits that should be listed using the special notations explained in the description, additional commit limiting may be applied. Using more options generally further limits the output (e.g. --since=<date1> limits to commits newer than <date1>, and using it with --grep=<pattern> further limits to commits whose log message has a line that matches <pattern>), unless otherwise noted. Note that these are applied before commit ordering and formatting options, such as --reverse. -<number>, -n <number>, --max-count=<number> Limit the number of commits to output. --skip=<number> Skip number commits before starting to show the commit output. --since=<date>, --after=<date> Show commits more recent than a specific date. --since-as-filter=<date> Show all commits more recent than a specific date. This visits all commits in the range, rather than stopping at the first commit which is older than a specific date. --until=<date>, --before=<date> Show commits older than a specific date. --max-age=<timestamp>, --min-age=<timestamp> Limit the commits output to specified time range. --author=<pattern>, --committer=<pattern> Limit the commits output to ones with author/committer header lines that match the specified pattern (regular expression). With more than one --author=<pattern>, commits whose author matches any of the given patterns are chosen (similarly for multiple --committer=<pattern>). --grep-reflog=<pattern> Limit the commits output to ones with reflog entries that match the specified pattern (regular expression). With more than one --grep-reflog, commits whose reflog message matches any of the given patterns are chosen. It is an error to use this option unless --walk-reflogs is in use. --grep=<pattern> Limit the commits output to ones with log message that matches the specified pattern (regular expression). With more than one --grep=<pattern>, commits whose message matches any of the given patterns are chosen (but see --all-match). --all-match Limit the commits output to ones that match all given --grep, instead of ones that match at least one. --invert-grep Limit the commits output to ones with log message that do not match the pattern specified with --grep=<pattern>. -i, --regexp-ignore-case Match the regular expression limiting patterns without regard to letter case. --basic-regexp Consider the limiting patterns to be basic regular expressions; this is the default. -E, --extended-regexp Consider the limiting patterns to be extended regular expressions instead of the default basic regular expressions. -F, --fixed-strings Consider the limiting patterns to be fixed strings (don\u2019t interpret pattern as a regular expression). -P, --perl-regexp Consider the limiting patterns to be Perl-compatible regular expressions. Support for these types of regular expressions is an optional compile-time dependency. If Git wasn\u2019t compiled with support for them providing this option will cause it to die. --remove-empty Stop when a given path disappears from the tree. --merges Print only merge commits. This is exactly the same as --min-parents=2. --no-merges Do not print commits with more than one parent. This is exactly the same as --max-parents=1. --min-parents=<number>, --max-parents=<number>, --no-min-parents, --no-max-parents Show only commits which have at least (or at most) that many parent commits. In particular, --max-parents=1 is the same as --no-merges, --min-parents=2 is the same as --merges. --max-parents=0 gives all root commits and --min-parents=3 all octopus merges. --no-min-parents and --no-max-parents reset these limits (to no limit) again. Equivalent forms are --min-parents=0 (any commit has 0 or more parents) and --max-parents=-1 (negative numbers denote no upper limit). --first-parent When finding commits to include, follow only the first parent commit upon seeing a merge commit. This option can give a better overview when viewing the evolution of a particular topic branch, because merges into a topic branch tend to be only about adjusting to updated upstream from time to time, and this option allows you to ignore the individual commits brought in to your history by such a merge. --exclude-first-parent-only When finding commits to exclude (with a ^), follow only the first parent commit upon seeing a merge commit. This can be used to find the set of changes in a topic branch from the point where it diverged from the remote branch, given that arbitrary merges can be valid topic branch changes. --not Reverses the meaning of the ^ prefix (or lack thereof) for all following revision specifiers, up to the next --not. --all Pretend as if all the refs in refs/, along with HEAD, are listed on the command line as <commit>. --branches[=<pattern>] Pretend as if all the refs in refs/heads are listed on the command line as <commit>. If <pattern> is given, limit branches to ones matching given shell glob. If pattern lacks ?, *, or [, /* at the end is implied. --tags[=<pattern>] Pretend as if all the refs in refs/tags are listed on the command line as <commit>. If <pattern> is given, limit tags to ones matching given shell glob. If pattern lacks ?, *, or [, /* at the end is implied. --remotes[=<pattern>] Pretend as if all the refs in refs/remotes are listed on the command line as <commit>. If <pattern> is given, limit remote-tracking branches to ones matching given shell glob. If pattern lacks ?, *, or [, /* at the end is implied. --glob=<glob-pattern> Pretend as if all the refs matching shell glob <glob-pattern> are listed on the command line as <commit>. Leading refs/, is automatically prepended if missing. If pattern lacks ?, *, or [, /* at the end is implied. --exclude=<glob-pattern> Do not include refs matching <glob-pattern> that the next --all, --branches, --tags, --remotes, or --glob would otherwise consider. Repetitions of this option accumulate exclusion patterns up to the next --all, --branches, --tags, --remotes, or --glob option (other options or arguments do not clear accumulated patterns). The patterns given should not begin with refs/heads, refs/tags, or refs/remotes when applied to --branches, --tags, or --remotes, respectively, and they must begin with refs/ when applied to --glob or --all. If a trailing /* is intended, it must be given explicitly. --exclude-hidden=[fetch|receive|uploadpack] Do not include refs that would be hidden by git-fetch, git-receive-pack or git-upload-pack by consulting the appropriate fetch.hideRefs, receive.hideRefs or uploadpack.hideRefs configuration along with transfer.hideRefs (see git-config(1)). This option affects the next pseudo-ref option --all or --glob and is cleared after processing them. --reflog Pretend as if all objects mentioned by reflogs are listed on the command line as <commit>. --alternate-refs Pretend as if all objects mentioned as ref tips of alternate repositories were listed on the command line. An alternate repository is any repository whose object directory is specified in objects/info/alternates. The set of included objects may be modified by core.alternateRefsCommand, etc. See git-config(1). --single-worktree By default, all working trees will be examined by the following options when there are more than one (see git-worktree(1)): --all, --reflog and --indexed-objects. This option forces them to examine the current working tree only. --ignore-missing Upon seeing an invalid object name in the input, pretend as if the bad input was not given. --stdin In addition to the <commit> listed on the command line, read them from the standard input. If a -- separator is seen, stop reading commits and start reading paths to limit the result. --quiet Don\u2019t print anything to standard output. This form is primarily meant to allow the caller to test the exit status to see if a range of objects is fully connected (or not). It is faster than redirecting stdout to /dev/null as the output does not have to be formatted. --disk-usage, --disk-usage=human Suppress normal output; instead, print the sum of the bytes used for on-disk storage by the selected commits or objects. This is equivalent to piping the output into git cat-file --batch-check='%(objectsize:disk)', except that it runs much faster (especially with --use-bitmap-index). See the CAVEATS section in git-cat-file(1) for the limitations of what \"on-disk storage\" means. With the optional value human, on-disk storage size is shown in human-readable string(e.g. 12.24 Kib, 3.50 Mib). --cherry-mark Like --cherry-pick (see below) but mark equivalent commits with = rather than omitting them, and inequivalent ones with +. --cherry-pick Omit any commit that introduces the same change as another commit on the \u201cother side\u201d when the set of commits are limited with symmetric difference. For example, if you have two branches, A and B, a usual way to list all commits on only one side of them is with --left-right (see the example below in the description of the --left-right option). However, it shows the commits that were cherry-picked from the other branch (for example, \u201c3rd on b\u201d may be cherry-picked from branch A). With this option, such pairs of commits are excluded from the output. --left-only, --right-only List only commits on the respective side of a symmetric difference, i.e. only those which would be marked < resp. > by --left-right. For example, --cherry-pick --right-only A...B omits those commits from B which are in A or are patch-equivalent to a commit in A. In other words, this lists the + commits from git cherry A B. More precisely, --cherry-pick --right-only --no-merges gives the exact list. --cherry A synonym for --right-only --cherry-mark --no-merges; useful to limit the output to the commits on our side and mark those that have been applied to the other side of a forked history with git log --cherry upstream...mybranch, similar to git cherry upstream mybranch. -g, --walk-reflogs Instead of walking the commit ancestry chain, walk reflog entries from the most recent one to older ones. When this option is used you cannot specify commits to exclude (that is, ^commit, commit1..commit2, and commit1...commit2 notations cannot be used). With --pretty format other than oneline and reference (for obvious reasons), this causes the output to have two extra lines of information taken from the reflog. The reflog designator in the output may be shown as ref@{Nth} (where Nth is the reverse-chronological index in the reflog) or as ref@{timestamp} (with the timestamp for that entry), depending on a few rules: 1. If the starting point is specified as ref@{Nth}, show the index format. 2. If the starting point was specified as ref@{now}, show the timestamp format. 3. If neither was used, but --date was given on the command line, show the timestamp in the format requested by --date. 4. Otherwise, show the index format. Under --pretty=oneline, the commit message is prefixed with this information on the same line. This option cannot be combined with --reverse. See also git-reflog(1). Under --pretty=reference, this information will not be shown at all. --merge After a failed merge, show refs that touch files having a conflict and don\u2019t exist on all heads to merge. --boundary Output excluded boundary commits. Boundary commits are prefixed with -. --use-bitmap-index Try to speed up the traversal using the pack bitmap index (if one is available). Note that when traversing with --objects, trees and blobs will not have their associated path printed. --progress=<header> Show progress reports on stderr as objects are considered. The <header> text will be printed with each progress update. History Simplification Sometimes you are only interested in parts of the history, for example the commits modifying a particular <path>. But there are two parts of History Simplification, one part is selecting the commits and the other is how to do it, as there are various strategies to simplify the history. The following options select the commits to be shown: <paths> Commits modifying the given <paths> are selected. --simplify-by-decoration Commits that are referred by some branch or tag are selected. Note that extra commits can be shown to give a meaningful history. The following options affect the way the simplification is performed: Default mode Simplifies the history to the simplest history explaining the final state of the tree. Simplest because it prunes some side branches if the end result is the same (i.e. merging branches with the same content) --show-pulls Include all commits from the default mode, but also any merge commits that are not TREESAME to the first parent but are TREESAME to a later parent. This mode is helpful for showing the merge commits that \"first introduced\" a change to a branch. --full-history Same as the default mode, but does not prune some history. --dense Only the selected commits are shown, plus some to have a meaningful history. --sparse All commits in the simplified history are shown. --simplify-merges Additional option to --full-history to remove some needless merges from the resulting history, as there are no selected commits contributing to this merge. --ancestry-path[=<commit>] When given a range of commits to display (e.g. commit1..commit2 or commit2 ^commit1), only display commits in that range that are ancestors of <commit>, descendants of <commit>, or <commit> itself. If no commit is specified, use commit1 (the excluded part of the range) as <commit>. Can be passed multiple times; if so, a commit is included if it is any of the commits given or if it is an ancestor or descendant of one of them. A more detailed explanation follows. Suppose you specified foo as the <paths>. We shall call commits that modify foo !TREESAME, and the rest TREESAME. (In a diff filtered for foo, they look different and equal, respectively.) In the following, we will always refer to the same example history to illustrate the differences between simplification settings. We assume that you are filtering for a file foo in this commit graph: .-A---M---N---O---P---Q / / / / / / I B C D E Y \\ / / / / / `-------------' X The horizontal line of history A---Q is taken to be the first parent of each merge. The commits are: \u2022 I is the initial commit, in which foo exists with contents \u201casdf\u201d, and a file quux exists with contents \u201cquux\u201d. Initial commits are compared to an empty tree, so I is !TREESAME. \u2022 In A, foo contains just \u201cfoo\u201d. \u2022 B contains the same change as A. Its merge M is trivial and hence TREESAME to all parents. \u2022 C does not change foo, but its merge N changes it to \u201cfoobar\u201d, so it is not TREESAME to any parent. \u2022 D sets foo to \u201cbaz\u201d. Its merge O combines the strings from N and D to \u201cfoobarbaz\u201d; i.e., it is not TREESAME to any parent. \u2022 E changes quux to \u201cxyzzy\u201d, and its merge P combines the strings to \u201cquux xyzzy\u201d. P is TREESAME to O, but not to E. \u2022 X is an independent root commit that added a new file side, and Y modified it. Y is TREESAME to X. Its merge Q added side to P, and Q is TREESAME to P, but not to Y. rev-list walks backwards through history, including or excluding commits based on whether --full-history and/or parent rewriting (via --parents or --children) are used. The following settings are available. Default mode Commits are included if they are not TREESAME to any parent (though this can be changed, see --sparse below). If the commit was a merge, and it was TREESAME to one parent, follow only that parent. (Even if there are several TREESAME parents, follow only one of them.) Otherwise, follow all parents. This results in: .-A---N---O / / / I---------D Note how the rule to only follow the TREESAME parent, if one is available, removed B from consideration entirely. C was considered via N, but is TREESAME. Root commits are compared to an empty tree, so I is !TREESAME. Parent/child relations are only visible with --parents, but that does not affect the commits selected in default mode, so we have shown the parent lines. --full-history without parent rewriting This mode differs from the default in one point: always follow all parents of a merge, even if it is TREESAME to one of them. Even if more than one side of the merge has commits that are included, this does not imply that the merge itself is! In the example, we get I A B N D O P Q M was excluded because it is TREESAME to both parents. E, C and B were all walked, but only B was !TREESAME, so the others do not appear. Note that without parent rewriting, it is not really possible to talk about the parent/child relationships between the commits, so we show them disconnected. --full-history with parent rewriting Ordinary commits are only included if they are !TREESAME (though this can be changed, see --sparse below). Merges are always included. However, their parent list is rewritten: Along each parent, prune away commits that are not included themselves. This results in .-A---M---N---O---P---Q / / / / / I B / D / \\ / / / / `-------------' Compare to --full-history without rewriting above. Note that E was pruned away because it is TREESAME, but the parent list of P was rewritten to contain E's parent I. The same happened for C and N, and X, Y and Q. In addition to the above settings, you can change whether TREESAME affects inclusion: --dense Commits that are walked are included if they are not TREESAME to any parent. --sparse All commits that are walked are included. Note that without --full-history, this still simplifies merges: if one of the parents is TREESAME, we follow only that one, so the other sides of the merge are never walked. --simplify-merges First, build a history graph in the same way that --full-history with parent rewriting does (see above). Then simplify each commit C to its replacement C' in the final history according to the following rules: \u2022 Set C' to C. \u2022 Replace each parent P of C' with its simplification P'. In the process, drop parents that are ancestors of other parents or that are root commits TREESAME to an empty tree, and remove duplicates, but take care to never drop all parents that we are TREESAME to. \u2022 If after this parent rewriting, C' is a root or merge commit (has zero or >1 parents), a boundary commit, or !TREESAME, it remains. Otherwise, it is replaced with its only parent. The effect of this is best shown by way of comparing to --full-history with parent rewriting. The example turns into: .-A---M---N---O / / / I B D \\ / / `---------' Note the major differences in N, P, and Q over --full-history: \u2022 N's parent list had I removed, because it is an ancestor of the other parent M. Still, N remained because it is !TREESAME. \u2022 P's parent list similarly had I removed. P was then removed completely, because it had one parent and is TREESAME. \u2022 Q's parent list had Y simplified to X. X was then removed, because it was a TREESAME root. Q was then removed completely, because it had one parent and is TREESAME. There is another simplification mode available: --ancestry-path[=<commit>] Limit the displayed commits to those which are an ancestor of <commit>, or which are a descendant of <commit>, or are <commit> itself. As an example use case, consider the following commit history: D---E-------F / \\ \\ B---C---G---H---I---J / \\ A-------K---------------L--M A regular D..M computes the set of commits that are ancestors of M, but excludes the ones that are ancestors of D. This is useful to see what happened to the history leading to M since D, in the sense that \u201cwhat does M have that did not exist in D\u201d. The result in this example would be all the commits, except A and B (and D itself, of course). When we want to find out what commits in M are contaminated with the bug introduced by D and need fixing, however, we might want to view only the subset of D..M that are actually descendants of D, i.e. excluding C and K. This is exactly what the --ancestry-path option does. Applied to the D..M range, it results in: E-------F \\ \\ G---H---I---J \\ L--M We can also use --ancestry-path=D instead of --ancestry-path which means the same thing when applied to the D..M range but is just more explicit. If we instead are interested in a given topic within this range, and all commits affected by that topic, we may only want to view the subset of D..M which contain that topic in their ancestry path. So, using --ancestry-path=H D..M for example would result in: E \\ G---H---I---J \\ L--M Whereas --ancestry-path=K D..M would result in K---------------L--M Before discussing another option, --show-pulls, we need to create a new example history. A common problem users face when looking at simplified history is that a commit they know changed a file somehow does not appear in the file\u2019s simplified history. Let\u2019s demonstrate a new example and show how options such as --full-history and --simplify-merges works in that case: .-A---M-----C--N---O---P / / \\ \\ \\/ / / I B \\ R-'`-Z' / \\ / \\/ / \\ / /\\ / `---X--' `---Y--' For this example, suppose I created file.txt which was modified by A, B, and X in different ways. The single-parent commits C, Z, and Y do not change file.txt. The merge commit M was created by resolving the merge conflict to include both changes from A and B and hence is not TREESAME to either. The merge commit R, however, was created by ignoring the contents of file.txt at M and taking only the contents of file.txt at X. Hence, R is TREESAME to X but not M. Finally, the natural merge resolution to create N is to take the contents of file.txt at R, so N is TREESAME to R but not C. The merge commits O and P are TREESAME to their first parents, but not to their second parents, Z and Y respectively. When using the default mode, N and R both have a TREESAME parent, so those edges are walked and the others are ignored. The resulting history graph is: I---X When using --full-history, Git walks every edge. This will discover the commits A and B and the merge M, but also will reveal the merge commits O and P. With parent rewriting, the resulting graph is: .-A---M--------N---O---P / / \\ \\ \\/ / / I B \\ R-'`--' / \\ / \\/ / \\ / /\\ / `---X--' `------' Here, the merge commits O and P contribute extra noise, as they did not actually contribute a change to file.txt. They only merged a topic that was based on an older version of file.txt. This is a common issue in repositories using a workflow where many contributors work in parallel and merge their topic branches along a single trunk: many unrelated merges appear in the --full-history results. When using the --simplify-merges option, the commits O and P disappear from the results. This is because the rewritten second parents of O and P are reachable from their first parents. Those edges are removed and then the commits look like single-parent commits that are TREESAME to their parent. This also happens to the commit N, resulting in a history view as follows: .-A---M--. / / \\ I B R \\ / / \\ / / `---X--' In this view, we see all of the important single-parent changes from A, B, and X. We also see the carefully-resolved merge M and the not-so-carefully-resolved merge R. This is usually enough information to determine why the commits A and B \"disappeared\" from history in the default view. However, there are a few issues with this approach. The first issue is performance. Unlike any previous option, the --simplify-merges option requires walking the entire commit history before returning a single result. This can make the option difficult to use for very large repositories. The second issue is one of auditing. When many contributors are working on the same repository, it is important which merge commits introduced a change into an important branch. The problematic merge R above is not likely to be the merge commit that was used to merge into an important branch. Instead, the merge N was used to merge R and X into the important branch. This commit may have information about why the change X came to override the changes from A and B in its commit message. --show-pulls In addition to the commits shown in the default history, show each merge commit that is not TREESAME to its first parent but is TREESAME to a later parent. When a merge commit is included by --show-pulls, the merge is treated as if it \"pulled\" the change from another branch. When using --show-pulls on this example (and no other options) the resulting graph is: I---X---R---N Here, the merge commits R and N are included because they pulled the commits X and R into the base branch, respectively. These merges are the reason the commits A and B do not appear in the default history. When --show-pulls is paired with --simplify-merges, the graph includes all of the necessary information: .-A---M--. N / / \\ / I B R \\ / / \\ / / `---X--' Notice that since M is reachable from R, the edge from N to M was simplified away. However, N still appears in the history as an important commit because it \"pulled\" the change R into the main branch. The --simplify-by-decoration option allows you to view only the big picture of the topology of the history, by omitting commits that are not referenced by tags. Commits are marked as !TREESAME (in other words, kept after history simplification rules described above) if (1) they are referenced by tags, or (2) they change the contents of the paths given on the command line. All other commits are marked as TREESAME (subject to be simplified away). Bisection Helpers --bisect Limit output to the one commit object which is roughly halfway between included and excluded commits. Note that the bad bisection ref refs/bisect/bad is added to the included commits (if it exists) and the good bisection refs refs/bisect/good-* are added to the excluded commits (if they exist). Thus, supposing there are no refs in refs/bisect/, if $ git rev-list --bisect foo ^bar ^baz outputs midpoint, the output of the two commands $ git rev-list foo ^midpoint $ git rev-list midpoint ^bar ^baz would be of roughly the same length. Finding the change which introduces a regression is thus reduced to a binary search: repeatedly generate and test new 'midpoint\u2019s until the commit chain is of length one. --bisect-vars This calculates the same as --bisect, except that refs in refs/bisect/ are not used, and except that this outputs text ready to be eval\u2019ed by the shell. These lines will assign the name of the midpoint revision to the variable bisect_rev, and the expected number of commits to be tested after bisect_rev is tested to bisect_nr, the expected number of commits to be tested if bisect_rev turns out to be good to bisect_good, the expected number of commits to be tested if bisect_rev turns out to be bad to bisect_bad, and the number of commits we are bisecting right now to bisect_all. --bisect-all This outputs all the commit objects between the included and excluded commits, ordered by their distance to the included and excluded commits. Refs in refs/bisect/ are not used. The farthest from them is displayed first. (This is the only one displayed by --bisect.) This is useful because it makes it easy to choose a good commit to test when you want to avoid to test some of them for some reason (they may not compile for example). This option can be used along with --bisect-vars, in this case, after all the sorted commit objects, there will be the same text as if --bisect-vars had been used alone. Commit Ordering By default, the commits are shown in reverse chronological order. --date-order Show no parents before all of its children are shown, but otherwise show commits in the commit timestamp order. --author-date-order Show no parents before all of its children are shown, but otherwise show commits in the author timestamp order. --topo-order Show no parents before all of its children are shown, and avoid showing commits on multiple lines of history intermixed. For example, in a commit history like this: ---1----2----4----7 \\ \\ 3----5----6----8--- where the numbers denote the order of commit timestamps, git rev-list and friends with --date-order show the commits in the timestamp order: 8 7 6 5 4 3 2 1. With --topo-order, they would show 8 6 5 3 7 4 2 1 (or 8 7 4 2 6 5 3 1); some older commits are shown before newer ones in order to avoid showing the commits from two parallel development track mixed together. --reverse Output the commits chosen to be shown (see Commit Limiting section above) in reverse order. Cannot be combined with --walk-reflogs. Object Traversal These options are mostly targeted for packing of Git repositories. --objects Print the object IDs of any object referenced by the listed commits. --objects foo ^bar thus means \u201csend me all object IDs which I need to download if I have the commit object bar but not foo\u201d. See also --object-names below. --in-commit-order Print tree and blob ids in order of the commits. The tree and blob ids are printed after they are first referenced by a commit. --objects-edge Similar to --objects, but also print the IDs of excluded commits prefixed with a \u201c-\u201d character. This is used by git-pack-objects(1) to build a \u201cthin\u201d pack, which records objects in deltified form based on objects contained in these excluded commits to reduce network traffic. --objects-edge-aggressive Similar to --objects-edge, but it tries harder to find excluded commits at the cost of increased time. This is used instead of --objects-edge to build \u201cthin\u201d packs for shallow repositories. --indexed-objects Pretend as if all trees and blobs used by the index are listed on the command line. Note that you probably want to use --objects, too. --unpacked Only useful with --objects; print the object IDs that are not in packs. --object-names Only useful with --objects; print the names of the object IDs that are found. This is the default behavior. Note that the \"name\" of each object is ambiguous, and mostly intended as a hint for packing objects. In particular: no distinction is made between the names of tags, trees, and blobs; path names may be modified to remove newlines; and if an object would appear multiple times with different names, only one name is shown. --no-object-names Only useful with --objects; does not print the names of the object IDs that are found. This inverts --object-names. This flag allows the output to be more easily parsed by commands such as git-cat-file(1). --filter=<filter-spec> Only useful with one of the --objects*; omits objects (usually blobs) from the list of printed objects. The <filter-spec> may be one of the following: The form --filter=blob:none omits all blobs. The form --filter=blob:limit=<n>[kmg] omits blobs larger than n bytes or units. n may be zero. The suffixes k, m, and g can be used to name units in KiB, MiB, or GiB. For example, blob:limit=1k is the same as blob:limit=1024. The form --filter=object:type=(tag|commit|tree|blob) omits all objects which are not of the requested type. The form --filter=sparse:oid=<blob-ish> uses a sparse-checkout specification contained in the blob (or blob-expression) <blob-ish> to omit blobs that would not be required for a sparse checkout on the requested refs. The form --filter=tree:<depth> omits all blobs and trees whose depth from the root tree is >= <depth> (minimum depth if an object is located at multiple depths in the commits traversed). <depth>=0 will not include any trees or blobs unless included explicitly in the command-line (or standard input when --stdin is used). <depth>=1 will include only the tree and blobs which are referenced directly by a commit reachable from <commit> or an explicitly-given object. <depth>=2 is like <depth>=1 while also including trees and blobs one more level removed from an explicitly-given commit or tree. Note that the form --filter=sparse:path=<path> that wants to read from an arbitrary path on the filesystem has been dropped for security reasons. Multiple --filter= flags can be specified to combine filters. Only objects which are accepted by every filter are included. The form --filter=combine:<filter1>+<filter2>+...<filterN> can also be used to combined several filters, but this is harder than just repeating the --filter flag and is usually not necessary. Filters are joined by + and individual filters are %-encoded (i.e. URL-encoded). Besides the + and % characters, the following characters are reserved and also must be encoded: ~!@#$^&*()[]{}\\;\",<>?'` as well as all characters with ASCII code <= 0x20, which includes space and newline. Other arbitrary characters can also be encoded. For instance, combine:tree:3+blob:none and combine:tree%3A3+blob%3Anone are equivalent. --no-filter Turn off any previous --filter= argument. --filter-provided-objects Filter the list of explicitly provided objects, which would otherwise always be printed even if they did not match any of the filters. Only useful with --filter=. --filter-print-omitted Only useful with --filter=; prints a list of the objects omitted by the filter. Object IDs are prefixed with a \u201c~\u201d character. --missing=<missing-action> A debug option to help with future \"partial clone\" development. This option specifies how missing objects are handled. The form --missing=error requests that rev-list stop with an error if a missing object is encountered. This is the default action. The form --missing=allow-any will allow object traversal to continue if a missing object is encountered. Missing objects will silently be omitted from the results. The form --missing=allow-promisor is like allow-any, but will only allow object traversal to continue for EXPECTED promisor missing objects. Unexpected missing objects will raise an error. The form --missing=print is like allow-any, but will also print a list of the missing objects. Object IDs are prefixed with a \u201c?\u201d character. --exclude-promisor-objects (For internal use only.) Prefilter object traversal at promisor boundary. This is used with partial clone. This is stronger than --missing=allow-promisor because it limits the traversal, rather than just silencing errors about missing objects. --no-walk[=(sorted|unsorted)] Only show the given commits, but do not traverse their ancestors. This has no effect if a range is specified. If the argument unsorted is given, the commits are shown in the order they were given on the command line. Otherwise (if sorted or no argument was given), the commits are shown in reverse chronological order by commit time. Cannot be combined with --graph. --do-walk Overrides a previous --no-walk. Commit Formatting Using these options, git-rev-list(1) will act similar to the more specialized family of commit log tools: git-log(1), git-show(1), and git-whatchanged(1) --pretty[=<format>], --format=<format> Pretty-print the contents of the commit logs in a given format, where <format> can be one of oneline, short, medium, full, fuller, reference, email, raw, format:<string> and tformat:<string>. When <format> is none of the above, and has %placeholder in it, it acts as if --pretty=tformat:<format> were given. See the \"PRETTY FORMATS\" section for some additional details for each format. When =<format> part is omitted, it defaults to medium. Note: you can specify the default pretty format in the repository configuration (see git-config(1)). --abbrev-commit Instead of showing the full 40-byte hexadecimal commit object name, show a prefix that names the object uniquely. \"--abbrev=<n>\" (which also modifies diff output, if it is displayed) option can be used to specify the minimum length of the prefix. This should make \"--pretty=oneline\" a whole lot more readable for people using 80-column terminals. --no-abbrev-commit Show the full 40-byte hexadecimal commit object name. This negates --abbrev-commit, either explicit or implied by other options such as \"--oneline\". It also overrides the log.abbrevCommit variable. --oneline This is a shorthand for \"--pretty=oneline --abbrev-commit\" used together. --encoding=<encoding> Commit objects record the character encoding used for the log message in their encoding header; this option can be used to tell the command to re-code the commit log message in the encoding preferred by the user. For non plumbing commands this defaults to UTF-8. Note that if an object claims to be encoded in X and we are outputting in X, we will output the object verbatim; this means that invalid sequences in the original commit may be copied to the output. Likewise, if iconv(3) fails to convert the commit, we will quietly output the original object verbatim. --expand-tabs=<n>, --expand-tabs, --no-expand-tabs Perform a tab expansion (replace each tab with enough spaces to fill to the next display column that is multiple of <n>) in the log message before showing it in the output. --expand-tabs is a short-hand for --expand-tabs=8, and --no-expand-tabs is a short-hand for --expand-tabs=0, which disables tab expansion. By default, tabs are expanded in pretty formats that indent the log message by 4 spaces (i.e. medium, which is the default, full, and fuller). --show-signature Check the validity of a signed commit object by passing the signature to gpg --verify and show the output. --relative-date Synonym for --date=relative. --date=<format> Only takes effect for dates shown in human-readable format, such as when using --pretty. log.date config variable sets a default value for the log command\u2019s --date option. By default, dates are shown in the original time zone (either committer\u2019s or author\u2019s). If -local is appended to the format (e.g., iso-local), the user\u2019s local time zone is used instead. --date=relative shows dates relative to the current time, e.g. \u201c2 hours ago\u201d. The -local option has no effect for --date=relative. --date=local is an alias for --date=default-local. --date=iso (or --date=iso8601) shows timestamps in a ISO 8601-like format. The differences to the strict ISO 8601 format are: \u2022 a space instead of the T date/time delimiter \u2022 a space between time and time zone \u2022 no colon between hours and minutes of the time zone --date=iso-strict (or --date=iso8601-strict) shows timestamps in strict ISO 8601 format. --date=rfc (or --date=rfc2822) shows timestamps in RFC 2822 format, often found in email messages. --date=short shows only the date, but not the time, in YYYY-MM-DD format. --date=raw shows the date as seconds since the epoch (1970-01-01 00:00:00 UTC), followed by a space, and then the timezone as an offset from UTC (a + or - with four digits; the first two are hours, and the second two are minutes). I.e., as if the timestamp were formatted with strftime(\"%s %z\")). Note that the -local option does not affect the seconds-since-epoch value (which is always measured in UTC), but does switch the accompanying timezone value. --date=human shows the timezone if the timezone does not match the current time-zone, and doesn\u2019t print the whole date if that matches (ie skip printing year for dates that are \"this year\", but also skip the whole date itself if it\u2019s in the last few days and we can just say what weekday it was). For older dates the hour and minute is also omitted. --date=unix shows the date as a Unix epoch timestamp (seconds since 1970). As with --raw, this is always in UTC and therefore -local has no effect. --date=format:... feeds the format ... to your system strftime, except for %s, %z, and %Z, which are handled internally. Use --date=format:%c to show the date in your system locale\u2019s preferred format. See the strftime manual for a complete list of format placeholders. When using -local, the correct syntax is --date=format-local:.... --date=default is the default format, and is based on ctime(3) output. It shows a single line with three-letter day of the week, three-letter month, day-of-month, hour-minute-seconds in \"HH:MM:SS\" format, followed by 4-digit year, plus timezone information, unless the local time zone is used, e.g. Thu Jan 1 00:00:00 1970 +0000. --header Print the contents of the commit in raw-format; each record is separated with a NUL character. --no-commit-header Suppress the header line containing \"commit\" and the object ID printed before the specified format. This has no effect on the built-in formats; only custom formats are affected. --commit-header Overrides a previous --no-commit-header. --parents Print also the parents of the commit (in the form \"commit parent...\"). Also enables parent rewriting, see History Simplification above. --children Print also the children of the commit (in the form \"commit child...\"). Also enables parent rewriting, see History Simplification above. --timestamp Print the raw commit timestamp. --left-right Mark which side of a symmetric difference a commit is reachable from. Commits from the left side are prefixed with < and those from the right with >. If combined with --boundary, those commits are prefixed with -. For example, if you have this topology: y---b---b branch B / \\ / / . / / \\ o---x---a---a branch A you would get an output like this: $ git rev-list --left-right --boundary --pretty=oneline A...B >bbbbbbb... 3rd on b >bbbbbbb... 2nd on b <aaaaaaa... 3rd on a <aaaaaaa... 2nd on a -yyyyyyy... 1st on b -xxxxxxx... 1st on a --graph Draw a text-based graphical representation of the commit history on the left hand side of the output. This may cause extra lines to be printed in between commits, in order for the graph history to be drawn properly. Cannot be combined with --no-walk. This enables parent rewriting, see History Simplification above. This implies the --topo-order option by default, but the --date-order option may also be specified. --show-linear-break[=<barrier>] When --graph is not used, all history branches are flattened which can make it hard to see that the two consecutive commits do not belong to a linear branch. This option puts a barrier in between them in that case. If <barrier> is specified, it is the string that will be shown instead of the default one. --count Print a number stating how many commits would have been listed, and suppress all other output. When used together with --left-right, instead print the counts for left and right commits, separated by a tab. When used together with --cherry-mark, omit patch equivalent commits from these counts and print the count for equivalent commits separated by a tab. "
  },
  {
    "command": "lpr",
    "description": " lpr submits files for printing. Files named on the command line are sent to the named printer or the default destination if no destination is specified. If no files are listed on the command- line, lpr reads the print file from the standard input. THE DEFAULT DESTINATION CUPS provides many ways to set the default destination. The LPDEST and PRINTER environment variables are consulted first. If neither are set, the current default set using the lpoptions(1) command is used, followed by the default set using the lpadmin(8) command. The following options are recognized by lpr: -E Forces encryption when connecting to the server. -H server[:port] Specifies an alternate server. -C \"name\" -J \"name\" -T \"name\" Sets the job name/title. -P destination[/instance] Prints files to the named printer. -U username Specifies an alternate username. -# copies Sets the number of copies to print. -h Disables banner printing. This option is equivalent to -o job-sheets=none. -l Specifies that the print file is already formatted for the destination and should be sent without filtering. This option is equivalent to -o raw. -m Send an email on job completion. -o option[=value] Sets a job option. See \"COMMON JOB OPTIONS\" below. -p Specifies that the print file should be formatted with a shaded header with the date, time, job name, and page number. This option is equivalent to -o prettyprint and is only useful when printing text files. -q Hold job for printing. -r Specifies that the named print files should be deleted after submitting them. COMMON JOB OPTIONS Aside from the printer-specific options reported by the lpoptions(1) command, the following generic options are available: -o job-sheets=name Prints a cover page (banner) with the document. The \"name\" can be \"classified\", \"confidential\", \"secret\", \"standard\", \"topsecret\", or \"unclassified\". -o media=size Sets the page size to size. Most printers support at least the size names \"a4\", \"letter\", and \"legal\". -o number-up={2|4|6|9|16} Prints 2, 4, 6, 9, or 16 document (input) pages on each output page. -o orientation-requested=4 Prints the job in landscape (rotated 90 degrees counter- clockwise). -o orientation-requested=5 Prints the job in landscape (rotated 90 degrees clockwise). -o orientation-requested=6 Prints the job in reverse portrait (rotated 180 degrees). -o print-quality=3 -o print-quality=4 -o print-quality=5 Specifies the output quality - draft (3), normal (4), or best (5). -o sides=one-sided Prints on one side of the paper. -o sides=two-sided-long-edge Prints on both sides of the paper for portrait output. -o sides=two-sided-short-edge Prints on both sides of the paper for landscape output. "
  },
  {
    "command": "lp",
    "description": " lp submits files for printing or alters a pending job. Use a filename of \"-\" to force printing from the standard input. THE DEFAULT DESTINATION CUPS provides many ways to set the default destination. The LPDEST and PRINTER environment variables are consulted first. If neither are set, the current default set using the lpoptions(1) command is used, followed by the default set using the lpadmin(8) command. The following options are recognized by lp: -- Marks the end of options; use this to print a file whose name begins with a dash (-). -E Forces encryption when connecting to the server. -U username Specifies the username to use when connecting to the server. -c This option is provided for backwards-compatibility only. On systems that support it, this option forces the print file to be copied to the spool directory before printing. In CUPS, print files are always sent to the scheduler via IPP which has the same effect. -d destination Prints files to the named printer. -h hostname[:port] Chooses an alternate server. -i job-id Specifies an existing job to modify. -m Sends an email when the job is completed. -n copies Sets the number of copies to print. -o \"name=value [ ... name=value ]\" Sets one or more job options. See \"COMMON JOB OPTIONS\" below. -q priority Sets the job priority from 1 (lowest) to 100 (highest). The default priority is 50. -s Do not report the resulting job IDs (silent mode.) -t \"name\" Sets the job name. -H hh:mm -H hold -H immediate -H restart -H resume Specifies when the job should be printed. A value of immediate will print the file immediately, a value of hold will hold the job indefinitely, and a UTC time value (HH:MM) will hold the job until the specified UTC (not local) time. Use a value of resume with the -i option to resume a held job. Use a value of restart with the -i option to restart a completed job. -P page-list Specifies which pages to print in the document. The list can contain a list of numbers and ranges (#-#) separated by commas, e.g., \"1,3-5,16\". The page numbers refer to the output pages and not the document's original pages - options like \"number-up\" can affect the numbering of the pages. COMMON JOB OPTIONS Aside from the printer-specific options reported by the lpoptions(1) command, the following generic options are available: -o job-sheets=name Prints a cover page (banner) with the document. The \"name\" can be \"classified\", \"confidential\", \"secret\", \"standard\", \"topsecret\", or \"unclassified\". -o media=size Sets the page size to size. Most printers support at least the size names \"a4\", \"letter\", and \"legal\". -o number-up={2|4|6|9|16} Prints 2, 4, 6, 9, or 16 document (input) pages on each output page. -o orientation-requested=4 Prints the job in landscape (rotated 90 degrees counter- clockwise). -o orientation-requested=5 Prints the job in landscape (rotated 90 degrees clockwise). -o orientation-requested=6 Prints the job in reverse portrait (rotated 180 degrees). -o print-quality=3 -o print-quality=4 -o print-quality=5 Specifies the output quality - draft (3), normal (4), or best (5). -o sides=one-sided Prints on one side of the paper. -o sides=two-sided-long-edge Prints on both sides of the paper for portrait output. -o sides=two-sided-short-edge Prints on both sides of the paper for landscape output. "
  },
  {
    "command": "uptime",
    "description": " Print the current time, the length of time the system has been up, the number of users on the system, and the average number of jobs in the run queue over the last 1, 5 and 15 minutes. Processes in an uninterruptible sleep state also contribute to the load average. If FILE is not specified, use /var/run/utmp. /var/log/wtmp as FILE is common. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "git-count-objects",
    "description": " This counts the number of unpacked object files and disk space consumed by them, to help you decide when it is a good time to repack. -v, --verbose Report in more detail: count: the number of loose objects size: disk space consumed by loose objects, in KiB (unless -H is specified) in-pack: the number of in-pack objects size-pack: disk space consumed by the packs, in KiB (unless -H is specified) prune-packable: the number of loose objects that are also present in the packs. These objects could be pruned using git prune-packed. garbage: the number of files in object database that are neither valid loose objects nor valid packs size-garbage: disk space consumed by garbage files, in KiB (unless -H is specified) alternate: absolute path of alternate object databases; may appear multiple times, one line per path. Note that if the path contains non-printable characters, it may be surrounded by double-quotes and contain C-style backslashed escape sequences. -H, --human-readable Print sizes in human readable format "
  },
  {
    "command": "git-shortlog",
    "description": " Summarizes git log output in a format suitable for inclusion in release announcements. Each commit will be grouped by author and title. Additionally, \"[PATCH]\" will be stripped from the commit description. If no revisions are passed on the command line and either standard input is not a terminal or there is no current branch, git shortlog will output a summary of the log read from standard input, without reference to the current repository. -n, --numbered Sort output according to the number of commits per author instead of author alphabetic order. -s, --summary Suppress commit description and provide a commit count summary only. -e, --email Show the email address of each author. --format[=<format>] Instead of the commit subject, use some other information to describe each commit. <format> can be any string accepted by the --format option of git log, such as * [%h] %s. (See the \"PRETTY FORMATS\" section of git-log(1).) Each pretty-printed commit will be rewrapped before it is shown. --date=<format> Show dates formatted according to the given date string. (See the --date option in the \"Commit Formatting\" section of git-log(1)). Useful with --group=format:<format>. --group=<type> Group commits based on <type>. If no --group option is specified, the default is author. <type> is one of: \u2022 author, commits are grouped by author \u2022 committer, commits are grouped by committer (the same as -c) \u2022 trailer:<field>, the <field> is interpreted as a case-insensitive commit message trailer (see git-interpret-trailers(1)). For example, if your project uses Reviewed-by trailers, you might want to see who has been reviewing with git shortlog -ns --group=trailer:reviewed-by. \u2022 format:<format>, any string accepted by the --format option of git log. (See the \"PRETTY FORMATS\" section of git-log(1).) Note that commits that do not include the trailer will not be counted. Likewise, commits with multiple trailers (e.g., multiple signoffs) may be counted more than once (but only once per unique trailer value in that commit). Shortlog will attempt to parse each trailer value as a name <email> identity. If successful, the mailmap is applied and the email is omitted unless the --email option is specified. If the value cannot be parsed as an identity, it will be taken literally and completely. If --group is specified multiple times, commits are counted under each value (but again, only once per unique value in that commit). For example, git shortlog --group=author --group=trailer:co-authored-by counts both authors and co-authors. -c, --committer This is an alias for --group=committer. -w[<width>[,<indent1>[,<indent2>]]] Linewrap the output by wrapping each line at width. The first line of each entry is indented by indent1 spaces, and the second and subsequent lines are indented by indent2 spaces. width, indent1, and indent2 default to 76, 6 and 9 respectively. If width is 0 (zero) then indent the lines of the output without wrapping them. <revision-range> Show only commits in the specified revision range. When no <revision-range> is specified, it defaults to HEAD (i.e. the whole history leading to the current commit). origin..HEAD specifies all the commits reachable from the current commit (i.e. HEAD), but not from origin. For a complete list of ways to spell <revision-range>, see the \"Specifying Ranges\" section of gitrevisions(7). [--] <path>... Consider only commits that are enough to explain how the files that match the specified paths came to be. Paths may need to be prefixed with -- to separate them from options or the revision range, when confusion arises. Commit Limiting Besides specifying a range of commits that should be listed using the special notations explained in the description, additional commit limiting may be applied. Using more options generally further limits the output (e.g. --since=<date1> limits to commits newer than <date1>, and using it with --grep=<pattern> further limits to commits whose log message has a line that matches <pattern>), unless otherwise noted. Note that these are applied before commit ordering and formatting options, such as --reverse. -<number>, -n <number>, --max-count=<number> Limit the number of commits to output. --skip=<number> Skip number commits before starting to show the commit output. --since=<date>, --after=<date> Show commits more recent than a specific date. --since-as-filter=<date> Show all commits more recent than a specific date. This visits all commits in the range, rather than stopping at the first commit which is older than a specific date. --until=<date>, --before=<date> Show commits older than a specific date. --author=<pattern>, --committer=<pattern> Limit the commits output to ones with author/committer header lines that match the specified pattern (regular expression). With more than one --author=<pattern>, commits whose author matches any of the given patterns are chosen (similarly for multiple --committer=<pattern>). --grep-reflog=<pattern> Limit the commits output to ones with reflog entries that match the specified pattern (regular expression). With more than one --grep-reflog, commits whose reflog message matches any of the given patterns are chosen. It is an error to use this option unless --walk-reflogs is in use. --grep=<pattern> Limit the commits output to ones with log message that matches the specified pattern (regular expression). With more than one --grep=<pattern>, commits whose message matches any of the given patterns are chosen (but see --all-match). When --notes is in effect, the message from the notes is matched as if it were part of the log message. --all-match Limit the commits output to ones that match all given --grep, instead of ones that match at least one. --invert-grep Limit the commits output to ones with log message that do not match the pattern specified with --grep=<pattern>. -i, --regexp-ignore-case Match the regular expression limiting patterns without regard to letter case. --basic-regexp Consider the limiting patterns to be basic regular expressions; this is the default. -E, --extended-regexp Consider the limiting patterns to be extended regular expressions instead of the default basic regular expressions. -F, --fixed-strings Consider the limiting patterns to be fixed strings (don\u2019t interpret pattern as a regular expression). -P, --perl-regexp Consider the limiting patterns to be Perl-compatible regular expressions. Support for these types of regular expressions is an optional compile-time dependency. If Git wasn\u2019t compiled with support for them providing this option will cause it to die. --remove-empty Stop when a given path disappears from the tree. --merges Print only merge commits. This is exactly the same as --min-parents=2. --no-merges Do not print commits with more than one parent. This is exactly the same as --max-parents=1. --min-parents=<number>, --max-parents=<number>, --no-min-parents, --no-max-parents Show only commits which have at least (or at most) that many parent commits. In particular, --max-parents=1 is the same as --no-merges, --min-parents=2 is the same as --merges. --max-parents=0 gives all root commits and --min-parents=3 all octopus merges. --no-min-parents and --no-max-parents reset these limits (to no limit) again. Equivalent forms are --min-parents=0 (any commit has 0 or more parents) and --max-parents=-1 (negative numbers denote no upper limit). --first-parent When finding commits to include, follow only the first parent commit upon seeing a merge commit. This option can give a better overview when viewing the evolution of a particular topic branch, because merges into a topic branch tend to be only about adjusting to updated upstream from time to time, and this option allows you to ignore the individual commits brought in to your history by such a merge. --exclude-first-parent-only When finding commits to exclude (with a ^), follow only the first parent commit upon seeing a merge commit. This can be used to find the set of changes in a topic branch from the point where it diverged from the remote branch, given that arbitrary merges can be valid topic branch changes. --not Reverses the meaning of the ^ prefix (or lack thereof) for all following revision specifiers, up to the next --not. --all Pretend as if all the refs in refs/, along with HEAD, are listed on the command line as <commit>. --branches[=<pattern>] Pretend as if all the refs in refs/heads are listed on the command line as <commit>. If <pattern> is given, limit branches to ones matching given shell glob. If pattern lacks ?, *, or [, /* at the end is implied. --tags[=<pattern>] Pretend as if all the refs in refs/tags are listed on the command line as <commit>. If <pattern> is given, limit tags to ones matching given shell glob. If pattern lacks ?, *, or [, /* at the end is implied. --remotes[=<pattern>] Pretend as if all the refs in refs/remotes are listed on the command line as <commit>. If <pattern> is given, limit remote-tracking branches to ones matching given shell glob. If pattern lacks ?, *, or [, /* at the end is implied. --glob=<glob-pattern> Pretend as if all the refs matching shell glob <glob-pattern> are listed on the command line as <commit>. Leading refs/, is automatically prepended if missing. If pattern lacks ?, *, or [, /* at the end is implied. --exclude=<glob-pattern> Do not include refs matching <glob-pattern> that the next --all, --branches, --tags, --remotes, or --glob would otherwise consider. Repetitions of this option accumulate exclusion patterns up to the next --all, --branches, --tags, --remotes, or --glob option (other options or arguments do not clear accumulated patterns). The patterns given should not begin with refs/heads, refs/tags, or refs/remotes when applied to --branches, --tags, or --remotes, respectively, and they must begin with refs/ when applied to --glob or --all. If a trailing /* is intended, it must be given explicitly. --exclude-hidden=[fetch|receive|uploadpack] Do not include refs that would be hidden by git-fetch, git-receive-pack or git-upload-pack by consulting the appropriate fetch.hideRefs, receive.hideRefs or uploadpack.hideRefs configuration along with transfer.hideRefs (see git-config(1)). This option affects the next pseudo-ref option --all or --glob and is cleared after processing them. --reflog Pretend as if all objects mentioned by reflogs are listed on the command line as <commit>. --alternate-refs Pretend as if all objects mentioned as ref tips of alternate repositories were listed on the command line. An alternate repository is any repository whose object directory is specified in objects/info/alternates. The set of included objects may be modified by core.alternateRefsCommand, etc. See git-config(1). --single-worktree By default, all working trees will be examined by the following options when there are more than one (see git-worktree(1)): --all, --reflog and --indexed-objects. This option forces them to examine the current working tree only. --ignore-missing Upon seeing an invalid object name in the input, pretend as if the bad input was not given. --bisect Pretend as if the bad bisection ref refs/bisect/bad was listed and as if it was followed by --not and the good bisection refs refs/bisect/good-* on the command line. --stdin In addition to the <commit> listed on the command line, read them from the standard input. If a -- separator is seen, stop reading commits and start reading paths to limit the result. --cherry-mark Like --cherry-pick (see below) but mark equivalent commits with = rather than omitting them, and inequivalent ones with +. --cherry-pick Omit any commit that introduces the same change as another commit on the \u201cother side\u201d when the set of commits are limited with symmetric difference. For example, if you have two branches, A and B, a usual way to list all commits on only one side of them is with --left-right (see the example below in the description of the --left-right option). However, it shows the commits that were cherry-picked from the other branch (for example, \u201c3rd on b\u201d may be cherry-picked from branch A). With this option, such pairs of commits are excluded from the output. --left-only, --right-only List only commits on the respective side of a symmetric difference, i.e. only those which would be marked < resp. > by --left-right. For example, --cherry-pick --right-only A...B omits those commits from B which are in A or are patch-equivalent to a commit in A. In other words, this lists the + commits from git cherry A B. More precisely, --cherry-pick --right-only --no-merges gives the exact list. --cherry A synonym for --right-only --cherry-mark --no-merges; useful to limit the output to the commits on our side and mark those that have been applied to the other side of a forked history with git log --cherry upstream...mybranch, similar to git cherry upstream mybranch. -g, --walk-reflogs Instead of walking the commit ancestry chain, walk reflog entries from the most recent one to older ones. When this option is used you cannot specify commits to exclude (that is, ^commit, commit1..commit2, and commit1...commit2 notations cannot be used). With --pretty format other than oneline and reference (for obvious reasons), this causes the output to have two extra lines of information taken from the reflog. The reflog designator in the output may be shown as ref@{Nth} (where Nth is the reverse-chronological index in the reflog) or as ref@{timestamp} (with the timestamp for that entry), depending on a few rules: 1. If the starting point is specified as ref@{Nth}, show the index format. 2. If the starting point was specified as ref@{now}, show the timestamp format. 3. If neither was used, but --date was given on the command line, show the timestamp in the format requested by --date. 4. Otherwise, show the index format. Under --pretty=oneline, the commit message is prefixed with this information on the same line. This option cannot be combined with --reverse. See also git-reflog(1). Under --pretty=reference, this information will not be shown at all. --merge After a failed merge, show refs that touch files having a conflict and don\u2019t exist on all heads to merge. --boundary Output excluded boundary commits. Boundary commits are prefixed with -. History Simplification Sometimes you are only interested in parts of the history, for example the commits modifying a particular <path>. But there are two parts of History Simplification, one part is selecting the commits and the other is how to do it, as there are various strategies to simplify the history. The following options select the commits to be shown: <paths> Commits modifying the given <paths> are selected. --simplify-by-decoration Commits that are referred by some branch or tag are selected. Note that extra commits can be shown to give a meaningful history. The following options affect the way the simplification is performed: Default mode Simplifies the history to the simplest history explaining the final state of the tree. Simplest because it prunes some side branches if the end result is the same (i.e. merging branches with the same content) --show-pulls Include all commits from the default mode, but also any merge commits that are not TREESAME to the first parent but are TREESAME to a later parent. This mode is helpful for showing the merge commits that \"first introduced\" a change to a branch. --full-history Same as the default mode, but does not prune some history. --dense Only the selected commits are shown, plus some to have a meaningful history. --sparse All commits in the simplified history are shown. --simplify-merges Additional option to --full-history to remove some needless merges from the resulting history, as there are no selected commits contributing to this merge. --ancestry-path[=<commit>] When given a range of commits to display (e.g. commit1..commit2 or commit2 ^commit1), only display commits in that range that are ancestors of <commit>, descendants of <commit>, or <commit> itself. If no commit is specified, use commit1 (the excluded part of the range) as <commit>. Can be passed multiple times; if so, a commit is included if it is any of the commits given or if it is an ancestor or descendant of one of them. A more detailed explanation follows. Suppose you specified foo as the <paths>. We shall call commits that modify foo !TREESAME, and the rest TREESAME. (In a diff filtered for foo, they look different and equal, respectively.) In the following, we will always refer to the same example history to illustrate the differences between simplification settings. We assume that you are filtering for a file foo in this commit graph: .-A---M---N---O---P---Q / / / / / / I B C D E Y \\ / / / / / `-------------' X The horizontal line of history A---Q is taken to be the first parent of each merge. The commits are: \u2022 I is the initial commit, in which foo exists with contents \u201casdf\u201d, and a file quux exists with contents \u201cquux\u201d. Initial commits are compared to an empty tree, so I is !TREESAME. \u2022 In A, foo contains just \u201cfoo\u201d. \u2022 B contains the same change as A. Its merge M is trivial and hence TREESAME to all parents. \u2022 C does not change foo, but its merge N changes it to \u201cfoobar\u201d, so it is not TREESAME to any parent. \u2022 D sets foo to \u201cbaz\u201d. Its merge O combines the strings from N and D to \u201cfoobarbaz\u201d; i.e., it is not TREESAME to any parent. \u2022 E changes quux to \u201cxyzzy\u201d, and its merge P combines the strings to \u201cquux xyzzy\u201d. P is TREESAME to O, but not to E. \u2022 X is an independent root commit that added a new file side, and Y modified it. Y is TREESAME to X. Its merge Q added side to P, and Q is TREESAME to P, but not to Y. rev-list walks backwards through history, including or excluding commits based on whether --full-history and/or parent rewriting (via --parents or --children) are used. The following settings are available. Default mode Commits are included if they are not TREESAME to any parent (though this can be changed, see --sparse below). If the commit was a merge, and it was TREESAME to one parent, follow only that parent. (Even if there are several TREESAME parents, follow only one of them.) Otherwise, follow all parents. This results in: .-A---N---O / / / I---------D Note how the rule to only follow the TREESAME parent, if one is available, removed B from consideration entirely. C was considered via N, but is TREESAME. Root commits are compared to an empty tree, so I is !TREESAME. Parent/child relations are only visible with --parents, but that does not affect the commits selected in default mode, so we have shown the parent lines. --full-history without parent rewriting This mode differs from the default in one point: always follow all parents of a merge, even if it is TREESAME to one of them. Even if more than one side of the merge has commits that are included, this does not imply that the merge itself is! In the example, we get I A B N D O P Q M was excluded because it is TREESAME to both parents. E, C and B were all walked, but only B was !TREESAME, so the others do not appear. Note that without parent rewriting, it is not really possible to talk about the parent/child relationships between the commits, so we show them disconnected. --full-history with parent rewriting Ordinary commits are only included if they are !TREESAME (though this can be changed, see --sparse below). Merges are always included. However, their parent list is rewritten: Along each parent, prune away commits that are not included themselves. This results in .-A---M---N---O---P---Q / / / / / I B / D / \\ / / / / `-------------' Compare to --full-history without rewriting above. Note that E was pruned away because it is TREESAME, but the parent list of P was rewritten to contain E's parent I. The same happened for C and N, and X, Y and Q. In addition to the above settings, you can change whether TREESAME affects inclusion: --dense Commits that are walked are included if they are not TREESAME to any parent. --sparse All commits that are walked are included. Note that without --full-history, this still simplifies merges: if one of the parents is TREESAME, we follow only that one, so the other sides of the merge are never walked. --simplify-merges First, build a history graph in the same way that --full-history with parent rewriting does (see above). Then simplify each commit C to its replacement C' in the final history according to the following rules: \u2022 Set C' to C. \u2022 Replace each parent P of C' with its simplification P'. In the process, drop parents that are ancestors of other parents or that are root commits TREESAME to an empty tree, and remove duplicates, but take care to never drop all parents that we are TREESAME to. \u2022 If after this parent rewriting, C' is a root or merge commit (has zero or >1 parents), a boundary commit, or !TREESAME, it remains. Otherwise, it is replaced with its only parent. The effect of this is best shown by way of comparing to --full-history with parent rewriting. The example turns into: .-A---M---N---O / / / I B D \\ / / `---------' Note the major differences in N, P, and Q over --full-history: \u2022 N's parent list had I removed, because it is an ancestor of the other parent M. Still, N remained because it is !TREESAME. \u2022 P's parent list similarly had I removed. P was then removed completely, because it had one parent and is TREESAME. \u2022 Q's parent list had Y simplified to X. X was then removed, because it was a TREESAME root. Q was then removed completely, because it had one parent and is TREESAME. There is another simplification mode available: --ancestry-path[=<commit>] Limit the displayed commits to those which are an ancestor of <commit>, or which are a descendant of <commit>, or are <commit> itself. As an example use case, consider the following commit history: D---E-------F / \\ \\ B---C---G---H---I---J / \\ A-------K---------------L--M A regular D..M computes the set of commits that are ancestors of M, but excludes the ones that are ancestors of D. This is useful to see what happened to the history leading to M since D, in the sense that \u201cwhat does M have that did not exist in D\u201d. The result in this example would be all the commits, except A and B (and D itself, of course). When we want to find out what commits in M are contaminated with the bug introduced by D and need fixing, however, we might want to view only the subset of D..M that are actually descendants of D, i.e. excluding C and K. This is exactly what the --ancestry-path option does. Applied to the D..M range, it results in: E-------F \\ \\ G---H---I---J \\ L--M We can also use --ancestry-path=D instead of --ancestry-path which means the same thing when applied to the D..M range but is just more explicit. If we instead are interested in a given topic within this range, and all commits affected by that topic, we may only want to view the subset of D..M which contain that topic in their ancestry path. So, using --ancestry-path=H D..M for example would result in: E \\ G---H---I---J \\ L--M Whereas --ancestry-path=K D..M would result in K---------------L--M Before discussing another option, --show-pulls, we need to create a new example history. A common problem users face when looking at simplified history is that a commit they know changed a file somehow does not appear in the file\u2019s simplified history. Let\u2019s demonstrate a new example and show how options such as --full-history and --simplify-merges works in that case: .-A---M-----C--N---O---P / / \\ \\ \\/ / / I B \\ R-'`-Z' / \\ / \\/ / \\ / /\\ / `---X--' `---Y--' For this example, suppose I created file.txt which was modified by A, B, and X in different ways. The single-parent commits C, Z, and Y do not change file.txt. The merge commit M was created by resolving the merge conflict to include both changes from A and B and hence is not TREESAME to either. The merge commit R, however, was created by ignoring the contents of file.txt at M and taking only the contents of file.txt at X. Hence, R is TREESAME to X but not M. Finally, the natural merge resolution to create N is to take the contents of file.txt at R, so N is TREESAME to R but not C. The merge commits O and P are TREESAME to their first parents, but not to their second parents, Z and Y respectively. When using the default mode, N and R both have a TREESAME parent, so those edges are walked and the others are ignored. The resulting history graph is: I---X When using --full-history, Git walks every edge. This will discover the commits A and B and the merge M, but also will reveal the merge commits O and P. With parent rewriting, the resulting graph is: .-A---M--------N---O---P / / \\ \\ \\/ / / I B \\ R-'`--' / \\ / \\/ / \\ / /\\ / `---X--' `------' Here, the merge commits O and P contribute extra noise, as they did not actually contribute a change to file.txt. They only merged a topic that was based on an older version of file.txt. This is a common issue in repositories using a workflow where many contributors work in parallel and merge their topic branches along a single trunk: many unrelated merges appear in the --full-history results. When using the --simplify-merges option, the commits O and P disappear from the results. This is because the rewritten second parents of O and P are reachable from their first parents. Those edges are removed and then the commits look like single-parent commits that are TREESAME to their parent. This also happens to the commit N, resulting in a history view as follows: .-A---M--. / / \\ I B R \\ / / \\ / / `---X--' In this view, we see all of the important single-parent changes from A, B, and X. We also see the carefully-resolved merge M and the not-so-carefully-resolved merge R. This is usually enough information to determine why the commits A and B \"disappeared\" from history in the default view. However, there are a few issues with this approach. The first issue is performance. Unlike any previous option, the --simplify-merges option requires walking the entire commit history before returning a single result. This can make the option difficult to use for very large repositories. The second issue is one of auditing. When many contributors are working on the same repository, it is important which merge commits introduced a change into an important branch. The problematic merge R above is not likely to be the merge commit that was used to merge into an important branch. Instead, the merge N was used to merge R and X into the important branch. This commit may have information about why the change X came to override the changes from A and B in its commit message. --show-pulls In addition to the commits shown in the default history, show each merge commit that is not TREESAME to its first parent but is TREESAME to a later parent. When a merge commit is included by --show-pulls, the merge is treated as if it \"pulled\" the change from another branch. When using --show-pulls on this example (and no other options) the resulting graph is: I---X---R---N Here, the merge commits R and N are included because they pulled the commits X and R into the base branch, respectively. These merges are the reason the commits A and B do not appear in the default history. When --show-pulls is paired with --simplify-merges, the graph includes all of the necessary information: .-A---M--. N / / \\ / I B R \\ / / \\ / / `---X--' Notice that since M is reachable from R, the edge from N to M was simplified away. However, N still appears in the history as an important commit because it \"pulled\" the change R into the main branch. The --simplify-by-decoration option allows you to view only the big picture of the topology of the history, by omitting commits that are not referenced by tags. Commits are marked as !TREESAME (in other words, kept after history simplification rules described above) if (1) they are referenced by tags, or (2) they change the contents of the paths given on the command line. All other commits are marked as TREESAME (subject to be simplified away). "
  },
  {
    "command": "pv",
    "description": " pv shows the progress of data through a pipeline by giving information such as time elapsed, percentage completed (with progress bar), current throughput rate, total data transferred, and ETA. To use it, insert it in a pipeline between two processes, with the appropriate options. Its standard input will be passed through to its standard output and progress will be shown on standard error. pv will copy each supplied FILE in turn to standard output (- means standard input), or if no FILEs are specified just standard input is copied. This is the same behaviour as cat(1). A simple example to watch how quickly a file is transferred using nc(1): pv file | nc -w 1 somewhere.com 3000 A similar example, transferring a file from another process and passing the expected size to pv: cat file | pv -s 12345 | nc -w 1 somewhere.com 3000 A more complicated example using numeric output to feed into the dialog(1) program for a full-screen progress display: (tar cf - . \\ | pv -n -s $(du -sb . | awk '{print $1}') \\ | gzip -9 > out.tgz) 2>&1 \\ | dialog --gauge 'Progress' 7 70 Taking an image of a disk, skipping errors: pv -EE /dev/your/disk/device > disk-image.img Writing an image back to a disk: pv disk-image.img > /dev/your/disk/device Zeroing a disk: pv < /dev/zero > /dev/your/disk/device Note that if the input size cannot be calculated, and the output is a block device, then the size of the block device will be used and pv will automatically stop at that size as if -S had been given. (Linux only): Watching file descriptor 3 opened by another process 1234: pv -d 1234:3 (Linux only): Watching all file descriptors used by process 1234: pv -d 1234 pv takes many options, which are divided into display switches, output modifiers, and general options. "
  },
  {
    "command": "nl",
    "description": " Write each FILE to standard output, with line numbers added. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -b, --body-numbering=STYLE use STYLE for numbering body lines -d, --section-delimiter=CC use CC for logical page delimiters -f, --footer-numbering=STYLE use STYLE for numbering footer lines -h, --header-numbering=STYLE use STYLE for numbering header lines -i, --line-increment=NUMBER line number increment at each line -l, --join-blank-lines=NUMBER group of NUMBER empty lines counted as one -n, --number-format=FORMAT insert line numbers according to FORMAT -p, --no-renumber do not reset line numbers for each section -s, --number-separator=STRING add STRING after (possible) line number -v, --starting-line-number=NUMBER first line number for each section -w, --number-width=NUMBER use NUMBER columns for line numbers --help display this help and exit --version output version information and exit Default options are: -bt -d'\\:' -fn -hn -i1 -l1 -n'rn' -s<TAB> -v1 -w6 CC are two delimiter characters used to construct logical page delimiters; a missing second character implies ':'. As a GNU extension one can specify more than two characters, and also specifying the empty string (-d '') disables section matching. STYLE is one of: a number all lines t number only nonempty lines n number no lines pBRE number only lines that contain a match for the basic regular expression, BRE FORMAT is one of: ln left justified, no leading zeros rn right justified, no leading zeros rz right justified, leading zeros "
  },
  {
    "command": "git-svn",
    "description": " git svn is a simple conduit for changesets between Subversion and Git. It provides a bidirectional flow of changes between a Subversion and a Git repository. git svn can track a standard Subversion repository, following the common \"trunk/branches/tags\" layout, with the --stdlayout option. It can also follow branches and tags in any layout with the -T/-t/-b options (see options to init below, and also the clone command). Once tracking a Subversion repository (with any of the above methods), the Git repository can be updated from Subversion by the fetch command and Subversion updated from Git by the dcommit command. --shared[=(false|true|umask|group|all|world|everybody)], --template=<template-directory> Only used with the init command. These are passed directly to git init. -r <arg>, --revision <arg> Used with the fetch command. This allows revision ranges for partial/cauterized history to be supported. $NUMBER, $NUMBER1:$NUMBER2 (numeric ranges), $NUMBER:HEAD, and BASE:$NUMBER are all supported. This can allow you to make partial mirrors when running fetch; but is generally not recommended because history will be skipped and lost. -, --stdin Only used with the set-tree command. Read a list of commits from stdin and commit them in reverse order. Only the leading sha1 is read from each line, so git rev-list --pretty=oneline output can be used. --rmdir Only used with the dcommit, set-tree and commit-diff commands. Remove directories from the SVN tree if there are no files left behind. SVN can version empty directories, and they are not removed by default if there are no files left in them. Git cannot version empty directories. Enabling this flag will make the commit to SVN act like Git. config key: svn.rmdir -e, --edit Only used with the dcommit, set-tree and commit-diff commands. Edit the commit message before committing to SVN. This is off by default for objects that are commits, and forced on when committing tree objects. config key: svn.edit -l<num>, --find-copies-harder Only used with the dcommit, set-tree and commit-diff commands. They are both passed directly to git diff-tree; see git-diff-tree(1) for more information. config key: svn.l config key: svn.findcopiesharder -A<filename>, --authors-file=<filename> Syntax is compatible with the file used by git cvsimport but an empty email address can be supplied with <>: loginname = Joe User <user@example.com> If this option is specified and git svn encounters an SVN committer name that does not exist in the authors-file, git svn will abort operation. The user will then have to add the appropriate entry. Re-running the previous git svn command after the authors-file is modified should continue operation. config key: svn.authorsfile --authors-prog=<filename> If this option is specified, for each SVN committer name that does not exist in the authors file, the given file is executed with the committer name as the first argument. The program is expected to return a single line of the form \"Name <email>\" or \"Name <>\", which will be treated as if included in the authors file. Due to historical reasons a relative filename is first searched relative to the current directory for init and clone and relative to the root of the working tree for fetch. If filename is not found, it is searched like any other command in $PATH. config key: svn.authorsProg -q, --quiet Make git svn less verbose. Specify a second time to make it even less verbose. -m, --merge, -s<strategy>, --strategy=<strategy>, -p, --rebase-merges These are only used with the dcommit and rebase commands. Passed directly to git rebase when using dcommit if a git reset cannot be used (see dcommit). -n, --dry-run This can be used with the dcommit, rebase, branch and tag commands. For dcommit, print out the series of Git arguments that would show which diffs would be committed to SVN. For rebase, display the local branch associated with the upstream svn repository associated with the current branch and the URL of svn repository that will be fetched from. For branch and tag, display the urls that will be used for copying when creating the branch or tag. --use-log-author When retrieving svn commits into Git (as part of fetch, rebase, or dcommit operations), look for the first From: line or Signed-off-by trailer in the log message and use that as the author string. config key: svn.useLogAuthor --add-author-from When committing to svn from Git (as part of set-tree or dcommit operations), if the existing log message doesn\u2019t already have a From: or Signed-off-by trailer, append a From: line based on the Git commit\u2019s author string. If you use this, then --use-log-author will retrieve a valid author string for all commits. config key: svn.addAuthorFrom "
  },
  {
    "command": "grep",
    "description": " grep searches for PATTERNS in each FILE. PATTERNS is one or more patterns separated by newline characters, and grep prints each line that matches a pattern. Typically PATTERNS should be quoted when grep is used in a shell command. A FILE of \u201c-\u201d stands for standard input. If no FILE is given, recursive searches examine the working directory, and nonrecursive searches read standard input. Generic Program Information --help Output a usage message and exit. -V, --version Output the version number of grep and exit. Pattern Syntax -E, --extended-regexp Interpret PATTERNS as extended regular expressions (EREs, see below). -F, --fixed-strings Interpret PATTERNS as fixed strings, not regular expressions. -G, --basic-regexp Interpret PATTERNS as basic regular expressions (BREs, see below). This is the default. -P, --perl-regexp Interpret PATTERNS as Perl-compatible regular expressions (PCREs). This option is experimental when combined with the -z (--null-data) option, and grep -P may warn of unimplemented features. Matching Control -e PATTERNS, --regexp=PATTERNS Use PATTERNS as the patterns. If this option is used multiple times or is combined with the -f (--file) option, search for all patterns given. This option can be used to protect a pattern beginning with \u201c-\u201d. -f FILE, --file=FILE Obtain patterns from FILE, one per line. If this option is used multiple times or is combined with the -e (--regexp) option, search for all patterns given. The empty file contains zero patterns, and therefore matches nothing. If FILE is - , read patterns from standard input. -i, --ignore-case Ignore case distinctions in patterns and input data, so that characters that differ only in case match each other. --no-ignore-case Do not ignore case distinctions in patterns and input data. This is the default. This option is useful for passing to shell scripts that already use -i, to cancel its effects because the two options override each other. -v, --invert-match Invert the sense of matching, to select non-matching lines. -w, --word-regexp Select only those lines containing matches that form whole words. The test is that the matching substring must either be at the beginning of the line, or preceded by a non-word constituent character. Similarly, it must be either at the end of the line or followed by a non-word constituent character. Word-constituent characters are letters, digits, and the underscore. This option has no effect if -x is also specified. -x, --line-regexp Select only those matches that exactly match the whole line. For a regular expression pattern, this is like parenthesizing the pattern and then surrounding it with ^ and $. General Output Control -c, --count Suppress normal output; instead print a count of matching lines for each input file. With the -v, --invert-match option (see above), count non-matching lines. --color[=WHEN], --colour[=WHEN] Surround the matched (non-empty) strings, matching lines, context lines, file names, line numbers, byte offsets, and separators (for fields and groups of context lines) with escape sequences to display them in color on the terminal. The colors are defined by the environment variable GREP_COLORS. WHEN is never, always, or auto. -L, --files-without-match Suppress normal output; instead print the name of each input file from which no output would normally have been printed. -l, --files-with-matches Suppress normal output; instead print the name of each input file from which output would normally have been printed. Scanning each input file stops upon first match. -m NUM, --max-count=NUM Stop reading a file after NUM matching lines. If NUM is zero, grep stops right away without reading input. A NUM of -1 is treated as infinity and grep does not stop; this is the default. If the input is standard input from a regular file, and NUM matching lines are output, grep ensures that the standard input is positioned to just after the last matching line before exiting, regardless of the presence of trailing context lines. This enables a calling process to resume a search. When grep stops after NUM matching lines, it outputs any trailing context lines. When the -c or --count option is also used, grep does not output a count greater than NUM. When the -v or --invert-match option is also used, grep stops after outputting NUM non-matching lines. -o, --only-matching Print only the matched (non-empty) parts of a matching line, with each such part on a separate output line. -q, --quiet, --silent Quiet; do not write anything to standard output. Exit immediately with zero status if any match is found, even if an error was detected. Also see the -s or --no-messages option. -s, --no-messages Suppress error messages about nonexistent or unreadable files. Output Line Prefix Control -b, --byte-offset Print the 0-based byte offset within the input file before each line of output. If -o (--only-matching) is specified, print the offset of the matching part itself. -H, --with-filename Print the file name for each match. This is the default when there is more than one file to search. This is a GNU extension. -h, --no-filename Suppress the prefixing of file names on output. This is the default when there is only one file (or only standard input) to search. --label=LABEL Display input actually coming from standard input as input coming from file LABEL. This can be useful for commands that transform a file's contents before searching, e.g., gzip -cd foo.gz | grep --label=foo -H 'some pattern'. See also the -H option. -n, --line-number Prefix each line of output with the 1-based line number within its input file. -T, --initial-tab Make sure that the first character of actual line content lies on a tab stop, so that the alignment of tabs looks normal. This is useful with options that prefix their output to the actual content: -H,-n, and -b. In order to improve the probability that lines from a single file will all start at the same column, this also causes the line number and byte offset (if present) to be printed in a minimum size field width. -Z, --null Output a zero byte (the ASCII NUL character) instead of the character that normally follows a file name. For example, grep -lZ outputs a zero byte after each file name instead of the usual newline. This option makes the output unambiguous, even in the presence of file names containing unusual characters like newlines. This option can be used with commands like find -print0, perl -0, sort -z, and xargs -0 to process arbitrary file names, even those that contain newline characters. Context Line Control -A NUM, --after-context=NUM Print NUM lines of trailing context after matching lines. Places a line containing a group separator (--) between contiguous groups of matches. With the -o or --only-matching option, this has no effect and a warning is given. -B NUM, --before-context=NUM Print NUM lines of leading context before matching lines. Places a line containing a group separator (--) between contiguous groups of matches. With the -o or --only-matching option, this has no effect and a warning is given. -C NUM, -NUM, --context=NUM Print NUM lines of output context. Places a line containing a group separator (--) between contiguous groups of matches. With the -o or --only-matching option, this has no effect and a warning is given. --group-separator=SEP When -A, -B, or -C are in use, print SEP instead of -- between groups of lines. --no-group-separator When -A, -B, or -C are in use, do not print a separator between groups of lines. File and Directory Selection -a, --text Process a binary file as if it were text; this is equivalent to the --binary-files=text option. --binary-files=TYPE If a file's data or metadata indicate that the file contains binary data, assume that the file is of type TYPE. Non-text bytes indicate binary data; these are either output bytes that are improperly encoded for the current locale, or null input bytes when the -z option is not given. By default, TYPE is binary, and grep suppresses output after null input binary data is discovered, and suppresses output lines that contain improperly encoded data. When some output is suppressed, grep follows any output with a message to standard error saying that a binary file matches. If TYPE is without-match, when grep discovers null input binary data it assumes that the rest of the file does not match; this is equivalent to the -I option. If TYPE is text, grep processes a binary file as if it were text; this is equivalent to the -a option. When type is binary, grep may treat non-text bytes as line terminators even without the -z option. This means choosing binary versus text can affect whether a pattern matches a file. For example, when type is binary the pattern q$ might match q immediately followed by a null byte, even though this is not matched when type is text. Conversely, when type is binary the pattern . (period) might not match a null byte. Warning: The -a option might output binary garbage, which can have nasty side effects if the output is a terminal and if the terminal driver interprets some of it as commands. On the other hand, when reading files whose text encodings are unknown, it can be helpful to use -a or to set LC_ALL='C' in the environment, in order to find more matches even if the matches are unsafe for direct display. -D ACTION, --devices=ACTION If an input file is a device, FIFO or socket, use ACTION to process it. By default, ACTION is read, which means that devices are read just as if they were ordinary files. If ACTION is skip, devices are silently skipped. -d ACTION, --directories=ACTION If an input file is a directory, use ACTION to process it. By default, ACTION is read, i.e., read directories just as if they were ordinary files. If ACTION is skip, silently skip directories. If ACTION is recurse, read all files under each directory, recursively, following symbolic links only if they are on the command line. This is equivalent to the -r option. --exclude=GLOB Skip any command-line file with a name suffix that matches the pattern GLOB, using wildcard matching; a name suffix is either the whole name, or a trailing part that starts with a non-slash character immediately after a slash (/) in the name. When searching recursively, skip any subfile whose base name matches GLOB; the base name is the part after the last slash. A pattern can use *, ?, and [...] as wildcards, and \\ to quote a wildcard or backslash character literally. --exclude-from=FILE Skip files whose base name matches any of the file-name globs read from FILE (using wildcard matching as described under --exclude). --exclude-dir=GLOB Skip any command-line directory with a name suffix that matches the pattern GLOB. When searching recursively, skip any subdirectory whose base name matches GLOB. Ignore any redundant trailing slashes in GLOB. -I Process a binary file as if it did not contain matching data; this is equivalent to the --binary-files=without-match option. --include=GLOB Search only files whose base name matches GLOB (using wildcard matching as described under --exclude). If contradictory --include and --exclude options are given, the last matching one wins. If no --include or --exclude options match, a file is included unless the first such option is --include. -r, --recursive Read all files under each directory, recursively, following symbolic links only if they are on the command line. Note that if no file operand is given, grep searches the working directory. This is equivalent to the -d recurse option. -R, --dereference-recursive Read all files under each directory, recursively. Follow all symbolic links, unlike -r. Other Options --line-buffered Use line buffering on output. This can cause a performance penalty. -U, --binary Treat the file(s) as binary. By default, under MS-DOS and MS-Windows, grep guesses whether a file is text or binary as described for the --binary-files option. If grep decides the file is a text file, it strips the CR characters from the original file contents (to make regular expressions with ^ and $ work correctly). Specifying -U overrules this guesswork, causing all files to be read and passed to the matching mechanism verbatim; if the file is a text file with CR/LF pairs at the end of each line, this will cause some regular expressions to fail. This option has no effect on platforms other than MS-DOS and MS-Windows. -z, --null-data Treat input and output data as sequences of lines, each terminated by a zero byte (the ASCII NUL character) instead of a newline. Like the -Z or --null option, this option can be used with commands like sort -z to process arbitrary file names. "
  },
  {
    "command": "systemd-run",
    "description": " systemd-run may be used to create and start a transient .service or .scope unit and run the specified COMMAND in it. It may also be used to create and start a transient .path, .socket, or .timer unit, that activates a .service unit when elapsing. If a command is run as transient service unit, it will be started and managed by the service manager like any other service, and thus shows up in the output of systemctl list-units like any other unit. It will run in a clean and detached execution environment, with the service manager as its parent process. In this mode, systemd-run will start the service asynchronously in the background and return after the command has begun execution (unless --no-block or --wait are specified, see below). If a command is run as transient scope unit, it will be executed by systemd-run itself as parent process and will thus inherit the execution environment of the caller. However, the processes of the command are managed by the service manager similarly to normal services, and will show up in the output of systemctl list-units. Execution in this case is synchronous, and will return only when the command finishes. This mode is enabled via the --scope switch (see below). If a command is run with path, socket, or timer options such as --on-calendar= (see below), a transient path, socket, or timer unit is created alongside the service unit for the specified command. Only the transient path, socket, or timer unit is started immediately, the transient service unit will be triggered by the path, socket, or timer unit. If the --unit= option is specified, the COMMAND may be omitted. In this case, systemd-run creates only a .path, .socket, or .timer unit that triggers the specified unit. By default, services created with systemd-run default to the simple type, see the description of Type= in systemd.service(5) for details. Note that when this type is used, the service manager (and thus the systemd-run command) considers service start-up successful as soon as the fork() for the main service process succeeded, i.e. before the execve() is invoked, and thus even if the specified command cannot be started. Consider using the exec service type (i.e. --property=Type=exec) to ensure that systemd-run returns successfully only if the specified command line has been successfully started. After systemd-run passes the command to the service manager, the manager performs variable expansion. This means that dollar characters (\"$\") which should not be expanded need to be escaped as \"$$\". Expansion can also be disabled using --expand-environment=no. The following options are understood: --no-ask-password Do not query the user for authentication for privileged operations. --scope Create a transient .scope unit instead of the default transient .service unit (see above). --unit=, -u Use this unit name instead of an automatically generated one. --property=, -p Sets a property on the scope or service unit that is created. This option takes an assignment in the same format as systemctl(1)'s set-property command. --description= Provide a description for the service, scope, path, socket, or timer unit. If not specified, the command itself will be used as a description. See Description= in systemd.unit(5). --slice= Make the new .service or .scope unit part of the specified slice, instead of system.slice (when running in --system mode) or the root slice (when running in --user mode). --slice-inherit Make the new .service or .scope unit part of the inherited slice. This option can be combined with --slice=. An inherited slice is located within systemd-run slice. Example: if systemd-run slice is foo.slice, and the --slice= argument is bar, the unit will be placed under the foo-bar.slice. --expand-environment=BOOL Expand environment variables in command arguments. If enabled (the default), environment variables specified as \"${VARIABLE}\" will be expanded in the same way as in commands specified via ExecStart= in units. With --scope, this expansion is performed by systemd-run itself, and in other cases by the service manager that spawns the command. Note that this is similar to, but not the same as variable expansion in bash(1) and other shells. See systemd.service(5) for a description of variable expansion. Disabling variable expansion is useful if the specified command includes or may include a \"$\" sign. -r, --remain-after-exit After the service process has terminated, keep the service around until it is explicitly stopped. This is useful to collect runtime information about the service after it finished running. Also see RemainAfterExit= in systemd.service(5). --send-sighup When terminating the scope or service unit, send a SIGHUP immediately after SIGTERM. This is useful to indicate to shells and shell-like processes that the connection has been severed. Also see SendSIGHUP= in systemd.kill(5). --service-type= Sets the service type. Also see Type= in systemd.service(5). This option has no effect in conjunction with --scope. Defaults to simple. --uid=, --gid= Runs the service process under the specified UNIX user and group. Also see User= and Group= in systemd.exec(5). --nice= Runs the service process with the specified nice level. Also see Nice= in systemd.exec(5). --working-directory= Runs the service process with the specified working directory. Also see WorkingDirectory= in systemd.exec(5). --same-dir, -d Similar to --working-directory=, but uses the current working directory of the caller for the service to execute. -E NAME[=VALUE], --setenv=NAME[=VALUE] Runs the service process with the specified environment variable set. This parameter may be used more than once to set multiple variables. When \"=\" and VALUE are omitted, the value of the variable with the same name in the program environment will be used. Also see Environment= in systemd.exec(5). --pty, -t When invoking the command, the transient service connects its standard input, output and error to the terminal systemd-run is invoked on, via a pseudo TTY device. This allows running programs that expect interactive user input/output as services, such as interactive command shells. Note that machinectl(1)'s shell command is usually a better alternative for requesting a new, interactive login session on the local host or a local container. See below for details on how this switch combines with --pipe. --pipe, -P If specified, standard input, output, and error of the transient service are inherited from the systemd-run command itself. This allows systemd-run to be used within shell pipelines. Note that this mode is not suitable for interactive command shells and similar, as the service process will not become a TTY controller when invoked on a terminal. Use --pty instead in that case. When both --pipe and --pty are used in combination the more appropriate option is automatically determined and used. Specifically, when invoked with standard input, output and error connected to a TTY --pty is used, and otherwise --pipe. When this option is used the original file descriptors systemd-run receives are passed to the service processes as-is. If the service runs with different privileges than systemd-run, this means the service might not be able to re-open the passed file descriptors, due to normal file descriptor access restrictions. If the invoked process is a shell script that uses the echo \"hello\" >/dev/stderr construct for writing messages to stderr, this might cause problems, as this only works if stderr can be re-opened. To mitigate this use the construct echo \"hello\" >&2 instead, which is mostly equivalent and avoids this pitfall. --shell, -S A shortcut for \"--pty --same-dir --wait --collect --service-type=exec $SHELL\", i.e. requests an interactive shell in the current working directory, running in service context, accessible with a single switch. --quiet, -q Suppresses additional informational output while running. This is particularly useful in combination with --pty when it will suppress the initial message explaining how to terminate the TTY connection. --on-active=, --on-boot=, --on-startup=, --on-unit-active=, --on-unit-inactive= Defines a monotonic timer relative to different starting points for starting the specified command. See OnActiveSec=, OnBootSec=, OnStartupSec=, OnUnitActiveSec= and OnUnitInactiveSec= in systemd.timer(5) for details. These options are shortcuts for --timer-property= with the relevant properties. These options may not be combined with --scope or --pty. --on-calendar= Defines a calendar timer for starting the specified command. See OnCalendar= in systemd.timer(5). This option is a shortcut for --timer-property=OnCalendar=. This option may not be combined with --scope or --pty. --on-clock-change, --on-timezone-change Defines a trigger based on system clock jumps or timezone changes for starting the specified command. See OnClockChange= and OnTimezoneChange= in systemd.timer(5). These options are shortcuts for --timer-property=OnClockChange=yes and --timer-property=OnTimezoneChange=yes. These options may not be combined with --scope or --pty. --path-property=, --socket-property=, --timer-property= Sets a property on the path, socket, or timer unit that is created. This option is similar to --property=, but applies to the transient path, socket, or timer unit rather than the transient service unit created. This option takes an assignment in the same format as systemctl(1)'s set-property command. These options may not be combined with --scope or --pty. --no-block Do not synchronously wait for the unit start operation to finish. If this option is not specified, the start request for the transient unit will be verified, enqueued and systemd-run will wait until the unit's start-up is completed. By passing this argument, it is only verified and enqueued. This option may not be combined with --wait. --wait Synchronously wait for the transient service to terminate. If this option is specified, the start request for the transient unit is verified, enqueued, and waited for. Subsequently the invoked unit is monitored, and it is waited until it is deactivated again (most likely because the specified command completed). On exit, terse information about the unit's runtime is shown, including total runtime (as well as CPU usage, if --property=CPUAccounting=1 was set) and the exit code and status of the main process. This output may be suppressed with --quiet. This option may not be combined with --no-block, --scope or the various path, socket, or timer options. -G, --collect Unload the transient unit after it completed, even if it failed. Normally, without this option, all units that ran and failed are kept in memory until the user explicitly resets their failure state with systemctl reset-failed or an equivalent command. On the other hand, units that ran successfully are unloaded immediately. If this option is turned on the \"garbage collection\" of units is more aggressive, and unloads units regardless if they exited successfully or failed. This option is a shortcut for --property=CollectMode=inactive-or-failed, see the explanation for CollectMode= in systemd.unit(5) for further information. --user Talk to the service manager of the calling user, rather than the service manager of the system. --system Talk to the service manager of the system. This is the implied default. -H, --host= Execute the operation remotely. Specify a hostname, or a username and hostname separated by \"@\", to connect to. The hostname may optionally be suffixed by a port ssh is listening on, separated by \":\", and then a container name, separated by \"/\", which connects directly to a specific container on the specified host. This will use SSH to talk to the remote machine manager instance. Container names may be enumerated with machinectl -H HOST. Put IPv6 addresses in brackets. -M, --machine= Execute operation on a local container. Specify a container name to connect to, optionally prefixed by a user name to connect as and a separating \"@\" character. If the special string \".host\" is used in place of the container name, a connection to the local system is made (which is useful to connect to a specific user's user bus: \"--user --machine=lennart@.host\"). If the \"@\" syntax is not used, the connection is made as root user. If the \"@\" syntax is used either the left hand side or the right hand side may be omitted (but not both) in which case the local user name and \".host\" are implied. -h, --help Print a short help text and exit. --version Print a short version string and exit. All command line arguments after the first non-option argument become part of the command line of the launched process. "
  },
  {
    "command": "tput",
    "description": " The @TPUT@ utility uses the terminfo database to make the values of terminal-dependent capabilities and information available to the shell (see sh(1)), to initialize or reset the terminal, or return the long name of the requested terminal type. The result depends upon the capability's type: string @TPUT@ writes the string to the standard output. No trailing newline is supplied. integer @TPUT@ writes the decimal value to the standard output, with a trailing newline. boolean @TPUT@ simply sets the exit code (0 for TRUE if the terminal has the capability, 1 for FALSE if it does not), and writes nothing to the standard output. Before using a value returned on the standard output, the application should test the exit code (e.g., $?, see sh(1)) to be sure it is 0. (See the EXIT CODES and DIAGNOSTICS sections.) For a complete list of capabilities and the capname associated with each, see terminfo(5). Options -S allows more than one capability per invocation of @TPUT@. The capabilities must be passed to @TPUT@ from the standard input instead of from the command line (see example). Only one capname is allowed per line. The -S option changes the meaning of the 0 and 1 boolean and string exit codes (see the EXIT CODES section). Because some capabilities may use string parameters rather than numbers, @TPUT@ uses a table and the presence of parameters in its input to decide whether to use tparm(3X), and how to interpret the parameters. -Ttype indicates the type of terminal. Normally this option is unnecessary, because the default is taken from the environment variable TERM. If -T is specified, then the shell variables LINES and COLUMNS will also be ignored. -V reports the version of ncurses which was used in this program, and exits. -x do not attempt to clear the terminal's scrollback buffer using the extended \u201cE3\u201d capability. Commands A few commands (init, reset and longname) are special; they are defined by the @TPUT@ program. The others are the names of capabilities from the terminal database (see terminfo(5) for a list). Although init and reset resemble capability names, @TPUT@ uses several capabilities to perform these special functions. capname indicates the capability from the terminal database. If the capability is a string that takes parameters, the arguments following the capability will be used as parameters for the string. Most parameters are numbers. Only a few terminal capabilities require string parameters; @TPUT@ uses a table to decide which to pass as strings. Normally @TPUT@ uses tparm(3X) to perform the substitution. If no parameters are given for the capability, @TPUT@ writes the string without performing the substitution. init If the terminal database is present and an entry for the user's terminal exists (see -Ttype, above), the following will occur: (1) first, @TPUT@ retrieves the current terminal mode settings for your terminal. It does this by successively testing \u2022 the standard error, \u2022 standard output, \u2022 standard input and \u2022 ultimately \u201c/dev/tty\u201d to obtain terminal settings. Having retrieved these settings, @TPUT@ remembers which file descriptor to use when updating settings. (2) if the window size cannot be obtained from the operating system, but the terminal description (or environment, e.g., LINES and COLUMNS variables specify this), update the operating system's notion of the window size. (3) the terminal modes will be updated: \u2022 any delays (e.g., newline) specified in the entry will be set in the tty driver, \u2022 tabs expansion will be turned on or off according to the specification in the entry, and \u2022 if tabs are not expanded, standard tabs will be set (every 8 spaces). (4) if present, the terminal's initialization strings will be output as detailed in the terminfo(5) section on Tabs and Initialization, (5) output is flushed. If an entry does not contain the information needed for any of these activities, that activity will silently be skipped. reset This is similar to init, with two differences: (1) before any other initialization, the terminal modes will be reset to a \u201csane\u201d state: \u2022 set cooked and echo modes, \u2022 turn off cbreak and raw modes, \u2022 turn on newline translation and \u2022 reset any unset special characters to their default values (2) Instead of putting out initialization strings, the terminal's reset strings will be output if present (rs1, rs2, rs3, rf). If the reset strings are not present, but initialization strings are, the initialization strings will be output. Otherwise, reset acts identically to init. longname If the terminal database is present and an entry for the user's terminal exists (see -Ttype above), then the long name of the terminal will be put out. The long name is the last name in the first line of the terminal's description in the terminfo database [see term(5)]. Aliases @TPUT@ handles the clear, init and reset commands specially: it allows for the possibility that it is invoked by a link with those names. If @TPUT@ is invoked by a link named reset, this has the same effect as @TPUT@ reset. The @TSET@(1) utility also treats a link named reset specially. Before ncurses 6.1, the two utilities were different from each other: \u2022 @TSET@ utility reset the terminal modes and special characters (not done with @TPUT@). \u2022 On the other hand, @TSET@'s repertoire of terminal capabilities for resetting the terminal was more limited, i.e., only reset_1string, reset_2string and reset_file in contrast to the tab-stops and margins which are set by this utility. \u2022 The reset program is usually an alias for @TSET@, because of this difference with resetting terminal modes and special characters. With the changes made for ncurses 6.1, the reset feature of the two programs is (mostly) the same. A few differences remain: \u2022 The @TSET@ program waits one second when resetting, in case it happens to be a hardware terminal. \u2022 The two programs write the terminal initialization strings to different streams (i.e., the standard error for @TSET@ and the standard output for @TPUT@). Note: although these programs write to different streams, redirecting their output to a file will capture only part of their actions. The changes to the terminal modes are not affected by redirecting the output. If @TPUT@ is invoked by a link named init, this has the same effect as @TPUT@ init. Again, you are less likely to use that link because another program named init has a more well- established use. Terminal Size Besides the special commands (e.g., clear), @TPUT@ treats certain terminfo capabilities specially: lines and cols. @TPUT@ calls setupterm(3X) to obtain the terminal size: \u2022 first, it gets the size from the terminal database (which generally is not provided for terminal emulators which do not have a fixed window size) \u2022 then it asks the operating system for the terminal's size (which generally works, unless connecting via a serial line which does not support NAWS: negotiations about window size). \u2022 finally, it inspects the environment variables LINES and COLUMNS which may override the terminal size. If the -T option is given @TPUT@ ignores the environment variables by calling use_tioctl(TRUE), relying upon the operating system (or finally, the terminal database). "
  },
  {
    "command": "link",
    "description": " Call the link function to create a link named FILE2 to an existing FILE1. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "logname",
    "description": " The logname utility shall write the user's login name to standard output. The login name shall be the string that would be returned by the getlogin() function defined in the System Interfaces volume of POSIX.1\u20102017. Under the conditions where the getlogin() function would fail, the logname utility shall write a diagnostic message to standard error and exit with a non-zero exit status. None. "
  },
  {
    "command": "iconv",
    "description": " The iconv utility shall convert the encoding of characters in file from one codeset to another and write the results to standard output. When the options indicate that charmap files are used to specify the codesets (see OPTIONS), the codeset conversion shall be accomplished by performing a logical join on the symbolic character names in the two charmaps. The implementation need not support the use of charmap files for codeset conversion unless the POSIX2_LOCALEDEF symbol is defined on the system. The iconv utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -c Omit any characters that are invalid in the codeset of the input file from the output. When -c is not used, the results of encountering invalid characters in the input stream (either those that are not characters in the codeset of the input file or that have no corresponding character in the codeset of the output file) shall be specified in the system documentation. The presence or absence of -c shall not affect the exit status of iconv. -f fromcodeset Identify the codeset of the input file. The implementation shall recognize the following two forms of the fromcodeset option-argument: fromcode The fromcode option-argument must not contain a <slash> character. It shall be interpreted as the name of one of the codeset descriptions provided by the implementation in an unspecified format. Valid values of fromcode are implementation-defined. frommap The frommap option-argument must contain a <slash> character. It shall be interpreted as the pathname of a charmap file as defined in the Base Definitions volume of POSIX.1\u20102017, Section 6.4, Character Set Description File. If the pathname does not represent a valid, readable charmap file, the results are undefined. If this option is omitted, the codeset of the current locale shall be used. -l Write all supported fromcode and tocode values to standard output in an unspecified format. -s Suppress any messages written to standard error concerning invalid characters. When -s is not used, the results of encountering invalid characters in the input stream (either those that are not valid characters in the codeset of the input file or that have no corresponding character in the codeset of the output file) shall be specified in the system documentation. The presence or absence of -s shall not affect the exit status of iconv. -t tocodeset Identify the codeset to be used for the output file. The implementation shall recognize the following two forms of the tocodeset option-argument: tocode The semantics shall be equivalent to the -f fromcode option. tomap The semantics shall be equivalent to the -f frommap option. If this option is omitted, the codeset of the current locale shall be used. If either -f or -t represents a charmap file, but the other does not (or is omitted), or both -f and -t are omitted, the results are undefined. "
  },
  {
    "command": "paste",
    "description": " The paste utility shall concatenate the corresponding lines of the given input files, and write the resulting lines to standard output. The default operation of paste shall concatenate the corresponding lines of the input files. The <newline> of every line except the line from the last input file shall be replaced with a <tab>. If an end-of-file condition is detected on one or more input files, but not all input files, paste shall behave as though empty lines were read from the files on which end-of-file was detected, unless the -s option is specified. The paste utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -d list Unless a <backslash> character appears in list, each character in list is an element specifying a delimiter character. If a <backslash> character appears in list, the <backslash> character and one or more characters following it are an element specifying a delimiter character as described below. These elements specify one or more delimiters to use, instead of the default <tab>, to replace the <newline> of the input lines. The elements in list shall be used circularly; that is, when the list is exhausted the first element from the list is reused. When the -s option is specified: * The last <newline> in a file shall not be modified. * The delimiter shall be reset to the first element of list after each file operand is processed. When the -s option is not specified: * The <newline> characters in the file specified by the last file operand shall not be modified. * The delimiter shall be reset to the first element of list each time a line is processed from each file. If a <backslash> character appears in list, it and the character following it shall be used to represent the following delimiter characters: \\n <newline>. \\t <tab>. \\\\ <backslash> character. \\0 Empty string (not a null character). If '\\0' is immediately followed by the character 'x', the character 'X', or any character defined by the LC_CTYPE digit keyword (see the Base Definitions volume of POSIX.1\u20102017, Chapter 7, Locale), the results are unspecified. If any other characters follow the <backslash>, the results are unspecified. -s Concatenate all of the lines from each input file into one line of output per file, in command line order. The <newline> of every line except the last line in each input file shall be replaced with a <tab>, unless otherwise specified by the -d option. If an input file is empty, the output line corresponding to that file shall consist of only a <newline> character. "
  },
  {
    "command": "ls",
    "description": " For each operand that names a file of a type other than directory or symbolic link to a directory, ls shall write the name of the file as well as any requested, associated information. For each operand that names a file of type directory, ls shall write the names of files contained within the directory as well as any requested, associated information. Filenames beginning with a <period> ('.') and any associated information shall not be written out unless explicitly referenced, the -A or -a option is supplied, or an implementation-defined condition causes them to be written. If one or more of the -d, -F, or -l options are specified, and neither the -H nor the -L option is specified, for each operand that names a file of type symbolic link to a directory, ls shall write the name of the file as well as any requested, associated information. If none of the -d, -F, or -l options are specified, or the -H or -L options are specified, for each operand that names a file of type symbolic link to a directory, ls shall write the names of files contained within the directory as well as any requested, associated information. In each case where the names of files contained within a directory are written, if the directory contains any symbolic links then ls shall evaluate the file information and file type to be those of the symbolic link itself, unless the -L option is specified. If no operands are specified, ls shall behave as if a single operand of dot ('.') had been specified. If more than one operand is specified, ls shall write non-directory operands first; it shall sort directory and non-directory operands separately according to the collating sequence in the current locale. Whenever ls sorts filenames or pathnames according to the collating sequence in the current locale, if this collating sequence does not have a total ordering of all characters (see the Base Definitions volume of POSIX.1\u20102017, Section 7.3.2, LC_COLLATE), then any filenames or pathnames that collate equally should be further compared byte-by-byte using the collating sequence for the POSIX locale. The ls utility shall detect infinite loops; that is, entering a previously visited directory that is an ancestor of the last file encountered. When it detects an infinite loop, ls shall write a diagnostic message to standard error and shall either recover its position in the hierarchy or terminate. The ls utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -A Write out all directory entries, including those whose names begin with a <period> ('.') but excluding the entries dot and dot-dot (if they exist). -C Write multi-text-column output with entries sorted down the columns, according to the collating sequence. The number of text columns and the column separator characters are unspecified, but should be adapted to the nature of the output device. This option disables long format output. -F Do not follow symbolic links named as operands unless the -H or -L options are specified. Write a <slash> ('/') immediately after each pathname that is a directory, an <asterisk> ('*') after each that is executable, a <vertical-line> ('|') after each that is a FIFO, and an at-sign ('@') after each that is a symbolic link. For other file types, other symbols may be written. -H Evaluate the file information and file type for symbolic links specified on the command line to be those of the file referenced by the link, and not the link itself; however, ls shall write the name of the link itself and not the file referenced by the link. -L Evaluate the file information and file type for all symbolic links (whether named on the command line or encountered in a file hierarchy) to be those of the file referenced by the link, and not the link itself; however, ls shall write the name of the link itself and not the file referenced by the link. When -L is used with -l, write the contents of symbolic links in the long format (see the STDOUT section). -R Recursively list subdirectories encountered. When a symbolic link to a directory is encountered, the directory shall not be recursively listed unless the -L option is specified. The use of -R with -d or -f produces unspecified results. -S Sort with the primary key being file size (in decreasing order) and the secondary key being filename in the collating sequence (in increasing order). -a Write out all directory entries, including those whose names begin with a <period> ('.'). -c Use time of last modification of the file status information (see the Base Definitions volume of POSIX.1\u20102017, sys_stat.h(0p)) instead of last modification of the file itself for sorting (-t) or writing (-l). -d Do not follow symbolic links named as operands unless the -H or -L options are specified. Do not treat directories differently than other types of files. The use of -d with -R or -f produces unspecified results. -f List the entries in directory operands in the order they appear in the directory. The behavior for non- directory operands is unspecified. This option shall turn on -a. When -f is specified, any occurrences of the -r, -S, and -t options shall be ignored and any occurrences of the -A, -g, -l, -n, -o, and -s options may be ignored. The use of -f with -R or -d produces unspecified results. -g Turn on the -l (ell) option, but disable writing the file's owner name or number. Disable the -C, -m, and -x options. -i For each file, write the file's file serial number (see stat() in the System Interfaces volume of POSIX.1\u20102017). -k Set the block size for the -s option and the per- directory block count written for the -l, -n, -s, -g, and -o options (see the STDOUT section) to 1024 bytes. -l (The letter ell.) Do not follow symbolic links named as operands unless the -H or -L options are specified. Write out in long format (see the STDOUT section). Disable the -C, -m, and -x options. -m Stream output format; list pathnames across the page, separated by a <comma> character followed by a <space> character. Use a <newline> character as the list terminator and after the separator sequence when there is not room on a line for the next list entry. This option disables long format output. -n Turn on the -l (ell) option, but when writing the file's owner or group, write the file's numeric UID or GID rather than the user or group name, respectively. Disable the -C, -m, and -x options. -o Turn on the -l (ell) option, but disable writing the file's group name or number. Disable the -C, -m, and -x options. -p Write a <slash> ('/') after each filename if that file is a directory. -q Force each instance of non-printable filename characters and <tab> characters to be written as the <question-mark> ('?') character. Implementations may provide this option by default if the output is to a terminal device. -r Reverse the order of the sort to get reverse collating sequence oldest first, or smallest file size first depending on the other options given. -s Indicate the total number of file system blocks consumed by each file displayed. If the -k option is also specified, the block size shall be 1024 bytes; otherwise, the block size is implementation-defined. -t Sort with the primary key being time modified (most recently modified first) and the secondary key being filename in the collating sequence. For a symbolic link, the time used as the sort key is that of the symbolic link itself, unless ls is evaluating its file information to be that of the file referenced by the link (see the -H and -L options). -u Use time of last access (see the Base Definitions volume of POSIX.1\u20102017, sys_stat.h(0p)) instead of last modification of the file for sorting (-t) or writing (-l). -x The same as -C, except that the multi-text-column output is produced with entries sorted across, rather than down, the columns. This option disables long format output. -1 (The numeric digit one.) Force output to be one entry per line. This option does not disable long format output. (Long format output is enabled by -g, -l (ell), -n, and -o; and disabled by -C, -m, and -x.) If an option that enables long format output (-g, -l (ell), -n, and -o is given with an option that disables long format output (-C, -m, and -x), this shall not be considered an error. The last of these options specified shall determine whether long format output is written. If -R, -d, or -f are specified, the results of specifying these mutually-exclusive options are specified by the descriptions of these options above. If more than one of any of the other options shown in the SYNOPSIS section in mutually-exclusive sets are given, this shall not be considered an error; the last option specified in each set shall determine the output. Note that if -t is specified, -c and -u are not only mutually- exclusive with each other, they are also mutually-exclusive with -S when determining sort order. But even if -S is specified after all occurrences of -c, -t, and -u, the last use of -c or -u determines the timestamp printed when producing long format output. "
  },
  {
    "command": "mktemp",
    "description": " Create a temporary file or directory, safely, and print its name. TEMPLATE must contain at least 3 consecutive 'X's in last component. If TEMPLATE is not specified, use tmp.XXXXXXXXXX, and --tmpdir is implied. Files are created u+rw, and directories u+rwx, minus umask restrictions. -d, --directory create a directory, not a file -u, --dry-run do not create anything; merely print a name (unsafe) -q, --quiet suppress diagnostics about file/dir-creation failure --suffix=SUFF append SUFF to TEMPLATE; SUFF must not contain a slash. This option is implied if TEMPLATE does not end in X -p DIR, --tmpdir[=DIR] interpret TEMPLATE relative to DIR; if DIR is not specified, use $TMPDIR if set, else /tmp. With this option, TEMPLATE must not be an absolute name; unlike with -t, TEMPLATE may contain slashes, but mktemp creates only the final component -t interpret TEMPLATE as a single file name component, relative to a directory: $TMPDIR, if set; else the directory specified via -p; else /tmp [deprecated] --help display this help and exit --version output version information and exit "
  },
  {
    "command": "git-range-diff",
    "description": " This command shows the differences between two versions of a patch series, or more generally, two commit ranges (ignoring merge commits). In the presence of <path> arguments, these commit ranges are limited accordingly. To that end, it first finds pairs of commits from both commit ranges that correspond with each other. Two commits are said to correspond when the diff between their patches (i.e. the author information, the commit message and the commit diff) is reasonably small compared to the patches' size. See ``Algorithm`` below for details. Finally, the list of matching commits is shown in the order of the second commit range, with unmatched commits being inserted just after all of their ancestors have been shown. There are three ways to specify the commit ranges: \u2022 <range1> <range2>: Either commit range can be of the form <base>..<rev>, <rev>^! or <rev>^-<n>. See SPECIFYING RANGES in gitrevisions(7) for more details. \u2022 <rev1>...<rev2>. This is equivalent to <rev2>..<rev1> <rev1>..<rev2>. \u2022 <base> <rev1> <rev2>: This is equivalent to <base>..<rev1> <base>..<rev2>. --no-dual-color When the commit diffs differ, \u2018git range-diff` recreates the original diffs\u2019 coloring, and adds outer -/+ diff markers with the background being red/green to make it easier to see e.g. when there was a change in what exact lines were added. Additionally, the commit diff lines that are only present in the first commit range are shown \"dimmed\" (this can be overridden using the color.diff.<slot> config setting where <slot> is one of contextDimmed, oldDimmed and newDimmed), and the commit diff lines that are only present in the second commit range are shown in bold (which can be overridden using the config settings color.diff.<slot> with <slot> being one of contextBold, oldBold or newBold). This is known to range-diff as \"dual coloring\". Use --no-dual-color to revert to color all lines according to the outer diff markers (and completely ignore the inner diff when it comes to color). --creation-factor=<percent> Set the creation/deletion cost fudge factor to <percent>. Defaults to 60. Try a larger value if git range-diff erroneously considers a large change a total rewrite (deletion of one commit and addition of another), and a smaller one in the reverse case. See the ``Algorithm`` section below for an explanation why this is needed. --left-only Suppress commits that are missing from the first specified range (or the \"left range\" when using the <rev1>...<rev2> format). --right-only Suppress commits that are missing from the second specified range (or the \"right range\" when using the <rev1>...<rev2> format). --[no-]notes[=<ref>] This flag is passed to the git log program (see git-log(1)) that generates the patches. <range1> <range2> Compare the commits specified by the two ranges, where <range1> is considered an older version of <range2>. <rev1>...<rev2> Equivalent to passing <rev2>..<rev1> and <rev1>..<rev2>. <base> <rev1> <rev2> Equivalent to passing <base>..<rev1> and <base>..<rev2>. Note that <base> does not need to be the exact branch point of the branches. Example: after rebasing a branch my-topic, git range-diff my-topic@{u} my-topic@{1} my-topic would show the differences introduced by the rebase. git range-diff also accepts the regular diff options (see git-diff(1)), most notably the --color=[<when>] and --no-color options. These options are used when generating the \"diff between patches\", i.e. to compare the author, commit message and diff of corresponding old/new commits. There is currently no means to tweak most of the diff options passed to git log when generating those patches. "
  },
  {
    "command": "quilt",
    "description": " Quilt is a tool to manage large sets of patches by keeping track of the changes each patch makes. Patches can be applied, unapplied, refreshed, and so forth. The key philosophical concept is that your primary working material is patches. With quilt, all work occurs within a single directory tree. Commands can be invoked from anywhere within the source tree. Like CVS, Subversion, or Git, quilt takes commands of the form \u201cquilt command\u201d. A command can be truncated (abbreviated) as long as the specified part of the command is unambiguous. If command is ambiguously short, quilt lists all commands matching that prefix and exits. All commands print a brief contextual help message and exit if given the \u201c-h\u201d option. Quilt manages a stack of patches. Patches are applied incrementally on top of the base tree plus all preceding patches. They can be pushed onto the stack (\u201cquilt push\u201d), and popped off the stack (\u201cquilt pop\u201d). Commands are available for querying the contents of the stack (\u201cquilt applied\u201d, \u201cquilt previous\u201d, \u201cquilt top\u201d) and the patches that are not applied at a particular moment (\u201cquilt next\u201d, \u201cquilt unapplied\u201d). By default, most commands apply to the topmost patch on the stack. Patch files are located in the patches subdirectory of the source tree (see Example of working tree, under FILES, below). The QUILT_PATCHES environment variable overrides this default location. When not found in the current directory, that subdirectory is searched recursively in the parent directories (this is similar to the way Git searches for its configuration files). The patches directory may contain subdirectories. It may also be a symbolic link instead of a directory. Quilt creates and maintains a file called series, which defines the order in which patches are applied. The QUILT_SERIES environment variable overrides this default name. You can query the contents of the series file at any time with \u201cquilt series\u201d. In this file, each patch file name is on a separate line. Patch files are identified by path names that are relative to the patches directory; patches may be in subdirectories below this directory. Lines in the series file that start with a hash character (#) are ignored. Patch options, such as the strip level or whether the patch is reversed, can be added after each patch file name. Options are introduced by a space, separated by spaces, and follow the syntax of the patch(1) options (e.g., \u201c-p2\u201d). Quilt records patch options automatically when a command supporting them is used. Without options, strip level 1 is assumed. You can also add a comment after each patch file name and options, introduced by a space followed by a hash character. When quilt adds, removes, or renames patches, it automatically updates the series file. Users of quilt can modify series files while some patches are applied, as long as the applied patches remain in their original order. Unless there are means by which a series file can be generated automatically, you should provide it along with any set of quilt-managed patches you distribute. Different series files can be used to assemble patches in different ways, corresponding (for example) to different development branches. Before a patch is applied, copies of all files the patch modifies are saved to the .pc/patch-name directory, where patch-name is the name of the patch (for example, fix-buffer-overflow.patch). The patch is added to the list of currently applied patches (.pc/applied-patches). Later, when a patch is regenerated (\u201cquilt refresh\u201d), the backup copies in .pc/patch-name are compared with the current versions of the files in the source tree using GNU diff(1). A similar process occurs when starting a new patch (\u201cquilt new\u201d); the new patch file name is added to the series file. A file to be changed by the patch is backed up and opened for editing (\u201cquilt edit\u201d). After editing, inspect the impact of your changes (\u201cquilt diff\u201d); the changes stay local to your working tree until you call \u201cquilt refresh\u201d to write them to the patch file. Documentation related to a patch can be put at the beginning of its patch file (\u201cquilt header\u201d). Quilt is careful to preserve all text that precedes the actual patch when doing a refresh. (This is limited to patches in unified format; see the GNU Diffutils manual.) The series file is looked up in the .pc directory, in the root of the source tree, and in the patches directory. The first series file that is found is used. This may also be a symbolic link, or a file with multiple hard links. Usually, only one series file is used for a set of patches, making the patches subdirectory a convenient location. The .pc directory cannot be relocated, but it can be a symbolic link. Its subdirectories must not be renamed or restructured. While patches are applied to the source tree, this directory is essential for many operations, including popping patches off the stack and refreshing them. Files in the .pc directory are automatically removed when they are no longer needed, so there is no need to clean up manually. Quilt commands reference add [-P patch] {file} ... Add one or more files to the topmost or named patch. Files must be added to the patch before being modified. Files that are modified by patches already applied on top of the specified patch cannot be added. -P patch Patch to add files to. annotate [-P patch] {file} Print an annotated listing of the specified file showing which patches modify which lines. Only applied patches are included. -P patch Stop checking for changes at the specified rather than the topmost patch. applied [patch] Print a list of applied patches, or all patches up to and including the specified patch in the file series. delete [-r] [--backup] [patch|-n] Remove the specified or topmost patch from the series file. If the patch is applied, quilt will attempt to remove it first. (Only the topmost patch can be removed right now.) -n Delete the next patch after topmost, rather than the specified or topmost patch. -r Remove the deleted patch file from the patches directory as well. --backup Rename the patch file to patch~ rather than deleting it. Ignored if not used with `-r'. diff [-p n|-p ab] [-u|-U num|-c|-C num] [--combine patch|-z] [-R] [-P patch] [--snapshot] [--diff=utility] [--no-timestamps] [--no- index] [--sort] [--color[=always|auto|never]] [file ...] Produces a diff of the specified file(s) in the topmost or specified patch. If no files are specified, all files that are modified are included. -p n Create a -p n style patch (-p0 or -p1 are supported). -p ab Create a -p1 style patch, but use a/file and b/file as the original and new filenames instead of the default dir.orig/file and dir/file names. -u, -U num, -c, -C num Create a unified diff (-u, -U) with num lines of context. Create a context diff (-c, -C) with num lines of context. The number of context lines defaults to 3. --no-timestamps Do not include file timestamps in patch headers. --no-index Do not output Index: lines. -z Write to standard output the changes that have been made relative to the topmost or specified patch. -R Create a reverse diff. -P patch Create a diff for the specified patch. (Defaults to the topmost patch.) --combine patch Create a combined diff for all patches between this patch and the patch specified with -P. A patch name of `-' is equivalent to specifying the first applied patch. --snapshot Diff against snapshot (see `quilt snapshot -h'). --diff=utility Use the specified utility for generating the diff. The utility is invoked with the original and new file name as arguments. --color[=always|auto|never] Use syntax coloring (auto activates it only if the output is a tty). --sort Sort files by their name instead of preserving the original order. edit file ... Edit the specified file(s) in $EDITOR after adding it (them) to the topmost patch. files [-v] [-a] [-l] [--combine patch] [patch] Print the list of files that the topmost or specified patch changes. -a List all files in all applied patches. -l Add patch name to output. -v Verbose, more user friendly output. --combine patch Create a listing for all patches between this patch and the topmost or specified patch. A patch name of `-' is equivalent to specifying the first applied patch. fold [-R] [-q] [-f] [-p strip-level] Integrate the patch read from standard input into the topmost patch: After making sure that all files modified are part of the topmost patch, the patch is applied with the specified strip level (which defaults to 1). -R Apply patch in reverse. -q Quiet operation. -f Force apply, even if the patch has rejects. Unless in quiet mode, apply the patch interactively: the patch utility may ask questions. -p strip-level The number of pathname components to strip from file names when applying patchfile. fork [new_name] Fork the topmost patch. Forking a patch means creating a verbatim copy of it under a new name, and use that new name instead of the original one in the current series. This is useful when a patch has to be modified, but the original version of it should be preserved, e.g. because it is used in another series, or for the history. A typical sequence of commands would be: fork, edit, refresh. If new_name is missing, the name of the forked patch will be the current patch name, followed by `-2'. If the patch name already ends in a dash-and-number, the number is further incremented (e.g., patch.diff, patch-2.diff, patch-3.diff). graph [--all] [--reduce] [--lines[=num]] [--edge-labels=files] [-T ps] [patch] Generate a dot(1) directed graph showing the dependencies between applied patches. A patch depends on another patch if both touch the same file or, with the --lines option, if their modifications overlap. Unless otherwise specified, the graph includes all patches that the topmost patch depends on. When a patch name is specified, instead of the topmost patch, create a graph for the specified patch. The graph will include all other patches that this patch depends on, as well as all patches that depend on this patch. --all Generate a graph including all applied patches and their dependencies. (Unapplied patches are not included.) --reduce Eliminate transitive edges from the graph. --lines[=num] Compute dependencies by looking at the lines the patches modify. Unless a different num is specified, two lines of context are included. --edge-labels=files Label graph edges with the file names that the adjacent patches modify. -T ps Directly produce a PostScript output file. grep [-h|options] {pattern} Grep through the source files, recursively, skipping patches and quilt meta-information. If no filename argument is given, the whole source tree is searched. Please see the grep(1) manual page for options. -h Print this help. The grep -h option can be passed after a double-dash (--). Search expressions that start with a dash can be passed after a second double-dash (-- --). header [-a|-r|-e] [--backup] [--strip-diffstat] [--strip- trailing-whitespace] [patch] Print or change the header of the topmost or specified patch. -a, -r, -e Append to (-a) or replace (-r) the exiting patch header, or edit (-e) the header in $EDITOR. If none of these options is given, print the patch header. --strip-diffstat Strip diffstat output from the header. --strip-trailing-whitespace Strip trailing whitespace at the end of lines of the header. --backup Create a backup copy of the old version of a patch as patch~. import [-p num] [-R] [-P patch] [-f] [-d {o|a|n}] patchfile ... Import external patches. The patches will be inserted following the current top patch, and must be pushed after import to apply them. -p num Number of directory levels to strip when applying (default=1) -R Apply patch in reverse. -P patch Patch filename to use inside quilt. This option can only be used when importing a single patch. -f Overwrite/update existing patches. -d {o|a|n} When overwriting in existing patch, keep the old (o), all (a), or new (n) patch header. If both patches include headers, this option must be specified. This option is only effective when -f is used. mail {--mbox file|--send} [-m text] [-M file] [--prefix prefix] [--sender ...] [--from ...] [--to ...] [--cc ...] [--bcc ...] [--subject ...] [--reply-to message] [--charset ...] [--signature file] [first_patch [last_patch]] Create mail messages from a specified range of patches, or all patches in the series file, and either store them in a mailbox file, or send them immediately. The editor is opened with a template for the introduction. Please see /usr/local/share/doc/quilt/README.MAIL for details. When specifying a range of patches, a first patch name of `-' denotes the first, and a last patch name of `-' denotes the last patch in the series. -m text Text to use as the text in the introduction. When this option is used, the editor will not be invoked, and the patches will be processed immediately. -M file Like the -m option, but read the introduction from file. --prefix prefix Use an alternate prefix in the bracketed part of the subjects generated. Defaults to `patch'. --mbox file Store all messages in the specified file in mbox format. The mbox can later be sent using formail, for example. --send Send the messages directly. --sender The envelope sender address to use. The address must be of the form `user@domain.name'. No display name is allowed. --from, --subject The values for the From and Subject headers to use. If no --from option is given, the value of the --sender option is used. --to, --cc, --bcc Append a recipient to the To, Cc, or Bcc header. --charset Specify a particular message encoding on systems which don't use UTF-8 or ISO-8859-15. This character encoding must match the one used in the patches. --signature file Append the specified signature to messages (defaults to ~/.signature if found; use `-' for no signature). --reply-to message Add the appropriate headers to reply to the specified message. new [-p n|-p ab] {patchname} Create a new patch with the specified file name, and insert it after the topmost patch. The name can be prefixed with a sub-directory name, allowing for grouping related patches together. -p n Create a -p n style patch (-p0 or -p1 are supported). -p ab Create a -p1 style patch, but use a/file and b/file as the original and new filenames instead of the default dir.orig/file and dir/file names. Quilt can be used in sub-directories of a source tree. It determines the root of a source tree by searching for a directory above the current working directory. Create a directory in the intended root directory if quilt chooses a top-level directory that is too high up in the directory tree. next [patch] Print the name of the next patch after the specified or topmost patch in the series file. patches [-v] [--color[=always|auto|never]] {file} [files...] Print the list of patches that modify any of the specified files. (Uses a heuristic to determine which files are modified by unapplied patches. Note that this heuristic is much slower than scanning applied patches.) -v Verbose, more user friendly output. --color[=always|auto|never] Use syntax coloring (auto activates it only if the output is a tty). pop [-afRqv] [--refresh] [num|patch] Remove patch(es) from the stack of applied patches. Without options, the topmost patch is removed. When a number is specified, remove the specified number of patches. When a patch name is specified, remove patches until the specified patch end up on top of the stack. Patch names may include the patches/ prefix, which means that filename completion can be used. -a Remove all applied patches. -f Force remove. The state before the patch(es) were applied will be restored from backup files. -R Always verify if the patch removes cleanly; don't rely on timestamp checks. -q Quiet operation. -v Verbose operation. --refresh Automatically refresh every patch before it gets unapplied. previous [patch] Print the name of the previous patch before the specified or topmost patch in the series file. push [-afqvm] [--fuzz=N] [--merge[=merge|diff3]] [--leave- rejects] [--color[=always|auto|never]] [--refresh] [num|patch] Apply patch(es) from the series file. Without options, the next patch in the series file is applied. When a number is specified, apply the specified number of patches. When a patch name is specified, apply all patches up to and including the specified patch. Patch names may include the patches/ prefix, which means that filename completion can be used. -a Apply all patches in the series file. -q Quiet operation. -f Force apply, even if the patch has rejects. -v Verbose operation. --fuzz=N Set the maximum fuzz factor (default: 2). -m, --merge[=merge|diff3] Merge the patch file into the original files (see patch(1)). --leave-rejects Leave around the reject files patch produced, even if the patch is not actually applied. --color[=always|auto|never] Use syntax coloring (auto activates it only if the output is a tty). --refresh Automatically refresh every patch after it was successfully applied. refresh [-p n|-p ab] [-u|-U num|-c|-C num] [-z[new_name]] [-f] [--no-timestamps] [--no-index] [--diffstat] [--sort] [--backup] [--strip-trailing-whitespace] [patch] Refreshes the specified patch, or the topmost patch by default. Documentation that comes before the actual patch in the patch file is retained. It is possible to refresh patches that are not on top. If any patches on top of the patch to refresh modify the same files, the script aborts by default. Patches can still be refreshed with -f. In that case this script will print a warning for each shadowed file, changes by more recent patches will be ignored, and only changes in files that have not been modified by any more recent patches will end up in the specified patch. -p n Create a -p n style patch (-p0 or -p1 supported). -p ab Create a -p1 style patch, but use a/file and b/file as the original and new filenames instead of the default dir.orig/file and dir/file names. -u, -U num, -c, -C num Create a unified diff (-u, -U) with num lines of context. Create a context diff (-c, -C) with num lines of context. The number of context lines defaults to 3. -z[new_name] Create a new patch containing the changes instead of refreshing the topmost patch. If no new name is specified, `-2' is added to the original patch name, etc. (See the fork command.) --no-timestamps Do not include file timestamps in patch headers. --no-index Do not output Index: lines. --diffstat Add a diffstat section to the patch header, or replace the existing diffstat section. -f Enforce refreshing of a patch that is not on top. --backup Create a backup copy of the old version of a patch as patch~. --sort Sort files by their name instead of preserving the original order. --strip-trailing-whitespace Strip trailing whitespace at the end of lines. remove [-P patch] {file} ... Remove one or more files from the topmost or named patch. Files that are modified by patches on top of the specified patch cannot be removed. -P patch Remove named files from the named patch. rename [-P patch] new_name Rename the topmost or named patch. -P patch Patch to rename. revert [-P patch] {file} ... Revert uncommitted changes to the topmost or named patch for the specified file(s): after the revert, 'quilt diff -z' will show no differences for those files. Changes to files that are modified by patches on top of the specified patch cannot be reverted. -P patch Revert changes in the named patch. series [--color[=always|auto|never]] [-v] Print the names of all patches in the series file. --color[=always|auto|never] Use syntax coloring (auto activates it only if the output is a tty). -v Verbose, more user friendly output. setup [-d path-prefix] [-v] [--sourcedir dir] [--fuzz=N] [--slow|--fast] {specfile|seriesfile} Initializes a source tree from an rpm spec file or a quilt series file. -d Optional path prefix for the resulting source tree. --sourcedir Directory that contains the package sources. Defaults to `.'. -v Verbose debug output. --fuzz=N Set the maximum fuzz factor (needs rpm 4.6 or later). --slow Use the original, slow method to process the spec file. In this mode, rpmbuild generates a working tree in a temporary directory while all its actions are recorded, and then everything is replayed from scratch in the target directory. --fast Use the new, faster method to process the spec file. In this mode, rpmbuild is told to generate a working tree directly in the target directory. This is the default (since quilt version 0.67). The setup command is only guaranteed to work properly on spec files where applying all the patches is the last thing done in the %prep section. This is a design limitation due to the fact that quilt can only operate on patches. If other commands in the %prep section modify the patched files, this must happen first, otherwise you won't be able to push the patch series. snapshot [-d] Take a snapshot of the current working state. After taking the snapshot, the tree can be modified in the usual ways, including pushing and popping patches. A diff against the tree at the moment of the snapshot can be generated with `quilt diff --snapshot'. -d Only remove current snapshot. top Print the name of the topmost patch on the current stack of applied patches. unapplied [patch] Print a list of patches that are not applied, or all patches that follow the specified patch in the series file. upgrade Upgrade the meta-data in a working tree from an old version of quilt to the current version. This command is only needed when the quilt meta-data format has changed, and the working tree still contains old-format meta-data. In that case, quilt will request to run `quilt upgrade'. These options are common to all quilt commands. -h Print a usage message (for the given command, if one is specified, otherwise for quilt itself) and exit. --quiltrc file Use file as the configuration file instead of ~/.quiltrc (or /etc/quilt.quiltrc if ~/.quiltrc does not exist). The special value \u201c-\u201d causes quilt not to read any configuration file. --trace Run the command in the shell's trace mode (-x) for debugging of internal operations. --version Print the version number and exit. "
  },
  {
    "command": "nohup",
    "description": " The nohup utility shall invoke the utility named by the utility operand with arguments supplied as the argument operands. At the time the named utility is invoked, the SIGHUP signal shall be set to be ignored. If standard input is associated with a terminal, the nohup utility may redirect standard input from an unspecified file. If the standard output is a terminal, all output written by the named utility to its standard output shall be appended to the end of the file nohup.out in the current directory. If nohup.out cannot be created or opened for appending, the output shall be appended to the end of the file nohup.out in the directory specified by the HOME environment variable. If neither file can be created or opened for appending, utility shall not be invoked. If a file is created, the file's permission bits shall be set to S_IRUSR | S_IWUSR. If standard error is a terminal and standard output is open but is not a terminal, all output written by the named utility to its standard error shall be redirected to the same open file description as the standard output. If standard error is a terminal and standard output either is a terminal or is closed, the same output shall instead be appended to the end of the nohup.out file as described above. None. "
  },
  {
    "command": "expand",
    "description": " The expand utility shall write files or the standard input to the standard output with <tab> characters replaced with one or more <space> characters needed to pad to the next tab stop. Any <backspace> characters shall be copied to the output and cause the column position count for tab stop calculations to be decremented; the column position count shall not be decremented below zero. The expand utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -t tablist Specify the tab stops. The application shall ensure that the argument tablist consists of either a single positive decimal integer or a list of tabstops. If a single number is given, tabs shall be set that number of column positions apart instead of the default 8. If a list of tabstops is given, the application shall ensure that it consists of a list of two or more positive decimal integers, separated by <blank> or <comma> characters, in ascending order. The <tab> characters shall be set at those specific column positions. Each tab stop N shall be an integer value greater than zero, and the list is in strictly ascending order. This is taken to mean that, from the start of a line of output, tabbing to position N shall cause the next character output to be in the (N+1)th column position on that line. In the event of expand having to process a <tab> at a position beyond the last of those specified in a multiple tab-stop list, the <tab> shall be replaced by a single <space> in the output. "
  },
  {
    "command": "strace",
    "description": " In the simplest case strace runs the specified command until it exits. It intercepts and records the system calls which are called by a process and the signals which are received by a process. The name of each system call, its arguments and its return value are printed on standard error or to the file specified with the -o option. strace is a useful diagnostic, instructional, and debugging tool. System administrators, diagnosticians and trouble-shooters will find it invaluable for solving problems with programs for which the source is not readily available since they do not need to be recompiled in order to trace them. Students, hackers and the overly-curious will find that a great deal can be learned about a system and its system calls by tracing even ordinary programs. And programmers will find that since system calls and signals are events that happen at the user/kernel interface, a close examination of this boundary is very useful for bug isolation, sanity checking and attempting to capture race conditions. Each line in the trace contains the system call name, followed by its arguments in parentheses and its return value. An example from stracing the command \"cat /dev/null\" is: open(\"/dev/null\", O_RDONLY) = 3 Errors (typically a return value of -1) have the errno symbol and error string appended. open(\"/foo/bar\", O_RDONLY) = -1 ENOENT (No such file or directory) Signals are printed as signal symbol and decoded siginfo structure. An excerpt from stracing and interrupting the command \"sleep 666\" is: sigsuspend([] <unfinished ...> --- SIGINT {si_signo=SIGINT, si_code=SI_USER, si_pid=...} --- +++ killed by SIGINT +++ If a system call is being executed and meanwhile another one is being called from a different thread/process then strace will try to preserve the order of those events and mark the ongoing call as being unfinished. When the call returns it will be marked as resumed. [pid 28772] select(4, [3], NULL, NULL, NULL <unfinished ...> [pid 28779] clock_gettime(CLOCK_REALTIME, {tv_sec=1130322148, tv_nsec=3977000}) = 0 [pid 28772] <... select resumed> ) = 1 (in [3]) Interruption of a (restartable) system call by a signal delivery is processed differently as kernel terminates the system call and also arranges its immediate reexecution after the signal handler completes. read(0, 0x7ffff72cf5cf, 1) = ? ERESTARTSYS (To be restarted) --- SIGALRM {si_signo=SIGALRM, si_code=SI_KERNEL} --- rt_sigreturn({mask=[]}) = 0 read(0, \"\", 1) = 0 Arguments are printed in symbolic form with passion. This example shows the shell performing \">>xyzzy\" output redirection: open(\"xyzzy\", O_WRONLY|O_APPEND|O_CREAT, 0666) = 3 Here, the second and the third argument of open(2) are decoded by breaking down the flag argument into its three bitwise-OR constituents and printing the mode value in octal by tradition. Where the traditional or native usage differs from ANSI or POSIX, the latter forms are preferred. In some cases, strace output is proven to be more readable than the source. Structure pointers are dereferenced and the members are displayed as appropriate. In most cases, arguments are formatted in the most C-like fashion possible. For example, the essence of the command \"ls -l /dev/null\" is captured as: lstat(\"/dev/null\", {st_mode=S_IFCHR|0666, st_rdev=makedev(0x1, 0x3), ...}) = 0 Notice how the 'struct stat' argument is dereferenced and how each member is displayed symbolically. In particular, observe how the st_mode member is carefully decoded into a bitwise-OR of symbolic and numeric values. Also notice in this example that the first argument to lstat(2) is an input to the system call and the second argument is an output. Since output arguments are not modified if the system call fails, arguments may not always be dereferenced. For example, retrying the \"ls -l\" example with a non-existent file produces the following line: lstat(\"/foo/bar\", 0xb004) = -1 ENOENT (No such file or directory) In this case the porch light is on but nobody is home. Syscalls unknown to strace are printed raw, with the unknown system call number printed in hexadecimal form and prefixed with \"syscall_\": syscall_0xbad(0x1, 0x2, 0x3, 0x4, 0x5, 0x6) = -1 ENOSYS (Function not implemented) Character pointers are dereferenced and printed as C strings. Non-printing characters in strings are normally represented by ordinary C escape codes. Only the first strsize (32 by default) bytes of strings are printed; longer strings have an ellipsis appended following the closing quote. Here is a line from \"ls -l\" where the getpwuid(3) library routine is reading the password file: read(3, \"root::0:0:System Administrator:/\"..., 1024) = 422 While structures are annotated using curly braces, pointers to basic types and arrays are printed using square brackets with commas separating the elements. Here is an example from the command id(1) on a system with supplementary group ids: getgroups(32, [100, 0]) = 2 On the other hand, bit-sets are also shown using square brackets, but set elements are separated only by a space. Here is the shell, preparing to execute an external command: sigprocmask(SIG_BLOCK, [CHLD TTOU], []) = 0 Here, the second argument is a bit-set of two signals, SIGCHLD and SIGTTOU. In some cases, the bit-set is so full that printing out the unset elements is more valuable. In that case, the bit- set is prefixed by a tilde like this: sigprocmask(SIG_UNBLOCK, ~[], NULL) = 0 Here, the second argument represents the full set of all signals. General -e expr A qualifying expression which modifies which events to trace or how to trace them. The format of the expression is: [qualifier=][!]value[,value]... where qualifier is one of trace (or t), trace-fds (or trace-fd or fd or fds), abbrev (or a), verbose (or v), raw (or x), signal (or signals or s), read (or reads or r), write (or writes or w), fault, inject, status, quiet (or silent or silence or q), secontext, decode-fds (or decode-fd), decode-pids (or decode-pid), or kvm, and value is a qualifier-dependent symbol or number. The default qualifier is trace. Using an exclamation mark negates the set of values. For example, -e open means literally -e trace=open which in turn means trace only the open system call. By contrast, -e trace=!open means to trace every system call except open. In addition, the special values all and none have the obvious meanings. Note that some shells use the exclamation point for history expansion even inside quoted arguments. If so, you must escape the exclamation point with a backslash. Startup -E var=val --env=var=val Run command with var=val in its list of environment variables. -E var --env=var Remove var from the inherited list of environment variables before passing it on to the command. -p pid --attach=pid Attach to the process with the process ID pid and begin tracing. The trace may be terminated at any time by a keyboard interrupt signal (CTRL-C). strace will respond by detaching itself from the traced process(es) leaving it (them) to continue running. Multiple -p options can be used to attach to many processes in addition to command (which is optional if at least one -p option is given). Multiple process IDs, separated by either comma (\u201c,\u201d), space (\u201c \u201d), tab, or newline character, can be provided as an argument to a single -p option, so, for example, -p \"$(pidof PROG)\" and -p \"$(pgrep PROG)\" syntaxes are supported. -u username --user=username Run command with the user ID, group ID, and supplementary groups of username. This option is only useful when running as root and enables the correct execution of setuid and/or setgid binaries. Unless this option is used setuid and setgid programs are executed without effective privileges. --argv0=name Set argv[0] of the command being executed to name. Useful for tracing multi-call executables which interpret argv[0], such as busybox or kmod. Tracing -b syscall --detach-on=syscall If specified syscall is reached, detach from traced process. Currently, only execve(2) syscall is supported. This option is useful if you want to trace multi-threaded process and therefore require -f, but don't want to trace its (potentially very complex) children. -D --daemonize --daemonize=grandchild Run tracer process as a grandchild, not as the parent of the tracee. This reduces the visible effect of strace by keeping the tracee a direct child of the calling process. -DD --daemonize=pgroup --daemonize=pgrp Run tracer process as tracee's grandchild in a separate process group. In addition to reduction of the visible effect of strace, it also avoids killing of strace with kill(2) issued to the whole process group. -DDD --daemonize=session Run tracer process as tracee's grandchild in a separate session (\"true daemonisation\"). In addition to reduction of the visible effect of strace, it also avoids killing of strace upon session termination. -f --follow-forks Trace child processes as they are created by currently traced processes as a result of the fork(2), vfork(2) and clone(2) system calls. Note that -p PID -f will attach all threads of process PID if it is multi-threaded, not only thread with thread_id = PID. --output-separately If the --output=filename option is in effect, each processes trace is written to filename.pid where pid is the numeric process id of each process. -ff --follow-forks --output-separately Combine the effects of --follow-forks and --output-separately options. This is incompatible with -c, since no per-process counts are kept. One might want to consider using strace-log-merge(1) to obtain a combined strace log view. -I interruptible --interruptible=interruptible When strace can be interrupted by signals (such as pressing CTRL-C). 1, anywhere no signals are blocked; 2, waiting fatal signals are blocked while decoding syscall (default); 3, never fatal signals are always blocked (default if -o FILE PROG); 4, never_tstp fatal signals and SIGTSTP (CTRL-Z) are always blocked (useful to make strace -o FILE PROG not stop on CTRL-Z, default if -D). --syscall-limit=limit Detach all tracees when limit number of syscalls have been captured. Syscalls filtered out via --trace, --trace-path or --status options are not considered when keeping track of the number of syscalls that are captured. Filtering -e trace=syscall_set -e t=syscall_set --trace=syscall_set Trace only the specified set of system calls. syscall_set is defined as [!]value[,value], and value can be one of the following: syscall Trace specific syscall, specified by its name (see syscalls(2) for a reference, but also see NOTES). ?value Question mark before the syscall qualification allows suppression of error in case no syscalls matched the qualification provided. value@64 Limit the syscall specification described by value to 64-bit personality. value@32 Limit the syscall specification described by value to 32-bit personality. value@x32 Limit the syscall specification described by value to x32 personality. all Trace all system calls. /regex Trace only those system calls that match the regex. You can use POSIX Extended Regular Expression syntax (see regex(7)). %file file Trace all system calls which take a file name as an argument. You can think of this as an abbreviation for -e trace=open,stat,chmod,unlink,... which is useful to seeing what files the process is referencing. Furthermore, using the abbreviation will ensure that you don't accidentally forget to include a call like lstat(2) in the list. Betchya woulda forgot that one. The syntax without a preceding percent sign (\"-e trace=file\") is deprecated. %process process Trace system calls associated with process lifecycle (creation, exec, termination). The syntax without a preceding percent sign (\"-e trace=process\") is deprecated. %net %network network Trace all the network related system calls. The syntax without a preceding percent sign (\"-e trace=network\") is deprecated. %signal signal Trace all signal related system calls. The syntax without a preceding percent sign (\"-e trace=signal\") is deprecated. %ipc ipc Trace all IPC related system calls. The syntax without a preceding percent sign (\"-e trace=ipc\") is deprecated. %desc desc Trace all file descriptor related system calls. The syntax without a preceding percent sign (\"-e trace=desc\") is deprecated. %memory memory Trace all memory mapping related system calls. The syntax without a preceding percent sign (\"-e trace=memory\") is deprecated. %creds Trace system calls that read or modify user and group identifiers or capability sets. %stat Trace stat syscall variants. %lstat Trace lstat syscall variants. %fstat Trace fstat, fstatat, and statx syscall variants. %%stat Trace syscalls used for requesting file status (stat, lstat, fstat, fstatat, statx, and their variants). %statfs Trace statfs, statfs64, statvfs, osf_statfs, and osf_statfs64 system calls. The same effect can be achieved with -e trace=/^(.*_)?statv?fs regular expression. %fstatfs Trace fstatfs, fstatfs64, fstatvfs, osf_fstatfs, and osf_fstatfs64 system calls. The same effect can be achieved with -e trace=/fstatv?fs regular expression. %%statfs Trace syscalls related to file system statistics (statfs-like, fstatfs-like, and ustat). The same effect can be achieved with -e trace=/statv?fs|fsstat|ustat regular expression. %clock Trace system calls that read or modify system clocks. %pure Trace syscalls that always succeed and have no arguments. Currently, this list includes arc_gettls(2), getdtablesize(2), getegid(2), getegid32(2), geteuid(2), geteuid32(2), getgid(2), getgid32(2), getpagesize(2), getpgrp(2), getpid(2), getppid(2), get_thread_area(2) (on architectures other than x86), gettid(2), get_tls(2), getuid(2), getuid32(2), getxgid(2), getxpid(2), getxuid(2), kern_features(2), and metag_get_tls(2) syscalls. The -c option is useful for determining which system calls might be useful to trace. For example, trace=open,close,read,write means to only trace those four system calls. Be careful when making inferences about the user/kernel boundary if only a subset of system calls are being monitored. The default is trace=all. -e trace-fd=set -e trace-fds=set -e fd=set -e fds=set --trace-fds=set Trace only the syscalls that operate on the specified subset of (non-negative) file descriptors. Note that usage of this option also filters out all the syscalls that do not operate on file descriptors at all. Applies in (inclusive) disjunction with the --trace-path option. -e signal=set -e signals=set -e s=set --signal=set Trace only the specified subset of signals. The default is signal=all. For example, signal=!SIGIO (or signal=!io) causes SIGIO signals not to be traced. -e status=set --status=set Print only system calls with the specified return status. The default is status=all. When using the status qualifier, because strace waits for system calls to return before deciding whether they should be printed or not, the traditional order of events may not be preserved anymore. If two system calls are executed by concurrent threads, strace will first print both the entry and exit of the first system call to exit, regardless of their respective entry time. The entry and exit of the second system call to exit will be printed afterwards. Here is an example when select(2) is called, but a different thread calls clock_gettime(2) before select(2) finishes: [pid 28779] 1130322148.939977 clock_gettime(CLOCK_REALTIME, {1130322148, 939977000}) = 0 [pid 28772] 1130322148.438139 select(4, [3], NULL, NULL, NULL) = 1 (in [3]) set can include the following elements: successful Trace system calls that returned without an error code. The -z option has the effect of status=successful. failed Trace system calls that returned with an error code. The -Z option has the effect of status=failed. unfinished Trace system calls that did not return. This might happen, for example, due to an execve call in a neighbour thread. unavailable Trace system calls that returned but strace failed to fetch the error status. detached Trace system calls for which strace detached before the return. -P path --trace-path=path Trace only system calls accessing path. Multiple -P options can be used to specify several paths. Applies in (inclusive) disjunction with the --trace-fds option. -z --successful-only Print only syscalls that returned without an error code. -Z --failed-only Print only syscalls that returned with an error code. Output format -a column --columns=column Align return values in a specific column (default column 40). -e abbrev=syscall_set -e a=syscall_set --abbrev=syscall_set Abbreviate the output from printing each member of large structures. The syntax of the syscall_set specification is the same as in the -e trace option. The default is abbrev=all. The -v option has the effect of abbrev=none. -e verbose=syscall_set -e v=syscall_set --verbose=syscall_set Dereference structures for the specified set of system calls. The syntax of the syscall_set specification is the same as in the -e trace option. The default is verbose=all. -e raw=syscall_set -e x=syscall_set --raw=syscall_set Print raw, undecoded arguments for the specified set of system calls. The syntax of the syscall_set specification is the same as in the -e trace option. This option has the effect of causing all arguments to be printed in hexadecimal. This is mostly useful if you don't trust the decoding or you need to know the actual numeric value of an argument. See also -X raw option. -e read=set -e reads=set -e r=set --read=set Perform a full hexadecimal and ASCII dump of all the data read from file descriptors listed in the specified set. For example, to see all input activity on file descriptors 3 and 5 use -e read=3,5. Note that this is independent from the normal tracing of the read(2) system call which is controlled by the option -e trace=read. -e write=set -e writes=set -e w=set --write=set Perform a full hexadecimal and ASCII dump of all the data written to file descriptors listed in the specified set. For example, to see all output activity on file descriptors 3 and 5 use -e write=3,5. Note that this is independent from the normal tracing of the write(2) system call which is controlled by the option -e trace=write. -e quiet=set -e silent=set -e silence=set -e q=set --quiet=set --silent=set --silence=set Suppress various information messages. The default is quiet=none. set can include the following elements: attach Suppress messages about attaching and detaching (\"[ Process NNNN attached ]\", \"[ Process NNNN detached ]\"). exit Suppress messages about process exits (\"+++ exited with SSS +++\"). path-resolution Suppress messages about resolution of paths provided via the -P option (\"Requested path \"...\" resolved into \"...\"\"). personality Suppress messages about process personality changes (\"[ Process PID=NNNN runs in PPP mode. ]\"). thread-execve superseded Suppress messages about process being superseded by execve(2) in another thread (\"+++ superseded by execve in pid NNNN +++\"). -e decode-fds=set --decode-fds=set Decode various information associated with file descriptors. The default is decode-fds=none. set can include the following elements: path Print file paths. Also enables printing of tracee's current working directory when AT_FDCWD constant is used. socket Print socket protocol-specific information, dev Print character/block device numbers. pidfd Print PIDs associated with pidfd file descriptors. signalfd Print signal masks associated with signalfd file descriptors. -e decode-pids=set --decode-pids=set Decode various information associated with process IDs (and also thread IDs, process group IDs, and session IDs). The default is decode-pids=none. set can include the following elements: comm Print command names associated with thread or process IDs. pidns Print thread, process, process group, and session IDs in strace's PID namespace if the tracee is in a different PID namespace. -e kvm=vcpu --kvm=vcpu Print the exit reason of kvm vcpu. Requires Linux kernel version 4.16.0 or higher. -i --instruction-pointer Print the instruction pointer at the time of the system call. -n --syscall-number Print the syscall number. -k --stack-traces Print the execution stack trace of the traced processes after each system call. -o filename --output=filename Write the trace output to the file filename rather than to stderr. filename.pid form is used if -ff option is supplied. If the argument begins with '|' or '!', the rest of the argument is treated as a command and all output is piped to it. This is convenient for piping the debugging output to a program without affecting the redirections of executed programs. The latter is not compatible with -ff option currently. -A --output-append-mode Open the file provided in the -o option in append mode. -q --quiet --quiet=attach,personality Suppress messages about attaching, detaching, and personality changes. This happens automatically when output is redirected to a file and the command is run directly instead of attaching. -qq --quiet=attach,personality,exit Suppress messages attaching, detaching, personality changes, and about process exit status. -qqq --quiet=all Suppress all suppressible messages (please refer to the -e quiet option description for the full list of suppressible messages). -r --relative-timestamps[=precision] Print a relative timestamp upon entry to each system call. This records the time difference between the beginning of successive system calls. precision can be one of s (for seconds), ms (milliseconds), us (microseconds), or ns (nanoseconds), and allows setting the precision of time value being printed. Default is us (microseconds). Note that since -r option uses the monotonic clock time for measuring time difference and not the wall clock time, its measurements can differ from the difference in time reported by the -t option. -s strsize --string-limit=strsize Specify the maximum string size to print (the default is 32). Note that filenames are not considered strings and are always printed in full. --absolute-timestamps[=[[format:]format],[[precision:]precision]] --timestamps[=[[format:]format],[[precision:]precision]] Prefix each line of the trace with the wall clock time in the specified format with the specified precision. format can be one of the following: none No time stamp is printed. Can be used to override the previous setting. time Wall clock time (strftime(3) format string is %T). unix Number of seconds since the epoch (strftime(3) format string is %s). precision can be one of s (for seconds), ms (milliseconds), us (microseconds), or ns (nanoseconds). Default arguments for the option are format:time,precision:s. -t --absolute-timestamps Prefix each line of the trace with the wall clock time. -tt --absolute-timestamps=precision:us If given twice, the time printed will include the microseconds. -ttt --absolute-timestamps=format:unix,precision:us If given thrice, the time printed will include the microseconds and the leading portion will be printed as the number of seconds since the epoch. -T --syscall-times[=precision] Show the time spent in system calls. This records the time difference between the beginning and the end of each system call. precision can be one of s (for seconds), ms (milliseconds), us (microseconds), or ns (nanoseconds), and allows setting the precision of time value being printed. Default is us (microseconds). -v --no-abbrev Print unabbreviated versions of environment, stat, termios, etc. calls. These structures are very common in calls and so the default behavior displays a reasonable subset of structure members. Use this option to get all of the gory details. --strings-in-hex[=option] Control usage of escape sequences with hexadecimal numbers in the printed strings. Normally (when no --strings-in-hex or -x option is supplied), escape sequences are used to print non-printable and non-ASCII characters (that is, characters with a character code less than 32 or greater than 127), or to disambiguate the output (so, for quotes and other characters that encase the printed string, for example, angle brackets, in case of file descriptor path output); for the former use case, unless it is a white space character that has a symbolic escape sequence defined in the C standard (that is, \u201c\\t\u201d for a horizontal tab, \u201c\\n\u201d for a newline, \u201c\\v\u201d for a vertical tab, \u201c\\f\u201d for a form feed page break, and \u201c\\r\u201d for a carriage return) are printed using escape sequences with numbers that correspond to their byte values, with octal number format being the default. option can be one of the following: none Hexadecimal numbers are not used in the output at all. When there is a need to emit an escape sequence, octal numbers are used. non-ascii-chars Hexadecimal numbers are used instead of octal in the escape sequences. non-ascii Strings that contain non-ASCII characters are printed using escape sequences with hexadecimal numbers. all All strings are printed using escape sequences with hexadecimal numbers. When the option is supplied without an argument, all is assumed. -x --strings-in-hex=non-ascii Print all non-ASCII strings in hexadecimal string format. -xx --strings-in-hex[=all] Print all strings in hexadecimal string format. -X format --const-print-style=format Set the format for printing of named constants and flags. Supported format values are: raw Raw number output, without decoding. abbrev Output a named constant or a set of flags instead of the raw number if they are found. This is the default strace behaviour. verbose Output both the raw value and the decoded string (as a comment). -y --decode-fds --decode-fds=path Print paths associated with file descriptor arguments and with the AT_FDCWD constant. -yy --decode-fds=all Print all available information associated with file descriptors: protocol-specific information associated with socket file descriptors, block/character device number associated with device file descriptors, and PIDs associated with pidfd file descriptors. --pidns-translation --decode-pids=pidns If strace and tracee are in different PID namespaces, print PIDs in strace's namespace, too. -Y --decode-pids=comm Print command names for PIDs. --secontext[=format] -e secontext=format When SELinux is available and is not disabled, print in square brackets SELinux contexts of processes, files, and descriptors. The format argument is a comma-separated list of items being one of the following: full Print the full context (user, role, type level and category). mismatch Also print the context recorded by the SELinux database in case the current context differs. The latter is printed after two exclamation marks (!!). The default value for --secontext is !full,mismatch which prints only the type instead of full context and doesn't check for context mismatches. Statistics -c --summary-only Count time, calls, and errors for each system call and report a summary on program exit, suppressing the regular output. This attempts to show system time (CPU time spent running in the kernel) independent of wall clock time. If -c is used with -f, only aggregate totals for all traced processes are kept. -C --summary Like -c but also print regular output while processes are running. -O overhead --summary-syscall-overhead=overhead Set the overhead for tracing system calls to overhead. This is useful for overriding the default heuristic for guessing how much time is spent in mere measuring when timing system calls using the -c option. The accuracy of the heuristic can be gauged by timing a given program run without tracing (using time(1)) and comparing the accumulated system call time to the total produced using -c. The format of overhead specification is described in section Time specification format description. -S sortby --summary-sort-by=sortby Sort the output of the histogram printed by the -c option by the specified criterion. Legal values are time (or time-percent or time-total or total-time), min-time (or shortest or time-min), max-time (or longest or time-max), avg-time (or time-avg), calls (or count), errors (or error), name (or syscall or syscall-name), and nothing (or none); default is time. -U columns --summary-columns=columns Configure a set (and order) of columns being shown in the call summary. The columns argument is a comma-separated list with items being one of the following: time-percent (or time) Percentage of cumulative time consumed by a specific system call. total-time (or time-total) Total system (or wall clock, if -w option is provided) time consumed by a specific system call. min-time (or shortest or time-min) Minimum observed call duration. max-time (or longest or time-max) Maximum observed call duration. avg-time (or time-avg) Average call duration. calls (or count) Call count. errors (or error) Error count. name (or syscall or syscall-name) Syscall name. The default value is time-percent,total-time,avg-time,calls,errors,name. If the name field is not supplied explicitly, it is added as the last column. -w --summary-wall-clock Summarise the time difference between the beginning and end of each system call. The default is to summarise the system time. Tampering -e inject=syscall_set[:error=errno|:retval=value][:signal=sig] [:syscall=syscall][:delay_enter=delay][:delay_exit=delay] [:poke_enter=@argN=DATAN,@argM=DATAM...] [:poke_exit=@argN=DATAN,@argM=DATAM...][:when=expr] --inject=syscall_set[:error=errno|:retval=value][:signal=sig] [:syscall=syscall][:delay_enter=delay][:delay_exit=delay] [:poke_enter=@argN=DATAN,@argM=DATAM...] [:poke_exit=@argN=DATAN,@argM=DATAM...][:when=expr] Perform syscall tampering for the specified set of syscalls. The syntax of the syscall_set specification is the same as in the -e trace option. At least one of error, retval, signal, delay_enter, delay_exit, poke_enter, or poke_exit options has to be specified. error and retval are mutually exclusive. If :error=errno option is specified, a fault is injected into a syscall invocation: the syscall number is replaced by -1 which corresponds to an invalid syscall (unless a syscall is specified with :syscall= option), and the error code is specified using a symbolic errno value like ENOSYS or a numeric value within 1..4095 range. If :retval=value option is specified, success injection is performed: the syscall number is replaced by -1, but a bogus success value is returned to the callee. If :signal=sig option is specified with either a symbolic value like SIGSEGV or a numeric value within 1..SIGRTMAX range, that signal is delivered on entering every syscall specified by the set. If :delay_enter=delay or :delay_exit=delay options are specified, delay injection is performed: the tracee is delayed by time period specified by delay on entering or exiting the syscall, respectively. The format of delay specification is described in section Time specification format description. If :poke_enter=@argN=DATAN,@argM=DATAM... or :poke_exit=@argN=DATAN,@argM=DATAM... options are specified, tracee's memory at locations, pointed to by system call arguments argN and argM (going from arg1 to arg7) is overwritten by data DATAN and DATAM (specified in hexadecimal format; for example :poke_enter=@arg1=0000DEAD0000BEEF). :poke_enter modifies memory on syscall enter, and :poke_exit - on exit. If :signal=sig option is specified without :error=errno, :retval=value or :delay_{enter,exit}=usecs options, then only a signal sig is delivered without a syscall fault or delay injection. Conversely, :error=errno or :retval=value option without :delay_enter=delay, :delay_exit=delay or :signal=sig options injects a fault without delivering a signal or injecting a delay, etc. If :signal=sig option is specified together with :error=errno or :retval=value, then both injection of a fault or success and signal delivery are performed. if :syscall=syscall option is specified, the corresponding syscall with no side effects is injected instead of -1. Currently, only \"pure\" (see -e trace=%pure description) syscalls can be specified there. Unless a :when=expr subexpression is specified, an injection is being made into every invocation of each syscall from the set. The format of the subexpression is: first[..last][+[step]] Number first stands for the first invocation number in the range, number last stands for the last invocation number in the range, and step stands for the step between two consecutive invocations. The following combinations are useful: first For every syscall from the set, perform an injection for the syscall invocation number first only. first..last For every syscall from the set, perform an injection for the syscall invocation number first and all subsequent invocations until the invocation number last (inclusive). first+ For every syscall from the set, perform injections for the syscall invocation number first and all subsequent invocations. first..last+ For every syscall from the set, perform injections for the syscall invocation number first and all subsequent invocations until the invocation number last (inclusive). first+step For every syscall from the set, perform injections for syscall invocations number first, first+step, first+step+step, and so on. first..last+step Same as the previous, but consider only syscall invocations with numbers up to last (inclusive). For example, to fail each third and subsequent chdir syscalls with ENOENT, use -e inject=chdir:error=ENOENT:when=3+. The valid range for numbers first and step is 1..65535, and for number last is 1..65534. An injection expression can contain only one error= or retval= specification, and only one signal= specification. If an injection expression contains multiple when= specifications, the last one takes precedence. Accounting of syscalls that are subject to injection is done per syscall and per tracee. Specification of syscall injection can be combined with other syscall filtering options, for example, -P /dev/urandom -e inject=file:error=ENOENT. -e fault=syscall_set[:error=errno][:when=expr] --fault=syscall_set[:error=errno][:when=expr] Perform syscall fault injection for the specified set of syscalls. This is equivalent to more generic -e inject= expression with default value of errno option set to ENOSYS. Miscellaneous -d --debug Show some debugging output of strace itself on the standard error. -F This option is deprecated. It is retained for backward compatibility only and may be removed in future releases. Usage of multiple instances of -F option is still equivalent to a single -f, and it is ignored at all if used along with one or more instances of -f option. -h --help Print the help summary. --seccomp-bpf Try to enable use of seccomp-bpf (see seccomp(2)) to have ptrace(2)-stops only when system calls that are being traced occur in the traced processes. This option has no effect unless -f/--follow-forks is also specified. --seccomp-bpf is not compatible with --syscall-limit and -b/--detach-on options. It is also not applicable to processes attached using -p/--attach option. An attempt to enable system calls filtering using seccomp-bpf may fail for various reasons, e.g. there are too many system calls to filter, the seccomp API is not available, or strace itself is being traced. In cases when seccomp-bpf filter setup failed, strace proceeds as usual and stops traced processes on every system call. --tips[=[[id:]id],[[format:]format]] Show strace tips, tricks, and tweaks before exit. id can be a non-negative integer number, which enables printing of specific tip, trick, or tweak (these ID are not guaranteed to be stable), or random (the default), in which case a random tip is printed. format can be one of the following: none No tip is printed. Can be used to override the previous setting. compact Print the tip just big enough to contain all the text. full Print the tip in its full glory. Default is id:random,format:compact. -V --version Print the version number of strace. Multiple instances of the option beyond specific threshold tend to increase Strauss awareness. Time specification format description Time values can be specified as a decimal floating point number (in a format accepted by strtod(3)), optionally followed by one of the following suffices that specify the unit of time: s (seconds), ms (milliseconds), us (microseconds), or ns (nanoseconds). If no suffix is specified, the value is interpreted as microseconds. The described format is used for -O, -e inject=delay_enter, and -e inject=delay_exit options. "
  },
  {
    "command": "cmp",
    "description": " Compare two files byte by byte. The optional SKIP1 and SKIP2 specify the number of bytes to skip at the beginning of each file (zero by default). Mandatory arguments to long options are mandatory for short options too. -b, --print-bytes print differing bytes -i, --ignore-initial=SKIP skip first SKIP bytes of both inputs -i, --ignore-initial=SKIP1:SKIP2 skip first SKIP1 bytes of FILE1 and first SKIP2 bytes of FILE2 -l, --verbose output byte numbers and differing byte values -n, --bytes=LIMIT compare at most LIMIT bytes -s, --quiet, --silent suppress all normal output --help display this help and exit -v, --version output version information and exit SKIP values may be followed by the following multiplicative suffixes: kB 1000, K 1024, MB 1,000,000, M 1,048,576, GB 1,000,000,000, G 1,073,741,824, and so on for T, P, E, Z, Y. If a FILE is '-' or missing, read standard input. Exit status is 0 if inputs are the same, 1 if different, 2 if trouble. "
  },
  {
    "command": "chmod",
    "description": " The chmod utility shall change any or all of the file mode bits of the file named by each file operand in the way specified by the mode operand. It is implementation-defined whether and how the chmod utility affects any alternate or additional file access control mechanism (see the Base Definitions volume of POSIX.1\u20102017, Section 4.5, File Access Permissions) being used for the specified file. Only a process whose effective user ID matches the user ID of the file, or a process with appropriate privileges, shall be permitted to change the file mode bits of a file. Upon successfully changing the file mode bits of a file, the chmod utility shall mark for update the last file status change timestamp of the file. The chmod utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -R Recursively change file mode bits. For each file operand that names a directory, chmod shall change the file mode bits of the directory and all files in the file hierarchy below it. "
  },
  {
    "command": "chsh",
    "description": " The chsh command changes the user login shell. This determines the name of the user's initial login command. A normal user may only change the login shell for her own account; the superuser may change the login shell for any account. The options which apply to the chsh command are: -h, --help Display help message and exit. -R, --root CHROOT_DIR Apply changes in the CHROOT_DIR directory and use the configuration files from the CHROOT_DIR directory. Only absolute paths are supported. -s, --shell SHELL The name of the user's new login shell. Setting this field to blank causes the system to select the default login shell. If the -s option is not selected, chsh operates in an interactive fashion, prompting the user with the current login shell. Enter the new value to change the shell, or leave the line blank to use the current one. The current shell is displayed between a pair of [ ] marks. "
  },
  {
    "command": "coredumpctl",
    "description": " coredumpctl is a tool that can be used to retrieve and process core dumps and metadata which were saved by systemd-coredump(8). The following options are understood: -h, --help Print a short help text and exit. --version Print a short version string and exit. --no-pager Do not pipe output into a pager. --no-legend Do not print the legend, i.e. column headers and the footer with hints. --json=MODE Shows output formatted as JSON. Expects one of \"short\" (for the shortest possible output without any redundant whitespace or line breaks), \"pretty\" (for a pretty version of the same, with indentation and line breaks) or \"off\" (to turn off JSON output, the default). -1 Show information of the most recent core dump only, instead of listing all known core dumps. Equivalent to --reverse -n 1. -n INT Show at most the specified number of entries. The specified parameter must be an integer greater or equal to 1. -S, --since Only print entries which are since the specified date. -U, --until Only print entries which are until the specified date. -r, --reverse Reverse output so that the newest entries are displayed first. -F FIELD, --field=FIELD Print all possible data values the specified field takes in matching core dump entries of the journal. -o FILE, --output=FILE Write the core to FILE. --debugger=DEBUGGER Use the given debugger for the debug command. If not given and $SYSTEMD_DEBUGGER is unset, then gdb(1) will be used. -A ARGS, --debugger-arguments=ARGS Pass the given ARGS as extra command line arguments to the debugger. Quote as appropriate when ARGS contain whitespace. (See Examples.) --file=GLOB Takes a file glob as an argument. If specified, coredumpctl will operate on the specified journal files matching GLOB instead of the default runtime and system journal paths. May be specified multiple times, in which case files will be suitably interleaved. -D DIR, --directory=DIR Use the journal files in the specified DIR. --root=ROOT Use root directory ROOT when searching for coredumps. --image=image Takes a path to a disk image file or block device node. If specified, all operations are applied to file system in the indicated disk image. This option is similar to --root=, but operates on file systems stored in disk images or block devices. The disk image should either contain just a file system or a set of file systems within a GPT partition table, following the Discoverable Partitions Specification[1]. For further information on supported disk images, see systemd-nspawn(1)'s switch of the same name. --image-policy=policy Takes an image policy string as argument, as per systemd.image-policy(7). The policy is enforced when operating on the disk image specified via --image=, see above. If not specified defaults to the \"*\" policy, i.e. all recognized file systems in the image are used. -q, --quiet Suppresses informational messages about lack of access to journal files and possible in-flight coredumps. --all Look at all available journal files in /var/log/journal/ (excluding journal namespaces) instead of only local ones. "
  },
  {
    "command": "git-check-mailmap",
    "description": " For each \u201cName <user@host>\u201d or \u201c<user@host>\u201d from the command-line or standard input (when using --stdin), look up the person\u2019s canonical name and email address (see \"Mapping Authors\" below). If found, print them; otherwise print the input as-is. --stdin Read contacts, one per line, from the standard input after exhausting contacts provided on the command-line. "
  },
  {
    "command": "top",
    "description": " The top program provides a dynamic real-time view of a running system. It can display system summary information as well as a list of processes or threads currently being managed by the Linux kernel. The types of system summary information shown and the types, order and size of information displayed for processes are all user configurable and that configuration can be made persistent across restarts. The program provides a limited interactive interface for process manipulation as well as a much more extensive interface for personal configuration -- encompassing every aspect of its operation. And while top is referred to throughout this document, you are free to name the program anything you wish. That new name, possibly an alias, will then be reflected on top's display and used when reading and writing a configuration file. "
  },
  {
    "command": "unshare",
    "description": " The unshare command creates new namespaces (as specified by the command-line options described below) and then executes the specified program. If program is not given, then \"${SHELL}\" is run (default: /bin/sh). By default, a new namespace persists only as long as it has member processes. A new namespace can be made persistent even when it has no member processes by bind mounting /proc/pid/ns/type files to a filesystem path. A namespace that has been made persistent in this way can subsequently be entered with nsenter(1) even after the program terminates (except PID namespaces where a permanently running init process is required). Once a persistent namespace is no longer needed, it can be unpersisted by using umount(8) to remove the bind mount. See the EXAMPLES section for more details. unshare since util-linux version 2.36 uses /proc/[pid]/ns/pid_for_children and /proc/[pid]/ns/time_for_children files for persistent PID and TIME namespaces. This change requires Linux kernel 4.17 or newer. The following types of namespaces can be created with unshare: mount namespace Mounting and unmounting filesystems will not affect the rest of the system, except for filesystems which are explicitly marked as shared (with mount --make-shared; see /proc/self/mountinfo or findmnt -o+PROPAGATION for the shared flags). For further details, see mount_namespaces(7). unshare since util-linux version 2.27 automatically sets propagation to private in a new mount namespace to make sure that the new namespace is really unshared. It\u2019s possible to disable this feature with option --propagation unchanged. Note that private is the kernel default. UTS namespace Setting hostname or domainname will not affect the rest of the system. For further details, see uts_namespaces(7). IPC namespace The process will have an independent namespace for POSIX message queues as well as System V message queues, semaphore sets and shared memory segments. For further details, see ipc_namespaces(7). network namespace The process will have independent IPv4 and IPv6 stacks, IP routing tables, firewall rules, the /proc/net and /sys/class/net directory trees, sockets, etc. For further details, see network_namespaces(7). PID namespace Children will have a distinct set of PID-to-process mappings from their parent. For further details, see pid_namespaces(7). cgroup namespace The process will have a virtualized view of /proc/self/cgroup, and new cgroup mounts will be rooted at the namespace cgroup root. For further details, see cgroup_namespaces(7). user namespace The process will have a distinct set of UIDs, GIDs and capabilities. For further details, see user_namespaces(7). time namespace The process can have a distinct view of CLOCK_MONOTONIC and/or CLOCK_BOOTTIME which can be changed using /proc/self/timens_offsets. For further details, see time_namespaces(7). -i, --ipc[=file] Create a new IPC namespace. If file is specified, then the namespace is made persistent by creating a bind mount at file. -m, --mount[=file] Create a new mount namespace. If file is specified, then the namespace is made persistent by creating a bind mount at file. Note that file must be located on a mount whose propagation type is not shared (or an error results). Use the command findmnt -o+PROPAGATION when not sure about the current setting. See also the examples below. -n, --net[=file] Create a new network namespace. If file is specified, then the namespace is made persistent by creating a bind mount at file. -p, --pid[=file] Create a new PID namespace. If file is specified, then the namespace is made persistent by creating a bind mount at file. (Creation of a persistent PID namespace will fail if the --fork option is not also specified.) See also the --fork and --mount-proc options. -u, --uts[=file] Create a new UTS namespace. If file is specified, then the namespace is made persistent by creating a bind mount at file. -U, --user[=file] Create a new user namespace. If file is specified, then the namespace is made persistent by creating a bind mount at file. -C, --cgroup[=file] Create a new cgroup namespace. If file is specified, then the namespace is made persistent by creating a bind mount at file. -T, --time[=file] Create a new time namespace. If file is specified, then the namespace is made persistent by creating a bind mount at file. The --monotonic and --boottime options can be used to specify the corresponding offset in the time namespace. -f, --fork Fork the specified program as a child process of unshare rather than running it directly. This is useful when creating a new PID namespace. Note that when unshare is waiting for the child process, then it ignores SIGINT and SIGTERM and does not forward any signals to the child. It is necessary to send signals to the child process. --keep-caps When the --user option is given, ensure that capabilities granted in the user namespace are preserved in the child process. --kill-child[=signame] When unshare terminates, have signame be sent to the forked child process. Combined with --pid this allows for an easy and reliable killing of the entire process tree below unshare. If not given, signame defaults to SIGKILL. This option implies --fork. --mount-proc[=mountpoint] Just before running the program, mount the proc filesystem at mountpoint (default is /proc). This is useful when creating a new PID namespace. It also implies creating a new mount namespace since the /proc mount would otherwise mess up existing programs on the system. The new proc filesystem is explicitly mounted as private (with MS_PRIVATE|MS_REC). --map-user=uid|name Run the program only after the current effective user ID has been mapped to uid. If this option is specified multiple times, the last occurrence takes precedence. This option implies --user. --map-users=inneruid:outeruid:count|auto Run the program only after the block of user IDs of size count beginning at outeruid has been mapped to the block of user IDs beginning at inneruid. This mapping is created with newuidmap(1). If the range of user IDs overlaps with the mapping specified by --map-user, then a \"hole\" will be removed from the mapping. This may result in the highest user ID of the mapping not being mapped. The special value auto will map the first block of user IDs owned by the effective user from /etc/subuid to a block starting at user ID 0. If this option is specified multiple times, the last occurrence takes precedence. This option implies --user. Before util-linux version 2.39, this option expected a comma-separated argument of the form outeruid,inneruid,count but that format is now deprecated for consistency with the ordering used in /proc/[pid]/uid_map and the X-mount.idmap mount option. --map-group=gid|name Run the program only after the current effective group ID has been mapped to gid. If this option is specified multiple times, the last occurrence takes precedence. This option implies --setgroups=deny and --user. --map-groups=innergid:outergid:count|auto Run the program only after the block of group IDs of size count beginning at outergid has been mapped to the block of group IDs beginning at innergid. This mapping is created with newgidmap(1). If the range of group IDs overlaps with the mapping specified by --map-group, then a \"hole\" will be removed from the mapping. This may result in the highest group ID of the mapping not being mapped. The special value auto will map the first block of user IDs owned by the effective user from /etc/subgid to a block starting at group ID 0. If this option is specified multiple times, the last occurrence takes precedence. This option implies --user. Before util-linux version 2.39, this option expected a comma-separated argument of the form outergid,innergid,count but that format is now deprecated for consistency with the ordering used in /proc/[pid]/gid_map and the X-mount.idmap mount option. --map-auto Map the first block of user IDs owned by the effective user from /etc/subuid to a block starting at user ID 0. In the same manner, also map the first block of group IDs owned by the effective group from /etc/subgid to a block starting at group ID 0. This option is intended to handle the common case where the first block of subordinate user and group IDs can map the whole user and group ID space. This option is equivalent to specifying --map-users=auto and --map-groups=auto. -r, --map-root-user Run the program only after the current effective user and group IDs have been mapped to the superuser UID and GID in the newly created user namespace. This makes it possible to conveniently gain capabilities needed to manage various aspects of the newly created namespaces (such as configuring interfaces in the network namespace or mounting filesystems in the mount namespace) even when run unprivileged. As a mere convenience feature, it does not support more sophisticated use cases, such as mapping multiple ranges of UIDs and GIDs. This option implies --setgroups=deny and --user. This option is equivalent to --map-user=0 --map-group=0. -c, --map-current-user Run the program only after the current effective user and group IDs have been mapped to the same UID and GID in the newly created user namespace. This option implies --setgroups=deny and --user. This option is equivalent to --map-user=$(id -ru) --map-group=$(id -rg). --propagation private|shared|slave|unchanged Recursively set the mount propagation flag in the new mount namespace. The default is to set the propagation to private. It is possible to disable this feature with the argument unchanged. The option is silently ignored when the mount namespace (--mount) is not requested. --setgroups allow|deny Allow or deny the setgroups(2) system call in a user namespace. To be able to call setgroups(2), the calling process must at least have CAP_SETGID. But since Linux 3.19 a further restriction applies: the kernel gives permission to call setgroups(2) only after the GID map (/proc/pid*/gid_map*) has been set. The GID map is writable by root when setgroups(2) is enabled (i.e., allow, the default), and the GID map becomes writable by unprivileged processes when setgroups(2) is permanently disabled (with deny). -R, --root=dir run the command with root directory set to dir. -w, --wd=dir change working directory to dir. -S, --setuid uid Set the user ID which will be used in the entered namespace. -G, --setgid gid Set the group ID which will be used in the entered namespace and drop supplementary groups. --monotonic offset Set the offset of CLOCK_MONOTONIC which will be used in the entered time namespace. This option requires unsharing a time namespace with --time. --boottime offset Set the offset of CLOCK_BOOTTIME which will be used in the entered time namespace. This option requires unsharing a time namespace with --time. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "git-switch",
    "description": " Switch to a specified branch. The working tree and the index are updated to match the branch. All new commits will be added to the tip of this branch. Optionally a new branch could be created with either -c, -C, automatically from a remote branch of same name (see --guess), or detach the working tree from any branch with --detach, along with switching. Switching branches does not require a clean index and working tree (i.e. no differences compared to HEAD). The operation is aborted however if the operation leads to loss of local changes, unless told otherwise with --discard-changes or --merge. THIS COMMAND IS EXPERIMENTAL. THE BEHAVIOR MAY CHANGE. <branch> Branch to switch to. <new-branch> Name for the new branch. <start-point> The starting point for the new branch. Specifying a <start-point> allows you to create a branch based on some other point in history than where HEAD currently points. (Or, in the case of --detach, allows you to inspect and detach from some other point.) You can use the @{-N} syntax to refer to the N-th last branch/commit switched to using \"git switch\" or \"git checkout\" operation. You may also specify - which is synonymous to @{-1}. This is often used to switch quickly between two branches, or to undo a branch switch by mistake. As a special case, you may use A...B as a shortcut for the merge base of A and B if there is exactly one merge base. You can leave out at most one of A and B, in which case it defaults to HEAD. -c <new-branch>, --create <new-branch> Create a new branch named <new-branch> starting at <start-point> before switching to the branch. This is a convenient shortcut for: $ git branch <new-branch> $ git switch <new-branch> -C <new-branch>, --force-create <new-branch> Similar to --create except that if <new-branch> already exists, it will be reset to <start-point>. This is a convenient shortcut for: $ git branch -f <new-branch> $ git switch <new-branch> -d, --detach Switch to a commit for inspection and discardable experiments. See the \"DETACHED HEAD\" section in git-checkout(1) for details. --guess, --no-guess If <branch> is not found but there does exist a tracking branch in exactly one remote (call it <remote>) with a matching name, treat as equivalent to $ git switch -c <branch> --track <remote>/<branch> If the branch exists in multiple remotes and one of them is named by the checkout.defaultRemote configuration variable, we\u2019ll use that one for the purposes of disambiguation, even if the <branch> isn\u2019t unique across all remotes. Set it to e.g. checkout.defaultRemote=origin to always checkout remote branches from there if <branch> is ambiguous but exists on the origin remote. See also checkout.defaultRemote in git-config(1). --guess is the default behavior. Use --no-guess to disable it. The default behavior can be set via the checkout.guess configuration variable. -f, --force An alias for --discard-changes. --discard-changes Proceed even if the index or the working tree differs from HEAD. Both the index and working tree are restored to match the switching target. If --recurse-submodules is specified, submodule content is also restored to match the switching target. This is used to throw away local changes. -m, --merge If you have local modifications to one or more files that are different between the current branch and the branch to which you are switching, the command refuses to switch branches in order to preserve your modifications in context. However, with this option, a three-way merge between the current branch, your working tree contents, and the new branch is done, and you will be on the new branch. When a merge conflict happens, the index entries for conflicting paths are left unmerged, and you need to resolve the conflicts and mark the resolved paths with git add (or git rm if the merge should result in deletion of the path). --conflict=<style> The same as --merge option above, but changes the way the conflicting hunks are presented, overriding the merge.conflictStyle configuration variable. Possible values are \"merge\" (default), \"diff3\", and \"zdiff3\". -q, --quiet Quiet, suppress feedback messages. --progress, --no-progress Progress status is reported on the standard error stream by default when it is attached to a terminal, unless --quiet is specified. This flag enables progress reporting even if not attached to a terminal, regardless of --quiet. -t, --track [direct|inherit] When creating a new branch, set up \"upstream\" configuration. -c is implied. See --track in git-branch(1) for details. If no -c option is given, the name of the new branch will be derived from the remote-tracking branch, by looking at the local part of the refspec configured for the corresponding remote, and then stripping the initial part up to the \"*\". This would tell us to use hack as the local branch when branching off of origin/hack (or remotes/origin/hack, or even refs/remotes/origin/hack). If the given name has no slash, or the above guessing results in an empty name, the guessing is aborted. You can explicitly give a name with -c in such a case. --no-track Do not set up \"upstream\" configuration, even if the branch.autoSetupMerge configuration variable is true. --orphan <new-branch> Create a new orphan branch, named <new-branch>. All tracked files are removed. --ignore-other-worktrees git switch refuses when the wanted ref is already checked out by another worktree. This option makes it check the ref out anyway. In other words, the ref can be held by more than one worktree. --recurse-submodules, --no-recurse-submodules Using --recurse-submodules will update the content of all active submodules according to the commit recorded in the superproject. If nothing (or --no-recurse-submodules) is used, submodules working trees will not be updated. Just like git-submodule(1), this will detach HEAD of the submodules. "
  },
  {
    "command": "dpkg",
    "description": " dpkg is a medium-level tool to install, build, remove and manage Debian packages. The primary and more user-friendly front-end for dpkg as a CLI (command-line interface) is apt(8) and as a TUI (terminal user interface) is aptitude(8). dpkg itself is controlled entirely via command line parameters, which consist of exactly one action and zero or more options. The action-parameter tells dpkg what to do and options control the behavior of the action in some way. dpkg can also be used as a front-end to dpkg-deb(1) and dpkg-query(1). The list of supported actions can be found later on in the ACTIONS section. If any such action is encountered dpkg just runs dpkg-deb or dpkg-query with the parameters given to it, but no specific options are currently passed to them, to use any such option the back-ends need to be called directly. All options can be specified both on the command line and in the dpkg configuration file /usr/local/etc/dpkg/dpkg.cfg or fragment files (with names matching this shell pattern '[0-9a-zA-Z_-]*') on the configuration directory /usr/local/etc/dpkg/dpkg.cfg.d/. Each line in the configuration file is either an option (exactly the same as the command line option but without leading hyphens) or a comment (if it starts with a \u2018#\u2019). --abort-after=number Change after how many errors dpkg will abort. The default is 50. -B, --auto-deconfigure When a package is removed, there is a possibility that another installed package depended on the removed package. Specifying this option will cause automatic deconfiguration of the package which depended on the removed package. -Doctal, --debug=octal Switch debugging on. octal is formed by bitwise-ORing desired values together from the list below (note that these values may change in future releases). -Dh or --debug=help display these debugging values. Number Description 1 Generally helpful progress information 2 Invocation and status of maintainer scripts 10 Output for each file processed 100 Lots of output for each file processed 20 Output for each configuration file 200 Lots of output for each configuration file 40 Dependencies and conflicts 400 Lots of dependencies/conflicts output 10000 Trigger activation and processing 20000 Lots of output regarding triggers 40000 Silly amounts of output regarding triggers 1000 Lots of drivel about for example the dpkg/info dir 2000 Insane amounts of drivel --force-things --no-force-things, --refuse-things Force or refuse (no-force and refuse mean the same thing) to do some things. things is a comma separated list of things specified below. --force-help displays a message describing them. Things marked with (*) are forced by default. Warning: These options are mostly intended to be used by experts only. Using them without fully understanding their effects may break your whole system. all: Turns on (or off) all force options. downgrade(*): Install a package, even if newer version of it is already installed. Warning: At present dpkg does not do any dependency checking on downgrades and therefore will not warn you if the downgrade breaks the dependency of some other package. This can have serious side effects, downgrading essential system components can even make your whole system unusable. Use with care. configure-any: Configure also any unpacked but unconfigured packages on which the current package depends. hold: Allow automatic installs, upgrades or removals of packages even when marked to be on \u201chold\u201d. Note: When these actions are requested explicitly, the \u201chold\u201d package selection state always gets ignored. remove-reinstreq: Remove a package, even if it's broken and marked to require reinstallation. This may, for example, cause parts of the package to remain on the system, which will then be forgotten by dpkg. remove-protected: Remove, even if the package is considered protected (since dpkg 1.20.1). Protected packages contain mostly important system boot infrastructure or are used for custom system- local meta-packages. Removing them might cause the whole system to be unable to boot or lose required functionality to operate, so use with caution. remove-essential: Remove, even if the package is considered essential. Essential packages contain mostly very basic Unix commands, required for the packaging system, for the operation of the system in general or during boot (although the latter should be converted to protected packages instead). Removing them might cause the whole system to stop working, so use with caution. depends: Turn all dependency problems into warnings. This affects the Pre-Depends and Depends fields. depends-version: Don't care about versions when checking dependencies. This affects the Pre-Depends and Depends fields. breaks: Install, even if this would break another package (since dpkg 1.14.6). This affects the Breaks field. conflicts: Install, even if it conflicts with another package. This is dangerous, for it will usually cause overwriting of some files. This affects the Conflicts field. confmiss: Always install the missing conffile without prompting. This is dangerous, since it means not preserving a change (removing) made to the file. confnew: If a conffile has been modified and the version in the package did change, always install the new version without prompting, unless the --force-confdef is also specified, in which case the default action is preferred. confold: If a conffile has been modified and the version in the package did change, always keep the old version without prompting, unless the --force-confdef is also specified, in which case the default action is preferred. confdef: If a conffile has been modified and the version in the package did change, always choose the default action without prompting. If there is no default action it will stop to ask the user unless --force-confnew or --force-confold is also been given, in which case it will use that to decide the final action. confask: If a conffile has been modified always offer to replace it with the version in the package, even if the version in the package did not change (since dpkg 1.15.8). If any of --force-confnew, --force-confold, or --force-confdef is also given, it will be used to decide the final action. overwrite: Overwrite one package's file with another's file. overwrite-dir: Overwrite one package's directory with another's file. overwrite-diverted: Overwrite a diverted file with an undiverted version. statoverride-add: Overwrite an existing stat override when adding it (since dpkg 1.19.5). statoverride-remove: Ignore a missing stat override when removing it (since dpkg 1.19.5). security-mac(*): Use platform-specific Mandatory Access Controls (MAC) based security when installing files into the filesystem (since dpkg 1.19.5). On Linux systems the implementation uses SELinux. unsafe-io: Do not perform safe I/O operations when unpacking (since dpkg 1.15.8.6). Currently this implies not performing file system syncs before file renames, which is known to cause substantial performance degradation on some file systems, unfortunately the ones that require the safe I/O on the first place due to their unreliable behaviour causing zero- length files on abrupt system crashes. Note: For ext4, the main offender, consider using instead the mount option nodelalloc, which will fix both the performance degradation and the data safety issues, the latter by making the file system not produce zero-length files on abrupt system crashes with any software not doing syncs before atomic renames. Warning: Using this option might improve performance at the cost of losing data, use with care. script-chrootless: Run maintainer scripts without chroot(2)ing into instdir even if the package does not support this mode of operation (since dpkg 1.18.5). Warning: This can destroy your host system, use with extreme care. architecture: Process even packages with wrong or no architecture. bad-version: Process even packages with wrong versions (since dpkg 1.16.1). bad-path: PATH is missing important programs, so problems are likely. not-root: Try to (de)install things even when not root. bad-verify: Install a package even if it fails authenticity check. --ignore-depends=package,... Ignore dependency-checking for specified packages (actually, checking is performed, but only warnings about conflicts are given, nothing else). This affects the Pre-Depends, Depends and Breaks fields. --no-act, --dry-run, --simulate Do everything which is supposed to be done, but don't write any changes. This is used to see what would happen with the specified action, without actually modifying anything. Be sure to give --no-act before the action-parameter, or you might end up with undesirable results. (e.g. dpkg --purge foo --no-act will first purge package \u201cfoo\u201d and then try to purge package \u201d--no-act\u201d, even though you probably expected it to actually do nothing). -R, --recursive Recursively handle all regular files matching pattern *.deb found at specified directories and all of its subdirectories. This can be used with -i, -A, --install, --unpack and --record-avail actions. -G Don't install a package if a newer version of the same package is already installed. This is an alias of --refuse-downgrade. --admindir=dir Set the administrative directory to directory. This directory contains many files that give information about status of installed or uninstalled packages, etc. Defaults to \u00ab/usr/local/var/lib/dpkg\u00bb if DPKG_ADMINDIR has not been set. --instdir=dir Set the installation directory, which refers to the directory where packages are to be installed. instdir is also the directory passed to chroot(2) before running package's installation scripts, which means that the scripts see instdir as a root directory. Defaults to \u00ab/\u00bb. --root=dir Set the root directory to directory, which sets the installation directory to \u00abdir\u00bb and the administrative directory to \u00abdir/usr/local/var/lib/dpkg\u00bb. -O, --selected-only Only process the packages that are selected for installation. The actual marking is done with dselect or by dpkg, when it handles packages. For example, when a package is removed, it will be marked selected for deinstallation. -E, --skip-same-version Don't install the package if the same version and architecture of the package is already installed. Since dpkg 1.21.10, the architecture is also taken into account, which makes it possible to cross-grade packages or install additional co-installable instances with the same version, but different architecture. --pre-invoke=command --post-invoke=command Set an invoke hook command to be run via \u201csh -c\u201d before or after the dpkg run for the unpack, configure, install, triggers-only, remove, purge, add-architecture and remove- architecture dpkg actions (since dpkg 1.15.4; add- architecture and remove-architecture actions since dpkg 1.17.19). This option can be specified multiple times. The order the options are specified is preserved, with the ones from the configuration files taking precedence. The environment variable DPKG_HOOK_ACTION is set for the hooks to the current dpkg action. Note: Front-ends might call dpkg several times per invocation, which might run the hooks more times than expected. --path-exclude=glob-pattern --path-include=glob-pattern Set glob-pattern as a path filter, either by excluding or re- including previously excluded paths matching the specified patterns during install (since dpkg 1.15.8). Warning: Take into account that depending on the excluded paths you might completely break your system, use with caution. The glob patterns use the same wildcards used in the shell, were \u2018*\u2019 matches any sequence of characters, including the empty string and also \u2018/\u2019. For example, \u00ab/usr/*/READ*\u00bb matches \u00ab/usr/share/doc/package/README\u00bb. As usual, \u2018?\u2019 matches any single character (again, including \u2018/\u2019). And \u2018[\u2019 starts a character class, which can contain a list of characters, ranges and complementations. See glob(7) for detailed information about globbing. Note: The current implementation might re-include more directories and symlinks than needed, in particular when there is a more specific re- inclusion, to be on the safe side and avoid possible unpack failures; future work might fix this. This can be used to remove all paths except some particular ones; a typical case is: --path-exclude=/usr/share/doc/* --path-include=/usr/share/doc/*/copyright to remove all documentation files except the copyright files. These two options can be specified multiple times, and interleaved with each other. Both are processed in the given order, with the last rule that matches a file name making the decision. The filters are applied when unpacking the binary packages, and as such only have knowledge of the type of object currently being filtered (e.g. a normal file or a directory) and have not visibility of what objects will come next. Because these filters have side effects (in contrast to find(1) filters), excluding an exact pathname that happens to be a directory object like /usr/share/doc will not have the desired result, and only that pathname will be excluded (which could be automatically reincluded if the code sees the need). Any subsequent files contained within that directory will fail to unpack. Hint: make sure the globs are not expanded by your shell. --verify-format format-name Sets the output format for the --verify command (since dpkg 1.17.2). The only currently supported output format is rpm, which consists of a line for every path that failed any check. These lines have the following format: missing [c] pathname [(error-message)] ??5?????? [c] pathname The first 9 characters are used to report the checks result, either a literal missing when the file is not present or its metadata cannot be fetched, or one of the following special characters that report the result for each check: \u2018?\u2019 Implies the check could not be done (lack of support, file permissions, etc). \u2018.\u2019 Implies the check passed. \u2018A-Za-z0-9\u2019 Implies a specific check failed. The following positions and alphanumeric characters are currently supported: 1 \u2018?\u2019 These checks are currently not supported, will always be \u2018?\u2019. 2 \u2018M\u2019 The file mode check failed (since dpkg 1.21.0). Because pathname metadata is currently not tracked, this check can only be partially emulated via a very simple heuristic for pathnames that have a known digest, which implies they should be regular files, where the check will fail if the pathname is not a regular file on the filesystem. This check will currently never succeed as it does not have enough information available. 3 \u20185\u2019 The digest check failed, which means the file contents have changed. 4-9 \u2018?\u2019 These checks are currently not supported, will always be \u2018?\u2019. The line is followed by a space and an attribute character. The following attribute character is supported: \u2018c\u2019 The pathname is a conffile. Finally followed by another space and the pathname. In case the entry was of the missing type, and the file was not actually present on the filesystem, then the line is followed by a space and the error message enclosed within parenthesis. --status-fd n Send machine-readable package status and progress information to file descriptor n. This option can be specified multiple times. The information is generally one record per line, in one of the following forms: status: package: status Package status changed; status is as in the status file. status: package : error : extended-error-message An error occurred. Any possible newlines in extended- error-message will be converted to spaces before output. status: file : conffile-prompt : 'real-old' 'real-new' useredited distedited User is being asked a conffile question. processing: stage: package Sent just before a processing stage starts. stage is one of upgrade, install (both sent before unpacking), configure, trigproc, disappear, remove, purge. --status-logger=command Send machine-readable package status and progress information to the shell command's standard input, to be run via \u201csh -c\u201d (since dpkg 1.16.0). This option can be specified multiple times. The output format used is the same as in --status-fd. --log=filename Log status change updates and actions to filename, instead of the default /usr/local/var/log/dpkg.log. If this option is given multiple times, the last filename is used. Log messages are of the form: YYYY-MM-DD HH:MM:SS startup type command For each dpkg invocation where type is archives (with a command of unpack or install) or packages (with a command of configure, triggers-only, remove or purge). YYYY-MM-DD HH:MM:SS status state pkg installed-version For status change updates. YYYY-MM-DD HH:MM:SS action pkg installed-version available- version For actions where action is one of install, upgrade, configure, trigproc, disappear, remove or purge. YYYY-MM-DD HH:MM:SS conffile filename decision For conffile changes where decision is either install or keep. --robot Use a machine-readable output format. This provides an interface for programs that need to parse the output of some of the commands that do not otherwise emit a machine-readable output format. No localization will be used, and the output will be modified to make it easier to parse. The only currently supported command is --version. --no-pager Disables the use of any pager when showing information (since dpkg 1.19.2). --no-debsig Do not try to verify package signatures. --no-triggers Do not run any triggers in this run (since dpkg 1.14.17), but activations will still be recorded. If used with --configure package or --triggers-only package then the named package postinst will still be run even if only a triggers run is needed. Use of this option may leave packages in the improper triggers-awaited and triggers-pending states. This can be fixed later by running: dpkg --configure --pending. --triggers Cancels a previous --no-triggers (since dpkg 1.14.17). "
  },
  {
    "command": "m4",
    "description": " The m4 utility is a macro processor that shall read one or more text files, process them according to their included macro statements, and write the results to standard output. The m4 utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except that the order of the -D and -U options shall be significant, and options can be interspersed with operands. The following options shall be supported: -s Enable line synchronization output for the c99 preprocessor phase (that is, #line directives). -D name[=val] Define name to val or to null if =val is omitted. -U name Undefine name. "
  },
  {
    "command": "git-check-ref-format",
    "description": " Checks if a given refname is acceptable, and exits with a non-zero status if it is not. A reference is used in Git to specify branches and tags. A branch head is stored in the refs/heads hierarchy, while a tag is stored in the refs/tags hierarchy of the ref namespace (typically in $GIT_DIR/refs/heads and $GIT_DIR/refs/tags directories or, as entries in file $GIT_DIR/packed-refs if refs are packed by git gc). Git imposes the following rules on how references are named: 1. They can include slash / for hierarchical (directory) grouping, but no slash-separated component can begin with a dot . or end with the sequence .lock. 2. They must contain at least one /. This enforces the presence of a category like heads/, tags/ etc. but the actual names are not restricted. If the --allow-onelevel option is used, this rule is waived. 3. They cannot have two consecutive dots .. anywhere. 4. They cannot have ASCII control characters (i.e. bytes whose values are lower than \\040, or \\177 DEL), space, tilde ~, caret ^, or colon : anywhere. 5. They cannot have question-mark ?, asterisk *, or open bracket [ anywhere. See the --refspec-pattern option below for an exception to this rule. 6. They cannot begin or end with a slash / or contain multiple consecutive slashes (see the --normalize option below for an exception to this rule) 7. They cannot end with a dot .. 8. They cannot contain a sequence @{. 9. They cannot be the single character @. 10. They cannot contain a \\. These rules make it easy for shell script based tools to parse reference names, pathname expansion by the shell when a reference name is used unquoted (by mistake), and also avoid ambiguities in certain reference name expressions (see gitrevisions(7)): 1. A double-dot .. is often used as in ref1..ref2, and in some contexts this notation means ^ref1 ref2 (i.e. not in ref1 and in ref2). 2. A tilde ~ and caret ^ are used to introduce the postfix nth parent and peel onion operation. 3. A colon : is used as in srcref:dstref to mean \"use srcref\u2019s value and store it in dstref\" in fetch and push operations. It may also be used to select a specific object such as with git cat-file: \"git cat-file blob v1.3.3:refs.c\". 4. at-open-brace @{ is used as a notation to access a reflog entry. With the --branch option, the command takes a name and checks if it can be used as a valid branch name (e.g. when creating a new branch). But be cautious when using the previous checkout syntax that may refer to a detached HEAD state. The rule git check-ref-format --branch $name implements may be stricter than what git check-ref-format refs/heads/$name says (e.g. a dash may appear at the beginning of a ref component, but it is explicitly forbidden at the beginning of a branch name). When run with --branch option in a repository, the input is first expanded for the \u201cprevious checkout syntax\u201d @{-n}. For example, @{-1} is a way to refer the last thing that was checked out using \"git switch\" or \"git checkout\" operation. This option should be used by porcelains to accept this syntax anywhere a branch name is expected, so they can act as if you typed the branch name. As an exception note that, the \u201cprevious checkout operation\u201d might result in a commit object name when the N-th last thing checked out was not a branch. --[no-]allow-onelevel Controls whether one-level refnames are accepted (i.e., refnames that do not contain multiple /-separated components). The default is --no-allow-onelevel. --refspec-pattern Interpret <refname> as a reference name pattern for a refspec (as used with remote repositories). If this option is enabled, <refname> is allowed to contain a single * in the refspec (e.g., foo/bar*/baz or foo/bar*baz/ but not foo/bar*/baz*). --normalize Normalize refname by removing any leading slash (/) characters and collapsing runs of adjacent slashes between name components into a single slash. If the normalized refname is valid then print it to standard output and exit with a status of 0, otherwise exit with a non-zero status. (--print is a deprecated way to spell --normalize.) "
  },
  {
    "command": "date",
    "description": " The date utility shall write the date and time to standard output or attempt to set the system date and time. By default, the current date and time shall be written. If an operand beginning with '+' is specified, the output format of date shall be controlled by the conversion specifications and other text in the operand. The date utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -u Perform operations as if the TZ environment variable was set to the string \"UTC0\", or its equivalent historical value of \"GMT0\". Otherwise, date shall use the timezone indicated by the TZ environment variable or the system default if that variable is unset or null. "
  },
  {
    "command": "git-rebase",
    "description": " If <branch> is specified, git rebase will perform an automatic git switch <branch> before doing anything else. Otherwise it remains on the current branch. If <upstream> is not specified, the upstream configured in branch.<name>.remote and branch.<name>.merge options will be used (see git-config(1) for details) and the --fork-point option is assumed. If you are currently not on any branch or if the current branch does not have a configured upstream, the rebase will abort. All changes made by commits in the current branch but that are not in <upstream> are saved to a temporary area. This is the same set of commits that would be shown by git log <upstream>..HEAD; or by git log 'fork_point'..HEAD, if --fork-point is active (see the description on --fork-point below); or by git log HEAD, if the --root option is specified. The current branch is reset to <upstream> or <newbase> if the --onto option was supplied. This has the exact same effect as git reset --hard <upstream> (or <newbase>). ORIG_HEAD is set to point at the tip of the branch before the reset. Note ORIG_HEAD is not guaranteed to still point to the previous branch tip at the end of the rebase if other commands that write that pseudo-ref (e.g. git reset) are used during the rebase. The previous branch tip, however, is accessible using the reflog of the current branch (i.e. @{1}, see gitrevisions(7)). The commits that were previously saved into the temporary area are then reapplied to the current branch, one by one, in order. Note that any commits in HEAD which introduce the same textual changes as a commit in HEAD..<upstream> are omitted (i.e., a patch already accepted upstream with a different commit message or timestamp will be skipped). It is possible that a merge failure will prevent this process from being completely automatic. You will have to resolve any such merge failure and run git rebase --continue. Another option is to bypass the commit that caused the merge failure with git rebase --skip. To check out the original <branch> and remove the .git/rebase-apply working files, use the command git rebase --abort instead. Assume the following history exists and the current branch is \"topic\": A---B---C topic / D---E---F---G master From this point, the result of either of the following commands: git rebase master git rebase master topic would be: A'--B'--C' topic / D---E---F---G master NOTE: The latter form is just a short-hand of git checkout topic followed by git rebase master. When rebase exits topic will remain the checked-out branch. If the upstream branch already contains a change you have made (e.g., because you mailed a patch which was applied upstream), then that commit will be skipped and warnings will be issued (if the merge backend is used). For example, running git rebase master on the following history (in which A' and A introduce the same set of changes, but have different committer information): A---B---C topic / D---E---A'---F master will result in: B'---C' topic / D---E---A'---F master Here is how you would transplant a topic branch based on one branch to another, to pretend that you forked the topic branch from the latter branch, using rebase --onto. First let\u2019s assume your topic is based on branch next. For example, a feature developed in topic depends on some functionality which is found in next. o---o---o---o---o master \\ o---o---o---o---o next \\ o---o---o topic We want to make topic forked from branch master; for example, because the functionality on which topic depends was merged into the more stable master branch. We want our tree to look like this: o---o---o---o---o master | \\ | o'--o'--o' topic \\ o---o---o---o---o next We can get this using the following command: git rebase --onto master next topic Another example of --onto option is to rebase part of a branch. If we have the following situation: H---I---J topicB / E---F---G topicA / A---B---C---D master then the command git rebase --onto master topicA topicB would result in: H'--I'--J' topicB / | E---F---G topicA |/ A---B---C---D master This is useful when topicB does not depend on topicA. A range of commits could also be removed with rebase. If we have the following situation: E---F---G---H---I---J topicA then the command git rebase --onto topicA~5 topicA~3 topicA would result in the removal of commits F and G: E---H'---I'---J' topicA This is useful if F and G were flawed in some way, or should not be part of topicA. Note that the argument to --onto and the <upstream> parameter can be any valid commit-ish. In case of conflict, git rebase will stop at the first problematic commit and leave conflict markers in the tree. You can use git diff to locate the markers (<<<<<<) and make edits to resolve the conflict. For each file you edit, you need to tell Git that the conflict has been resolved, typically this would be done with git add <filename> After resolving the conflict manually and updating the index with the desired resolution, you can continue the rebasing process with git rebase --continue Alternatively, you can undo the git rebase with git rebase --abort --onto <newbase> Starting point at which to create the new commits. If the --onto option is not specified, the starting point is <upstream>. May be any valid commit, and not just an existing branch name. As a special case, you may use \"A...B\" as a shortcut for the merge base of A and B if there is exactly one merge base. You can leave out at most one of A and B, in which case it defaults to HEAD. --keep-base Set the starting point at which to create the new commits to the merge base of <upstream> and <branch>. Running git rebase --keep-base <upstream> <branch> is equivalent to running git rebase --reapply-cherry-picks --no-fork-point --onto <upstream>...<branch> <upstream> <branch>. This option is useful in the case where one is developing a feature on top of an upstream branch. While the feature is being worked on, the upstream branch may advance and it may not be the best idea to keep rebasing on top of the upstream but to keep the base commit as-is. As the base commit is unchanged this option implies --reapply-cherry-picks to avoid losing commits. Although both this option and --fork-point find the merge base between <upstream> and <branch>, this option uses the merge base as the starting point on which new commits will be created, whereas --fork-point uses the merge base to determine the set of commits which will be rebased. See also INCOMPATIBLE OPTIONS below. <upstream> Upstream branch to compare against. May be any valid commit, not just an existing branch name. Defaults to the configured upstream for the current branch. <branch> Working branch; defaults to HEAD. --apply Use applying strategies to rebase (calling git-am internally). This option may become a no-op in the future once the merge backend handles everything the apply one does. See also INCOMPATIBLE OPTIONS below. --empty={drop,keep,ask} How to handle commits that are not empty to start and are not clean cherry-picks of any upstream commit, but which become empty after rebasing (because they contain a subset of already upstream changes). With drop (the default), commits that become empty are dropped. With keep, such commits are kept. With ask (implied by --interactive), the rebase will halt when an empty commit is applied allowing you to choose whether to drop it, edit files more, or just commit the empty changes. Other options, like --exec, will use the default of drop unless -i/--interactive is explicitly specified. Note that commits which start empty are kept (unless --no-keep-empty is specified), and commits which are clean cherry-picks (as determined by git log --cherry-mark ...) are detected and dropped as a preliminary step (unless --reapply-cherry-picks or --keep-base is passed). See also INCOMPATIBLE OPTIONS below. --no-keep-empty, --keep-empty Do not keep commits that start empty before the rebase (i.e. that do not change anything from its parent) in the result. The default is to keep commits which start empty, since creating such commits requires passing the --allow-empty override flag to git commit, signifying that a user is very intentionally creating such a commit and thus wants to keep it. Usage of this flag will probably be rare, since you can get rid of commits that start empty by just firing up an interactive rebase and removing the lines corresponding to the commits you don\u2019t want. This flag exists as a convenient shortcut, such as for cases where external tools generate many empty commits and you want them all removed. For commits which do not start empty but become empty after rebasing, see the --empty flag. See also INCOMPATIBLE OPTIONS below. --reapply-cherry-picks, --no-reapply-cherry-picks Reapply all clean cherry-picks of any upstream commit instead of preemptively dropping them. (If these commits then become empty after rebasing, because they contain a subset of already upstream changes, the behavior towards them is controlled by the --empty flag.) In the absence of --keep-base (or if --no-reapply-cherry-picks is given), these commits will be automatically dropped. Because this necessitates reading all upstream commits, this can be expensive in repositories with a large number of upstream commits that need to be read. When using the merge backend, warnings will be issued for each dropped commit (unless --quiet is given). Advice will also be issued unless advice.skippedCherryPicks is set to false (see git-config(1)). --reapply-cherry-picks allows rebase to forgo reading all upstream commits, potentially improving performance. See also INCOMPATIBLE OPTIONS below. --allow-empty-message No-op. Rebasing commits with an empty message used to fail and this option would override that behavior, allowing commits with empty messages to be rebased. Now commits with an empty message do not cause rebasing to halt. See also INCOMPATIBLE OPTIONS below. -m, --merge Using merging strategies to rebase (default). Note that a rebase merge works by replaying each commit from the working branch on top of the <upstream> branch. Because of this, when a merge conflict happens, the side reported as ours is the so-far rebased series, starting with <upstream>, and theirs is the working branch. In other words, the sides are swapped. See also INCOMPATIBLE OPTIONS below. -s <strategy>, --strategy=<strategy> Use the given merge strategy, instead of the default ort. This implies --merge. Because git rebase replays each commit from the working branch on top of the <upstream> branch using the given strategy, using the ours strategy simply empties all patches from the <branch>, which makes little sense. See also INCOMPATIBLE OPTIONS below. -X <strategy-option>, --strategy-option=<strategy-option> Pass the <strategy-option> through to the merge strategy. This implies --merge and, if no strategy has been specified, -s ort. Note the reversal of ours and theirs as noted above for the -m option. See also INCOMPATIBLE OPTIONS below. --rerere-autoupdate, --no-rerere-autoupdate After the rerere mechanism reuses a recorded resolution on the current conflict to update the files in the working tree, allow it to also update the index with the result of resolution. --no-rerere-autoupdate is a good way to double-check what rerere did and catch potential mismerges, before committing the result to the index with a separate git add. -S[<keyid>], --gpg-sign[=<keyid>], --no-gpg-sign GPG-sign commits. The keyid argument is optional and defaults to the committer identity; if specified, it must be stuck to the option without a space. --no-gpg-sign is useful to countermand both commit.gpgSign configuration variable, and earlier --gpg-sign. -q, --quiet Be quiet. Implies --no-stat. -v, --verbose Be verbose. Implies --stat. --stat Show a diffstat of what changed upstream since the last rebase. The diffstat is also controlled by the configuration option rebase.stat. -n, --no-stat Do not show a diffstat as part of the rebase process. --no-verify This option bypasses the pre-rebase hook. See also githooks(5). --verify Allows the pre-rebase hook to run, which is the default. This option can be used to override --no-verify. See also githooks(5). -C<n> Ensure at least <n> lines of surrounding context match before and after each change. When fewer lines of surrounding context exist they all must match. By default no context is ever ignored. Implies --apply. See also INCOMPATIBLE OPTIONS below. --no-ff, --force-rebase, -f Individually replay all rebased commits instead of fast-forwarding over the unchanged ones. This ensures that the entire history of the rebased branch is composed of new commits. You may find this helpful after reverting a topic branch merge, as this option recreates the topic branch with fresh commits so it can be remerged successfully without needing to \"revert the reversion\" (see the revert-a-faulty-merge How-To[1] for details). --fork-point, --no-fork-point Use reflog to find a better common ancestor between <upstream> and <branch> when calculating which commits have been introduced by <branch>. When --fork-point is active, fork_point will be used instead of <upstream> to calculate the set of commits to rebase, where fork_point is the result of git merge-base --fork-point <upstream> <branch> command (see git-merge-base(1)). If fork_point ends up being empty, the <upstream> will be used as a fallback. If <upstream> or --keep-base is given on the command line, then the default is --no-fork-point, otherwise the default is --fork-point. See also rebase.forkpoint in git-config(1). If your branch was based on <upstream> but <upstream> was rewound and your branch contains commits which were dropped, this option can be used with --keep-base in order to drop those commits from your branch. See also INCOMPATIBLE OPTIONS below. --ignore-whitespace Ignore whitespace differences when trying to reconcile differences. Currently, each backend implements an approximation of this behavior: apply backend When applying a patch, ignore changes in whitespace in context lines. Unfortunately, this means that if the \"old\" lines being replaced by the patch differ only in whitespace from the existing file, you will get a merge conflict instead of a successful patch application. merge backend Treat lines with only whitespace changes as unchanged when merging. Unfortunately, this means that any patch hunks that were intended to modify whitespace and nothing else will be dropped, even if the other side had no changes that conflicted. --whitespace=<option> This flag is passed to the git apply program (see git-apply(1)) that applies the patch. Implies --apply. See also INCOMPATIBLE OPTIONS below. --committer-date-is-author-date Instead of using the current time as the committer date, use the author date of the commit being rebased as the committer date. This option implies --force-rebase. --ignore-date, --reset-author-date Instead of using the author date of the original commit, use the current time as the author date of the rebased commit. This option implies --force-rebase. See also INCOMPATIBLE OPTIONS below. --signoff Add a Signed-off-by trailer to all the rebased commits. Note that if --interactive is given then only commits marked to be picked, edited or reworded will have the trailer added. See also INCOMPATIBLE OPTIONS below. -i, --interactive Make a list of the commits which are about to be rebased. Let the user edit that list before rebasing. This mode can also be used to split commits (see SPLITTING COMMITS below). The commit list format can be changed by setting the configuration option rebase.instructionFormat. A customized instruction format will automatically have the long commit hash prepended to the format. See also INCOMPATIBLE OPTIONS below. -r, --rebase-merges[=(rebase-cousins|no-rebase-cousins)], --no-rebase-merges By default, a rebase will simply drop merge commits from the todo list, and put the rebased commits into a single, linear branch. With --rebase-merges, the rebase will instead try to preserve the branching structure within the commits that are to be rebased, by recreating the merge commits. Any resolved merge conflicts or manual amendments in these merge commits will have to be resolved/re-applied manually. --no-rebase-merges can be used to countermand both the rebase.rebaseMerges config option and a previous --rebase-merges. When rebasing merges, there are two modes: rebase-cousins and no-rebase-cousins. If the mode is not specified, it defaults to no-rebase-cousins. In no-rebase-cousins mode, commits which do not have <upstream> as direct ancestor will keep their original branch point, i.e. commits that would be excluded by git-log(1)'s --ancestry-path option will keep their original ancestry by default. In rebase-cousins mode, such commits are instead rebased onto <upstream> (or <onto>, if specified). It is currently only possible to recreate the merge commits using the ort merge strategy; different merge strategies can be used only via explicit exec git merge -s <strategy> [...] commands. See also REBASING MERGES and INCOMPATIBLE OPTIONS below. -x <cmd>, --exec <cmd> Append \"exec <cmd>\" after each line creating a commit in the final history. <cmd> will be interpreted as one or more shell commands. Any command that fails will interrupt the rebase, with exit code 1. You may execute several commands by either using one instance of --exec with several commands: git rebase -i --exec \"cmd1 && cmd2 && ...\" or by giving more than one --exec: git rebase -i --exec \"cmd1\" --exec \"cmd2\" --exec ... If --autosquash is used, exec lines will not be appended for the intermediate commits, and will only appear at the end of each squash/fixup series. This uses the --interactive machinery internally, but it can be run without an explicit --interactive. See also INCOMPATIBLE OPTIONS below. --root Rebase all commits reachable from <branch>, instead of limiting them with an <upstream>. This allows you to rebase the root commit(s) on a branch. See also INCOMPATIBLE OPTIONS below. --autosquash, --no-autosquash When the commit log message begins with \"squash! ...\" or \"fixup! ...\" or \"amend! ...\", and there is already a commit in the todo list that matches the same ..., automatically modify the todo list of rebase -i, so that the commit marked for squashing comes right after the commit to be modified, and change the action of the moved commit from pick to squash or fixup or fixup -C respectively. A commit matches the ... if the commit subject matches, or if the ... refers to the commit\u2019s hash. As a fall-back, partial matches of the commit subject work, too. The recommended way to create fixup/amend/squash commits is by using the --fixup, --fixup=amend: or --fixup=reword: and --squash options respectively of git-commit(1). If the --autosquash option is enabled by default using the configuration variable rebase.autoSquash, this option can be used to override and disable this setting. See also INCOMPATIBLE OPTIONS below. --autostash, --no-autostash Automatically create a temporary stash entry before the operation begins, and apply it after the operation ends. This means that you can run rebase on a dirty worktree. However, use with care: the final stash application after a successful rebase might result in non-trivial conflicts. --reschedule-failed-exec, --no-reschedule-failed-exec Automatically reschedule exec commands that failed. This only makes sense in interactive mode (or when an --exec option was provided). Even though this option applies once a rebase is started, it\u2019s set for the whole rebase at the start based on either the rebase.rescheduleFailedExec configuration (see git-config(1) or \"CONFIGURATION\" below) or whether this option is provided. Otherwise an explicit --no-reschedule-failed-exec at the start would be overridden by the presence of rebase.rescheduleFailedExec=true configuration. --update-refs, --no-update-refs Automatically force-update any branches that point to commits that are being rebased. Any branches that are checked out in a worktree are not updated in this way. If the configuration variable rebase.updateRefs is set, then this option can be used to override and disable this setting. See also INCOMPATIBLE OPTIONS below. "
  },
  {
    "command": "git-commit-graph",
    "description": " Manage the serialized commit-graph file. --object-dir Use given directory for the location of packfiles and commit-graph file. This parameter exists to specify the location of an alternate that only has the objects directory, not a full .git directory. The commit-graph file is expected to be in the <dir>/info directory and the packfiles are expected to be in <dir>/pack. If the directory could not be made into an absolute path, or does not match any known object directory, git commit-graph ... will exit with non-zero status. --[no-]progress Turn progress on/off explicitly. If neither is specified, progress is shown if standard error is connected to a terminal. "
  },
  {
    "command": "chroot",
    "description": " Run COMMAND with root directory set to NEWROOT. --groups=G_LIST specify supplementary groups as g1,g2,..,gN --userspec=USER:GROUP specify user and group (ID or name) to use --skip-chdir do not change working directory to '/' --help display this help and exit --version output version information and exit If no command is given, run '\"$SHELL\" -i' (default: '/bin/sh -i'). Exit status: 125 if the chroot command itself fails 126 if COMMAND is found but cannot be invoked 127 if COMMAND cannot be found - the exit status of COMMAND otherwise "
  },
  {
    "command": "mesg",
    "description": " The mesg utility is invoked by a user to control write access others have to the terminal device associated with standard error output. If write access is allowed, then programs such as talk(1) and write(1) may display messages on the terminal. Traditionally, write access is allowed by default. However, as users become more conscious of various security risks, there is a trend to remove write access by default, at least for the primary login shell. To make sure your ttys are set the way you want them to be set, mesg should be executed in your login scripts. The mesg utility silently exits with error status 2 if not executed on a terminal. In this case executing mesg is pointless. The command line option --verbose forces mesg to print a warning in this situation. This behaviour has been introduced in version 2.33. -v, --verbose Explain what is being done. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "grep",
    "description": " grep searches for PATTERNS in each FILE. PATTERNS is one or more patterns separated by newline characters, and grep prints each line that matches a pattern. Typically PATTERNS should be quoted when grep is used in a shell command. A FILE of \u201c-\u201d stands for standard input. If no FILE is given, recursive searches examine the working directory, and nonrecursive searches read standard input. Generic Program Information --help Output a usage message and exit. -V, --version Output the version number of grep and exit. Pattern Syntax -E, --extended-regexp Interpret PATTERNS as extended regular expressions (EREs, see below). -F, --fixed-strings Interpret PATTERNS as fixed strings, not regular expressions. -G, --basic-regexp Interpret PATTERNS as basic regular expressions (BREs, see below). This is the default. -P, --perl-regexp Interpret PATTERNS as Perl-compatible regular expressions (PCREs). This option is experimental when combined with the -z (--null-data) option, and grep -P may warn of unimplemented features. Matching Control -e PATTERNS, --regexp=PATTERNS Use PATTERNS as the patterns. If this option is used multiple times or is combined with the -f (--file) option, search for all patterns given. This option can be used to protect a pattern beginning with \u201c-\u201d. -f FILE, --file=FILE Obtain patterns from FILE, one per line. If this option is used multiple times or is combined with the -e (--regexp) option, search for all patterns given. The empty file contains zero patterns, and therefore matches nothing. If FILE is - , read patterns from standard input. -i, --ignore-case Ignore case distinctions in patterns and input data, so that characters that differ only in case match each other. --no-ignore-case Do not ignore case distinctions in patterns and input data. This is the default. This option is useful for passing to shell scripts that already use -i, to cancel its effects because the two options override each other. -v, --invert-match Invert the sense of matching, to select non-matching lines. -w, --word-regexp Select only those lines containing matches that form whole words. The test is that the matching substring must either be at the beginning of the line, or preceded by a non-word constituent character. Similarly, it must be either at the end of the line or followed by a non-word constituent character. Word-constituent characters are letters, digits, and the underscore. This option has no effect if -x is also specified. -x, --line-regexp Select only those matches that exactly match the whole line. For a regular expression pattern, this is like parenthesizing the pattern and then surrounding it with ^ and $. General Output Control -c, --count Suppress normal output; instead print a count of matching lines for each input file. With the -v, --invert-match option (see above), count non-matching lines. --color[=WHEN], --colour[=WHEN] Surround the matched (non-empty) strings, matching lines, context lines, file names, line numbers, byte offsets, and separators (for fields and groups of context lines) with escape sequences to display them in color on the terminal. The colors are defined by the environment variable GREP_COLORS. WHEN is never, always, or auto. -L, --files-without-match Suppress normal output; instead print the name of each input file from which no output would normally have been printed. -l, --files-with-matches Suppress normal output; instead print the name of each input file from which output would normally have been printed. Scanning each input file stops upon first match. -m NUM, --max-count=NUM Stop reading a file after NUM matching lines. If NUM is zero, grep stops right away without reading input. A NUM of -1 is treated as infinity and grep does not stop; this is the default. If the input is standard input from a regular file, and NUM matching lines are output, grep ensures that the standard input is positioned to just after the last matching line before exiting, regardless of the presence of trailing context lines. This enables a calling process to resume a search. When grep stops after NUM matching lines, it outputs any trailing context lines. When the -c or --count option is also used, grep does not output a count greater than NUM. When the -v or --invert-match option is also used, grep stops after outputting NUM non-matching lines. -o, --only-matching Print only the matched (non-empty) parts of a matching line, with each such part on a separate output line. -q, --quiet, --silent Quiet; do not write anything to standard output. Exit immediately with zero status if any match is found, even if an error was detected. Also see the -s or --no-messages option. -s, --no-messages Suppress error messages about nonexistent or unreadable files. Output Line Prefix Control -b, --byte-offset Print the 0-based byte offset within the input file before each line of output. If -o (--only-matching) is specified, print the offset of the matching part itself. -H, --with-filename Print the file name for each match. This is the default when there is more than one file to search. This is a GNU extension. -h, --no-filename Suppress the prefixing of file names on output. This is the default when there is only one file (or only standard input) to search. --label=LABEL Display input actually coming from standard input as input coming from file LABEL. This can be useful for commands that transform a file's contents before searching, e.g., gzip -cd foo.gz | grep --label=foo -H 'some pattern'. See also the -H option. -n, --line-number Prefix each line of output with the 1-based line number within its input file. -T, --initial-tab Make sure that the first character of actual line content lies on a tab stop, so that the alignment of tabs looks normal. This is useful with options that prefix their output to the actual content: -H,-n, and -b. In order to improve the probability that lines from a single file will all start at the same column, this also causes the line number and byte offset (if present) to be printed in a minimum size field width. -Z, --null Output a zero byte (the ASCII NUL character) instead of the character that normally follows a file name. For example, grep -lZ outputs a zero byte after each file name instead of the usual newline. This option makes the output unambiguous, even in the presence of file names containing unusual characters like newlines. This option can be used with commands like find -print0, perl -0, sort -z, and xargs -0 to process arbitrary file names, even those that contain newline characters. Context Line Control -A NUM, --after-context=NUM Print NUM lines of trailing context after matching lines. Places a line containing a group separator (--) between contiguous groups of matches. With the -o or --only-matching option, this has no effect and a warning is given. -B NUM, --before-context=NUM Print NUM lines of leading context before matching lines. Places a line containing a group separator (--) between contiguous groups of matches. With the -o or --only-matching option, this has no effect and a warning is given. -C NUM, -NUM, --context=NUM Print NUM lines of output context. Places a line containing a group separator (--) between contiguous groups of matches. With the -o or --only-matching option, this has no effect and a warning is given. --group-separator=SEP When -A, -B, or -C are in use, print SEP instead of -- between groups of lines. --no-group-separator When -A, -B, or -C are in use, do not print a separator between groups of lines. File and Directory Selection -a, --text Process a binary file as if it were text; this is equivalent to the --binary-files=text option. --binary-files=TYPE If a file's data or metadata indicate that the file contains binary data, assume that the file is of type TYPE. Non-text bytes indicate binary data; these are either output bytes that are improperly encoded for the current locale, or null input bytes when the -z option is not given. By default, TYPE is binary, and grep suppresses output after null input binary data is discovered, and suppresses output lines that contain improperly encoded data. When some output is suppressed, grep follows any output with a message to standard error saying that a binary file matches. If TYPE is without-match, when grep discovers null input binary data it assumes that the rest of the file does not match; this is equivalent to the -I option. If TYPE is text, grep processes a binary file as if it were text; this is equivalent to the -a option. When type is binary, grep may treat non-text bytes as line terminators even without the -z option. This means choosing binary versus text can affect whether a pattern matches a file. For example, when type is binary the pattern q$ might match q immediately followed by a null byte, even though this is not matched when type is text. Conversely, when type is binary the pattern . (period) might not match a null byte. Warning: The -a option might output binary garbage, which can have nasty side effects if the output is a terminal and if the terminal driver interprets some of it as commands. On the other hand, when reading files whose text encodings are unknown, it can be helpful to use -a or to set LC_ALL='C' in the environment, in order to find more matches even if the matches are unsafe for direct display. -D ACTION, --devices=ACTION If an input file is a device, FIFO or socket, use ACTION to process it. By default, ACTION is read, which means that devices are read just as if they were ordinary files. If ACTION is skip, devices are silently skipped. -d ACTION, --directories=ACTION If an input file is a directory, use ACTION to process it. By default, ACTION is read, i.e., read directories just as if they were ordinary files. If ACTION is skip, silently skip directories. If ACTION is recurse, read all files under each directory, recursively, following symbolic links only if they are on the command line. This is equivalent to the -r option. --exclude=GLOB Skip any command-line file with a name suffix that matches the pattern GLOB, using wildcard matching; a name suffix is either the whole name, or a trailing part that starts with a non-slash character immediately after a slash (/) in the name. When searching recursively, skip any subfile whose base name matches GLOB; the base name is the part after the last slash. A pattern can use *, ?, and [...] as wildcards, and \\ to quote a wildcard or backslash character literally. --exclude-from=FILE Skip files whose base name matches any of the file-name globs read from FILE (using wildcard matching as described under --exclude). --exclude-dir=GLOB Skip any command-line directory with a name suffix that matches the pattern GLOB. When searching recursively, skip any subdirectory whose base name matches GLOB. Ignore any redundant trailing slashes in GLOB. -I Process a binary file as if it did not contain matching data; this is equivalent to the --binary-files=without-match option. --include=GLOB Search only files whose base name matches GLOB (using wildcard matching as described under --exclude). If contradictory --include and --exclude options are given, the last matching one wins. If no --include or --exclude options match, a file is included unless the first such option is --include. -r, --recursive Read all files under each directory, recursively, following symbolic links only if they are on the command line. Note that if no file operand is given, grep searches the working directory. This is equivalent to the -d recurse option. -R, --dereference-recursive Read all files under each directory, recursively. Follow all symbolic links, unlike -r. Other Options --line-buffered Use line buffering on output. This can cause a performance penalty. -U, --binary Treat the file(s) as binary. By default, under MS-DOS and MS-Windows, grep guesses whether a file is text or binary as described for the --binary-files option. If grep decides the file is a text file, it strips the CR characters from the original file contents (to make regular expressions with ^ and $ work correctly). Specifying -U overrules this guesswork, causing all files to be read and passed to the matching mechanism verbatim; if the file is a text file with CR/LF pairs at the end of each line, this will cause some regular expressions to fail. This option has no effect on platforms other than MS-DOS and MS-Windows. -z, --null-data Treat input and output data as sequences of lines, each terminated by a zero byte (the ASCII NUL character) instead of a newline. Like the -Z or --null option, this option can be used with commands like sort -z to process arbitrary file names. "
  },
  {
    "command": "less",
    "description": " Less is a program similar to more(1), but which allows backward movement in the file as well as forward movement. Also, less does not have to read the entire input file before starting, so with large input files it starts up faster than text editors like vi(1). Less uses termcap (or terminfo on some systems), so it can run on a variety of terminals. There is even limited support for hardcopy terminals. (On a hardcopy terminal, lines which should be printed at the top of the screen are prefixed with a caret.) Commands are based on both more and vi. Commands may be preceded by a decimal number, called N in the descriptions below. The number is used by some commands, as indicated. Command line options are described below. Most options may be changed while less is running, via the \"-\" command. Some options may be given in one of two forms: either a dash followed by a single letter, or two dashes followed by a long option name. A long option name may be abbreviated as long as the abbreviation is unambiguous. For example, --quit-at-eof may be abbreviated --quit, but not --qui, since both --quit-at-eof and --quiet begin with --qui. Some long option names are in uppercase, such as --QUIT-AT-EOF, as distinct from --quit-at-eof. Such option names need only have their first letter capitalized; the remainder of the name may be in either case. For example, --Quit-at-eof is equivalent to --QUIT-AT-EOF. Options are also taken from the environment variable \"LESS\". For example, to avoid typing \"less -options ...\" each time less is invoked, you might tell csh: setenv LESS \"-options\" or if you use sh: LESS=\"-options\"; export LESS On MS-DOS, you don't need the quotes, but you should replace any percent signs in the options string by double percent signs. The environment variable is parsed before the command line, so command line options override the LESS environment variable. If an option appears in the LESS variable, it can be reset to its default value on the command line by beginning the command line option with \"-+\". Some options like -k or -D require a string to follow the option letter. The string for that option is considered to end when a dollar sign ($) is found. For example, you can set two -D options like this: LESS=\"Dn9.1$Ds4.1\" If the --use-backslash option appears earlier in the options, then a dollar sign or backslash may be included literally in an option string by preceding it with a backslash. If the --use- backslash option is not in effect, then backslashes are not treated specially, and there is no way to include a dollar sign in the option string. -? or --help This option displays a summary of the commands accepted by less (the same as the h command). (Depending on how your shell interprets the question mark, it may be necessary to quote the question mark, thus: \"-\\?\".) -a or --search-skip-screen By default, forward searches start at the top of the displayed screen and backwards searches start at the bottom of the displayed screen (except for repeated searches invoked by the n or N commands, which start after or before the \"target\" line respectively; see the -j option for more about the target line). The -a option causes forward searches to instead start at the bottom of the screen and backward searches to start at the top of the screen, thus skipping all lines displayed on the screen. -A or --SEARCH-SKIP-SCREEN Causes all forward searches (not just non-repeated searches) to start just after the target line, and all backward searches to start just before the target line. Thus, forward searches will skip part of the displayed screen (from the first line up to and including the target line). Similarly backwards searches will skip the displayed screen from the last line up to and including the target line. This was the default behavior in less versions prior to 441. -bn or --buffers=n Specifies the amount of buffer space less will use for each file, in units of kilobytes (1024 bytes). By default 64 KB of buffer space is used for each file (unless the file is a pipe; see the -B option). The -b option specifies instead that n kilobytes of buffer space should be used for each file. If n is -1, buffer space is unlimited; that is, the entire file can be read into memory. -B or --auto-buffers By default, when data is read from a pipe, buffers are allocated automatically as needed. If a large amount of data is read from the pipe, this can cause a large amount of memory to be allocated. The -B option disables this automatic allocation of buffers for pipes, so that only 64 KB (or the amount of space specified by the -b option) is used for the pipe. Warning: use of -B can result in erroneous display, since only the most recently viewed part of the piped data is kept in memory; any earlier data is lost. Lost characters are displayed as question marks. -c or --clear-screen Causes full screen repaints to be painted from the top line down. By default, full screen repaints are done by scrolling from the bottom of the screen. -C or --CLEAR-SCREEN Same as -c, for compatibility with older versions of less. -d or --dumb The -d option suppresses the error message normally displayed if the terminal is dumb; that is, lacks some important capability, such as the ability to clear the screen or scroll backward. The -d option does not otherwise change the behavior of less on a dumb terminal. -Dxcolor or --color=xcolor Changes the color of different parts of the displayed text. x is a single character which selects the type of text whose color is being set: B Binary characters. C Control characters. E Errors and informational messages. H Header lines and columns, set via the --header option. M Mark letters in the status column. N Line numbers enabled via the -N option. P Prompts. R The rscroll character. S Search results. 1-5 The text in a search result which matches the first through fifth parenthesized sub-pattern. Sub- pattern coloring works only if less is built with one of the regular expression libraries posix, pcre, or pcre2. W The highlight enabled via the -w option. d Bold text. k Blinking text. s Standout text. u Underlined text. The uppercase letters and digits can be used only when the --use-color option is enabled. When text color is specified by both an uppercase letter and a lowercase letter, the uppercase letter takes precedence. For example, error messages are normally displayed as standout text. So if both \"s\" and \"E\" are given a color, the \"E\" color applies to error messages, and the \"s\" color applies to other standout text. The \"d\" and \"u\" letters refer to bold and underline text formed by overstriking with backspaces (see the -U option), not to text using ANSI escape sequences with the -R option. A lowercase letter may be followed by a + to indicate that the normal format change and the specified color should both be used. For example, -Dug displays underlined text as green without underlining; the green color has replaced the usual underline formatting. But -Du+g displays underlined text as both green and in underlined format. color is either a 4-bit color string or an 8-bit color string: A 4-bit color string is zero, one or two characters, where the first character specifies the foreground color and the second specifies the background color as follows: b Blue c Cyan g Green k Black m Magenta r Red w White y Yellow The corresponding uppercase letter denotes a brighter shade of the color. For example, -DNGk displays line numbers as bright green text on a black background, and -DEbR displays error messages as blue text on a bright red background. If either character is a \"-\" or is omitted, the corresponding color is set to that of normal text. An 8-bit color string is one or two decimal integers separated by a dot, where the first integer specifies the foreground color and the second specifies the background color. Each integer is a value between 0 and 255 inclusive which selects a \"CSI 38;5\" color value (see https://en.wikipedia.org/wiki/ANSI_escape_code#SGR) If either integer is a \"-\" or is omitted, the corresponding color is set to that of normal text. On MS-DOS versions of less, 8-bit color is not supported; instead, decimal values are interpreted as 4-bit CHAR_INFO.Attributes values (see https://docs.microsoft.com/en-us/windows/console/char-info-str). -e or --quit-at-eof Causes less to automatically exit the second time it reaches end-of-file. By default, the only way to exit less is via the \"q\" command. -E or --QUIT-AT-EOF Causes less to automatically exit the first time it reaches end-of-file. -f or --force Forces non-regular files to be opened. (A non-regular file is a directory or a device special file.) Also suppresses the warning message when a binary file is opened. By default, less will refuse to open non-regular files. Note that some operating systems will not allow directories to be read, even if -f is set. -F or --quit-if-one-screen Causes less to automatically exit if the entire file can be displayed on the first screen. -g or --hilite-search Normally, less will highlight ALL strings which match the last search command. The -g option changes this behavior to highlight only the particular string which was found by the last search command. This can cause less to run somewhat faster than the default. -G or --HILITE-SEARCH The -G option suppresses all highlighting of strings found by search commands. -hn or --max-back-scroll=n Specifies a maximum number of lines to scroll backward. If it is necessary to scroll backward more than n lines, the screen is repainted in a forward direction instead. (If the terminal does not have the ability to scroll backward, -h0 is implied.) -i or --ignore-case Causes searches to ignore case; that is, uppercase and lowercase are considered identical. This option is ignored if any uppercase letters appear in the search pattern; in other words, if a pattern contains uppercase letters, then that search does not ignore case. -I or --IGNORE-CASE Like -i, but searches ignore case even if the pattern contains uppercase letters. -jn or --jump-target=n Specifies a line on the screen where the \"target\" line is to be positioned. The target line is the line specified by any command to search for a pattern, jump to a line number, jump to a file percentage or jump to a tag. The screen line may be specified by a number: the top line on the screen is 1, the next is 2, and so on. The number may be negative to specify a line relative to the bottom of the screen: the bottom line on the screen is -1, the second to the bottom is -2, and so on. Alternately, the screen line may be specified as a fraction of the height of the screen, starting with a decimal point: .5 is in the middle of the screen, .3 is three tenths down from the first line, and so on. If the line is specified as a fraction, the actual line number is recalculated if the terminal window is resized. If any form of the -j option is used, repeated forward searches (invoked with \"n\" or \"N\") begin at the line immediately after the target line, and repeated backward searches begin at the target line, unless changed by -a or -A. For example, if \"-j4\" is used, the target line is the fourth line on the screen, so forward searches begin at the fifth line on the screen. However nonrepeated searches (invoked with \"/\" or \"?\") always begin at the start or end of the current screen respectively. -J or --status-column Displays a status column at the left edge of the screen. The character displayed in the status column may be one of: > The line is chopped with the -S option, and the text that is chopped off beyond the right edge of the screen contains a match for the current search. < The line is horizontally shifted, and the text that is shifted beyond the left side of the screen contains a match for the current search. = The line is both chopped and shifted, and there are matches beyond both sides of the screen. * There are matches in the visible part of the line but none to the right or left of it. a-z, A-Z The line has been marked with the corresponding letter via the m command. -kfilename or --lesskey-file=filename Causes less to open and interpret the named file as a lesskey(1) binary file. Multiple -k options may be specified. If the LESSKEY or LESSKEY_SYSTEM environment variable is set, or if a lesskey file is found in a standard place (see KEY BINDINGS), it is also used as a lesskey file. --lesskey-src=filename Causes less to open and interpret the named file as a lesskey(1) source file. If the LESSKEYIN or LESSKEYIN_SYSTEM environment variable is set, or if a lesskey source file is found in a standard place (see KEY BINDINGS), it is also used as a lesskey source file. Prior to version 582, the lesskey program needed to be run to convert a lesskey source file to a lesskey binary file for less to use. Newer versions of less read the lesskey source file directly and ignore the binary file if the source file exists. -K or --quit-on-intr Causes less to exit immediately (with status 2) when an interrupt character (usually ^C) is typed. Normally, an interrupt character causes less to stop whatever it is doing and return to its command prompt. Note that use of this option makes it impossible to return to the command prompt from the \"F\" command. -L or --no-lessopen Ignore the LESSOPEN environment variable (see the INPUT PREPROCESSOR section below). This option can be set from within less, but it will apply only to files opened subsequently, not to the file which is currently open. -m or --long-prompt Causes less to prompt verbosely (like more(1)), with the percent into the file. By default, less prompts with a colon. -M or --LONG-PROMPT Causes less to prompt even more verbosely than more(1). -n or --line-numbers Suppresses line numbers. The default (to use line numbers) may cause less to run more slowly in some cases, especially with a very large input file. Suppressing line numbers with the -n option will avoid this problem. Using line numbers means: the line number will be displayed in the verbose prompt and in the = command, and the v command will pass the current line number to the editor (see also the discussion of LESSEDIT in PROMPTS below). -N or --LINE-NUMBERS Causes a line number to be displayed at the beginning of each line in the display. -ofilename or --log-file=filename Causes less to copy its input to the named file as it is being viewed. This applies only when the input file is a pipe, not an ordinary file. If the file already exists, less will ask for confirmation before overwriting it. -Ofilename or --LOG-FILE=filename The -O option is like -o, but it will overwrite an existing file without asking for confirmation. If no log file has been specified, the -o and -O options can be used from within less to specify a log file. Without a file name, they will simply report the name of the log file. The \"s\" command is equivalent to specifying -o from within less. -ppattern or --pattern=pattern The -p option on the command line is equivalent to specifying +/pattern; that is, it tells less to start at the first occurrence of pattern in the file. -Pprompt or --prompt=prompt Provides a way to tailor the three prompt styles to your own preference. This option would normally be put in the LESS environment variable, rather than being typed in with each less command. Such an option must either be the last option in the LESS variable, or be terminated by a dollar sign. -Ps followed by a string changes the default (short) prompt to that string. -Pm changes the medium (-m) prompt. -PM changes the long (-M) prompt. -Ph changes the prompt for the help screen. -P= changes the message printed by the = command. -Pw changes the message printed while waiting for data (in the \"F\" command). All prompt strings consist of a sequence of letters and special escape sequences. See the section on PROMPTS for more details. -q or --quiet or --silent Causes moderately \"quiet\" operation: the terminal bell is not rung if an attempt is made to scroll past the end of the file or before the beginning of the file. If the terminal has a \"visual bell\", it is used instead. The bell will be rung on certain other errors, such as typing an invalid character. The default is to ring the terminal bell in all such cases. -Q or --QUIET or --SILENT Causes totally \"quiet\" operation: the terminal bell is never rung. If the terminal has a \"visual bell\", it is used in all cases where the terminal bell would have been rung. -r or --raw-control-chars Causes \"raw\" control characters to be displayed. The default is to display control characters using the caret notation; for example, a control-A (octal 001) is displayed as \"^A\" (with some exceptions as described under the -U option). Warning: when the -r option is used, less cannot keep track of the actual appearance of the screen (since this depends on how the screen responds to each type of control character). Thus, various display problems may result, such as long lines being split in the wrong place. USE OF THE -r OPTION IS NOT RECOMMENDED. -R or --RAW-CONTROL-CHARS Like -r, but only ANSI \"color\" escape sequences and OSC 8 hyperlink sequences are output in \"raw\" form. Unlike -r, the screen appearance is maintained correctly, provided that there are no escape sequences in the file other than these types of escape sequences. Color escape sequences are only supported when the color is changed within one line, not across lines. In other words, the beginning of each line is assumed to be normal (non-colored), regardless of any escape sequences in previous lines. For the purpose of keeping track of screen appearance, these escape sequences are assumed to not move the cursor. OSC 8 hyperlinks are sequences of the form: ESC ] 8 ; ... \\7 The terminating sequence may be either a BEL character (\\7) or the two-character sequence \"ESC \\\". ANSI color escape sequences are sequences of the form: ESC [ ... m where the \"...\" is zero or more color specification characters. You can make less think that characters other than \"m\" can end ANSI color escape sequences by setting the environment variable LESSANSIENDCHARS to the list of characters which can end a color escape sequence. And you can make less think that characters other than the standard ones may appear between the ESC and the m by setting the environment variable LESSANSIMIDCHARS to the list of characters which can appear. -s or --squeeze-blank-lines Causes consecutive blank lines to be squeezed into a single blank line. This is useful when viewing nroff output. -S or --chop-long-lines Causes lines longer than the screen width to be chopped (truncated) rather than wrapped. That is, the portion of a long line that does not fit in the screen width is not displayed until you press RIGHT-ARROW. The default is to wrap long lines; that is, display the remainder on the next line. See also the --wordwrap option. -ttag or --tag=tag The -t option, followed immediately by a TAG, will edit the file containing that tag. For this to work, tag information must be available; for example, there may be a file in the current directory called \"tags\", which was previously built by ctags(1) or an equivalent command. If the environment variable LESSGLOBALTAGS is set, it is taken to be the name of a command compatible with global(1), and that command is executed to find the tag. (See http://www.gnu.org/software/global/global.html). The -t option may also be specified from within less (using the - command) as a way of examining a new file. The command \":t\" is equivalent to specifying -t from within less. -Ttagsfile or --tag-file=tagsfile Specifies a tags file to be used instead of \"tags\". -u or --underline-special Causes backspaces and carriage returns to be treated as printable characters; that is, they are sent to the terminal when they appear in the input. -U or --UNDERLINE-SPECIAL Causes backspaces, tabs, carriage returns and \"formatting characters\" (as defined by Unicode) to be treated as control characters; that is, they are handled as specified by the -r option. By default, if neither -u nor -U is given, backspaces which appear adjacent to an underscore character are treated specially: the underlined text is displayed using the terminal's hardware underlining capability. Also, backspaces which appear between two identical characters are treated specially: the overstruck text is printed using the terminal's hardware boldface capability. Other backspaces are deleted, along with the preceding character. Carriage returns immediately followed by a newline are deleted. Other carriage returns are handled as specified by the -r option. Unicode formatting characters, such as the Byte Order Mark, are sent to the terminal. Text which is overstruck or underlined can be searched for if neither -u nor -U is in effect. See also the --proc-backspace, --proc-tab, and --proc- return options. -V or --version Displays the version number of less. -w or --hilite-unread Temporarily highlights the first \"new\" line after a forward movement of a full page. The first \"new\" line is the line immediately following the line previously at the bottom of the screen. Also highlights the target line after a g or p command. The highlight is removed at the next command which causes movement. If the --status-line option is in effect, the entire line (the width of the screen) is highlighted. Otherwise, only the text in the line is highlighted, unless the -J option is in effect, in which case only the status column is highlighted. -W or --HILITE-UNREAD Like -w, but temporarily highlights the first new line after any forward movement command larger than one line. -xn,... or --tabs=n,... Sets tab stops. If only one n is specified, tab stops are set at multiples of n. If multiple values separated by commas are specified, tab stops are set at those positions, and then continue with the same spacing as the last two. For example, \"-x9,17\" will set tabs at positions 9, 17, 25, 33, etc. The default for n is 8. -X or --no-init Disables sending the termcap initialization and deinitialization strings to the terminal. This is sometimes desirable if the deinitialization string does something unnecessary, like clearing the screen. -yn or --max-forw-scroll=n Specifies a maximum number of lines to scroll forward. If it is necessary to scroll forward more than n lines, the screen is repainted instead. The -c or -C option may be used to repaint from the top of the screen if desired. By default, any forward movement causes scrolling. -zn or --window=n or -n Changes the default scrolling window size to n lines. The default is one screenful. The z and w commands can also be used to change the window size. The \"z\" may be omitted for compatibility with some versions of more(1). If the number n is negative, it indicates n lines less than the current screen size. For example, if the screen is 24 lines, -z-4 sets the scrolling window to 20 lines. If the screen is resized to 40 lines, the scrolling window automatically changes to 36 lines. -\"cc or --quotes=cc Changes the filename quoting character. This may be necessary if you are trying to name a file which contains both spaces and quote characters. Followed by a single character, this changes the quote character to that character. Filenames containing a space should then be surrounded by that character rather than by double quotes. Followed by two characters, changes the open quote to the first character, and the close quote to the second character. Filenames containing a space should then be preceded by the open quote character and followed by the close quote character. Note that even after the quote characters are changed, this option remains -\" (a dash followed by a double quote). -~ or --tilde Normally lines after end of file are displayed as a single tilde (~). This option causes lines after end of file to be displayed as blank lines. -# or --shift Specifies the default number of positions to scroll horizontally in the RIGHTARROW and LEFTARROW commands. If the number specified is zero, it sets the default number of positions to one half of the screen width. Alternately, the number may be specified as a fraction of the width of the screen, starting with a decimal point: .5 is half of the screen width, .3 is three tenths of the screen width, and so on. If the number is specified as a fraction, the actual number of scroll positions is recalculated if the terminal window is resized. --exit-follow-on-close When using the \"F\" command on a pipe, less will automatically stop waiting for more data when the input side of the pipe is closed. --file-size If --file-size is specified, less will determine the size of the file immediately after opening the file. Then the \"=\" command will display the number of lines in the file. Normally this is not done, because it can be slow if the input file is non-seekable (such as a pipe) and is large. --follow-name Normally, if the input file is renamed while an F command is executing, less will continue to display the contents of the original file despite its name change. If --follow-name is specified, during an F command less will periodically attempt to reopen the file by name. If the reopen succeeds and the file is a different file from the original (which means that a new file has been created with the same name as the original (now renamed) file), less will display the contents of that new file. --header=N[,M] Sets the number of header lines and columns displayed on the screen. The value may be of the form \"N,M\" where N and M are integers, to set the header lines to N and the header columns to M, or it may be a single integer \"N\" which sets the header lines to N and the header columns to zero, or it may be \",M\" which sets the header columns to M and the header lines to zero. When N is nonzero, the first N lines at the top of the screen are replaced with the first N lines of the file, regardless of what part of the file are being viewed. When M is nonzero, the characters displayed at the beginning of each line are replaced with the first M characters of the line, even if the rest of the line is scrolled horizontally. If either N or M is zero, less stops displaying header lines or columns, respectively. (Note that it may be necessary to change the setting of the -j option to ensure that the target line is not obscured by the header line(s).) --incsearch Subsequent search commands will be \"incremental\"; that is, less will advance to the next line containing the search pattern as each character of the pattern is typed in. --intr=c Use the character c instead of ^X to interrupt a read when the \"Waiting for data\" message is displayed. c must be an ASCII character; that is, one with a value between 1 and 127 inclusive. A caret followed by a single character can be used to specify a control character. --line-num-width=n Sets the minimum width of the line number field when the -N option is in effect to n characters. The default is 7. --modelines=n Before displaying a file, less will read the first n lines to try to find a vim-compatible modeline. If n is zero, less does not try to find modelines. By using a modeline, the file itself can specify the tab stops that should be used when viewing it. A modeline contains, anywhere in the line, a program name (\"vi\", \"vim\", \"ex\", or \"less\"), followed by a colon, possibly followed by the word \"set\", and finally followed by zero or more option settings. If the word \"set\" is used, option settings are separated by spaces, and end at the first colon. If the word \"set\" is not used, option settings may be separated by either spaces or colons. The word \"set\" is required if the program name is \"less\" but optional if any of the other three names are used. If any option setting is of the form \"tabstop=n\" or \"ts=n\", then tab stops are automatically set as if --tabs=n had been given. See the --tabs description for acceptable values of n. --mouse Enables mouse input: scrolling the mouse wheel down moves forward in the file, scrolling the mouse wheel up moves backwards in the file, and clicking the mouse sets the \"#\" mark to the line where the mouse is clicked. The number of lines to scroll when the wheel is moved can be set by the --wheel-lines option. Mouse input works only on terminals which support X11 mouse reporting, and on the Windows version of less. --MOUSE Like --mouse, except the direction scrolled on mouse wheel movement is reversed. --no-keypad Disables sending the keypad initialization and deinitialization strings to the terminal. This is sometimes useful if the keypad strings make the numeric keypad behave in an undesirable manner. --no-histdups This option changes the behavior so that if a search string or file name is typed in, and the same string is already in the history list, the existing copy is removed from the history list before the new one is added. Thus, a given string will appear only once in the history list. Normally, a string may appear multiple times. --no-number-headers Header lines (defined via the --header option) are not assigned line numbers. Line number 1 is assigned to the first line after any header lines. --no-search-headers Searches do not include header lines or header columns. --no-vbell Disables the terminal's visual bell. --proc-backspace If set, backspaces are handled as if neither the -u option nor the -U option were set. That is, a backspace adjacent to an underscore causes text to be displayed in underline mode, and a backspace between identical characters cause text to be displayed in boldface mode. This option overrides the -u and -U options, so that display of backspaces can be controlled separate from tabs and carriage returns. If not set, backspace display is controlled by the -u and -U options. --PROC-BACKSPACE If set, backspaces are handled as if the -U option were set; that is backspaces are treated as control characters. --proc-return If set, carriage returns are handled as if neither the -u option nor the -U option were set. That is, a carriage return immediately before a newline is deleted. This option overrides the -u and -U options, so that display of carriage returns can be controlled separate from that of backspaces and tabs. If not set, carriage return display is controlled by the -u and -U options. --PROC-RETURN If set, carriage returns are handled as if the -U option were set; that is carriage returns are treated as control characters. --proc-tab If set, tabs are handled as if the -U option were not set. That is, tabs are expanded to spaces. This option overrides the -U option, so that display of tabs can be controlled separate from that of backspaces and carriage returns. If not set, tab display is controlled by the -U options. --PROC-TAB If set, tabs are handled as if the -U option were set; that is tabs are treated as control characters. --redraw-on-quit When quitting, after sending the terminal deinitialization string, redraws the entire last screen. On terminals whose terminal deinitialization string causes the terminal to switch from an alternate screen, this makes the last screenful of the current file remain visible after less has quit. --rscroll=c This option changes the character used to mark truncated lines. It may begin with a two-character attribute indicator like LESSBINFMT does. If there is no attribute indicator, standout is used. If set to \"-\", truncated lines are not marked. --save-marks Save marks in the history file, so marks are retained across different invocations of less. --search-options=... Sets default search modifiers. The value is a string of one or more of the characters E, F, K, N, R or W. Setting any of these has the same effect as typing that control character at the beginning of every search pattern. For example, setting --search-options=W is the same as typing ^W at the beginning of every pattern. The value may also contain a digit between 1 and 5, which has the same effect as typing ^S followed by that digit at the beginning of every search pattern. The value \"-\" disables all default search modifiers. --show-preproc-errors If a preprocessor produces data, then exits with a non- zero exit code, less will display a warning. --status-col-width=n Sets the width of the status column when the -J option is in effect. The default is 2 characters. --status-line If a line is marked, the entire line (rather than just the status column) is highlighted. Also lines highlighted due to the -w option will have the entire line highlighted. If --use-color is set, the line is colored rather than highlighted. --use-backslash This option changes the interpretations of options which follow this one. After the --use-backslash option, any backslash in an option string is removed and the following character is taken literally. This allows a dollar sign to be included in option strings. --use-color Enables colored text in various places. The -D option can be used to change the colors. Colored text works only if the terminal supports ANSI color escape sequences (as defined in ECMA-48 SGR; see https://www.ecma-international.org/publications-and-standards/standards/ecma-48). --wheel-lines=n Set the number of lines to scroll when the mouse wheel is scrolled and the --mouse or --MOUSE option is in effect. The default is 1 line. --wordwrap When the -S option is not in use, wrap each line at a space or tab if possible, so that a word is not split between two lines. The default is to wrap at any character. -- A command line argument of \"--\" marks the end of option arguments. Any arguments following this are interpreted as filenames. This can be useful when viewing a file whose name begins with a \"-\" or \"+\". + If a command line option begins with +, the remainder of that option is taken to be an initial command to less. For example, +G tells less to start at the end of the file rather than the beginning, and +/xyz tells it to start at the first occurrence of \"xyz\" in the file. As a special case, +<number> acts like +<number>g; that is, it starts the display at the specified line number (however, see the caveat under the \"g\" command above). If the option starts with ++, the initial command applies to every file being viewed, not just the first one. The + command described previously may also be used to set (or change) an initial command for every file. "
  },
  {
    "command": "git-add",
    "description": " This command updates the index using the current content found in the working tree, to prepare the content staged for the next commit. It typically adds the current content of existing paths as a whole, but with some options it can also be used to add content with only part of the changes made to the working tree files applied, or remove paths that do not exist in the working tree anymore. The \"index\" holds a snapshot of the content of the working tree, and it is this snapshot that is taken as the contents of the next commit. Thus after making any changes to the working tree, and before running the commit command, you must use the add command to add any new or modified files to the index. This command can be performed multiple times before a commit. It only adds the content of the specified file(s) at the time the add command is run; if you want subsequent changes included in the next commit, then you must run git add again to add the new content to the index. The git status command can be used to obtain a summary of which files have changes that are staged for the next commit. The git add command will not add ignored files by default. If any ignored files were explicitly specified on the command line, git add will fail with a list of ignored files. Ignored files reached by directory recursion or filename globbing performed by Git (quote your globs before the shell) will be silently ignored. The git add command can be used to add ignored files with the -f (force) option. Please see git-commit(1) for alternative ways to add content to a commit. <pathspec>... Files to add content from. Fileglobs (e.g. *.c) can be given to add all matching files. Also a leading directory name (e.g. dir to add dir/file1 and dir/file2) can be given to update the index to match the current state of the directory as a whole (e.g. specifying dir will record not just a file dir/file1 modified in the working tree, a file dir/file2 added to the working tree, but also a file dir/file3 removed from the working tree). Note that older versions of Git used to ignore removed files; use --no-all option if you want to add modified or new files but ignore removed ones. For more details about the <pathspec> syntax, see the pathspec entry in gitglossary(7). -n, --dry-run Don\u2019t actually add the file(s), just show if they exist and/or will be ignored. -v, --verbose Be verbose. -f, --force Allow adding otherwise ignored files. --sparse Allow updating index entries outside of the sparse-checkout cone. Normally, git add refuses to update index entries whose paths do not fit within the sparse-checkout cone, since those files might be removed from the working tree without warning. See git-sparse-checkout(1) for more details. -i, --interactive Add modified contents in the working tree interactively to the index. Optional path arguments may be supplied to limit operation to a subset of the working tree. See \u201cInteractive mode\u201d for details. -p, --patch Interactively choose hunks of patch between the index and the work tree and add them to the index. This gives the user a chance to review the difference before adding modified contents to the index. This effectively runs add --interactive, but bypasses the initial command menu and directly jumps to the patch subcommand. See \u201cInteractive mode\u201d for details. -e, --edit Open the diff vs. the index in an editor and let the user edit it. After the editor was closed, adjust the hunk headers and apply the patch to the index. The intent of this option is to pick and choose lines of the patch to apply, or even to modify the contents of lines to be staged. This can be quicker and more flexible than using the interactive hunk selector. However, it is easy to confuse oneself and create a patch that does not apply to the index. See EDITING PATCHES below. -u, --update Update the index just where it already has an entry matching <pathspec>. This removes as well as modifies index entries to match the working tree, but adds no new files. If no <pathspec> is given when -u option is used, all tracked files in the entire working tree are updated (old versions of Git used to limit the update to the current directory and its subdirectories). -A, --all, --no-ignore-removal Update the index not only where the working tree has a file matching <pathspec> but also where the index already has an entry. This adds, modifies, and removes index entries to match the working tree. If no <pathspec> is given when -A option is used, all files in the entire working tree are updated (old versions of Git used to limit the update to the current directory and its subdirectories). --no-all, --ignore-removal Update the index by adding new files that are unknown to the index and files modified in the working tree, but ignore files that have been removed from the working tree. This option is a no-op when no <pathspec> is used. This option is primarily to help users who are used to older versions of Git, whose \"git add <pathspec>...\" was a synonym for \"git add --no-all <pathspec>...\", i.e. ignored removed files. -N, --intent-to-add Record only the fact that the path will be added later. An entry for the path is placed in the index with no content. This is useful for, among other things, showing the unstaged content of such files with git diff and committing them with git commit -a. --refresh Don\u2019t add the file(s), but only refresh their stat() information in the index. --ignore-errors If some files could not be added because of errors indexing them, do not abort the operation, but continue adding the others. The command shall still exit with non-zero status. The configuration variable add.ignoreErrors can be set to true to make this the default behaviour. --ignore-missing This option can only be used together with --dry-run. By using this option the user can check if any of the given files would be ignored, no matter if they are already present in the work tree or not. --no-warn-embedded-repo By default, git add will warn when adding an embedded repository to the index without using git submodule add to create an entry in .gitmodules. This option will suppress the warning (e.g., if you are manually performing operations on submodules). --renormalize Apply the \"clean\" process freshly to all tracked files to forcibly add them again to the index. This is useful after changing core.autocrlf configuration or the text attribute in order to correct files added with wrong CRLF/LF line endings. This option implies -u. Lone CR characters are untouched, thus while a CRLF cleans to LF, a CRCRLF sequence is only partially cleaned to CRLF. --chmod=(+|-)x Override the executable bit of the added files. The executable bit is only changed in the index, the files on disk are left unchanged. --pathspec-from-file=<file> Pathspec is passed in <file> instead of commandline args. If <file> is exactly - then standard input is used. Pathspec elements are separated by LF or CR/LF. Pathspec elements can be quoted as explained for the configuration variable core.quotePath (see git-config(1)). See also --pathspec-file-nul and global --literal-pathspecs. --pathspec-file-nul Only meaningful with --pathspec-from-file. Pathspec elements are separated with NUL character and all other characters are taken literally (including newlines and quotes). -- This option can be used to separate command-line options from the list of files, (useful when filenames might be mistaken for command-line options). "
  },
  {
    "command": "indent",
    "description": " This man page is generated from the file indent.texinfo. This is Edition of \"The indent Manual\", for Indent Version , last updated . The indent program can be used to make code easier to read. It can also convert from one style of writing C to another. indent understands a substantial amount about the syntax of C, but it also attempts to cope with incomplete and misformed syntax. In version 1.2 and more recent versions, the GNU style of indenting is the default. -as, --align-with-spaces If using tabs for indentation, use spaces for alignment. See INDENTATION. -bad, --blank-lines-after-declarations Force blank lines after the declarations. See BLANK LINES. -bap, --blank-lines-after-procedures Force blank lines after procedure bodies. See BLANK LINES. -bbb, --blank-lines-before-block-comments Force blank lines before block comments. See BLANK LINES. -bbo, --break-before-boolean-operator Prefer to break long lines before boolean operators. See BREAKING LONG LINES. -bc, --blank-lines-after-commas Force newline after comma in declaration. See DECLARATIONS. -bl, --braces-after-if-line Put braces on line after if, etc. See STATEMENTS. -blf, --braces-after-func-def-line Put braces on line following function definition line. See DECLARATIONS. -blin, --brace-indentn Indent braces n spaces. See STATEMENTS. -bls, --braces-after-struct-decl-line Put braces on the line after struct declaration lines. See DECLARATIONS. -br, --braces-on-if-line Put braces on line with if, etc. See STATEMENTS. -brf, --braces-on-func-def-line Put braces on function definition line. See DECLARATIONS. -brs, --braces-on-struct-decl-line Put braces on struct declaration line. See DECLARATIONS. -bs, --Bill-Shannon, --blank-before-sizeof Put a space between sizeof and its argument. See STATEMENTS. -cn, --comment-indentationn Put comments to the right of code in column n. See COMMENTS. -cbin, --case-brace-indentationn Indent braces after a case label N spaces. See STATEMENTS. -cdn, --declaration-comment-columnn Put comments to the right of the declarations in column n. See COMMENTS. -cdb, --comment-delimiters-on-blank-lines Put comment delimiters on blank lines. See COMMENTS. -cdw, --cuddle-do-while Cuddle while of do {} while; and preceding \u2018}\u2019. See COMMENTS. -ce, --cuddle-else Cuddle else and preceding \u2018}\u2019. See COMMENTS. -cin, --continuation-indentationn Continuation indent of n spaces. See STATEMENTS. -clin, --case-indentationn Case label indent of n spaces. See STATEMENTS. -cpn, --else-endif-columnn Put comments to the right of #else and #endif statements in column n. See COMMENTS. -cs, --space-after-cast Put a space after a cast operator. See STATEMENTS. -dn, --line-comments-indentationn Set indentation of comments not to the right of code to n spaces. See COMMENTS. -bfda, --break-function-decl-args Break the line before all arguments in a declaration. See DECLARATIONS. -bfde, --break-function-decl-args-end Break the line after the last argument in a declaration. See DECLARATIONS. -dj, --left-justify-declarations If -cd 0 is used then comments after declarations are left justified behind the declaration. See DECLARATIONS. -din, --declaration-indentationn Put variables in column n. See DECLARATIONS. -fc1, --format-first-column-comments Format comments in the first column. See COMMENTS. -fca, --format-all-comments Do not disable all formatting of comments. See COMMENTS. -fnc, --fix-nested-comments Fix nested comments. See COMMENTS. -gnu, --gnu-style Use GNU coding style. This is the default. See COMMON STYLES. -gts, --gettext-strings Treat gettext _(\"...\") and N_(\"...\") as strings rather than as functions. See BREAKING LONG LINES. -hnl, --honour-newlines Prefer to break long lines at the position of newlines in the input. See BREAKING LONG LINES. -in, --indent-leveln Set indentation level to n spaces. See INDENTATION. -iln, --indent-labeln Set offset for labels to column n. See INDENTATION. -ipn, --parameter-indentationn Indent parameter types in old-style function definitions by n spaces. See INDENTATION. -kr, --k-and-r-style Use Kernighan & Ritchie coding style. See COMMON STYLES. -ln, --line-lengthn Set maximum line length for non-comment lines to n. See BREAKING LONG LINES. -lcn, --comment-line-lengthn Set maximum line length for comment formatting to n. See COMMENTS. -linux, --linux-style Use Linux coding style. See COMMON STYLES. -lp, --continue-at-parentheses Line up continued lines at parentheses. See INDENTATION. -lps, --leave-preprocessor-space Leave space between \u2018#\u2019 and preprocessor directive. See INDENTATION. -nlps, --remove-preprocessor-space Remove space between \u2018#\u2019 and preprocessor directive. See INDENTATION. -nbad, --no-blank-lines-after-declarations Do not force blank lines after declarations. See BLANK LINES. -nbap, --no-blank-lines-after-procedures Do not force blank lines after procedure bodies. See BLANK LINES. -nbbo, --break-after-boolean-operator Do not prefer to break long lines before boolean operators. See BREAKING LONG LINES. -nbc, --no-blank-lines-after-commas Do not force newlines after commas in declarations. See DECLARATIONS. -nbfda, --dont-break-function-decl-args Don\u2019t put each argument in a function declaration on a separate line. See DECLARATIONS. -ncdb, --no-comment-delimiters-on-blank-lines Do not put comment delimiters on blank lines. See COMMENTS. -ncdw, --dont-cuddle-do-while Do not cuddle } and the while of a do {} while;. See STATEMENTS. -nce, --dont-cuddle-else Do not cuddle } and else. See STATEMENTS. -ncs, --no-space-after-casts Do not put a space after cast operators. See STATEMENTS. -ndjn, --dont-left-justify-declarations Comments after declarations are treated the same as comments after other statements. See DECLARATIONS. -nfc1, --dont-format-first-column-comments Do not format comments in the first column as normal. See COMMENTS. -nfca, --dont-format-comments Do not format any comments. See COMMENTS. -ngts, --no-gettext-strings Treat gettext _(\"...\") and N_(\"...\") as normal functions. This is the default. See BREAKING LONG LINES. -nhnl, --ignore-newlines Do not prefer to break long lines at the position of newlines in the input. See BREAKING LONG LINES. -nip, --no-parameter-indentation Zero width indentation for parameters. See INDENTATION. -nlp, --dont-line-up-parentheses Do not line up parentheses. See STATEMENTS. -npcs, --no-space-after-function-call-names Do not put space after the function in function calls. See STATEMENTS. -nprs, --no-space-after-parentheses Do not put a space after every \u2019(\u2019 and before every \u2019)\u2019. See STATEMENTS. -npsl, --dont-break-procedure-type Put the type of a procedure on the same line as its name. See DECLARATIONS. -nsaf, --no-space-after-for Do not put a space after every for. See STATEMENTS. -nsai, --no-space-after-if Do not put a space after every if. See STATEMENTS. -nsaw, --no-space-after-while Do not put a space after every while. See STATEMENTS. -nsc, --dont-star-comments Do not put the \u2018*\u2019 character at the left of comments. See COMMENTS. -nsob, --leave-optional-blank-lines Do not swallow optional blank lines. See BLANK LINES. -nss, --dont-space-special-semicolon Do not force a space before the semicolon after certain statements. Disables \u2018-ss\u2019. See STATEMENTS. -ntac, --dont-tab-align-comments Do not pad comments out to the nearest tabstop. See COMMENTS. -nut, --no-tabs Use spaces instead of tabs. See INDENTATION. -nv, --no-verbosity Disable verbose mode. See MISCELLANEOUS OPTIONS. -orig, --original Use the original Berkeley coding style. See COMMON STYLES. -npro, --ignore-profile Do not read \u2018.indent.pro\u2019 files. See INVOKING INDENT. -pal, --pointer-align-left Put asterisks in pointer declarations on the left of spaces, next to types: \u2018\u2018char* p\u2019\u2019. -par, --pointer-align-right Put asterisks in pointer declarations on the right of spaces, next to variable names: \u2018\u2018char *p\u2019\u2019. This is the default behavior. -pcs, --space-after-procedure-calls Insert a space between the name of the procedure being called and the \u2018(\u2019. See STATEMENTS. -pin, --paren-indentationn Specify the extra indentation per open parentheses \u2019(\u2019 when a statement is broken.See STATEMENTS. -pmt, --preserve-mtime Preserve access and modification times on output files.See MISCELLANEOUS OPTIONS. -ppin, --preprocessor-indentationn Specify the indentation for preprocessor conditional statements.See INDENTATION. -prs, --space-after-parentheses Put a space after every \u2019(\u2019 and before every \u2019)\u2019. See STATEMENTS. -psl, --procnames-start-lines Put the type of a procedure on the line before its name. See DECLARATIONS. -saf, --space-after-for Put a space after each for. See STATEMENTS. -sai, --space-after-if Put a space after each if. See STATEMENTS. -sar, --spaces-around-initializers Put a space after the \u2018{\u2019 and before the \u2018}\u2019 in initializers. See DECLARATIONS. -saw, --space-after-while Put a space after each while. See STATEMENTS. -sbin, --struct-brace-indentationn Indent braces of a struct, union or enum N spaces. See STATEMENTS. -sc, --start-left-side-of-comments Put the \u2018*\u2019 character at the left of comments. See COMMENTS. -slc, --single-line-conditionals Allow for unbraced conditionals (if, else, etc.) to have their inner statement on the same line. See STATEMENTS. -sob, --swallow-optional-blank-lines Swallow optional blank lines. See BLANK LINES. -ss, --space-special-semicolon On one-line for and while statements, force a blank before the semicolon. See STATEMENTS. -st, --standard-output Write to standard output. See INVOKING INDENT. -T Tell indent the name of typenames. See DECLARATIONS. -tsn, --tab-sizen Set tab size to n spaces. See INDENTATION. -ut, --use-tabs Use tabs. This is the default. See INDENTATION. -v, --verbose Enable verbose mode. See MISCELLANEOUS OPTIONS. -version Output the version number of indent. See MISCELLANEOUS OPTIONS. "
  },
  {
    "command": "stty",
    "description": " Print or change terminal characteristics. Mandatory arguments to long options are mandatory for short options too. -a, --all print all current settings in human-readable form -g, --save print all current settings in a stty-readable form -F, --file=DEVICE open and use the specified DEVICE instead of stdin --help display this help and exit --version output version information and exit Optional - before SETTING indicates negation. An * marks non-POSIX settings. The underlying system defines which settings are available. Special characters: * discard CHAR CHAR will toggle discarding of output eof CHAR CHAR will send an end of file (terminate the input) eol CHAR CHAR will end the line * eol2 CHAR alternate CHAR for ending the line erase CHAR CHAR will erase the last character typed intr CHAR CHAR will send an interrupt signal kill CHAR CHAR will erase the current line * lnext CHAR CHAR will enter the next character quoted quit CHAR CHAR will send a quit signal * rprnt CHAR CHAR will redraw the current line start CHAR CHAR will restart the output after stopping it stop CHAR CHAR will stop the output susp CHAR CHAR will send a terminal stop signal * swtch CHAR CHAR will switch to a different shell layer * werase CHAR CHAR will erase the last word typed Special settings: N set the input and output speeds to N bauds * cols N tell the kernel that the terminal has N columns * columns N same as cols N * [-]drain wait for transmission before applying settings (on by default) ispeed N set the input speed to N * line N use line discipline N min N with -icanon, set N characters minimum for a completed read ospeed N set the output speed to N * rows N tell the kernel that the terminal has N rows * size print the number of rows and columns according to the kernel speed print the terminal speed time N with -icanon, set read timeout of N tenths of a second Control settings: [-]clocal disable modem control signals [-]cread allow input to be received * [-]crtscts enable RTS/CTS handshaking csN set character size to N bits, N in [5..8] [-]cstopb use two stop bits per character (one with '-') [-]hup send a hangup signal when the last process closes the tty [-]hupcl same as [-]hup [-]parenb generate parity bit in output and expect parity bit in input [-]parodd set odd parity (or even parity with '-') * [-]cmspar use \"stick\" (mark/space) parity Input settings: [-]brkint breaks cause an interrupt signal [-]icrnl translate carriage return to newline [-]ignbrk ignore break characters [-]igncr ignore carriage return [-]ignpar ignore characters with parity errors * [-]imaxbel beep and do not flush a full input buffer on a character [-]inlcr translate newline to carriage return [-]inpck enable input parity checking [-]istrip clear high (8th) bit of input characters * [-]iutf8 assume input characters are UTF-8 encoded * [-]iuclc translate uppercase characters to lowercase * [-]ixany let any character restart output, not only start character [-]ixoff enable sending of start/stop characters [-]ixon enable XON/XOFF flow control [-]parmrk mark parity errors (with a 255-0-character sequence) [-]tandem same as [-]ixoff Output settings: * bsN backspace delay style, N in [0..1] * crN carriage return delay style, N in [0..3] * ffN form feed delay style, N in [0..1] * nlN newline delay style, N in [0..1] * [-]ocrnl translate carriage return to newline * [-]ofdel use delete characters for fill instead of NUL characters * [-]ofill use fill (padding) characters instead of timing for delays * [-]olcuc translate lowercase characters to uppercase * [-]onlcr translate newline to carriage return-newline * [-]onlret newline performs a carriage return * [-]onocr do not print carriage returns in the first column [-]opost postprocess output * tabN horizontal tab delay style, N in [0..3] * tabs same as tab0 * -tabs same as tab3 * vtN vertical tab delay style, N in [0..1] Local settings: [-]crterase echo erase characters as backspace-space-backspace * crtkill kill all line by obeying the echoprt and echoe settings * -crtkill kill all line by obeying the echoctl and echok settings * [-]ctlecho echo control characters in hat notation ('^c') [-]echo echo input characters * [-]echoctl same as [-]ctlecho [-]echoe same as [-]crterase [-]echok echo a newline after a kill character * [-]echoke same as [-]crtkill [-]echonl echo newline even if not echoing other characters * [-]echoprt echo erased characters backward, between '\\' and '/' * [-]extproc enable \"LINEMODE\"; useful with high latency links * [-]flusho discard output [-]icanon enable special characters: erase, kill, werase, rprnt [-]iexten enable non-POSIX special characters [-]isig enable interrupt, quit, and suspend special characters [-]noflsh disable flushing after interrupt and quit special characters * [-]prterase same as [-]echoprt * [-]tostop stop background jobs that try to write to the terminal * [-]xcase with icanon, escape with '\\' for uppercase characters Combination settings: * [-]LCASE same as [-]lcase cbreak same as -icanon -cbreak same as icanon cooked same as brkint ignpar istrip icrnl ixon opost isig icanon, eof and eol characters to their default values -cooked same as raw crt same as echoe echoctl echoke dec same as echoe echoctl echoke -ixany intr ^c erase 0177 kill ^u * [-]decctlq same as [-]ixany ek erase and kill characters to their default values evenp same as parenb -parodd cs7 -evenp same as -parenb cs8 * [-]lcase same as xcase iuclc olcuc litout same as -parenb -istrip -opost cs8 -litout same as parenb istrip opost cs7 nl same as -icrnl -onlcr -nl same as icrnl -inlcr -igncr onlcr -ocrnl -onlret oddp same as parenb parodd cs7 -oddp same as -parenb cs8 [-]parity same as [-]evenp pass8 same as -parenb -istrip cs8 -pass8 same as parenb istrip cs7 raw same as -ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr -icrnl -ixon -ixoff -icanon -opost -isig -iuclc -ixany -imaxbel -xcase min 1 time 0 -raw same as cooked sane same as cread -ignbrk brkint -inlcr -igncr icrnl icanon iexten echo echoe echok -echonl -noflsh -ixoff -iutf8 -iuclc -ixany imaxbel -xcase -olcuc -ocrnl opost -ofill onlcr -onocr -onlret nl0 cr0 tab0 bs0 vt0 ff0 isig -tostop -ofdel -echoprt echoctl echoke -extproc -flusho, all special characters to their default values Handle the tty line connected to standard input. Without arguments, prints baud rate, line discipline, and deviations from stty sane. In settings, CHAR is taken literally, or coded as in ^c, 0x37, 0177 or 127; special values ^- or undef used to disable special characters. "
  },
  {
    "command": "git-column",
    "description": " This command formats the lines of its standard input into a table with multiple columns. Each input line occupies one cell of the table. It is used internally by other git commands to format output into columns. --command=<name> Look up layout mode using configuration variable column.<name> and column.ui. --mode=<mode> Specify layout mode. See configuration variable column.ui for option syntax in git-config(1). --raw-mode=<n> Same as --mode but take mode encoded as a number. This is mainly used by other commands that have already parsed layout mode. --width=<width> Specify the terminal width. By default git column will detect the terminal width, or fall back to 80 if it is unable to do so. --indent=<string> String to be printed at the beginning of each line. --nl=<string> String to be printed at the end of each line, including newline character. --padding=<N> The number of spaces between columns. One space by default. "
  },
  {
    "command": "who",
    "description": " Print information about users who are currently logged in. -a, --all same as -b -d --login -p -r -t -T -u -b, --boot time of last system boot -d, --dead print dead processes -H, --heading print line of column headings -l, --login print system login processes --lookup attempt to canonicalize hostnames via DNS -m only hostname and user associated with stdin -p, --process print active processes spawned by init -q, --count all login names and number of users logged on -r, --runlevel print current runlevel -s, --short print only name, line, and time (default) -t, --time print last system clock change -T, -w, --mesg add user's message status as +, - or ? -u, --users list users logged in --message same as -T --writable same as -T --help display this help and exit --version output version information and exit If FILE is not specified, use /var/run/utmp. /var/log/wtmp as FILE is common. If ARG1 ARG2 given, -m presumed: 'am i' or 'mom likes' are usual. "
  },
  {
    "command": "git-notes",
    "description": " Adds, removes, or reads notes attached to objects, without touching the objects themselves. By default, notes are saved to and read from refs/notes/commits, but this default can be overridden. See the OPTIONS, CONFIGURATION, and ENVIRONMENT sections below. If this ref does not exist, it will be quietly created when it is first needed to store a note. A typical use of notes is to supplement a commit message without changing the commit itself. Notes can be shown by git log along with the original commit message. To distinguish these notes from the message stored in the commit object, the notes are indented like the message, after an unindented line saying \"Notes (<refname>):\" (or \"Notes:\" for refs/notes/commits). Notes can also be added to patches prepared with git format-patch by using the --notes option. Such notes are added as a patch commentary after a three dash separator line. To change which notes are shown by git log, see the \"notes.displayRef\" discussion in the section called \u201cCONFIGURATION\u201d. See the \"notes.rewrite.<command>\" configuration for a way to carry notes across commands that rewrite commits. -f, --force When adding notes to an object that already has notes, overwrite the existing notes (instead of aborting). -m <msg>, --message=<msg> Use the given note message (instead of prompting). If multiple -m options are given, their values are concatenated as separate paragraphs. Lines starting with # and empty lines other than a single line between paragraphs will be stripped out. -F <file>, --file=<file> Take the note message from the given file. Use - to read the note message from the standard input. Lines starting with # and empty lines other than a single line between paragraphs will be stripped out. -C <object>, --reuse-message=<object> Take the given blob object (for example, another note) as the note message. (Use git notes copy <object> instead to copy notes between objects.) -c <object>, --reedit-message=<object> Like -C, but with -c the editor is invoked, so that the user can further edit the note message. --allow-empty Allow an empty note object to be stored. The default behavior is to automatically remove empty notes. --ref <ref> Manipulate the notes tree in <ref>. This overrides GIT_NOTES_REF and the \"core.notesRef\" configuration. The ref specifies the full refname when it begins with refs/notes/; when it begins with notes/, refs/ and otherwise refs/notes/ is prefixed to form a full name of the ref. --ignore-missing Do not consider it an error to request removing notes from an object that does not have notes attached to it. --stdin Also read the object names to remove notes from the standard input (there is no reason you cannot combine this with object names from the command line). -n, --dry-run Do not remove anything; just report the object names whose notes would be removed. -s <strategy>, --strategy=<strategy> When merging notes, resolve notes conflicts using the given strategy. The following strategies are recognized: \"manual\" (default), \"ours\", \"theirs\", \"union\" and \"cat_sort_uniq\". This option overrides the \"notes.mergeStrategy\" configuration setting. See the \"NOTES MERGE STRATEGIES\" section below for more information on each notes merge strategy. --commit Finalize an in-progress git notes merge. Use this option when you have resolved the conflicts that git notes merge stored in .git/NOTES_MERGE_WORKTREE. This amends the partial merge commit created by git notes merge (stored in .git/NOTES_MERGE_PARTIAL) by adding the notes in .git/NOTES_MERGE_WORKTREE. The notes ref stored in the .git/NOTES_MERGE_REF symref is updated to the resulting commit. --abort Abort/reset an in-progress git notes merge, i.e. a notes merge with conflicts. This simply removes all files related to the notes merge. -q, --quiet When merging notes, operate quietly. -v, --verbose When merging notes, be more verbose. When pruning notes, report all object names whose notes are removed. "
  },
  {
    "command": "git-mv",
    "description": " Move or rename a file, directory or symlink. git mv [-v] [-f] [-n] [-k] <source> <destination> git mv [-v] [-f] [-n] [-k] <source> ... <destination directory> In the first form, it renames <source>, which must exist and be either a file, symlink or directory, to <destination>. In the second form, the last argument has to be an existing directory; the given sources will be moved into this directory. The index is updated after successful completion, but the change must still be committed. -f, --force Force renaming or moving of a file even if the <destination> exists. -k Skip move or rename actions which would lead to an error condition. An error happens when a source is neither existing nor controlled by Git, or when it would overwrite an existing file unless -f is given. -n, --dry-run Do nothing; only show what would happen -v, --verbose Report the names of files as they are moved. "
  },
  {
    "command": "strip",
    "description": " GNU strip discards all symbols from object files objfile. The list of object files may include archives. At least one object file must be given. strip modifies the files named in its argument, rather than writing modified copies under different names. -F bfdname --target=bfdname Treat the original objfile as a file with the object code format bfdname, and rewrite it in the same format. --help Show a summary of the options to strip and exit. --info Display a list showing all architectures and object formats available. -I bfdname --input-target=bfdname Treat the original objfile as a file with the object code format bfdname. -O bfdname --output-target=bfdname Replace objfile with a file in the output format bfdname. -R sectionname --remove-section=sectionname Remove any section named sectionname from the output file, in addition to whatever sections would otherwise be removed. This option may be given more than once. Note that using this option inappropriately may make the output file unusable. The wildcard character * may be given at the end of sectionname. If so, then any section starting with sectionname will be removed. If the first character of sectionpattern is the exclamation point (!) then matching sections will not be removed even if an earlier use of --remove-section on the same command line would otherwise remove it. For example: --remove-section=.text.* --remove-section=!.text.foo will remove all sections matching the pattern '.text.*', but will not remove the section '.text.foo'. --keep-section=sectionpattern When removing sections from the output file, keep sections that match sectionpattern. --remove-relocations=sectionpattern Remove relocations from the output file for any section matching sectionpattern. This option may be given more than once. Note that using this option inappropriately may make the output file unusable. Wildcard characters are accepted in sectionpattern. For example: --remove-relocations=.text.* will remove the relocations for all sections matching the patter '.text.*'. If the first character of sectionpattern is the exclamation point (!) then matching sections will not have their relocation removed even if an earlier use of --remove-relocations on the same command line would otherwise cause the relocations to be removed. For example: --remove-relocations=.text.* --remove-relocations=!.text.foo will remove all relocations for sections matching the pattern '.text.*', but will not remove relocations for the section '.text.foo'. -s --strip-all Remove all symbols. -g -S -d --strip-debug Remove debugging symbols only. --strip-dwo Remove the contents of all DWARF .dwo sections, leaving the remaining debugging sections and all symbols intact. See the description of this option in the objcopy section for more information. --strip-unneeded Remove all symbols that are not needed for relocation processing in addition to debugging symbols and sections stripped by --strip-debug. -K symbolname --keep-symbol=symbolname When stripping symbols, keep symbol symbolname even if it would normally be stripped. This option may be given more than once. -M --merge-notes --no-merge-notes For ELF files, attempt (or do not attempt) to reduce the size of any SHT_NOTE type sections by removing duplicate notes. The default is to attempt this reduction unless stripping debug or DWO information. -N symbolname --strip-symbol=symbolname Remove symbol symbolname from the source file. This option may be given more than once, and may be combined with strip options other than -K. -o file Put the stripped output in file, rather than replacing the existing file. When this argument is used, only one objfile argument may be specified. -p --preserve-dates Preserve the access and modification dates of the file. -D --enable-deterministic-archives Operate in deterministic mode. When copying archive members and writing the archive index, use zero for UIDs, GIDs, timestamps, and use consistent file modes for all files. If binutils was configured with --enable-deterministic-archives, then this mode is on by default. It can be disabled with the -U option, below. -U --disable-deterministic-archives Do not operate in deterministic mode. This is the inverse of the -D option, above: when copying archive members and writing the archive index, use their actual UID, GID, timestamp, and file mode values. This is the default unless binutils was configured with --enable-deterministic-archives. -w --wildcard Permit regular expressions in symbolnames used in other command line options. The question mark (?), asterisk (*), backslash (\\) and square brackets ([]) operators can be used anywhere in the symbol name. If the first character of the symbol name is the exclamation point (!) then the sense of the switch is reversed for that symbol. For example: -w -K !foo -K fo* would cause strip to only keep symbols that start with the letters \"fo\", but to discard the symbol \"foo\". -x --discard-all Remove non-global symbols. -X --discard-locals Remove compiler-generated local symbols. (These usually start with L or ..) --keep-section-symbols When stripping a file, perhaps with --strip-debug or --strip-unneeded, retain any symbols specifying section names, which would otherwise get stripped. --keep-file-symbols When stripping a file, perhaps with --strip-debug or --strip-unneeded, retain any symbols specifying source file names, which would otherwise get stripped. --only-keep-debug Strip a file, emptying the contents of any sections that would not be stripped by --strip-debug and leaving the debugging sections intact. In ELF files, this preserves all the note sections in the output as well. Note - the section headers of the stripped sections are preserved, including their sizes, but the contents of the section are discarded. The section headers are preserved so that other tools can match up the debuginfo file with the real executable, even if that executable has been relocated to a different address space. The intention is that this option will be used in conjunction with --add-gnu-debuglink to create a two part executable. One a stripped binary which will occupy less space in RAM and in a distribution and the second a debugging information file which is only needed if debugging abilities are required. The suggested procedure to create these files is as follows: 1.<Link the executable as normal. Assuming that it is called> \"foo\" then... 1.<Run \"objcopy --only-keep-debug foo foo.dbg\" to> create a file containing the debugging info. 1.<Run \"objcopy --strip-debug foo\" to create a> stripped executable. 1.<Run \"objcopy --add-gnu-debuglink=foo.dbg foo\"> to add a link to the debugging info into the stripped executable. Note---the choice of \".dbg\" as an extension for the debug info file is arbitrary. Also the \"--only-keep-debug\" step is optional. You could instead do this: 1.<Link the executable as normal.> 1.<Copy \"foo\" to \"foo.full\"> 1.<Run \"strip --strip-debug foo\"> 1.<Run \"objcopy --add-gnu-debuglink=foo.full foo\"> i.e., the file pointed to by the --add-gnu-debuglink can be the full executable. It does not have to be a file created by the --only-keep-debug switch. Note---this switch is only intended for use on fully linked files. It does not make sense to use it on object files where the debugging information may be incomplete. Besides the gnu_debuglink feature currently only supports the presence of one filename containing debugging information, not multiple filenames on a one-per-object-file basis. -V --version Show the version number for strip. -v --verbose Verbose output: list all object files modified. In the case of archives, strip -v lists all members of the archive. @file Read command-line options from file. The options read are inserted in place of the original @file option. If file does not exist, or cannot be read, then the option will be treated literally, and not removed. Options in file are separated by whitespace. A whitespace character may be included in an option by surrounding the entire option in either single or double quotes. Any character (including a backslash) may be included by prefixing the character to be included with a backslash. The file may itself contain additional @file options; any such options will be processed recursively. "
  },
  {
    "command": "bash",
    "description": " Bash is an sh-compatible command language interpreter that executes commands read from the standard input or from a file. Bash also incorporates useful features from the Korn and C shells (ksh and csh). Bash is intended to be a conformant implementation of the Shell and Utilities portion of the IEEE POSIX specification (IEEE Standard 1003.1). Bash can be configured to be POSIX-conformant by default. All of the single-character shell options documented in the description of the set builtin command, including -o, can be used as options when the shell is invoked. In addition, bash interprets the following options when it is invoked: -c If the -c option is present, then commands are read from the first non-option argument command_string. If there are arguments after the command_string, the first argument is assigned to $0 and any remaining arguments are assigned to the positional parameters. The assignment to $0 sets the name of the shell, which is used in warning and error messages. -i If the -i option is present, the shell is interactive. -l Make bash act as if it had been invoked as a login shell (see INVOCATION below). -r If the -r option is present, the shell becomes restricted (see RESTRICTED SHELL below). -s If the -s option is present, or if no arguments remain after option processing, then commands are read from the standard input. This option allows the positional parameters to be set when invoking an interactive shell or when reading input through a pipe. -D A list of all double-quoted strings preceded by $ is printed on the standard output. These are the strings that are subject to language translation when the current locale is not C or POSIX. This implies the -n option; no commands will be executed. [-+]O [shopt_option] shopt_option is one of the shell options accepted by the shopt builtin (see SHELL BUILTIN COMMANDS below). If shopt_option is present, -O sets the value of that option; +O unsets it. If shopt_option is not supplied, the names and values of the shell options accepted by shopt are printed on the standard output. If the invocation option is +O, the output is displayed in a format that may be reused as input. -- A -- signals the end of options and disables further option processing. Any arguments after the -- are treated as filenames and arguments. An argument of - is equivalent to --. Bash also interprets a number of multi-character options. These options must appear on the command line before the single- character options to be recognized. --debugger Arrange for the debugger profile to be executed before the shell starts. Turns on extended debugging mode (see the description of the extdebug option to the shopt builtin below). --dump-po-strings Equivalent to -D, but the output is in the GNU gettext po (portable object) file format. --dump-strings Equivalent to -D. --help Display a usage message on standard output and exit successfully. --init-file file --rcfile file Execute commands from file instead of the standard personal initialization file ~/.bashrc if the shell is interactive (see INVOCATION below). --login Equivalent to -l. --noediting Do not use the GNU readline library to read command lines when the shell is interactive. --noprofile Do not read either the system-wide startup file /etc/profile or any of the personal initialization files ~/.bash_profile, ~/.bash_login, or ~/.profile. By default, bash reads these files when it is invoked as a login shell (see INVOCATION below). --norc Do not read and execute the personal initialization file ~/.bashrc if the shell is interactive. This option is on by default if the shell is invoked as sh. --posix Change the behavior of bash where the default operation differs from the POSIX standard to match the standard (posix mode). See SEE ALSO below for a reference to a document that details how posix mode affects bash's behavior. --restricted The shell becomes restricted (see RESTRICTED SHELL below). --verbose Equivalent to -v. --version Show version information for this instance of bash on the standard output and exit successfully. "
  },
  {
    "command": "exit",
    "description": " The exit utility shall cause the shell to exit from its current execution environment with the exit status specified by the unsigned decimal integer n. If the current execution environment is a subshell environment, the shell shall exit from the subshell environment with the specified exit status and continue in the environment from which that subshell environment was invoked; otherwise, the shell utility shall terminate with the specified exit status. If n is specified, but its value is not between 0 and 255 inclusively, the exit status is undefined. A trap on EXIT shall be executed before the shell terminates, except when the exit utility is invoked in that trap itself, in which case the shell shall exit immediately. None. "
  },
  {
    "command": "uniq",
    "description": " The uniq utility shall read an input file comparing adjacent lines, and write one copy of each input line on the output. The second and succeeding copies of repeated adjacent input lines shall not be written. The trailing <newline> of each line in the input shall be ignored when doing comparisons. Repeated lines in the input shall not be detected if they are not adjacent. The uniq utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except that '+' may be recognized as an option delimiter as well as '-'. The following options shall be supported: -c Precede each output line with a count of the number of times the line occurred in the input. -d Suppress the writing of lines that are not repeated in the input. -f fields Ignore the first fields fields on each input line when doing comparisons, where fields is a positive decimal integer. A field is the maximal string matched by the basic regular expression: [[:blank:]]*[^[:blank:]]* If the fields option-argument specifies more fields than appear on an input line, a null string shall be used for comparison. -s chars Ignore the first chars characters when doing comparisons, where chars shall be a positive decimal integer. If specified in conjunction with the -f option, the first chars characters after the first fields fields shall be ignored. If the chars option- argument specifies more characters than remain on an input line, a null string shall be used for comparison. -u Suppress the writing of lines that are repeated in the input. "
  },
  {
    "command": "git-mailinfo",
    "description": " Reads a single e-mail message from the standard input, and writes the commit log message in <msg> file, and the patches in <patch> file. The author name, e-mail and e-mail subject are written out to the standard output to be used by git am to create a commit. It is usually not necessary to use this command directly. See git-am(1) instead. -k Usually the program removes email cruft from the Subject: header line to extract the title line for the commit log message. This option prevents this munging, and is most useful when used to read back git format-patch -k output. Specifically, the following are removed until none of them remain: \u2022 Leading and trailing whitespace. \u2022 Leading Re:, re:, and :. \u2022 Leading bracketed strings (between [ and ], usually [PATCH]). Finally, runs of whitespace are normalized to a single ASCII space character. -b When -k is not in effect, all leading strings bracketed with [ and ] pairs are stripped. This option limits the stripping to only the pairs whose bracketed string contains the word \"PATCH\". -u The commit log message, author name and author email are taken from the e-mail, and after minimally decoding MIME transfer encoding, re-coded in the charset specified by i18n.commitEncoding (defaulting to UTF-8) by transliterating them. This used to be optional but now it is the default. Note that the patch is always used as-is without charset conversion, even with this flag. --encoding=<encoding> Similar to -u. But when re-coding, the charset specified here is used instead of the one specified by i18n.commitEncoding or UTF-8. -n Disable all charset re-coding of the metadata. -m, --message-id Copy the Message-ID header at the end of the commit message. This is useful in order to associate commits with mailing list discussions. --scissors Remove everything in body before a scissors line (e.g. \"-- >8 --\"). The line represents scissors and perforation marks, and is used to request the reader to cut the message at that line. If that line appears in the body of the message before the patch, everything before it (including the scissors line itself) is ignored when this option is used. This is useful if you want to begin your message in a discussion thread with comments and suggestions on the message you are responding to, and to conclude it with a patch submission, separating the discussion and the beginning of the proposed commit log message with a scissors line. This can be enabled by default with the configuration option mailinfo.scissors. --no-scissors Ignore scissors lines. Useful for overriding mailinfo.scissors settings. --quoted-cr=<action> Action when processes email messages sent with base64 or quoted-printable encoding, and the decoded lines end with a CRLF instead of a simple LF. The valid actions are: \u2022 nowarn: Git will do nothing when such a CRLF is found. \u2022 warn: Git will issue a warning for each message if such a CRLF is found. \u2022 strip: Git will convert those CRLF to LF. The default action could be set by configuration option mailinfo.quotedCR. If no such configuration option has been set, warn will be used. <msg> The commit log message extracted from e-mail, usually except the title line which comes from e-mail Subject. <patch> The patch extracted from e-mail. "
  },
  {
    "command": "git-annotate",
    "description": " Annotates each line in the given file with information from the commit which introduced the line. Optionally annotates from a given revision. The only difference between this command and git-blame(1) is that they use slightly different output formats, and this command exists only for backward compatibility to support existing scripts, and provide a more familiar command name for people coming from other SCM systems. -b Show blank SHA-1 for boundary commits. This can also be controlled via the blame.blankBoundary config option. --root Do not treat root commits as boundaries. This can also be controlled via the blame.showRoot config option. --show-stats Include additional statistics at the end of blame output. -L <start>,<end>, -L :<funcname> Annotate only the line range given by <start>,<end>, or by the function name regex <funcname>. May be specified multiple times. Overlapping ranges are allowed. <start> and <end> are optional. -L <start> or -L <start>, spans from <start> to end of file. -L ,<end> spans from start of file to <end>. <start> and <end> can take one of these forms: \u2022 number If <start> or <end> is a number, it specifies an absolute line number (lines count from 1). \u2022 /regex/ This form will use the first line matching the given POSIX regex. If <start> is a regex, it will search from the end of the previous -L range, if any, otherwise from the start of file. If <start> is ^/regex/, it will search from the start of file. If <end> is a regex, it will search starting at the line given by <start>. \u2022 +offset or -offset This is only valid for <end> and will specify a number of lines before or after the line given by <start>. If :<funcname> is given in place of <start> and <end>, it is a regular expression that denotes the range from the first funcname line that matches <funcname>, up to the next funcname line. :<funcname> searches from the end of the previous -L range, if any, otherwise from the start of file. ^:<funcname> searches from the start of file. The function names are determined in the same way as git diff works out patch hunk headers (see Defining a custom hunk-header in gitattributes(5)). -l Show long rev (Default: off). -t Show raw timestamp (Default: off). -S <revs-file> Use revisions from revs-file instead of calling git-rev-list(1). --reverse <rev>..<rev> Walk history forward instead of backward. Instead of showing the revision in which a line appeared, this shows the last revision in which a line has existed. This requires a range of revision like START..END where the path to blame exists in START. git blame --reverse START is taken as git blame --reverse START..HEAD for convenience. --first-parent Follow only the first parent commit upon seeing a merge commit. This option can be used to determine when a line was introduced to a particular integration branch, rather than when it was introduced to the history overall. -p, --porcelain Show in a format designed for machine consumption. --line-porcelain Show the porcelain format, but output commit information for each line, not just the first time a commit is referenced. Implies --porcelain. --incremental Show the result incrementally in a format designed for machine consumption. --encoding=<encoding> Specifies the encoding used to output author names and commit summaries. Setting it to none makes blame output unconverted data. For more information see the discussion about encoding in the git-log(1) manual page. --contents <file> Annotate using the contents from the named file, starting from <rev> if it is specified, and HEAD otherwise. You may specify - to make the command read from the standard input for the file contents. --date <format> Specifies the format used to output dates. If --date is not provided, the value of the blame.date config variable is used. If the blame.date config variable is also not set, the iso format is used. For supported values, see the discussion of the --date option at git-log(1). --[no-]progress Progress status is reported on the standard error stream by default when it is attached to a terminal. This flag enables progress reporting even if not attached to a terminal. Can\u2019t use --progress together with --porcelain or --incremental. -M[<num>] Detect moved or copied lines within a file. When a commit moves or copies a block of lines (e.g. the original file has A and then B, and the commit changes it to B and then A), the traditional blame algorithm notices only half of the movement and typically blames the lines that were moved up (i.e. B) to the parent and assigns blame to the lines that were moved down (i.e. A) to the child commit. With this option, both groups of lines are blamed on the parent by running extra passes of inspection. <num> is optional but it is the lower bound on the number of alphanumeric characters that Git must detect as moving/copying within a file for it to associate those lines with the parent commit. The default value is 20. -C[<num>] In addition to -M, detect lines moved or copied from other files that were modified in the same commit. This is useful when you reorganize your program and move code around across files. When this option is given twice, the command additionally looks for copies from other files in the commit that creates the file. When this option is given three times, the command additionally looks for copies from other files in any commit. <num> is optional but it is the lower bound on the number of alphanumeric characters that Git must detect as moving/copying between files for it to associate those lines with the parent commit. And the default value is 40. If there are more than one -C options given, the <num> argument of the last -C will take effect. --ignore-rev <rev> Ignore changes made by the revision when assigning blame, as if the change never happened. Lines that were changed or added by an ignored commit will be blamed on the previous commit that changed that line or nearby lines. This option may be specified multiple times to ignore more than one revision. If the blame.markIgnoredLines config option is set, then lines that were changed by an ignored commit and attributed to another commit will be marked with a ? in the blame output. If the blame.markUnblamableLines config option is set, then those lines touched by an ignored commit that we could not attribute to another revision are marked with a *. --ignore-revs-file <file> Ignore revisions listed in file, which must be in the same format as an fsck.skipList. This option may be repeated, and these files will be processed after any files specified with the blame.ignoreRevsFile config option. An empty file name, \"\", will clear the list of revs from previously processed files. --color-lines Color line annotations in the default format differently if they come from the same commit as the preceding line. This makes it easier to distinguish code blocks introduced by different commits. The color defaults to cyan and can be adjusted using the color.blame.repeatedLines config option. --color-by-age Color line annotations depending on the age of the line in the default format. The color.blame.highlightRecent config option controls what color is used for each range of age. -h Show help message. "
  },
  {
    "command": "pstree",
    "description": " pstree shows running processes as a tree. The tree is rooted at either pid or init if pid is omitted. If a user name is specified, all process trees rooted at processes owned by that user are shown. pstree visually merges identical branches by putting them in square brackets and prefixing them with the repetition count, e.g. init-+-getty |-getty |-getty `-getty becomes init---4*[getty] Child threads of a process are found under the parent process and are shown with the process name in curly braces, e.g. icecast2---13*[{icecast2}] If pstree is called as pstree.x11 then it will prompt the user at the end of the line to press return and will not return until that has happened. This is useful for when pstree is run in a xterminal. Certain kernel or mount parameters, such as the hidepid option for procfs, will hide information for some processes. In these situations pstree will attempt to build the tree without this information, showing process names as question marks. -a Show command line arguments. If the command line of a process is swapped out, that process is shown in parentheses. -a implicitly disables compaction for processes but not threads. -A Use ASCII characters to draw the tree. -c Disable compaction of identical subtrees. By default, subtrees are compacted whenever possible. -C Color the process name by given attribute. Currently pstree only accepts the value age which colors by process age. Processes newer than 60 seconds are green, newer than an hour yellow and the remaining red. -g Show PGIDs. Process Group IDs are shown as decimal numbers in parentheses after each process name. If both PIDs and PGIDs are displayed then PIDs are shown first. -G Use VT100 line drawing characters. -h Highlight the current process and its ancestors. This is a no-op if the terminal doesn't support highlighting or if neither the current process nor any of its ancestors are in the subtree being shown. -H Like -h, but highlight the specified process instead. Unlike with -h, pstree fails when using -H if highlighting is not available. -l Display long lines. By default, lines are truncated to either the COLUMNS environment variable or the display width. If neither of these methods work, the default of 132 columns is used. -n Sort processes with the same parent by PID instead of by name. (Numeric sort.) -N Show individual trees for each namespace of the type specified. The available types are: ipc, mnt, net, pid, time, user, uts. Regular users don't have access to other users' processes information, so the output will be limited. -p Show PIDs. PIDs are shown as decimal numbers in parentheses after each process name. -p implicitly disables compaction. -s Show parent processes of the specified process. -S Show namespaces transitions. Like -N, the output is limited when running as a regular user. -t Show full names for threads when available. -T Hide threads and only show processes. -u Show uid transitions. Whenever the uid of a process differs from the uid of its parent, the new uid is shown in parentheses after the process name. -U Use UTF-8 (Unicode) line drawing characters. Under Linux 1.1-54 and above, UTF-8 mode is entered on the console with echo -e ' 33%8' and left with echo -e ' 33%@'. -V Display version information. -Z Show the current security attributes of the process. For SELinux systems this will be the security context. "
  },
  {
    "command": "ac",
    "description": " ac prints out a report of connect time (in hours) based on the logins/logouts in the current wtmp file. A total is also printed out. The accounting file wtmp is maintained by init(8) and login(1). Neither ac nor login creates the wtmp if it doesn't exist, no accounting is done. To begin accounting, create the file with a length of zero. NOTE: The wtmp file can get really big, really fast. You might want to trim it every once and a while. GNU ac works nearly the same UNIX ac, though it's a little smarter in several ways. You should therefore expect differences in the output of GNU ac and the output of ac's on other systems. Use the command info accounting to get additional information. -d, --daily-totals Print totals for each day rather than just one big total at the end. The output looks like this: Jul 3 total 1.17 Jul 4 total 2.10 Jul 5 total 8.23 Jul 6 total 2.10 Jul 7 total 0.30 -p, --individual-totals Print time totals for each user in addition to the usual everything-lumped-into-one value. It looks like: bob 8.06 goff 0.60 maley 7.37 root 0.12 total 16.15 people Print out the sum total of the connect time used by all of the users included in people. Note that people is a space separated list of valid user names; wildcards are not allowed. -f, --file filename Read from the file filename instead of the system's wtmp file. --complain When the wtmp file has a problem (a time-warp, missing record, or whatever), print out an appropriate error. --reboots Reboot records are NOT written at the time of a reboot, but when the system restarts; therefore, it is impossible to know exactly when the reboot occurred. Users may have been logged into the system at the time of the reboot, and many ac's automatically count the time between the login and the reboot record against the user (even though all of that time shouldn't be, perhaps, if the system is down for a long time, for instance). If you want to count this time, include the flag. *For vanilla ac compatibility, include this flag.* --supplants Sometimes, a logout record is not written for a specific terminal, so the time that the last user accrued cannot be calculated. If you want to include the time from the user's login to the next login on the terminal (though probably incorrect), include this you want to include the time from the user's login to the next login on the terminal (though probably incorrect), include this flag. *For vanilla ac compatibility, include this flag.* --timewarps Sometimes, entries in a wtmp file will suddenly jump back into the past without a clock change record occurring. It is impossible to know how long a user was logged in when this occurs. If you want to count the time between the login and the time warp against the user, include this flag. *For vanilla ac compatibility, include this flag.* --compatibility This is shorthand for typing out the three above options. -a, --all-days If we're printing daily totals, print a record for every day instead of skipping intervening days where there is no login activity. Without this flag, time accrued during those intervening days gets listed under the next day where there is login activity. --tw-leniency num Set the time warp leniency to num seconds. Records in wtmp files might be slightly out of order (most notably when two logins occur within a one-second period - the second one gets written first). By default, this value is set to 60. If the program notices this problem, time is not assigned to users unless the --timewarps flag is used. --tw-suspicious num Set the time warp suspicious value to num seconds. If two records in the wtmp file are farther than this number of seconds apart, there is a problem with the wtmp file (or your machine hasn't been used in a year). If the program notices this problem, time is not assigned to users unless the --timewarps flag is used. -y, --print-year Print year when displaying dates. -z, --print-zeros If a total for any category (save the grand total) is zero, print it. The default is to suppress printing. --debug Print verbose internal information. -V, --version Print the version number of ac to standard output and quit. -h, --help Prints the usage string and default locations of system files to standard output and exits. "
  },
  {
    "command": "sha1sum",
    "description": " Print or check SHA1 (160-bit) checksums. With no FILE, or when FILE is -, read standard input. -b, --binary read in binary mode -c, --check read checksums from the FILEs and check them --tag create a BSD-style checksum -t, --text read in text mode (default) -z, --zero end each output line with NUL, not newline, and disable file name escaping The following five options are useful only when verifying checksums: --ignore-missing don't fail or report status for missing files --quiet don't print OK for each successfully verified file --status don't output anything, status code shows success --strict exit non-zero for improperly formatted checksum lines -w, --warn warn about improperly formatted checksum lines --help display this help and exit --version output version information and exit The sums are computed as described in FIPS-180-1. When checking, the input should be a former output of this program. The default mode is to print a line with: checksum, a space, a character indicating input mode ('*' for binary, ' ' for text or where binary is insignificant), and name for each FILE. Note: There is no difference between binary mode and text mode on GNU systems. "
  },
  {
    "command": "ed",
    "description": " The ed utility is a line-oriented text editor that uses two modes: command mode and input mode. In command mode the input characters shall be interpreted as commands, and in input mode they shall be interpreted as text. See the EXTENDED DESCRIPTION section. If an operand is '-', the results are unspecified. The ed utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for the unspecified usage of '-'. The following options shall be supported: -p string Use string as the prompt string when in command mode. By default, there shall be no prompt string. -s Suppress the writing of byte counts by e, E, r, and w commands and of the '!' prompt after a !command. "
  },
  {
    "command": "systemd-analyze",
    "description": " systemd-analyze may be used to determine system boot-up performance statistics and retrieve other state and tracing information from the system and service manager, and to verify the correctness of unit files. It is also used to access special functions useful for advanced system manager debugging. If no command is passed, systemd-analyze time is implied. systemd-analyze time This command prints the time spent in the kernel before userspace has been reached, the time spent in the initrd before normal system userspace has been reached, and the time normal system userspace took to initialize. Note that these measurements simply measure the time passed up to the point where all system services have been spawned, but not necessarily until they fully finished initialization or the disk is idle. Example 1. Show how long the boot took # in a container $ systemd-analyze time Startup finished in 296ms (userspace) multi-user.target reached after 275ms in userspace # on a real machine $ systemd-analyze time Startup finished in 2.584s (kernel) + 19.176s (initrd) + 47.847s (userspace) = 1min 9.608s multi-user.target reached after 47.820s in userspace systemd-analyze blame This command prints a list of all running units, ordered by the time they took to initialize. This information may be used to optimize boot-up times. Note that the output might be misleading as the initialization of one service might be slow simply because it waits for the initialization of another service to complete. Also note: systemd-analyze blame doesn't display results for services with Type=simple, because systemd considers such services to be started immediately, hence no measurement of the initialization delays can be done. Also note that this command only shows the time units took for starting up, it does not show how long unit jobs spent in the execution queue. In particular it shows the time units spent in \"activating\" state, which is not defined for units such as device units that transition directly from \"inactive\" to \"active\". This command hence gives an impression of the performance of program code, but cannot accurately reflect latency introduced by waiting for hardware and similar events. Example 2. Show which units took the most time during boot $ systemd-analyze blame 32.875s pmlogger.service 20.905s systemd-networkd-wait-online.service 13.299s dev-vda1.device ... 23ms sysroot.mount 11ms initrd-udevadm-cleanup-db.service 3ms sys-kernel-config.mount systemd-analyze critical-chain [UNIT...] This command prints a tree of the time-critical chain of units (for each of the specified UNITs or for the default target otherwise). The time after the unit is active or started is printed after the \"@\" character. The time the unit takes to start is printed after the \"+\" character. Note that the output might be misleading as the initialization of services might depend on socket activation and because of the parallel execution of units. Also, similarly to the blame command, this only takes into account the time units spent in \"activating\" state, and hence does not cover units that never went through an \"activating\" state (such as device units that transition directly from \"inactive\" to \"active\"). Moreover it does not show information on jobs (and in particular not jobs that timed out). Example 3. systemd-analyze critical-chain $ systemd-analyze critical-chain multi-user.target @47.820s \u2514\u2500pmie.service @35.968s +548ms \u2514\u2500pmcd.service @33.715s +2.247s \u2514\u2500network-online.target @33.712s \u2514\u2500systemd-networkd-wait-online.service @12.804s +20.905s \u2514\u2500systemd-networkd.service @11.109s +1.690s \u2514\u2500systemd-udevd.service @9.201s +1.904s \u2514\u2500systemd-tmpfiles-setup-dev.service @7.306s +1.776s \u2514\u2500kmod-static-nodes.service @6.976s +177ms \u2514\u2500systemd-journald.socket \u2514\u2500system.slice \u2514\u2500-.slice systemd-analyze dump [pattern...] Without any parameter, this command outputs a (usually very long) human-readable serialization of the complete service manager state. Optional glob pattern may be specified, causing the output to be limited to units whose names match one of the patterns. The output format is subject to change without notice and should not be parsed by applications. This command is rate limited for unprivileged users. Example 4. Show the internal state of user manager $ systemd-analyze --user dump Timestamp userspace: Thu 2019-03-14 23:28:07 CET Timestamp finish: Thu 2019-03-14 23:28:07 CET Timestamp generators-start: Thu 2019-03-14 23:28:07 CET Timestamp generators-finish: Thu 2019-03-14 23:28:07 CET Timestamp units-load-start: Thu 2019-03-14 23:28:07 CET Timestamp units-load-finish: Thu 2019-03-14 23:28:07 CET -> Unit proc-timer_list.mount: Description: /proc/timer_list ... -> Unit default.target: Description: Main user target ... systemd-analyze malloc [D-Bus service...] This command can be used to request the output of the internal memory state (as returned by malloc_info(3)) of a D-Bus service. If no service is specified, the query will be sent to org.freedesktop.systemd1 (the system or user service manager). The output format is not guaranteed to be stable and should not be parsed by applications. The service must implement the org.freedesktop.MemoryAllocation1 interface. In the systemd suite, it is currently only implemented by the manager. systemd-analyze plot This command prints either an SVG graphic, detailing which system services have been started at what time, highlighting the time they spent on initialization, or the raw time data in JSON or table format. Example 5. Plot a bootchart $ systemd-analyze plot >bootup.svg $ eog bootup.svg& Note that this plot is based on the most recent per-unit timing data of loaded units. This means that if a unit gets started, then stopped and then started again the information shown will cover the most recent start cycle, not the first one. Thus it's recommended to consult this information only shortly after boot, so that this distinction doesn't matter. Moreover, units that are not referenced by any other unit through a dependency might be unloaded by the service manager once they terminate (and did not fail). Such units will not show up in the plot. systemd-analyze dot [pattern...] This command generates textual dependency graph description in dot format for further processing with the GraphViz dot(1) tool. Use a command line like systemd-analyze dot | dot -Tsvg >systemd.svg to generate a graphical dependency tree. Unless --order or --require is passed, the generated graph will show both ordering and requirement dependencies. Optional pattern globbing style specifications (e.g. *.target) may be given at the end. A unit dependency is included in the graph if any of these patterns match either the origin or destination node. Example 6. Plot all dependencies of any unit whose name starts with \"avahi-daemon\" $ systemd-analyze dot 'avahi-daemon.*' | dot -Tsvg >avahi.svg $ eog avahi.svg Example 7. Plot the dependencies between all known target units $ systemd-analyze dot --to-pattern='*.target' --from-pattern='*.target' \\ | dot -Tsvg >targets.svg $ eog targets.svg systemd-analyze unit-paths This command outputs a list of all directories from which unit files, .d overrides, and .wants, .requires symlinks may be loaded. Combine with --user to retrieve the list for the user manager instance, and --global for the global configuration of user manager instances. Example 8. Show all paths for generated units $ systemd-analyze unit-paths | grep '^/run' /run/systemd/system.control /run/systemd/transient /run/systemd/generator.early /run/systemd/system /run/systemd/system.attached /run/systemd/generator /run/systemd/generator.late Note that this verb prints the list that is compiled into systemd-analyze itself, and does not communicate with the running manager. Use systemctl [--user] [--global] show -p UnitPath --value to retrieve the actual list that the manager uses, with any empty directories omitted. systemd-analyze exit-status [STATUS...] This command prints a list of exit statuses along with their \"class\", i.e. the source of the definition (one of \"glibc\", \"systemd\", \"LSB\", or \"BSD\"), see the Process Exit Codes section in systemd.exec(5). If no additional arguments are specified, all known statuses are shown. Otherwise, only the definitions for the specified codes are shown. Example 9. Show some example exit status names $ systemd-analyze exit-status 0 1 {63..65} NAME STATUS CLASS SUCCESS 0 glibc FAILURE 1 glibc - 63 - USAGE 64 BSD DATAERR 65 BSD systemd-analyze capability [CAPABILITY...] This command prints a list of Linux capabilities along with their numeric IDs. See capabilities(7) for details. If no argument is specified the full list of capabilities known to the service manager and the kernel is shown. Capabilities defined by the kernel but not known to the service manager are shown as \"cap_???\". Optionally, if arguments are specified they may refer to specific cabilities by name or numeric ID, in which case only the indicated capabilities are shown in the table. Example 10. Show some example capability names $ systemd-analyze capability 0 1 {30..32} NAME NUMBER cap_chown 0 cap_dac_override 1 cap_audit_control 30 cap_setfcap 31 cap_mac_override 32 systemd-analyze condition CONDITION... This command will evaluate Condition*=... and Assert*=... assignments, and print their values, and the resulting value of the combined condition set. See systemd.unit(5) for a list of available conditions and asserts. Example 11. Evaluate conditions that check kernel versions $ systemd-analyze condition 'ConditionKernelVersion = ! <4.0' \\ 'ConditionKernelVersion = >=5.1' \\ 'ConditionACPower=|false' \\ 'ConditionArchitecture=|!arm' \\ 'AssertPathExists=/etc/os-release' test.service: AssertPathExists=/etc/os-release succeeded. Asserts succeeded. test.service: ConditionArchitecture=|!arm succeeded. test.service: ConditionACPower=|false failed. test.service: ConditionKernelVersion=>=5.1 succeeded. test.service: ConditionKernelVersion=!<4.0 succeeded. Conditions succeeded. systemd-analyze syscall-filter [SET...] This command will list system calls contained in the specified system call set SET, or all known sets if no sets are specified. Argument SET must include the \"@\" prefix. systemd-analyze filesystems [SET...] This command will list filesystems in the specified filesystem set SET, or all known sets if no sets are specified. Argument SET must include the \"@\" prefix. systemd-analyze calendar EXPRESSION... This command will parse and normalize repetitive calendar time events, and will calculate when they elapse next. This takes the same input as the OnCalendar= setting in systemd.timer(5), following the syntax described in systemd.time(7). By default, only the next time the calendar expression will elapse is shown; use --iterations= to show the specified number of next times the expression elapses. Each time the expression elapses forms a timestamp, see the timestamp verb below. Example 12. Show leap days in the near future $ systemd-analyze calendar --iterations=5 '*-2-29 0:0:0' Original form: *-2-29 0:0:0 Normalized form: *-02-29 00:00:00 Next elapse: Sat 2020-02-29 00:00:00 UTC From now: 11 months 15 days left Iter. #2: Thu 2024-02-29 00:00:00 UTC From now: 4 years 11 months left Iter. #3: Tue 2028-02-29 00:00:00 UTC From now: 8 years 11 months left Iter. #4: Sun 2032-02-29 00:00:00 UTC From now: 12 years 11 months left Iter. #5: Fri 2036-02-29 00:00:00 UTC From now: 16 years 11 months left systemd-analyze timestamp TIMESTAMP... This command parses a timestamp (i.e. a single point in time) and outputs the normalized form and the difference between this timestamp and now. The timestamp should adhere to the syntax documented in systemd.time(7), section \"PARSING TIMESTAMPS\". Example 13. Show parsing of timestamps $ systemd-analyze timestamp yesterday now tomorrow Original form: yesterday Normalized form: Mon 2019-05-20 00:00:00 CEST (in UTC): Sun 2019-05-19 22:00:00 UTC UNIX seconds: @15583032000 From now: 1 day 9h ago Original form: now Normalized form: Tue 2019-05-21 09:48:39 CEST (in UTC): Tue 2019-05-21 07:48:39 UTC UNIX seconds: @1558424919.659757 From now: 43us ago Original form: tomorrow Normalized form: Wed 2019-05-22 00:00:00 CEST (in UTC): Tue 2019-05-21 22:00:00 UTC UNIX seconds: @15584760000 From now: 14h left systemd-analyze timespan EXPRESSION... This command parses a time span (i.e. a difference between two timestamps) and outputs the normalized form and the equivalent value in microseconds. The time span should adhere to the syntax documented in systemd.time(7), section \"PARSING TIME SPANS\". Values without units are parsed as seconds. Example 14. Show parsing of timespans $ systemd-analyze timespan 1s 300s '1year 0.000001s' Original: 1s \u03bcs: 1000000 Human: 1s Original: 300s \u03bcs: 300000000 Human: 5min Original: 1year 0.000001s \u03bcs: 31557600000001 Human: 1y 1us systemd-analyze cat-config NAME|PATH... This command is similar to systemctl cat, but operates on config files. It will copy the contents of a config file and any drop-ins to standard output, using the usual systemd set of directories and rules for precedence. Each argument must be either an absolute path including the prefix (such as /etc/systemd/logind.conf or /usr/lib/systemd/logind.conf), or a name relative to the prefix (such as systemd/logind.conf). Example 15. Showing logind configuration $ systemd-analyze cat-config systemd/logind.conf # /etc/systemd/logind.conf ... [Login] NAutoVTs=8 ... # /usr/lib/systemd/logind.conf.d/20-test.conf ... some override from another package # /etc/systemd/logind.conf.d/50-override.conf ... some administrator override systemd-analyze compare-versions VERSION1 [OP] VERSION2 This command has two distinct modes of operation, depending on whether the operator OP is specified. In the first mode \u2014 when OP is not specified \u2014 it will compare the two version strings and print either \"VERSION1 < VERSION2\", or \"VERSION1 == VERSION2\", or \"VERSION1 > VERSION2\" as appropriate. The exit status is 0 if the versions are equal, 11 if the version of the right is smaller, and 12 if the version of the left is smaller. (This matches the convention used by rpmdev-vercmp.) In the second mode \u2014 when OP is specified \u2014 it will compare the two version strings using the operation OP and return 0 (success) if they condition is satisfied, and 1 (failure) otherwise. OP may be lt, le, eq, ne, ge, gt. In this mode, no output is printed. (This matches the convention used by dpkg(1) --compare-versions.) Example 16. Compare versions of a package $ systemd-analyze compare-versions systemd-250~rc1.fc36.aarch64 systemd-251.fc36.aarch64 systemd-250~rc1.fc36.aarch64 < systemd-251.fc36.aarch64 $ echo $? 12 $ systemd-analyze compare-versions 1 lt 2; echo $? 0 $ systemd-analyze compare-versions 1 ge 2; echo $? 1 systemd-analyze verify FILE... This command will load unit files and print warnings if any errors are detected. Files specified on the command line will be loaded, but also any other units referenced by them. A unit's name on disk can be overridden by specifying an alias after a colon; see below for an example. The full unit search path is formed by combining the directories for all command line arguments, and the usual unit load paths. The variable $SYSTEMD_UNIT_PATH is supported, and may be used to replace or augment the compiled in set of unit load paths; see systemd.unit(5). All units files present in the directories containing the command line arguments will be used in preference to the other paths. The following errors are currently detected: \u2022 unknown sections and directives, \u2022 missing dependencies which are required to start the given unit, \u2022 man pages listed in Documentation= which are not found in the system, \u2022 commands listed in ExecStart= and similar which are not found in the system or not executable. Example 17. Misspelt directives $ cat ./user.slice [Unit] WhatIsThis=11 Documentation=man:nosuchfile(1) Requires=different.service [Service] Description=x $ systemd-analyze verify ./user.slice [./user.slice:9] Unknown lvalue 'WhatIsThis' in section 'Unit' [./user.slice:13] Unknown section 'Service'. Ignoring. Error: org.freedesktop.systemd1.LoadFailed: Unit different.service failed to load: No such file or directory. Failed to create user.slice/start: Invalid argument user.slice: man nosuchfile(1) command failed with code 16 Example 18. Missing service units $ tail ./a.socket ./b.socket ==> ./a.socket <== [Socket] ListenStream=100 ==> ./b.socket <== [Socket] ListenStream=100 Accept=yes $ systemd-analyze verify ./a.socket ./b.socket Service a.service not loaded, a.socket cannot be started. Service b@0.service not loaded, b.socket cannot be started. Example 19. Aliasing a unit $ cat /tmp/source [Unit] Description=Hostname printer [Service] Type=simple ExecStart=/usr/bin/echo %H MysteryKey=true $ systemd-analyze verify /tmp/source Failed to prepare filename /tmp/source: Invalid argument $ systemd-analyze verify /tmp/source:alias.service alias.service:7: Unknown key name 'MysteryKey' in section 'Service', ignoring. systemd-analyze security [UNIT...] This command analyzes the security and sandboxing settings of one or more specified service units. If at least one unit name is specified the security settings of the specified service units are inspected and a detailed analysis is shown. If no unit name is specified, all currently loaded, long-running service units are inspected and a terse table with results shown. The command checks for various security-related service settings, assigning each a numeric \"exposure level\" value, depending on how important a setting is. It then calculates an overall exposure level for the whole unit, which is an estimation in the range 0.0...10.0 indicating how exposed a service is security-wise. High exposure levels indicate very little applied sandboxing. Low exposure levels indicate tight sandboxing and strongest security restrictions. Note that this only analyzes the per-service security features systemd itself implements. This means that any additional security mechanisms applied by the service code itself are not accounted for. The exposure level determined this way should not be misunderstood: a high exposure level neither means that there is no effective sandboxing applied by the service code itself, nor that the service is actually vulnerable to remote or local attacks. High exposure levels do indicate however that most likely the service might benefit from additional settings applied to them. Please note that many of the security and sandboxing settings individually can be circumvented \u2014 unless combined with others. For example, if a service retains the privilege to establish or undo mount points many of the sandboxing options can be undone by the service code itself. Due to that is essential that each service uses the most comprehensive and strict sandboxing and security settings possible. The tool will take into account some of these combinations and relationships between the settings, but not all. Also note that the security and sandboxing settings analyzed here only apply to the operations executed by the service code itself. If a service has access to an IPC system (such as D-Bus) it might request operations from other services that are not subject to the same restrictions. Any comprehensive security and sandboxing analysis is hence incomplete if the IPC access policy is not validated too. Example 20. Analyze systemd-logind.service $ systemd-analyze security --no-pager systemd-logind.service NAME DESCRIPTION EXPOSURE \u2717 PrivateNetwork= Service has access to the host's network 0.5 \u2717 User=/DynamicUser= Service runs as root user 0.4 \u2717 DeviceAllow= Service has no device ACL 0.2 \u2713 IPAddressDeny= Service blocks all IP address ranges ... \u2192 Overall exposure level for systemd-logind.service: 4.1 OK \ud83d\ude42 systemd-analyze inspect-elf FILE... This command will load the specified files, and if they are ELF objects (executables, libraries, core files, etc.) it will parse the embedded packaging metadata, if any, and print it in a table or json format. See the Packaging Metadata[1] documentation for more information. Example 21. Print information about a core file as JSON $ systemd-analyze inspect-elf --json=pretty \\ core.fsverity.1000.f77dac5dc161402aa44e15b7dd9dcf97.58561.1637106137000000 { \"elfType\" : \"coredump\", \"elfArchitecture\" : \"AMD x86-64\", \"/home/bluca/git/fsverity-utils/fsverity\" : { \"type\" : \"deb\", \"name\" : \"fsverity-utils\", \"version\" : \"1.3-1\", \"buildId\" : \"7c895ecd2a271f93e96268f479fdc3c64a2ec4ee\" }, \"/home/bluca/git/fsverity-utils/libfsverity.so.0\" : { \"type\" : \"deb\", \"name\" : \"fsverity-utils\", \"version\" : \"1.3-1\", \"buildId\" : \"b5e428254abf14237b0ae70ed85fffbb98a78f88\" } } systemd-analyze fdstore [UNIT...] Lists the current contents of the specified service unit's file descriptor store. This shows names, inode types, device numbers, inode numbers, paths and open modes of the open file descriptors. The specified units must have FileDescriptorStoreMax= enabled, see systemd.service(5) for details. Example 22. Table output $ systemd-analyze fdstore systemd-journald.service FDNAME TYPE DEVNO INODE RDEVNO PATH FLAGS stored sock 0:8 4218620 - socket:[4218620] ro stored sock 0:8 4213198 - socket:[4213198] ro stored sock 0:8 4213190 - socket:[4213190] ro ... Note: the \"DEVNO\" column refers to the major/minor numbers of the device node backing the file system the file descriptor's inode is on. The \"RDEVNO\" column refers to the major/minor numbers of the device node itself if the file descriptor refers to one. Compare with corresponding .st_dev and .st_rdev fields in struct stat (see stat(2) for details). The listed inode numbers in the \"INODE\" column are on the file system indicated by \"DEVNO\". systemd-analyze image-policy [POLICY...] This command analyzes the specified image policy string, as per systemd.image-policy(7). The policy is normalized and simplified. For each currently defined partition identifier (as per the Discoverable Partitions Specification[2] the effect of the image policy string is shown in tabular form. Example 23. Example Output $ systemd-analyze image-policy swap=encrypted:usr=read-only-on+verity:root=encrypted Analyzing policy: root=encrypted:usr=verity+read-only-on:swap=encrypted Long form: root=encrypted:usr=verity+read-only-on:swap=encrypted:=unused+absent PARTITION MODE READ-ONLY GROWFS root encrypted - - usr verity yes - home ignore - - srv ignore - - esp ignore - - xbootldr ignore - - swap encrypted - - root-verity ignore - - usr-verity unprotected yes - root-verity-sig ignore - - usr-verity-sig ignore - - tmp ignore - - var ignore - - default ignore - - The following options are understood: --system Operates on the system systemd instance. This is the implied default. --user Operates on the user systemd instance. --global Operates on the system-wide configuration for user systemd instance. --order, --require When used in conjunction with the dot command (see above), selects which dependencies are shown in the dependency graph. If --order is passed, only dependencies of type After= or Before= are shown. If --require is passed, only dependencies of type Requires=, Requisite=, Wants= and Conflicts= are shown. If neither is passed, this shows dependencies of all these types. --from-pattern=, --to-pattern= When used in conjunction with the dot command (see above), this selects which relationships are shown in the dependency graph. Both options require a glob(7) pattern as an argument, which will be matched against the left-hand and the right-hand, respectively, nodes of a relationship. Each of these can be used more than once, in which case the unit name must match one of the values. When tests for both sides of the relation are present, a relation must pass both tests to be shown. When patterns are also specified as positional arguments, they must match at least one side of the relation. In other words, patterns specified with those two options will trim the list of edges matched by the positional arguments, if any are given, and fully determine the list of edges shown otherwise. --fuzz=timespan When used in conjunction with the critical-chain command (see above), also show units, which finished timespan earlier, than the latest unit in the same level. The unit of timespan is seconds unless specified with a different unit, e.g. \"50ms\". --man=no Do not invoke man(1) to verify the existence of man pages listed in Documentation=. --generators Invoke unit generators, see systemd.generator(7). Some generators require root privileges. Under a normal user, running with generators enabled will generally result in some warnings. --recursive-errors=MODE Control verification of units and their dependencies and whether systemd-analyze verify exits with a non-zero process exit status or not. With yes, return a non-zero process exit status when warnings arise during verification of either the specified unit or any of its associated dependencies. With no, return a non-zero process exit status when warnings arise during verification of only the specified unit. With one, return a non-zero process exit status when warnings arise during verification of either the specified unit or its immediate dependencies. If this option is not specified, zero is returned as the exit status regardless whether warnings arise during verification or not. --root=PATH With cat-files and verify, operate on files underneath the specified root path PATH. --image=PATH With cat-files and verify, operate on files inside the specified image path PATH. --image-policy=policy Takes an image policy string as argument, as per systemd.image-policy(7). The policy is enforced when operating on the disk image specified via --image=, see above. If not specified defaults to the \"*\" policy, i.e. all recognized file systems in the image are used. --offline=BOOL With security, perform an offline security review of the specified unit files, i.e. does not have to rely on PID 1 to acquire security information for the files like the security verb when used by itself does. This means that --offline= can be used with --root= and --image= as well. If a unit's overall exposure level is above that set by --threshold= (default value is 100), --offline= will return an error. --profile=PATH With security --offline=, takes into consideration the specified portable profile when assessing unit settings. The profile can be passed by name, in which case the well-known system locations will be searched, or it can be the full path to a specific drop-in file. --threshold=NUMBER With security, allow the user to set a custom value to compare the overall exposure level with, for the specified unit files. If a unit's overall exposure level, is greater than that set by the user, security will return an error. --threshold= can be used with --offline= as well and its default value is 100. --security-policy=PATH With security, allow the user to define a custom set of requirements formatted as a JSON file against which to compare the specified unit file(s) and determine their overall exposure level to security threats. Table 1. Accepted Assessment Test Identifiers \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502Assessment Test Identifier \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502UserOrDynamicUser \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SupplementaryGroups \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502PrivateMounts \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502PrivateDevices \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502PrivateTmp \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502PrivateNetwork \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502PrivateUsers \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502ProtectControlGroups \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502ProtectKernelModules \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502ProtectKernelTunables \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502ProtectKernelLogs \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502ProtectClock \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502ProtectHome \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502ProtectHostname \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502ProtectSystem \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RootDirectoryOrRootImage \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502LockPersonality \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502MemoryDenyWriteExecute \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502NoNewPrivileges \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_SYS_ADMIN \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_SET_UID_GID_PCAP \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_SYS_PTRACE \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_SYS_TIME \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_NET_ADMIN \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_SYS_RAWIO \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_SYS_MODULE \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_AUDIT \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_SYSLOG \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_SYS_NICE_RESOURCE \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_MKNOD \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_CHOWN_FSETID_SETFCAP \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_DAC_FOWNER_IPC_OWNER \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_KILL \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_NET_BIND_SERVICE_BROADCAST_RAW \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_SYS_BOOT \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_MAC \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_LINUX_IMMUTABLE \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_IPC_LOCK \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_SYS_CHROOT \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_BLOCK_SUSPEND \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_WAKE_ALARM \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_LEASE \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502CapabilityBoundingSet_CAP_SYS_TTY_CONFIG \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502UMask \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502KeyringMode \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502ProtectProc \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502ProcSubset \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502NotifyAccess \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RemoveIPC \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502Delegate \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictRealtime \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictSUIDSGID \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictNamespaces_user \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictNamespaces_mnt \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictNamespaces_ipc \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictNamespaces_pid \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictNamespaces_cgroup \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictNamespaces_uts \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictNamespaces_net \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictAddressFamilies_AF_INET_INET6 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictAddressFamilies_AF_UNIX \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictAddressFamilies_AF_NETLINK \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictAddressFamilies_AF_PACKET \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502RestrictAddressFamilies_OTHER \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SystemCallArchitectures \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SystemCallFilter_swap \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SystemCallFilter_obsolete \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SystemCallFilter_clock \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SystemCallFilter_cpu_emulation \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SystemCallFilter_debug \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SystemCallFilter_mount \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SystemCallFilter_module \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SystemCallFilter_raw_io \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SystemCallFilter_reboot \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SystemCallFilter_privileged \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502SystemCallFilter_resources \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502IPAddressDeny \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502DeviceAllow \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502AmbientCapabilities \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 See example \"JSON Policy\" below. --json=MODE With the security command, generate a JSON formatted output of the security analysis table. The format is a JSON array with objects containing the following fields: set which indicates if the setting has been enabled or not, name which is what is used to refer to the setting, json_field which is the JSON compatible identifier of the setting, description which is an outline of the setting state, and exposure which is a number in the range 0.0...10.0, where a higher value corresponds to a higher security threat. The JSON version of the table is printed to standard output. The MODE passed to the option can be one of three: off which is the default, pretty and short which respectively output a prettified or shorted JSON version of the security table. With the plot command, generate a JSON formatted output of the raw time data. The format is a JSON array with objects containing the following fields: name which is the unit name, activated which is the time after startup the service was activated, activating which is how long after startup the service was initially started, time which is how long the service took to activate from when it was initially started, deactivated which is the time after startup that the service was deactivated, deactivating which is the time after startup that the service was initially told to deactivate. --iterations=NUMBER When used with the calendar command, show the specified number of iterations the specified calendar expression will elapse next. Defaults to 1. --base-time=TIMESTAMP When used with the calendar command, show next iterations relative to the specified point in time. If not specified defaults to the current time. --unit=UNIT When used with the condition command, evaluate all the Condition*=... and Assert*=... assignments in the specified unit file. The full unit search path is formed by combining the directories for the specified unit with the usual unit load paths. The variable $SYSTEMD_UNIT_PATH is supported, and may be used to replace or augment the compiled in set of unit load paths; see systemd.unit(5). All units files present in the directory containing the specified unit will be used in preference to the other paths. --table When used with the plot command, the raw time data is output in a table. --no-legend When used with the plot command in combination with either --table or --json=, no legends or hints are included in the output. -H, --host= Execute the operation remotely. Specify a hostname, or a username and hostname separated by \"@\", to connect to. The hostname may optionally be suffixed by a port ssh is listening on, separated by \":\", and then a container name, separated by \"/\", which connects directly to a specific container on the specified host. This will use SSH to talk to the remote machine manager instance. Container names may be enumerated with machinectl -H HOST. Put IPv6 addresses in brackets. -M, --machine= Execute operation on a local container. Specify a container name to connect to, optionally prefixed by a user name to connect as and a separating \"@\" character. If the special string \".host\" is used in place of the container name, a connection to the local system is made (which is useful to connect to a specific user's user bus: \"--user --machine=lennart@.host\"). If the \"@\" syntax is not used, the connection is made as root user. If the \"@\" syntax is used either the left hand side or the right hand side may be omitted (but not both) in which case the local user name and \".host\" are implied. --quiet Suppress hints and other non-essential output. -h, --help Print a short help text and exit. --version Print a short version string and exit. --no-pager Do not pipe output into a pager. "
  },
  {
    "command": "timeout",
    "description": " Start COMMAND, and kill it if still running after DURATION. Mandatory arguments to long options are mandatory for short options too. --preserve-status exit with the same status as COMMAND, even when the command times out --foreground when not running timeout directly from a shell prompt, allow COMMAND to read from the TTY and get TTY signals; in this mode, children of COMMAND will not be timed out -k, --kill-after=DURATION also send a KILL signal if COMMAND is still running this long after the initial signal was sent -s, --signal=SIGNAL specify the signal to be sent on timeout; SIGNAL may be a name like 'HUP' or a number; see 'kill -l' for a list of signals -v, --verbose diagnose to stderr any signal sent upon timeout --help display this help and exit --version output version information and exit DURATION is a floating point number with an optional suffix: 's' for seconds (the default), 'm' for minutes, 'h' for hours or 'd' for days. A duration of 0 disables the associated timeout. Upon timeout, send the TERM signal to COMMAND, if no other SIGNAL specified. The TERM signal kills any process that does not block or catch that signal. It may be necessary to use the KILL signal, since this signal can't be caught. Exit status: 124 if COMMAND times out, and --preserve-status is not specified 125 if the timeout command itself fails 126 if COMMAND is found but cannot be invoked 127 if COMMAND cannot be found 137 if COMMAND (or timeout itself) is sent the KILL (9) signal (128+9) - the exit status of COMMAND otherwise "
  },
  {
    "command": "git-am",
    "description": " Splits mail messages in a mailbox into commit log message, authorship information and patches, and applies them to the current branch. You could think of it as a reverse operation of git-format-patch(1) run on a branch with a straight history without merges. (<mbox>|<Maildir>)... The list of mailbox files to read patches from. If you do not supply this argument, the command reads from the standard input. If you supply directories, they will be treated as Maildirs. -s, --signoff Add a Signed-off-by trailer to the commit message, using the committer identity of yourself. See the signoff option in git-commit(1) for more information. -k, --keep Pass -k flag to git mailinfo (see git-mailinfo(1)). --keep-non-patch Pass -b flag to git mailinfo (see git-mailinfo(1)). --[no-]keep-cr With --keep-cr, call git mailsplit (see git-mailsplit(1)) with the same option, to prevent it from stripping CR at the end of lines. am.keepcr configuration variable can be used to specify the default behaviour. --no-keep-cr is useful to override am.keepcr. -c, --scissors Remove everything in body before a scissors line (see git-mailinfo(1)). Can be activated by default using the mailinfo.scissors configuration variable. --no-scissors Ignore scissors lines (see git-mailinfo(1)). --quoted-cr=<action> This flag will be passed down to git mailinfo (see git-mailinfo(1)). --empty=(stop|drop|keep) By default, or when the option is set to stop, the command errors out on an input e-mail message lacking a patch and stops into the middle of the current am session. When this option is set to drop, skip such an e-mail message instead. When this option is set to keep, create an empty commit, recording the contents of the e-mail message as its log. -m, --message-id Pass the -m flag to git mailinfo (see git-mailinfo(1)), so that the Message-ID header is added to the commit message. The am.messageid configuration variable can be used to specify the default behaviour. --no-message-id Do not add the Message-ID header to the commit message. no-message-id is useful to override am.messageid. -q, --quiet Be quiet. Only print error messages. -u, --utf8 Pass -u flag to git mailinfo (see git-mailinfo(1)). The proposed commit log message taken from the e-mail is re-coded into UTF-8 encoding (configuration variable i18n.commitEncoding can be used to specify project\u2019s preferred encoding if it is not UTF-8). This was optional in prior versions of git, but now it is the default. You can use --no-utf8 to override this. --no-utf8 Pass -n flag to git mailinfo (see git-mailinfo(1)). -3, --3way, --no-3way When the patch does not apply cleanly, fall back on 3-way merge if the patch records the identity of blobs it is supposed to apply to and we have those blobs available locally. --no-3way can be used to override am.threeWay configuration variable. For more information, see am.threeWay in git-config(1). --rerere-autoupdate, --no-rerere-autoupdate After the rerere mechanism reuses a recorded resolution on the current conflict to update the files in the working tree, allow it to also update the index with the result of resolution. --no-rerere-autoupdate is a good way to double-check what rerere did and catch potential mismerges, before committing the result to the index with a separate git add. --ignore-space-change, --ignore-whitespace, --whitespace=<option>, -C<n>, -p<n>, --directory=<dir>, --exclude=<path>, --include=<path>, --reject These flags are passed to the git apply (see git-apply(1)) program that applies the patch. --patch-format By default the command will try to detect the patch format automatically. This option allows the user to bypass the automatic detection and specify the patch format that the patch(es) should be interpreted as. Valid formats are mbox, mboxrd, stgit, stgit-series and hg. -i, --interactive Run interactively. -n, --no-verify By default, the pre-applypatch and applypatch-msg hooks are run. When any of --no-verify or -n is given, these are bypassed. See also githooks(5). --committer-date-is-author-date By default the command records the date from the e-mail message as the commit author date, and uses the time of commit creation as the committer date. This allows the user to lie about the committer date by using the same value as the author date. --ignore-date By default the command records the date from the e-mail message as the commit author date, and uses the time of commit creation as the committer date. This allows the user to lie about the author date by using the same value as the committer date. --skip Skip the current patch. This is only meaningful when restarting an aborted patch. -S[<keyid>], --gpg-sign[=<keyid>], --no-gpg-sign GPG-sign commits. The keyid argument is optional and defaults to the committer identity; if specified, it must be stuck to the option without a space. --no-gpg-sign is useful to countermand both commit.gpgSign configuration variable, and earlier --gpg-sign. --continue, -r, --resolved After a patch failure (e.g. attempting to apply conflicting patch), the user has applied it by hand and the index file stores the result of the application. Make a commit using the authorship and commit log extracted from the e-mail message and the current index file, and continue. --resolvemsg=<msg> When a patch failure occurs, <msg> will be printed to the screen before exiting. This overrides the standard message informing you to use --continue or --skip to handle the failure. This is solely for internal use between git rebase and git am. --abort Restore the original branch and abort the patching operation. Revert contents of files involved in the am operation to their pre-am state. --quit Abort the patching operation but keep HEAD and the index untouched. --show-current-patch[=(diff|raw)] Show the message at which git am has stopped due to conflicts. If raw is specified, show the raw contents of the e-mail message; if diff, show the diff portion only. Defaults to raw. --allow-empty After a patch failure on an input e-mail message lacking a patch, create an empty commit with the contents of the e-mail message as its log message. "
  },
  {
    "command": "strings",
    "description": " The strings utility shall look for printable strings in regular files and shall write those strings to standard output. A printable string is any sequence of four (by default) or more printable characters terminated by a <newline> or NUL character. Additional implementation-defined strings may be written; see localedef. If the first argument is '-', the results are unspecified. The strings utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for the unspecified usage of '-'. The following options shall be supported: -a Scan files in their entirety. If -a is not specified, it is implementation-defined what portion of each file is scanned for strings. -n number Specify the minimum string length, where the number argument is a positive decimal integer. The default shall be 4. -t format Write each string preceded by its byte offset from the start of the file. The format shall be dependent on the single character used as the format option-argument: d The offset shall be written in decimal. o The offset shall be written in octal. x The offset shall be written in hexadecimal. "
  },
  {
    "command": "git-pull",
    "description": " Incorporates changes from a remote repository into the current branch. If the current branch is behind the remote, then by default it will fast-forward the current branch to match the remote. If the current branch and the remote have diverged, the user needs to specify how to reconcile the divergent branches with --rebase or --no-rebase (or the corresponding configuration option in pull.rebase). More precisely, git pull runs git fetch with the given parameters and then depending on configuration options or command line flags, will call either git rebase or git merge to reconcile diverging branches. <repository> should be the name of a remote repository as passed to git-fetch(1). <refspec> can name an arbitrary remote ref (for example, the name of a tag) or even a collection of refs with corresponding remote-tracking branches (e.g., refs/heads/*:refs/remotes/origin/*), but usually it is the name of a branch in the remote repository. Default values for <repository> and <branch> are read from the \"remote\" and \"merge\" configuration for the current branch as set by git-branch(1) --track. Assume the following history exists and the current branch is \"master\": A---B---C master on origin / D---E---F---G master ^ origin/master in your repository Then \"git pull\" will fetch and replay the changes from the remote master branch since it diverged from the local master (i.e., E) until its current commit (C) on top of master and record the result in a new commit along with the names of the two parent commits and a log message from the user describing the changes. A---B---C origin/master / \\ D---E---F---G---H master See git-merge(1) for details, including how conflicts are presented and handled. In Git 1.7.0 or later, to cancel a conflicting merge, use git reset --merge. Warning: In older versions of Git, running git pull with uncommitted changes is discouraged: while possible, it leaves you in a state that may be hard to back out of in the case of a conflict. If any of the remote changes overlap with local uncommitted changes, the merge will be automatically canceled and the work tree untouched. It is generally best to get any local changes in working order before pulling or stash them away with git-stash(1). -q, --quiet This is passed to both underlying git-fetch to squelch reporting of during transfer, and underlying git-merge to squelch output during merging. -v, --verbose Pass --verbose to git-fetch and git-merge. --[no-]recurse-submodules[=yes|on-demand|no] This option controls if new commits of populated submodules should be fetched, and if the working trees of active submodules should be updated, too (see git-fetch(1), git-config(1) and gitmodules(5)). If the checkout is done via rebase, local submodule commits are rebased as well. If the update is done via merge, the submodule conflicts are resolved and checked out. Options related to merging --commit, --no-commit Perform the merge and commit the result. This option can be used to override --no-commit. Only useful when merging. With --no-commit perform the merge and stop just before creating a merge commit, to give the user a chance to inspect and further tweak the merge result before committing. Note that fast-forward updates do not create a merge commit and therefore there is no way to stop those merges with --no-commit. Thus, if you want to ensure your branch is not changed or updated by the merge command, use --no-ff with --no-commit. --edit, -e, --no-edit Invoke an editor before committing successful mechanical merge to further edit the auto-generated merge message, so that the user can explain and justify the merge. The --no-edit option can be used to accept the auto-generated message (this is generally discouraged). Older scripts may depend on the historical behaviour of not allowing the user to edit the merge log message. They will see an editor opened when they run git merge. To make it easier to adjust such scripts to the updated behaviour, the environment variable GIT_MERGE_AUTOEDIT can be set to no at the beginning of them. --cleanup=<mode> This option determines how the merge message will be cleaned up before committing. See git-commit(1) for more details. In addition, if the <mode> is given a value of scissors, scissors will be appended to MERGE_MSG before being passed on to the commit machinery in the case of a merge conflict. --ff-only Only update to the new history if there is no divergent local history. This is the default when no method for reconciling divergent histories is provided (via the --rebase=* flags). --ff, --no-ff When merging rather than rebasing, specifies how a merge is handled when the merged-in history is already a descendant of the current history. If merging is requested, --ff is the default unless merging an annotated (and possibly signed) tag that is not stored in its natural place in the refs/tags/ hierarchy, in which case --no-ff is assumed. With --ff, when possible resolve the merge as a fast-forward (only update the branch pointer to match the merged branch; do not create a merge commit). When not possible (when the merged-in history is not a descendant of the current history), create a merge commit. With --no-ff, create a merge commit in all cases, even when the merge could instead be resolved as a fast-forward. -S[<keyid>], --gpg-sign[=<keyid>], --no-gpg-sign GPG-sign the resulting merge commit. The keyid argument is optional and defaults to the committer identity; if specified, it must be stuck to the option without a space. --no-gpg-sign is useful to countermand both commit.gpgSign configuration variable, and earlier --gpg-sign. --log[=<n>], --no-log In addition to branch names, populate the log message with one-line descriptions from at most <n> actual commits that are being merged. See also git-fmt-merge-msg(1). Only useful when merging. With --no-log do not list one-line descriptions from the actual commits being merged. --signoff, --no-signoff Add a Signed-off-by trailer by the committer at the end of the commit log message. The meaning of a signoff depends on the project to which you\u2019re committing. For example, it may certify that the committer has the rights to submit the work under the project\u2019s license or agrees to some contributor representation, such as a Developer Certificate of Origin. (See http://developercertificate.org for the one used by the Linux kernel and Git projects.) Consult the documentation or leadership of the project to which you\u2019re contributing to understand how the signoffs are used in that project. The --no-signoff option can be used to countermand an earlier --signoff option on the command line. --stat, -n, --no-stat Show a diffstat at the end of the merge. The diffstat is also controlled by the configuration option merge.stat. With -n or --no-stat do not show a diffstat at the end of the merge. --squash, --no-squash Produce the working tree and index state as if a real merge happened (except for the merge information), but do not actually make a commit, move the HEAD, or record $GIT_DIR/MERGE_HEAD (to cause the next git commit command to create a merge commit). This allows you to create a single commit on top of the current branch whose effect is the same as merging another branch (or more in case of an octopus). With --no-squash perform the merge and commit the result. This option can be used to override --squash. With --squash, --commit is not allowed, and will fail. Only useful when merging. --[no-]verify By default, the pre-merge and commit-msg hooks are run. When --no-verify is given, these are bypassed. See also githooks(5). Only useful when merging. -s <strategy>, --strategy=<strategy> Use the given merge strategy; can be supplied more than once to specify them in the order they should be tried. If there is no -s option, a built-in list of strategies is used instead (ort when merging a single head, octopus otherwise). -X <option>, --strategy-option=<option> Pass merge strategy specific option through to the merge strategy. --verify-signatures, --no-verify-signatures Verify that the tip commit of the side branch being merged is signed with a valid key, i.e. a key that has a valid uid: in the default trust model, this means the signing key has been signed by a trusted key. If the tip commit of the side branch is not signed with a valid key, the merge is aborted. Only useful when merging. --summary, --no-summary Synonyms to --stat and --no-stat; these are deprecated and will be removed in the future. --autostash, --no-autostash Automatically create a temporary stash entry before the operation begins, record it in the special ref MERGE_AUTOSTASH and apply it after the operation ends. This means that you can run the operation on a dirty worktree. However, use with care: the final stash application after a successful merge might result in non-trivial conflicts. --allow-unrelated-histories By default, git merge command refuses to merge histories that do not share a common ancestor. This option can be used to override this safety when merging histories of two projects that started their lives independently. As that is a very rare occasion, no configuration variable to enable this by default exists and will not be added. Only useful when merging. -r, --rebase[=false|true|merges|interactive] When true, rebase the current branch on top of the upstream branch after fetching. If there is a remote-tracking branch corresponding to the upstream branch and the upstream branch was rebased since last fetched, the rebase uses that information to avoid rebasing non-local changes. When set to merges, rebase using git rebase --rebase-merges so that the local merge commits are included in the rebase (see git-rebase(1) for details). When false, merge the upstream branch into the current branch. When interactive, enable the interactive mode of rebase. See pull.rebase, branch.<name>.rebase and branch.autoSetupRebase in git-config(1) if you want to make git pull always use --rebase instead of merging. Note This is a potentially dangerous mode of operation. It rewrites history, which does not bode well when you published that history already. Do not use this option unless you have read git-rebase(1) carefully. --no-rebase This is shorthand for --rebase=false. Options related to fetching --all Fetch all remotes. -a, --append Append ref names and object names of fetched refs to the existing contents of .git/FETCH_HEAD. Without this option old data in .git/FETCH_HEAD will be overwritten. --atomic Use an atomic transaction to update local refs. Either all refs are updated, or on error, no refs are updated. --depth=<depth> Limit fetching to the specified number of commits from the tip of each remote branch history. If fetching to a shallow repository created by git clone with --depth=<depth> option (see git-clone(1)), deepen or shorten the history to the specified number of commits. Tags for the deepened commits are not fetched. --deepen=<depth> Similar to --depth, except it specifies the number of commits from the current shallow boundary instead of from the tip of each remote branch history. --shallow-since=<date> Deepen or shorten the history of a shallow repository to include all reachable commits after <date>. --shallow-exclude=<revision> Deepen or shorten the history of a shallow repository to exclude commits reachable from a specified remote branch or tag. This option can be specified multiple times. --unshallow If the source repository is complete, convert a shallow repository to a complete one, removing all the limitations imposed by shallow repositories. If the source repository is shallow, fetch as much as possible so that the current repository has the same history as the source repository. --update-shallow By default when fetching from a shallow repository, git fetch refuses refs that require updating .git/shallow. This option updates .git/shallow and accept such refs. --negotiation-tip=<commit|glob> By default, Git will report, to the server, commits reachable from all local refs to find common commits in an attempt to reduce the size of the to-be-received packfile. If specified, Git will only report commits reachable from the given tips. This is useful to speed up fetches when the user knows which local ref is likely to have commits in common with the upstream ref being fetched. This option may be specified more than once; if so, Git will report commits reachable from any of the given commits. The argument to this option may be a glob on ref names, a ref, or the (possibly abbreviated) SHA-1 of a commit. Specifying a glob is equivalent to specifying this option multiple times, one for each matching ref name. See also the fetch.negotiationAlgorithm and push.negotiate configuration variables documented in git-config(1), and the --negotiate-only option below. --negotiate-only Do not fetch anything from the server, and instead print the ancestors of the provided --negotiation-tip=* arguments, which we have in common with the server. This is incompatible with --recurse-submodules=[yes|on-demand]. Internally this is used to implement the push.negotiate option, see git-config(1). --dry-run Show what would be done, without making any changes. --porcelain Print the output to standard output in an easy-to-parse format for scripts. See section OUTPUT in git-fetch(1) for details. This is incompatible with --recurse-submodules=[yes|on-demand] and takes precedence over the fetch.output config option. -f, --force When git fetch is used with <src>:<dst> refspec it may refuse to update the local branch as discussed in the <refspec> part of the git-fetch(1) documentation. This option overrides that check. -k, --keep Keep downloaded pack. --prefetch Modify the configured refspec to place all refs into the refs/prefetch/ namespace. See the prefetch task in git-maintenance(1). -p, --prune Before fetching, remove any remote-tracking references that no longer exist on the remote. Tags are not subject to pruning if they are fetched only because of the default tag auto-following or due to a --tags option. However, if tags are fetched due to an explicit refspec (either on the command line or in the remote configuration, for example if the remote was cloned with the --mirror option), then they are also subject to pruning. Supplying --prune-tags is a shorthand for providing the tag refspec. --no-tags By default, tags that point at objects that are downloaded from the remote repository are fetched and stored locally. This option disables this automatic tag following. The default behavior for a remote may be specified with the remote.<name>.tagOpt setting. See git-config(1). --refmap=<refspec> When fetching refs listed on the command line, use the specified refspec (can be given more than once) to map the refs to remote-tracking branches, instead of the values of remote.*.fetch configuration variables for the remote repository. Providing an empty <refspec> to the --refmap option causes Git to ignore the configured refspecs and rely entirely on the refspecs supplied as command-line arguments. See section on \"Configured Remote-tracking Branches\" for details. -t, --tags Fetch all tags from the remote (i.e., fetch remote tags refs/tags/* into local tags with the same name), in addition to whatever else would otherwise be fetched. Using this option alone does not subject tags to pruning, even if --prune is used (though tags may be pruned anyway if they are also the destination of an explicit refspec; see --prune). -j, --jobs=<n> Number of parallel children to be used for all forms of fetching. If the --multiple option was specified, the different remotes will be fetched in parallel. If multiple submodules are fetched, they will be fetched in parallel. To control them independently, use the config settings fetch.parallel and submodule.fetchJobs (see git-config(1)). Typically, parallel recursive and multi-remote fetches will be faster. By default fetches are performed sequentially, not in parallel. --set-upstream If the remote is fetched successfully, add upstream (tracking) reference, used by argument-less git-pull(1) and other commands. For more information, see branch.<name>.merge and branch.<name>.remote in git-config(1). --upload-pack <upload-pack> When given, and the repository to fetch from is handled by git fetch-pack, --exec=<upload-pack> is passed to the command to specify non-default path for the command run on the other end. --progress Progress status is reported on the standard error stream by default when it is attached to a terminal, unless -q is specified. This flag forces progress status even if the standard error stream is not directed to a terminal. -o <option>, --server-option=<option> Transmit the given string to the server when communicating using protocol version 2. The given string must not contain a NUL or LF character. The server\u2019s handling of server options, including unknown ones, is server-specific. When multiple --server-option=<option> are given, they are all sent to the other side in the order listed on the command line. --show-forced-updates By default, git checks if a branch is force-updated during fetch. This can be disabled through fetch.showForcedUpdates, but the --show-forced-updates option guarantees this check occurs. See git-config(1). --no-show-forced-updates By default, git checks if a branch is force-updated during fetch. Pass --no-show-forced-updates or set fetch.showForcedUpdates to false to skip this check for performance reasons. If used during git-pull the --ff-only option will still check for forced updates before attempting a fast-forward update. See git-config(1). -4, --ipv4 Use IPv4 addresses only, ignoring IPv6 addresses. -6, --ipv6 Use IPv6 addresses only, ignoring IPv4 addresses. <repository> The \"remote\" repository that is the source of a fetch or pull operation. This parameter can be either a URL (see the section GIT URLS below) or the name of a remote (see the section REMOTES below). <refspec> Specifies which refs to fetch and which local refs to update. When no <refspec>s appear on the command line, the refs to fetch are read from remote.<repository>.fetch variables instead (see the section \"CONFIGURED REMOTE-TRACKING BRANCHES\" in git-fetch(1)). The format of a <refspec> parameter is an optional plus +, followed by the source <src>, followed by a colon :, followed by the destination ref <dst>. The colon can be omitted when <dst> is empty. <src> is typically a ref, but it can also be a fully spelled hex object name. A <refspec> may contain a * in its <src> to indicate a simple pattern match. Such a refspec functions like a glob that matches any ref with the same prefix. A pattern <refspec> must have a * in both the <src> and <dst>. It will map refs to the destination by replacing the * with the contents matched from the source. If a refspec is prefixed by ^, it will be interpreted as a negative refspec. Rather than specifying which refs to fetch or which local refs to update, such a refspec will instead specify refs to exclude. A ref will be considered to match if it matches at least one positive refspec, and does not match any negative refspec. Negative refspecs can be useful to restrict the scope of a pattern refspec so that it will not include specific refs. Negative refspecs can themselves be pattern refspecs. However, they may only contain a <src> and do not specify a <dst>. Fully spelled out hex object names are also not supported. tag <tag> means the same as refs/tags/<tag>:refs/tags/<tag>; it requests fetching everything up to the given tag. The remote ref that matches <src> is fetched, and if <dst> is not an empty string, an attempt is made to update the local ref that matches it. Whether that update is allowed without --force depends on the ref namespace it\u2019s being fetched to, the type of object being fetched, and whether the update is considered to be a fast-forward. Generally, the same rules apply for fetching as when pushing, see the <refspec>... section of git-push(1) for what those are. Exceptions to those rules particular to git fetch are noted below. Until Git version 2.20, and unlike when pushing with git-push(1), any updates to refs/tags/* would be accepted without + in the refspec (or --force). When fetching, we promiscuously considered all tag updates from a remote to be forced fetches. Since Git version 2.20, fetching to update refs/tags/* works the same way as when pushing. I.e. any updates will be rejected without + in the refspec (or --force). Unlike when pushing with git-push(1), any updates outside of refs/{tags,heads}/* will be accepted without + in the refspec (or --force), whether that\u2019s swapping e.g. a tree object for a blob, or a commit for another commit that\u2019s doesn\u2019t have the previous commit as an ancestor etc. Unlike when pushing with git-push(1), there is no configuration which\u2019ll amend these rules, and nothing like a pre-fetch hook analogous to the pre-receive hook. As with pushing with git-push(1), all of the rules described above about what\u2019s not allowed as an update can be overridden by adding an the optional leading + to a refspec (or using --force command line option). The only exception to this is that no amount of forcing will make the refs/heads/* namespace accept a non-commit object. Note When the remote branch you want to fetch is known to be rewound and rebased regularly, it is expected that its new tip will not be descendant of its previous tip (as stored in your remote-tracking branch the last time you fetched). You would want to use the + sign to indicate non-fast-forward updates will be needed for such branches. There is no way to determine or declare that a branch will be made available in a repository with this behavior; the pulling user simply must know this is the expected usage pattern for a branch. Note There is a difference between listing multiple <refspec> directly on git pull command line and having multiple remote.<repository>.fetch entries in your configuration for a <repository> and running a git pull command without any explicit <refspec> parameters. <refspec>s listed explicitly on the command line are always merged into the current branch after fetching. In other words, if you list more than one remote ref, git pull will create an Octopus merge. On the other hand, if you do not list any explicit <refspec> parameter on the command line, git pull will fetch all the <refspec>s it finds in the remote.<repository>.fetch configuration and merge only the first <refspec> found into the current branch. This is because making an Octopus from remote refs is rarely done, while keeping track of multiple remote heads in one-go by fetching more than one is often useful. "
  },
  {
    "command": "yacc",
    "description": " The yacc utility shall read a description of a context-free grammar in grammar and write C source code, conforming to the ISO C standard, to a code file, and optionally header information into a header file, in the current directory. The generated source code shall not depend on any undefined, unspecified, or implementation-defined behavior, except in cases where it is copied directly from the supplied grammar, or in cases that are documented by the implementation. The C code shall define a function and related routines and macros for an automaton that executes a parsing algorithm meeting the requirements in Algorithms. The form and meaning of the grammar are described in the EXTENDED DESCRIPTION section. The C source code and header file shall be produced in a form suitable as input for the C compiler (see c99(1p)). The yacc utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for Guideline 9. The following options shall be supported: -b file_prefix Use file_prefix instead of y as the prefix for all output filenames. The code file y.tab.c, the header file y.tab.h (created when -d is specified), and the description file y.output (created when -v is specified), shall be changed to file_prefix.tab.c, file_prefix.tab.h, and file_prefix.output, respectively. -d Write the header file; by default only the code file is written. See the OUTPUT FILES section. -l Produce a code file that does not contain any #line constructs. If this option is not present, it is unspecified whether the code file or header file contains #line directives. This should only be used after the grammar and the associated actions are fully debugged. -p sym_prefix Use sym_prefix instead of yy as the prefix for all external names produced by yacc. The names affected shall include the functions yyparse(), yylex(), and yyerror(), and the variables yylval, yychar, and yydebug. (In the remainder of this section, the six symbols cited are referenced using their default names only as a notational convenience.) Local names may also be affected by the -p option; however, the -p option shall not affect #define symbols generated by yacc. -t Modify conditional compilation directives to permit compilation of debugging code in the code file. Runtime debugging statements shall always be contained in the code file, but by default conditional compilation directives prevent their compilation. -v Write a file containing a description of the parser and a report of conflicts generated by ambiguities in the grammar. "
  },
  {
    "command": "df",
    "description": " This manual page documents the GNU version of df. df displays the amount of space available on the file system containing each file name argument. If no file name is given, the space available on all currently mounted file systems is shown. Space is shown in 1K blocks by default, unless the environment variable POSIXLY_CORRECT is set, in which case 512-byte blocks are used. If an argument is the absolute file name of a device node containing a mounted file system, df shows the space available on that file system rather than on the file system containing the device node. This version of df cannot show the space available on unmounted file systems, because on most kinds of systems doing so requires very nonportable intimate knowledge of file system structures. Show information about the file system on which each FILE resides, or all file systems by default. Mandatory arguments to long options are mandatory for short options too. -a, --all include pseudo, duplicate, inaccessible file systems -B, --block-size=SIZE scale sizes by SIZE before printing them; e.g., '-BM' prints sizes in units of 1,048,576 bytes; see SIZE format below -h, --human-readable print sizes in powers of 1024 (e.g., 1023M) -H, --si print sizes in powers of 1000 (e.g., 1.1G) -i, --inodes list inode information instead of block usage -k like --block-size=1K -l, --local limit listing to local file systems --no-sync do not invoke sync before getting usage info (default) --output[=FIELD_LIST] use the output format defined by FIELD_LIST, or print all fields if FIELD_LIST is omitted. -P, --portability use the POSIX output format --sync invoke sync before getting usage info --total elide all entries insignificant to available space, and produce a grand total -t, --type=TYPE limit listing to file systems of type TYPE -T, --print-type print file system type -x, --exclude-type=TYPE limit listing to file systems not of type TYPE -v (ignored) --help display this help and exit --version output version information and exit Display values are in units of the first available SIZE from --block-size, and the DF_BLOCK_SIZE, BLOCK_SIZE and BLOCKSIZE environment variables. Otherwise, units default to 1024 bytes (or 512 if POSIXLY_CORRECT is set). The SIZE argument is an integer and optional unit (example: 10K is 10*1024). Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or KB,MB,... (powers of 1000). Binary prefixes can be used, too: KiB=K, MiB=M, and so on. FIELD_LIST is a comma-separated list of columns to be included. Valid field names are: 'source', 'fstype', 'itotal', 'iused', 'iavail', 'ipcent', 'size', 'used', 'avail', 'pcent', 'file' and 'target' (see info page). "
  },
  {
    "command": "ipcmk",
    "description": " ipcmk allows you to create System V inter-process communication (IPC) objects: shared memory segments, message queues, and semaphore arrays. Resources can be specified with these options: -M, --shmem size Create a shared memory segment of size bytes. The size argument may be followed by the multiplicative suffixes KiB (=1024), MiB (=1024*1024), and so on for GiB, etc. (the \"iB\" is optional, e.g., \"K\" has the same meaning as \"KiB\") or the suffixes KB (=1000), MB (=1000*1000), and so on for GB, etc. -Q, --queue Create a message queue. -S, --semaphore number Create a semaphore array with number of elements. Other options are: -p, --mode mode Access permissions for the resource. Default is 0644. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "newgrp",
    "description": " The newgrp utility shall create a new shell execution environment with a new real and effective group identification. Of the attributes listed in Section 2.12, Shell Execution Environment, the new shell execution environment shall retain the working directory, file creation mask, and exported variables from the previous environment (that is, open files, traps, unexported variables, alias definitions, shell functions, and set options may be lost). All other aspects of the process environment that are preserved by the exec family of functions defined in the System Interfaces volume of POSIX.1\u20102017 shall also be preserved by newgrp; whether other aspects are preserved is unspecified. A failure to assign the new group identifications (for example, for security or password-related reasons) shall not prevent the new shell execution environment from being created. The newgrp utility shall affect the supplemental groups for the process as follows: * On systems where the effective group ID is normally in the supplementary group list (or whenever the old effective group ID actually is in the supplementary group list): -- If the new effective group ID is also in the supplementary group list, newgrp shall change the effective group ID. -- If the new effective group ID is not in the supplementary group list, newgrp shall add the new effective group ID to the list, if there is room to add it. * On systems where the effective group ID is not normally in the supplementary group list (or whenever the old effective group ID is not in the supplementary group list): -- If the new effective group ID is in the supplementary group list, newgrp shall delete it. -- If the old effective group ID is not in the supplementary list, newgrp shall add it if there is room. Note: The System Interfaces volume of POSIX.1\u20102017 does not specify whether the effective group ID of a process is included in its supplementary group list. With no operands, newgrp shall change the effective group back to the groups identified in the user's user entry, and shall set the list of supplementary groups to that set in the user's group database entries. If the first argument is '-', the results are unspecified. If a password is required for the specified group, and the user is not listed as a member of that group in the group database, the user shall be prompted to enter the correct password for that group. If the user is listed as a member of that group, no password shall be requested. If no password is required for the specified group, it is implementation-defined whether users not listed as members of that group can change to that group. Whether or not a password is required, implementation-defined system accounting or security mechanisms may impose additional authorization restrictions that may cause newgrp to write a diagnostic message and suppress the changing of the group identification. The newgrp utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for the unspecified usage of '-'. The following option shall be supported: -l (The letter ell.) Change the environment to what would be expected if the user actually logged in again. "
  },
  {
    "command": "ssh-agent",
    "description": " ssh-agent is a program to hold private keys used for public key authentication. Through use of environment variables the agent can be located and automatically used for authentication when logging in to other machines using ssh(1). The options are as follows: -a bind_address Bind the agent to the UNIX-domain socket bind_address. The default is $TMPDIR/ssh-XXXXXXXXXX/agent.<ppid>. -c Generate C-shell commands on stdout. This is the default if SHELL looks like it's a csh style of shell. -D Foreground mode. When this option is specified, ssh-agent will not fork. -d Debug mode. When this option is specified, ssh-agent will not fork and will write debug information to standard error. -E fingerprint_hash Specifies the hash algorithm used when displaying key fingerprints. Valid options are: \u201cmd5\u201d and \u201csha256\u201d. The default is \u201csha256\u201d. -k Kill the current agent (given by the SSH_AGENT_PID environment variable). -O option Specify an option when starting ssh-agent. Currently only one option is supported: no-restrict-websafe. This instructs ssh-agent to permit signatures using FIDO keys that might be web authentication requests. By default, ssh-agent refuses signature requests for FIDO keys where the key application string does not start with \u201cssh:\u201d and when the data to be signed does not appear to be a ssh(1) user authentication request or a ssh-keygen(1) signature. The default behaviour prevents forwarded access to a FIDO key from also implicitly forwarding the ability to authenticate to websites. -P allowed_providers Specify a pattern-list of acceptable paths for PKCS#11 provider and FIDO authenticator middleware shared libraries that may be used with the -S or -s options to ssh-add(1). Libraries that do not match the pattern list will be refused. See PATTERNS in ssh_config(5) for a description of pattern-list syntax. The default list is \u201c/usr/lib/*,/usr/local/lib/*\u201d. -s Generate Bourne shell commands on stdout. This is the default if SHELL does not look like it's a csh style of shell. -t life Set a default value for the maximum lifetime of identities added to the agent. The lifetime may be specified in seconds or in a time format specified in sshd_config(5). A lifetime specified for an identity with ssh-add(1) overrides this value. Without this option the default maximum lifetime is forever. command [arg ...] If a command (and optional arguments) is given, this is executed as a subprocess of the agent. The agent exits automatically when the command given on the command line terminates. There are two main ways to get an agent set up. The first is at the start of an X session, where all other windows or programs are started as children of the ssh-agent program. The agent starts a command under which its environment variables are exported, for example ssh-agent xterm &. When the command terminates, so does the agent. The second method is used for a login session. When ssh-agent is started, it prints the shell commands required to set its environment variables, which in turn can be evaluated in the calling shell, for example eval `ssh-agent -s`. In both cases, ssh(1) looks at these environment variables and uses them to establish a connection to the agent. The agent initially does not have any private keys. Keys are added using ssh-add(1) or by ssh(1) when AddKeysToAgent is set in ssh_config(5). Multiple identities may be stored in ssh-agent concurrently and ssh(1) will automatically use them if present. ssh-add(1) is also used to remove keys from ssh-agent and to query the keys that are held in one. Connections to ssh-agent may be forwarded from further remote hosts using the -A option to ssh(1) (but see the caveats documented therein), avoiding the need for authentication data to be stored on other machines. Authentication passphrases and private keys never go over the network: the connection to the agent is forwarded over SSH remote connections and the result is returned to the requester, allowing the user access to their identities anywhere in the network in a secure fashion. "
  },
  {
    "command": "basenc",
    "description": " basenc encode or decode FILE, or standard input, to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. --base64 same as 'base64' program (RFC4648 section 4) --base64url file- and url-safe base64 (RFC4648 section 5) --base32 same as 'base32' program (RFC4648 section 6) --base32hex extended hex alphabet base32 (RFC4648 section 7) --base16 hex encoding (RFC4648 section 8) --base2msbf bit string with most significant bit (msb) first --base2lsbf bit string with least significant bit (lsb) first -d, --decode decode data -i, --ignore-garbage when decoding, ignore non-alphabet characters -w, --wrap=COLS wrap encoded lines after COLS character (default 76). Use 0 to disable line wrapping --z85 ascii85-like encoding (ZeroMQ spec:32/Z85); when encoding, input length must be a multiple of 4; when decoding, input length must be a multiple of 5 --help display this help and exit --version output version information and exit When decoding, the input may contain newlines in addition to the bytes of the formal alphabet. Use --ignore-garbage to attempt to recover from any other non-alphabet bytes in the encoded stream. "
  },
  {
    "command": "locale",
    "description": " The locale command displays information about the current locale, or all locales, on standard output. When invoked without arguments, locale displays the current locale settings for each locale category (see locale(5)), based on the settings of the environment variables that control the locale (see locale(7)). Values for variables set in the environment are printed without double quotes, implied values are printed with double quotes. If either the -a or the -m option (or one of their long-format equivalents) is specified, the behavior is as follows: -a, --all-locales Display a list of all available locales. The -v option causes the LC_IDENTIFICATION metadata about each locale to be included in the output. -m, --charmaps Display the available charmaps (character set description files). To display the current character set for the locale, use locale -c charmap. The locale command can also be provided with one or more arguments, which are the names of locale keywords (for example, date_fmt, ctype-class-names, yesexpr, or decimal_point) or locale categories (for example, LC_CTYPE or LC_TIME). For each argument, the following is displayed: \u2022 For a locale keyword, the value of that keyword to be displayed. \u2022 For a locale category, the values of all keywords in that category are displayed. When arguments are supplied, the following options are meaningful: -c, --category-name For a category name argument, write the name of the locale category on a separate line preceding the list of keyword values for that category. For a keyword name argument, write the name of the locale category for this keyword on a separate line preceding the keyword value. This option improves readability when multiple name arguments are specified. It can be combined with the -k option. -k, --keyword-name For each keyword whose value is being displayed, include also the name of that keyword, so that the output has the format: keyword=\"value\" The locale command also knows about the following options: -v, --verbose Display additional information for some command-line option and argument combinations. -?, --help Display a summary of command-line options and arguments and exit. --usage Display a short usage message and exit. -V, --version Display the program version and exit. "
  },
  {
    "command": "unlink",
    "description": " The unlink utility shall perform the function call: unlink(file); A user may need appropriate privileges to invoke the unlink utility. None. "
  },
  {
    "command": "diff3",
    "description": " Compare three files line by line. Mandatory arguments to long options are mandatory for short options too. -A, --show-all output all changes, bracketing conflicts -e, --ed output ed script incorporating changes from OLDFILE to YOURFILE into MYFILE -E, --show-overlap like -e, but bracket conflicts -3, --easy-only like -e, but incorporate only nonoverlapping changes -x, --overlap-only like -e, but incorporate only overlapping changes -X like -x, but bracket conflicts -i append 'w' and 'q' commands to ed scripts -m, --merge output actual merged file, according to -A if no other options are given -a, --text treat all files as text --strip-trailing-cr strip trailing carriage return on input -T, --initial-tab make tabs line up by prepending a tab --diff-program=PROGRAM use PROGRAM to compare files -L, --label=LABEL use LABEL instead of file name (can be repeated up to three times) --help display this help and exit -v, --version output version information and exit The default output format is a somewhat human-readable representation of the changes. The -e, -E, -x, -X (and corresponding long) options cause an ed script to be output instead of the default. Finally, the -m (--merge) option causes diff3 to do the merge internally and output the actual merged file. For unusual input, this is more robust than using ed. If a FILE is '-', read standard input. Exit status is 0 if successful, 1 if conflicts, 2 if trouble. "
  },
  {
    "command": "gpasswd",
    "description": " The gpasswd command is used to administer /etc/group, and /etc/gshadow. Every group can have administrators, members and a password. System administrators can use the -A option to define group administrator(s) and the -M option to define members. They have all rights of group administrators and members. gpasswd called by a group administrator with a group name only prompts for the new password of the group. If a password is set the members can still use newgrp(1) without a password, and non-members must supply the password. Notes about group passwords Group passwords are an inherent security problem since more than one person is permitted to know the password. However, groups are a useful tool for permitting co-operation between different users. Except for the -A and -M options, the options cannot be combined. The options which apply to the gpasswd command are: -a, --add user Add the user to the named group. -d, --delete user Remove the user from the named group. -h, --help Display help message and exit. -Q, --root CHROOT_DIR Apply changes in the CHROOT_DIR directory and use the configuration files from the CHROOT_DIR directory. Only absolute paths are supported. -r, --remove-password Remove the password from the named group. The group password will be empty. Only group members will be allowed to use newgrp to join the named group. -R, --restrict Restrict the access to the named group. The group password is set to \"!\". Only group members with a password will be allowed to use newgrp to join the named group. -A, --administrators user,... Set the list of administrative users. -M, --members user,... Set the list of group members. "
  },
  {
    "command": "htop",
    "description": " htop is a cross-platform ncurses-based process viewer. It is similar to top, but allows you to scroll vertically and horizontally, and interact using a pointing device (mouse). You can observe all processes running on the system, along with their command line arguments, as well as view them in a tree format, select multiple processes and act on them all at once. Tasks related to processes (killing, renicing) can be done without entering their PIDs. pcp-htop is a version of htop built using the Performance Co- Pilot (PCP) Metrics API (see PCPIntro(1), PMAPI(3)), allowing to extend htop to display values from arbitrary metrics. See the section below titled CONFIG FILES for further details. "
  },
  {
    "command": "git-show",
    "description": " Shows one or more objects (blobs, trees, tags and commits). For commits it shows the log message and textual diff. It also presents the merge commit in a special format as produced by git diff-tree --cc. For tags, it shows the tag message and the referenced objects. For trees, it shows the names (equivalent to git ls-tree with --name-only). For plain blobs, it shows the plain contents. The command takes options applicable to the git diff-tree command to control how the changes the commit introduces are shown. This manual page describes only the most frequently used options. <object>... The names of objects to show (defaults to HEAD). For a more complete list of ways to spell object names, see \"SPECIFYING REVISIONS\" section in gitrevisions(7). --pretty[=<format>], --format=<format> Pretty-print the contents of the commit logs in a given format, where <format> can be one of oneline, short, medium, full, fuller, reference, email, raw, format:<string> and tformat:<string>. When <format> is none of the above, and has %placeholder in it, it acts as if --pretty=tformat:<format> were given. See the \"PRETTY FORMATS\" section for some additional details for each format. When =<format> part is omitted, it defaults to medium. Note: you can specify the default pretty format in the repository configuration (see git-config(1)). --abbrev-commit Instead of showing the full 40-byte hexadecimal commit object name, show a prefix that names the object uniquely. \"--abbrev=<n>\" (which also modifies diff output, if it is displayed) option can be used to specify the minimum length of the prefix. This should make \"--pretty=oneline\" a whole lot more readable for people using 80-column terminals. --no-abbrev-commit Show the full 40-byte hexadecimal commit object name. This negates --abbrev-commit, either explicit or implied by other options such as \"--oneline\". It also overrides the log.abbrevCommit variable. --oneline This is a shorthand for \"--pretty=oneline --abbrev-commit\" used together. --encoding=<encoding> Commit objects record the character encoding used for the log message in their encoding header; this option can be used to tell the command to re-code the commit log message in the encoding preferred by the user. For non plumbing commands this defaults to UTF-8. Note that if an object claims to be encoded in X and we are outputting in X, we will output the object verbatim; this means that invalid sequences in the original commit may be copied to the output. Likewise, if iconv(3) fails to convert the commit, we will quietly output the original object verbatim. --expand-tabs=<n>, --expand-tabs, --no-expand-tabs Perform a tab expansion (replace each tab with enough spaces to fill to the next display column that is multiple of <n>) in the log message before showing it in the output. --expand-tabs is a short-hand for --expand-tabs=8, and --no-expand-tabs is a short-hand for --expand-tabs=0, which disables tab expansion. By default, tabs are expanded in pretty formats that indent the log message by 4 spaces (i.e. medium, which is the default, full, and fuller). --notes[=<ref>] Show the notes (see git-notes(1)) that annotate the commit, when showing the commit log message. This is the default for git log, git show and git whatchanged commands when there is no --pretty, --format, or --oneline option given on the command line. By default, the notes shown are from the notes refs listed in the core.notesRef and notes.displayRef variables (or corresponding environment overrides). See git-config(1) for more details. With an optional <ref> argument, use the ref to find the notes to display. The ref can specify the full refname when it begins with refs/notes/; when it begins with notes/, refs/ and otherwise refs/notes/ is prefixed to form a full name of the ref. Multiple --notes options can be combined to control which notes are being displayed. Examples: \"--notes=foo\" will show only notes from \"refs/notes/foo\"; \"--notes=foo --notes\" will show both notes from \"refs/notes/foo\" and from the default notes ref(s). --no-notes Do not show notes. This negates the above --notes option, by resetting the list of notes refs from which notes are shown. Options are parsed in the order given on the command line, so e.g. \"--notes --notes=foo --no-notes --notes=bar\" will only show notes from \"refs/notes/bar\". --show-notes[=<ref>], --[no-]standard-notes These options are deprecated. Use the above --notes/--no-notes options instead. --show-signature Check the validity of a signed commit object by passing the signature to gpg --verify and show the output. "
  },
  {
    "command": "tar",
    "description": " GNU tar is an archiving program designed to store multiple files in a single file (an archive), and to manipulate such archives. The archive can be either a regular file or a device (e.g. a tape drive, hence the name of the program, which stands for tape archiver), which can be located either on the local or on a remote machine. Option styles Options to GNU tar can be given in three different styles. In traditional style, the first argument is a cluster of option letters and all subsequent arguments supply arguments to those options that require them. The arguments are read in the same order as the option letters. Any command line words that remain after all options has been processed are treated as non-optional arguments: file or archive member names. For example, the c option requires creating the archive, the v option requests the verbose operation, and the f option takes an argument that sets the name of the archive to operate upon. The following command, written in the traditional style, instructs tar to store all files from the directory /etc into the archive file etc.tar verbosely listing the files being archived: tar cfv etc.tar /etc In UNIX or short-option style, each option letter is prefixed with a single dash, as in other command line utilities. If an option takes argument, the argument follows it, either as a separate command line word, or immediately following the option. However, if the option takes an optional argument, the argument must follow the option letter without any intervening whitespace, as in -g/tmp/snar.db. Any number of options not taking arguments can be clustered together after a single dash, e.g. -vkp. Options that take arguments (whether mandatory or optional), can appear at the end of such a cluster, e.g. -vkpf a.tar. The example command above written in the short-option style could look like: tar -cvf etc.tar /etc or tar -c -v -f etc.tar /etc In GNU or long-option style, each option begins with two dashes and has a meaningful name, consisting of lower-case letters and dashes. When used, the long option can be abbreviated to its initial letters, provided that this does not create ambiguity. Arguments to long options are supplied either as a separate command line word, immediately following the option, or separated from the option by an equals sign with no intervening whitespace. Optional arguments must always use the latter method. Here are several ways of writing the example command in this style: tar --create --file etc.tar --verbose /etc or (abbreviating some options): tar --cre --file=etc.tar --verb /etc The options in all three styles can be intermixed, although doing so with old options is not encouraged. Operation mode The options listed in the table below tell GNU tar what operation it is to perform. Exactly one of them must be given. Meaning of non-optional arguments depends on the operation mode requested. -A, --catenate, --concatenate Append archive to the end of another archive. The arguments are treated as the names of archives to append. All archives must be of the same format as the archive they are appended to, otherwise the resulting archive might be unusable with non-GNU implementations of tar. Notice also that when more than one archive is given, the members from archives other than the first one will be accessible in the resulting archive only if using the -i (--ignore-zeros) option. Compressed archives cannot be concatenated. -c, --create Create a new archive. Arguments supply the names of the files to be archived. Directories are archived recursively, unless the --no-recursion option is given. -d, --diff, --compare Find differences between archive and file system. The arguments are optional and specify archive members to compare. If not given, the current working directory is assumed. --delete Delete from the archive. The arguments supply names of the archive members to be removed. At least one argument must be given. This option does not operate on compressed archives. There is no short option equivalent. -r, --append Append files to the end of an archive. Arguments have the same meaning as for -c (--create). -t, --list List the contents of an archive. Arguments are optional. When given, they specify the names of the members to list. --test-label Test the archive volume label and exit. When used without arguments, it prints the volume label (if any) and exits with status 0. When one or more command line arguments are given. tar compares the volume label with each argument. It exits with code 0 if a match is found, and with code 1 otherwise. No output is displayed, unless used together with the -v (--verbose) option. There is no short option equivalent for this option. -u, --update Append files which are newer than the corresponding copy in the archive. Arguments have the same meaning as with -c and -r options. Notice, that newer files don't replace their old archive copies, but instead are appended to the end of archive. The resulting archive can thus contain several members of the same name, corresponding to various versions of the same file. -x, --extract, --get Extract files from an archive. Arguments are optional. When given, they specify names of the archive members to be extracted. --show-defaults Show built-in defaults for various tar options and exit. No arguments are allowed. -?, --help Display a short option summary and exit. No arguments allowed. --usage Display a list of available options and exit. No arguments allowed. --version Print program version and copyright information and exit. Operation modifiers --check-device Check device numbers when creating incremental archives (default). -g, --listed-incremental=FILE Handle new GNU-format incremental backups. FILE is the name of a snapshot file, where tar stores additional information which is used to decide which files changed since the previous incremental dump and, consequently, must be dumped again. If FILE does not exist when creating an archive, it will be created and all files will be added to the resulting archive (the level 0 dump). To create incremental archives of non-zero level N, create a copy of the snapshot file created during the level N-1, and use it as FILE. When listing or extracting, the actual contents of FILE is not inspected, it is needed only due to syntactical requirements. It is therefore common practice to use /dev/null in its place. --hole-detection=METHOD Use METHOD to detect holes in sparse files. This option implies --sparse. Valid values for METHOD are seek and raw. Default is seek with fallback to raw when not applicable. -G, --incremental Handle old GNU-format incremental backups. --ignore-failed-read Do not exit with nonzero on unreadable files. --level=NUMBER Set dump level for created listed-incremental archive. Currently only --level=0 is meaningful: it instructs tar to truncate the snapshot file before dumping, thereby forcing a level 0 dump. -n, --seek Assume the archive is seekable. Normally tar determines automatically whether the archive can be seeked or not. This option is intended for use in cases when such recognition fails. It takes effect only if the archive is open for reading (e.g. with --list or --extract options). --no-check-device Do not check device numbers when creating incremental archives. --no-seek Assume the archive is not seekable. --occurrence[=N] Process only the Nth occurrence of each file in the archive. This option is valid only when used with one of the following subcommands: --delete, --diff, --extract or --list and when a list of files is given either on the command line or via the -T option. The default N is 1. --restrict Disable the use of some potentially harmful options. --sparse-version=MAJOR[.MINOR] Set version of the sparse format to use (implies --sparse). This option implies --sparse. Valid argument values are 0.0, 0.1, and 1.0. For a detailed discussion of sparse formats, refer to the GNU Tar Manual, appendix D, \"Sparse Formats\". Using info reader, it can be accessed running the following command: info tar 'Sparse Formats'. -S, --sparse Handle sparse files efficiently. Some files in the file system may have segments which were actually never written (quite often these are database files created by such systems as DBM). When given this option, tar attempts to determine if the file is sparse prior to archiving it, and if so, to reduce the resulting archive size by not dumping empty parts of the file. Overwrite control These options control tar actions when extracting a file over an existing copy on disk. -k, --keep-old-files Don't replace existing files when extracting. --keep-newer-files Don't replace existing files that are newer than their archive copies. --keep-directory-symlink Don't replace existing symlinks to directories when extracting. --no-overwrite-dir Preserve metadata of existing directories. --one-top-level[=DIR] Extract all files into DIR, or, if used without argument, into a subdirectory named by the base name of the archive (minus standard compression suffixes recognizable by --auto-compress). --overwrite Overwrite existing files when extracting. --overwrite-dir Overwrite metadata of existing directories when extracting (default). --recursive-unlink Recursively remove all files in the directory prior to extracting it. --remove-files Remove files from disk after adding them to the archive. --skip-old-files Don't replace existing files when extracting, silently skip over them. -U, --unlink-first Remove each file prior to extracting over it. -W, --verify Verify the archive after writing it. Output stream selection --ignore-command-error Ignore subprocess exit codes. --no-ignore-command-error Treat non-zero exit codes of children as error (default). -O, --to-stdout Extract files to standard output. --to-command=COMMAND Pipe extracted files to COMMAND. The argument is the pathname of an external program, optionally with command line arguments. The program will be invoked and the contents of the file being extracted supplied to it on its standard input. Additional data will be supplied via the following environment variables: TAR_FILETYPE Type of the file. It is a single letter with the following meaning: f Regular file d Directory l Symbolic link h Hard link b Block device c Character device Currently only regular files are supported. TAR_MODE File mode, an octal number. TAR_FILENAME The name of the file. TAR_REALNAME Name of the file as stored in the archive. TAR_UNAME Name of the file owner. TAR_GNAME Name of the file owner group. TAR_ATIME Time of last access. It is a decimal number, representing seconds since the Epoch. If the archive provides times with nanosecond precision, the nanoseconds are appended to the timestamp after a decimal point. TAR_MTIME Time of last modification. TAR_CTIME Time of last status change. TAR_SIZE Size of the file. TAR_UID UID of the file owner. TAR_GID GID of the file owner. Additionally, the following variables contain information about tar operation mode and the archive being processed: TAR_VERSION GNU tar version number. TAR_ARCHIVE The name of the archive tar is processing. TAR_BLOCKING_FACTOR Current blocking factor, i.e. number of 512-byte blocks in a record. TAR_VOLUME Ordinal number of the volume tar is processing (set if reading a multi-volume archive). TAR_FORMAT Format of the archive being processed. One of: gnu, oldgnu, posix, ustar, v7. TAR_SUBCOMMAND A short option (with a leading dash) describing the operation tar is executing. Handling of file attributes --atime-preserve[=METHOD] Preserve access times on dumped files, either by restoring the times after reading (METHOD=replace, this is the default) or by not setting the times in the first place (METHOD=system) --delay-directory-restore Delay setting modification times and permissions of extracted directories until the end of extraction. Use this option when extracting from an archive which has unusual member ordering. --group=NAME[:GID] Force NAME as group for added files. If GID is not supplied, NAME can be either a user name or numeric GID. In this case the missing part (GID or name) will be inferred from the current host's group database. When used with --group-map=FILE, affects only those files whose owner group is not listed in FILE. --group-map=FILE Read group translation map from FILE. Empty lines are ignored. Comments are introduced with # sign and extend to the end of line. Each non-empty line in FILE defines translation for a single group. It must consist of two fields, delimited by any amount of whitespace: OLDGRP NEWGRP[:NEWGID] OLDGRP is either a valid group name or a GID prefixed with +. Unless NEWGID is supplied, NEWGRP must also be either a valid group name or a +GID. Otherwise, both NEWGRP and NEWGID need not be listed in the system group database. As a result, each input file with owner group OLDGRP will be stored in archive with owner group NEWGRP and GID NEWGID. --mode=CHANGES Force symbolic mode CHANGES for added files. --mtime=DATE-OR-FILE Set mtime for added files. DATE-OR-FILE is either a date/time in almost arbitrary format, or the name of an existing file. In the latter case the mtime of that file will be used. -m, --touch Don't extract file modified time. --no-delay-directory-restore Cancel the effect of the prior --delay-directory-restore option. --no-same-owner Extract files as yourself (default for ordinary users). --no-same-permissions Apply the user's umask when extracting permissions from the archive (default for ordinary users). --numeric-owner Always use numbers for user/group names. --owner=NAME[:UID] Force NAME as owner for added files. If UID is not supplied, NAME can be either a user name or numeric UID. In this case the missing part (UID or name) will be inferred from the current host's user database. When used with --owner-map=FILE, affects only those files whose owner is not listed in FILE. --owner-map=FILE Read owner translation map from FILE. Empty lines are ignored. Comments are introduced with # sign and extend to the end of line. Each non-empty line in FILE defines translation for a single UID. It must consist of two fields, delimited by any amount of whitespace: OLDUSR NEWUSR[:NEWUID] OLDUSR is either a valid user name or a UID prefixed with +. Unless NEWUID is supplied, NEWUSR must also be either a valid user name or a +UID. Otherwise, both NEWUSR and NEWUID need not be listed in the system user database. As a result, each input file owned by OLDUSR will be stored in archive with owner name NEWUSR and UID NEWUID. -p, --preserve-permissions, --same-permissions extract information about file permissions (default for superuser) --same-owner Try extracting files with the same ownership as exists in the archive (default for superuser). -s, --preserve-order, --same-order Sort names to extract to match archive --sort=ORDER When creating an archive, sort directory entries according to ORDER, which is one of none, name, or inode. The default is --sort=none, which stores archive members in the same order as returned by the operating system. Using --sort=name ensures the member ordering in the created archive is uniform and reproducible. Using --sort=inode reduces the number of disk seeks made when creating the archive and thus can considerably speed up archivation. This sorting order is supported only if the underlying system provides the necessary information. Extended file attributes --acls Enable POSIX ACLs support. --no-acls Disable POSIX ACLs support. --selinux Enable SELinux context support. --no-selinux Disable SELinux context support. --xattrs Enable extended attributes support. --no-xattrs Disable extended attributes support. --xattrs-exclude=PATTERN Specify the exclude pattern for xattr keys. PATTERN is a globbing pattern, e.g. --xattrs-exclude='user.*' to include only attributes from the user namespace. --xattrs-include=PATTERN Specify the include pattern for xattr keys. PATTERN is a globbing pattern. Device selection and switching -f, --file=ARCHIVE Use archive file or device ARCHIVE. If this option is not given, tar will first examine the environment variable `TAPE'. If it is set, its value will be used as the archive name. Otherwise, tar will assume the compiled-in default. The default value can be inspected either using the --show-defaults option, or at the end of the tar --help output. An archive name that has a colon in it specifies a file or device on a remote machine. The part before the colon is taken as the machine name or IP address, and the part after it as the file or device pathname, e.g.: --file=remotehost:/dev/sr0 An optional username can be prefixed to the hostname, placing a @ sign between them. By default, the remote host is accessed via the rsh(1) command. Nowadays it is common to use ssh(1) instead. You can do so by giving the following command line option: --rsh-command=/usr/bin/ssh The remote machine should have the rmt(8) command installed. If its pathname does not match tar's default, you can inform tar about the correct pathname using the --rmt-command option. --force-local Archive file is local even if it has a colon. -F, --info-script=COMMAND, --new-volume-script=COMMAND Run COMMAND at the end of each tape (implies -M). The command can include arguments. When started, it will inherit tar's environment plus the following variables: TAR_VERSION GNU tar version number. TAR_ARCHIVE The name of the archive tar is processing. TAR_BLOCKING_FACTOR Current blocking factor, i.e. number of 512-byte blocks in a record. TAR_VOLUME Ordinal number of the volume tar is processing (set if reading a multi-volume archive). TAR_FORMAT Format of the archive being processed. One of: gnu, oldgnu, posix, ustar, v7. TAR_SUBCOMMAND A short option (with a leading dash) describing the operation tar is executing. TAR_FD File descriptor which can be used to communicate the new volume name to tar. If the info script fails, tar exits; otherwise, it begins writing the next volume. -L, --tape-length=N Change tape after writing Nx1024 bytes. If N is followed by a size suffix (see the subsection Size suffixes below), the suffix specifies the multiplicative factor to be used instead of 1024. This option implies -M. -M, --multi-volume Create/list/extract multi-volume archive. --rmt-command=COMMAND Use COMMAND instead of rmt when accessing remote archives. See the description of the -f option, above. --rsh-command=COMMAND Use COMMAND instead of rsh when accessing remote archives. See the description of the -f option, above. --volno-file=FILE When this option is used in conjunction with --multi-volume, tar will keep track of which volume of a multi-volume archive it is working in FILE. Device blocking -b, --blocking-factor=BLOCKS Set record size to BLOCKSx512 bytes. -B, --read-full-records When listing or extracting, accept incomplete input records after end-of-file marker. -i, --ignore-zeros Ignore zeroed blocks in archive. Normally two consecutive 512-blocks filled with zeroes mean EOF and tar stops reading after encountering them. This option instructs it to read further and is useful when reading archives created with the -A option. --record-size=NUMBER Set record size. NUMBER is the number of bytes per record. It must be multiple of 512. It can can be suffixed with a size suffix, e.g. --record-size=10K, for 10 Kilobytes. See the subsection Size suffixes, for a list of valid suffixes. Archive format selection -H, --format=FORMAT Create archive of the given format. Valid formats are: gnu GNU tar 1.13.x format oldgnu GNU format as per tar <= 1.12. pax, posix POSIX 1003.1-2001 (pax) format. ustar POSIX 1003.1-1988 (ustar) format. v7 Old V7 tar format. --old-archive, --portability Same as --format=v7. --pax-option=keyword[[:]=value][,keyword[[:]=value]]... Control pax keywords when creating PAX archives (-H pax). This option is equivalent to the -o option of the pax(1) utility. --posix Same as --format=posix. -V, --label=TEXT Create archive with volume name TEXT. If listing or extracting, use TEXT as a globbing pattern for volume name. Compression options -a, --auto-compress Use archive suffix to determine the compression program. -I, --use-compress-program=COMMAND Filter data through COMMAND. It must accept the -d option, for decompression. The argument can contain command line options. -j, --bzip2 Filter the archive through bzip2(1). -J, --xz Filter the archive through xz(1). --lzip Filter the archive through lzip(1). --lzma Filter the archive through lzma(1). --lzop Filter the archive through lzop(1). --no-auto-compress Do not use archive suffix to determine the compression program. -z, --gzip, --gunzip, --ungzip Filter the archive through gzip(1). -Z, --compress, --uncompress Filter the archive through compress(1). --zstd Filter the archive through zstd(1). Local file selection --add-file=FILE Add FILE to the archive (useful if its name starts with a dash). --backup[=CONTROL] Backup before removal. The CONTROL argument, if supplied, controls the backup policy. Its valid values are: none, off Never make backups. t, numbered Make numbered backups. nil, existing Make numbered backups if numbered backups exist, simple backups otherwise. never, simple Always make simple backups If CONTROL is not given, the value is taken from the VERSION_CONTROL environment variable. If it is not set, existing is assumed. -C, --directory=DIR Change to DIR before performing any operations. This option is order-sensitive, i.e. it affects all options that follow. --exclude=PATTERN Exclude files matching PATTERN, a glob(3)-style wildcard pattern. --exclude-backups Exclude backup and lock files. --exclude-caches Exclude contents of directories containing file CACHEDIR.TAG, except for the tag file itself. --exclude-caches-all Exclude directories containing file CACHEDIR.TAG and the file itself. --exclude-caches-under Exclude everything under directories containing CACHEDIR.TAG --exclude-ignore=FILE Before dumping a directory, see if it contains FILE. If so, read exclusion patterns from this file. The patterns affect only the directory itself. --exclude-ignore-recursive=FILE Same as --exclude-ignore, except that patterns from FILE affect both the directory and all its subdirectories. --exclude-tag=FILE Exclude contents of directories containing FILE, except for FILE itself. --exclude-tag-all=FILE Exclude directories containing FILE. --exclude-tag-under=FILE Exclude everything under directories containing FILE. --exclude-vcs Exclude version control system directories. --exclude-vcs-ignores Exclude files that match patterns read from VCS-specific ignore files. Supported files are: .cvsignore, .gitignore, .bzrignore, and .hgignore. -h, --dereference Follow symlinks; archive and dump the files they point to. --hard-dereference Follow hard links; archive and dump the files they refer to. -K, --starting-file=MEMBER Begin at the given member in the archive. --newer-mtime=DATE Work on files whose data changed after the DATE. If DATE starts with / or . it is taken to be a file name; the mtime of that file is used as the date. --no-null Disable the effect of the previous --null option. --no-recursion Avoid descending automatically in directories. --no-unquote Do not unquote input file or member names. --no-verbatim-files-from Treat each line read from a file list as if it were supplied in the command line. I.e., leading and trailing whitespace is removed and, if the resulting string begins with a dash, it is treated as tar command line option. This is the default behavior. The --no-verbatim-files-from option is provided as a way to restore it after --verbatim-files-from option. This option is positional: it affects all --files-from options that occur after it in, until --verbatim-files-from option or end of line, whichever occurs first. It is implied by the --no-null option. --null Instruct subsequent -T options to read null-terminated names verbatim (disables special handling of names that start with a dash). See also --verbatim-files-from. -N, --newer=DATE, --after-date=DATE Only store files newer than DATE. If DATE starts with / or . it is taken to be a file name; the mtime of that file is used as the date. --one-file-system Stay in local file system when creating archive. -P, --absolute-names Don't strip leading slashes from file names when creating archives. --recursion Recurse into directories (default). --suffix=STRING Backup before removal, override usual suffix. Default suffix is ~, unless overridden by environment variable SIMPLE_BACKUP_SUFFIX. -T, --files-from=FILE Get names to extract or create from FILE. Unless specified otherwise, the FILE must contain a list of names separated by ASCII LF (i.e. one name per line). The names read are handled the same way as command line arguments. They undergo quote removal and word splitting, and any string that starts with a - is handled as tar command line option. If this behavior is undesirable, it can be turned off using the --verbatim-files-from option. The --null option instructs tar that the names in FILE are separated by ASCII NUL character, instead of LF. It is useful if the list is generated by find(1) -print0 predicate. --unquote Unquote file or member names (default). --verbatim-files-from Treat each line obtained from a file list as a file name, even if it starts with a dash. File lists are supplied with the --files-from (-T) option. The default behavior is to handle names supplied in file lists as if they were typed in the command line, i.e. any names starting with a dash are treated as tar options. The --verbatim-files-from option disables this behavior. This option affects all --files-from options that occur after it in the command line. Its effect is reverted by the --no-verbatim-files-from} option. This option is implied by the --null option. See also --add-file. -X, --exclude-from=FILE Exclude files matching patterns listed in FILE. File name transformations --strip-components=NUMBER Strip NUMBER leading components from file names on extraction. --transform=EXPRESSION, --xform=EXPRESSION Use sed replace EXPRESSION to transform file names. File name matching options These options affect both exclude and include patterns. --anchored Patterns match file name start. --ignore-case Ignore case. --no-anchored Patterns match after any / (default for exclusion). --no-ignore-case Case sensitive matching (default). --no-wildcards Verbatim string matching. --no-wildcards-match-slash Wildcards do not match /. --wildcards Use wildcards (default for exclusion). --wildcards-match-slash Wildcards match / (default for exclusion). Informative output --checkpoint[=N] Display progress messages every Nth record (default 10). --checkpoint-action=ACTION Run ACTION on each checkpoint. --clamp-mtime Only set time when the file is more recent than what was given with --mtime. --full-time Print file time to its full resolution. --index-file=FILE Send verbose output to FILE. -l, --check-links Print a message if not all links are dumped. --no-quote-chars=STRING Disable quoting for characters from STRING. --quote-chars=STRING Additionally quote characters from STRING. --quoting-style=STYLE Set quoting style for file and member names. Valid values for STYLE are literal, shell, shell-always, c, c-maybe, escape, locale, clocale. -R, --block-number Show block number within archive with each message. --show-omitted-dirs When listing or extracting, list each directory that does not match search criteria. --show-transformed-names, --show-stored-names Show file or archive names after transformation by --strip and --transform options. --totals[=SIGNAL] Print total bytes after processing the archive. If SIGNAL is given, print total bytes when this signal is delivered. Allowed signals are: SIGHUP, SIGQUIT, SIGINT, SIGUSR1, and SIGUSR2. The SIG prefix can be omitted. --utc Print file modification times in UTC. -v, --verbose Verbosely list files processed. Each instance of this option on the command line increases the verbosity level by one. The maximum verbosity level is 3. For a detailed discussion of how various verbosity levels affect tar's output, please refer to GNU Tar Manual, subsection 2.5.1 \"The --verbose Option\". --warning=KEYWORD Enable or disable warning messages identified by KEYWORD. The messages are suppressed if KEYWORD is prefixed with no- and enabled otherwise. Multiple --warning messages accumulate. Keywords controlling general tar operation: all Enable all warning messages. This is the default. none Disable all warning messages. filename-with-nuls \"%s: file name read contains nul character\" alone-zero-block \"A lone zero block at %s\" Keywords applicable for tar --create: cachedir \"%s: contains a cache directory tag %s; %s\" file-shrank \"%s: File shrank by %s bytes; padding with zeros\" xdev \"%s: file is on a different filesystem; not dumped\" file-ignored \"%s: Unknown file type; file ignored\" \"%s: socket ignored\" \"%s: door ignored\" file-unchanged \"%s: file is unchanged; not dumped\" ignore-archive \"%s: archive cannot contain itself; not dumped\" file-removed \"%s: File removed before we read it\" file-changed \"%s: file changed as we read it\" failed-read Suppresses warnings about unreadable files or directories. This keyword applies only if used together with the --ignore-failed-read option. Keywords applicable for tar --extract: existing-file \"%s: skipping existing file\" timestamp \"%s: implausibly old time stamp %s\" \"%s: time stamp %s is %s s in the future\" contiguous-cast \"Extracting contiguous files as regular files\" symlink-cast \"Attempting extraction of symbolic links as hard links\" unknown-cast \"%s: Unknown file type '%c', extracted as normal file\" ignore-newer \"Current %s is newer or same age\" unknown-keyword \"Ignoring unknown extended header keyword '%s'\" decompress-program Controls verbose description of failures occurring when trying to run alternative decompressor programs. This warning is disabled by default (unless --verbose is used). A common example of what you can get when using this warning is: $ tar --warning=decompress-program -x -f archive.Z tar (child): cannot run compress: No such file or directory tar (child): trying gzip This means that tar first tried to decompress archive.Z using compress, and, when that failed, switched to gzip. record-size \"Record size = %lu blocks\" Keywords controlling incremental extraction: rename-directory \"%s: Directory has been renamed from %s\" \"%s: Directory has been renamed\" new-directory \"%s: Directory is new\" xdev \"%s: directory is on a different device: not purging\" bad-dumpdir \"Malformed dumpdir: 'X' never used\" -w, --interactive, --confirmation Ask for confirmation for every action. Compatibility options -o When creating, same as --old-archive. When extracting, same as --no-same-owner. Size suffixes Suffix Units Byte Equivalent b Blocks SIZE x 512 B Kilobytes SIZE x 1024 c Bytes SIZE G Gigabytes SIZE x 1024^3 K Kilobytes SIZE x 1024 k Kilobytes SIZE x 1024 M Megabytes SIZE x 1024^2 P Petabytes SIZE x 1024^5 T Terabytes SIZE x 1024^4 w Words SIZE x 2 "
  },
  {
    "command": "pr",
    "description": " Paginate or columnate FILE(s) for printing. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. +FIRST_PAGE[:LAST_PAGE], --pages=FIRST_PAGE[:LAST_PAGE] begin [stop] printing with page FIRST_[LAST_]PAGE -COLUMN, --columns=COLUMN output COLUMN columns and print columns down, unless -a is used. Balance number of lines in the columns on each page -a, --across print columns across rather than down, used together with -COLUMN -c, --show-control-chars use hat notation (^G) and octal backslash notation -d, --double-space double space the output -D, --date-format=FORMAT use FORMAT for the header date -e[CHAR[WIDTH]], --expand-tabs[=CHAR[WIDTH]] expand input CHARs (TABs) to tab WIDTH (8) -F, -f, --form-feed use form feeds instead of newlines to separate pages (by a 3-line page header with -F or a 5-line header and trailer without -F) -h, --header=HEADER use a centered HEADER instead of filename in page header, -h \"\" prints a blank line, don't use -h\"\" -i[CHAR[WIDTH]], --output-tabs[=CHAR[WIDTH]] replace spaces with CHARs (TABs) to tab WIDTH (8) -J, --join-lines merge full lines, turns off -W line truncation, no column alignment, --sep-string[=STRING] sets separators -l, --length=PAGE_LENGTH set the page length to PAGE_LENGTH (66) lines (default number of lines of text 56, and with -F 63). implies -t if PAGE_LENGTH <= 10 -m, --merge print all files in parallel, one in each column, truncate lines, but join lines of full length with -J -n[SEP[DIGITS]], --number-lines[=SEP[DIGITS]] number lines, use DIGITS (5) digits, then SEP (TAB), default counting starts with 1st line of input file -N, --first-line-number=NUMBER start counting with NUMBER at 1st line of first page printed (see +FIRST_PAGE) -o, --indent=MARGIN offset each line with MARGIN (zero) spaces, do not affect -w or -W, MARGIN will be added to PAGE_WIDTH -r, --no-file-warnings omit warning when a file cannot be opened -s[CHAR], --separator[=CHAR] separate columns by a single character, default for CHAR is the <TAB> character without -w and 'no char' with -w. -s[CHAR] turns off line truncation of all 3 column options (-COLUMN|-a -COLUMN|-m) except -w is set -S[STRING], --sep-string[=STRING] separate columns by STRING, without -S: Default separator <TAB> with -J and <space> otherwise (same as -S\" \"), no effect on column options -t, --omit-header omit page headers and trailers; implied if PAGE_LENGTH <= 10 -T, --omit-pagination omit page headers and trailers, eliminate any pagination by form feeds set in input files -v, --show-nonprinting use octal backslash notation -w, --width=PAGE_WIDTH set page width to PAGE_WIDTH (72) characters for multiple text-column output only, -s[char] turns off (72) -W, --page-width=PAGE_WIDTH set page width to PAGE_WIDTH (72) characters always, truncate lines, except -J option is set, no interference with -S or -s --help display this help and exit --version output version information and exit "
  },
  {
    "command": "git-restore",
    "description": " Restore specified paths in the working tree with some contents from a restore source. If a path is tracked but does not exist in the restore source, it will be removed to match the source. The command can also be used to restore the content in the index with --staged, or restore both the working tree and the index with --staged --worktree. By default, if --staged is given, the contents are restored from HEAD, otherwise from the index. Use --source to restore from a different commit. See \"Reset, restore and revert\" in git(1) for the differences between the three commands. THIS COMMAND IS EXPERIMENTAL. THE BEHAVIOR MAY CHANGE. -s <tree>, --source=<tree> Restore the working tree files with the content from the given tree. It is common to specify the source tree by naming a commit, branch or tag associated with it. If not specified, the contents are restored from HEAD if --staged is given, otherwise from the index. As a special case, you may use \"A...B\" as a shortcut for the merge base of A and B if there is exactly one merge base. You can leave out at most one of A and B, in which case it defaults to HEAD. -p, --patch Interactively select hunks in the difference between the restore source and the restore location. See the \u201cInteractive Mode\u201d section of git-add(1) to learn how to operate the --patch mode. Note that --patch can accept no pathspec and will prompt to restore all modified paths. -W, --worktree, -S, --staged Specify the restore location. If neither option is specified, by default the working tree is restored. Specifying --staged will only restore the index. Specifying both restores both. -q, --quiet Quiet, suppress feedback messages. Implies --no-progress. --progress, --no-progress Progress status is reported on the standard error stream by default when it is attached to a terminal, unless --quiet is specified. This flag enables progress reporting even if not attached to a terminal, regardless of --quiet. --ours, --theirs When restoring files in the working tree from the index, use stage #2 (ours) or #3 (theirs) for unmerged paths. Note that during git rebase and git pull --rebase, ours and theirs may appear swapped. See the explanation of the same options in git-checkout(1) for details. -m, --merge When restoring files on the working tree from the index, recreate the conflicted merge in the unmerged paths. --conflict=<style> The same as --merge option above, but changes the way the conflicting hunks are presented, overriding the merge.conflictStyle configuration variable. Possible values are \"merge\" (default), \"diff3\", and \"zdiff3\". --ignore-unmerged When restoring files on the working tree from the index, do not abort the operation if there are unmerged entries and neither --ours, --theirs, --merge or --conflict is specified. Unmerged paths on the working tree are left alone. --ignore-skip-worktree-bits In sparse checkout mode, by default is to only update entries matched by <pathspec> and sparse patterns in $GIT_DIR/info/sparse-checkout. This option ignores the sparse patterns and unconditionally restores any files in <pathspec>. --recurse-submodules, --no-recurse-submodules If <pathspec> names an active submodule and the restore location includes the working tree, the submodule will only be updated if this option is given, in which case its working tree will be restored to the commit recorded in the superproject, and any local modifications overwritten. If nothing (or --no-recurse-submodules) is used, submodules working trees will not be updated. Just like git-checkout(1), this will detach HEAD of the submodule. --overlay, --no-overlay In overlay mode, the command never removes files when restoring. In no-overlay mode, tracked files that do not appear in the --source tree are removed, to make them match <tree> exactly. The default is no-overlay mode. --pathspec-from-file=<file> Pathspec is passed in <file> instead of commandline args. If <file> is exactly - then standard input is used. Pathspec elements are separated by LF or CR/LF. Pathspec elements can be quoted as explained for the configuration variable core.quotePath (see git-config(1)). See also --pathspec-file-nul and global --literal-pathspecs. --pathspec-file-nul Only meaningful with --pathspec-from-file. Pathspec elements are separated with NUL character and all other characters are taken literally (including newlines and quotes). -- Do not interpret any more arguments as options. <pathspec>... Limits the paths affected by the operation. For more details, see the pathspec entry in gitglossary(7). "
  },
  {
    "command": "git-archive",
    "description": " Creates an archive of the specified format containing the tree structure for the named tree, and writes it out to the standard output. If <prefix> is specified it is prepended to the filenames in the archive. git archive behaves differently when given a tree ID versus when given a commit ID or tag ID. In the first case the current time is used as the modification time of each file in the archive. In the latter case the commit time as recorded in the referenced commit object is used instead. Additionally the commit ID is stored in a global extended pax header if the tar format is used; it can be extracted using git get-tar-commit-id. In ZIP files it is stored as a file comment. --format=<fmt> Format of the resulting archive. Possible values are tar, zip, tar.gz, tgz, and any format defined using the configuration option tar.<format>.command. If --format is not given, and the output file is specified, the format is inferred from the filename if possible (e.g. writing to foo.zip makes the output to be in the zip format). Otherwise the output format is tar. -l, --list Show all available formats. -v, --verbose Report progress to stderr. --prefix=<prefix>/ Prepend <prefix>/ to paths in the archive. Can be repeated; its rightmost value is used for all tracked files. See below which value gets used by --add-file and --add-virtual-file. -o <file>, --output=<file> Write the archive to <file> instead of stdout. --add-file=<file> Add a non-tracked file to the archive. Can be repeated to add multiple files. The path of the file in the archive is built by concatenating the value of the last --prefix option (if any) before this --add-file and the basename of <file>. --add-virtual-file=<path>:<content> Add the specified contents to the archive. Can be repeated to add multiple files. The path of the file in the archive is built by concatenating the value of the last --prefix option (if any) before this --add-virtual-file and <path>. The <path> argument can start and end with a literal double-quote character; the contained file name is interpreted as a C-style string, i.e. the backslash is interpreted as escape character. The path must be quoted if it contains a colon, to avoid the colon from being misinterpreted as the separator between the path and the contents, or if the path begins or ends with a double-quote character. The file mode is limited to a regular file, and the option may be subject to platform-dependent command-line limits. For non-trivial cases, write an untracked file and use --add-file instead. --worktree-attributes Look for attributes in .gitattributes files in the working tree as well (see the section called \u201cATTRIBUTES\u201d). --mtime=<time> Set modification time of archive entries. Without this option the committer time is used if <tree-ish> is a commit or tag, and the current time if it is a tree. <extra> This can be any options that the archiver backend understands. See next section. --remote=<repo> Instead of making a tar archive from the local repository, retrieve a tar archive from a remote repository. Note that the remote repository may place restrictions on which sha1 expressions may be allowed in <tree-ish>. See git-upload-archive(1) for details. --exec=<git-upload-archive> Used with --remote to specify the path to the git-upload-archive on the remote side. <tree-ish> The tree or commit to produce an archive for. <path> Without an optional path parameter, all files and subdirectories of the current working directory are included in the archive. If one or more paths are specified, only these are included. "
  },
  {
    "command": "uname",
    "description": " Print certain system information. With no OPTION, same as -s. -a, --all print all information, in the following order, except omit -p and -i if unknown: -s, --kernel-name print the kernel name -n, --nodename print the network node hostname -r, --kernel-release print the kernel release -v, --kernel-version print the kernel version -m, --machine print the machine hardware name -p, --processor print the processor type (non-portable) -i, --hardware-platform print the hardware platform (non-portable) -o, --operating-system print the operating system --help display this help and exit --version output version information and exit "
  },
  {
    "command": "tee",
    "description": " Copy standard input to each FILE, and also to standard output. -a, --append append to the given FILEs, do not overwrite -i, --ignore-interrupts ignore interrupt signals -p operate in a more appropriate MODE with pipes. --output-error[=MODE] set behavior on write error. See MODE below --help display this help and exit --version output version information and exit MODE determines behavior with write errors on the outputs: warn diagnose errors writing to any output warn-nopipe diagnose errors writing to any output not a pipe exit exit on error writing to any output exit-nopipe exit on error writing to any output not a pipe The default MODE for the -p option is 'warn-nopipe'. With \"nopipe\" MODEs, exit immediately if all outputs become broken pipes. The default operation when --output-error is not specified, is to exit immediately on error writing to a pipe, and diagnose errors writing to non pipe outputs. "
  },
  {
    "command": "join",
    "description": " For each pair of input lines with identical join fields, write a line to standard output. The default join field is the first, delimited by blanks. When FILE1 or FILE2 (not both) is -, read standard input. -a FILENUM also print unpairable lines from file FILENUM, where FILENUM is 1 or 2, corresponding to FILE1 or FILE2 -e STRING replace missing (empty) input fields with STRING; I.e., missing fields specified with '-12jo' options -i, --ignore-case ignore differences in case when comparing fields -j FIELD equivalent to '-1 FIELD -2 FIELD' -o FORMAT obey FORMAT while constructing output line -t CHAR use CHAR as input and output field separator -v FILENUM like -a FILENUM, but suppress joined output lines -1 FIELD join on this FIELD of file 1 -2 FIELD join on this FIELD of file 2 --check-order check that the input is correctly sorted, even if all input lines are pairable --nocheck-order do not check that the input is correctly sorted --header treat the first line in each file as field headers, print them without trying to pair them -z, --zero-terminated line delimiter is NUL, not newline --help display this help and exit --version output version information and exit Unless -t CHAR is given, leading blanks separate fields and are ignored, else fields are separated by CHAR. Any FIELD is a field number counted from 1. FORMAT is one or more comma or blank separated specifications, each being 'FILENUM.FIELD' or '0'. Default FORMAT outputs the join field, the remaining fields from FILE1, the remaining fields from FILE2, all separated by CHAR. If FORMAT is the keyword 'auto', then the first line of each file determines the number of fields output for each line. Important: FILE1 and FILE2 must be sorted on the join fields. E.g., use \"sort -k 1b,1\" if 'join' has no options, or use \"join -t ''\" if 'sort' has no options. Note, comparisons honor the rules specified by 'LC_COLLATE'. If the input is not sorted and some lines cannot be joined, a warning message will be given. "
  },
  {
    "command": "pidof",
    "description": " Pidof finds the process id's (pids) of the named programs. It prints those id's on the standard output. -s Single shot - this instructs the program to only return one pid. -c Only return process ids that are running with the same root directory. This option is ignored for non-root users, as they will be unable to check the current root directory of processes they do not own. -q Quiet mode, suppress any output and only sets the exit status accordingly. -w Show also processes that do not have visible command line (e.g. kernel worker threads). -x Scripts too - this causes the program to also return process id's of shells running the named scripts. -o omitpid Tells pidof to omit processes with that process id. The special pid %PPID can be used to name the parent process of the pidof program, in other words the calling shell or shell script. -S separator Use separator as a separator put between pids. Used only when more than one pids are printed for the program. The -d option is an alias for this option for sysvinit pidof compatibility. "
  },
  {
    "command": "wait",
    "description": " When an asynchronous list (see Section 2.9.3.1, Examples) is started by the shell, the process ID of the last command in each element of the asynchronous list shall become known in the current shell execution environment; see Section 2.12, Shell Execution Environment. If the wait utility is invoked with no operands, it shall wait until all process IDs known to the invoking shell have terminated and exit with a zero exit status. If one or more pid operands are specified that represent known process IDs, the wait utility shall wait until all of them have terminated. If one or more pid operands are specified that represent unknown process IDs, wait shall treat them as if they were known process IDs that exited with exit status 127. The exit status returned by the wait utility shall be the exit status of the process requested by the last pid operand. The known process IDs are applicable only for invocations of wait in the current shell execution environment. None. "
  },
  {
    "command": "git-difftool",
    "description": " git difftool is a Git command that allows you to compare and edit files between revisions using common diff tools. git difftool is a frontend to git diff and accepts the same options and arguments. See git-diff(1). -d, --dir-diff Copy the modified files to a temporary location and perform a directory diff on them. This mode never prompts before launching the diff tool. -y, --no-prompt Do not prompt before launching a diff tool. --prompt Prompt before each invocation of the diff tool. This is the default behaviour; the option is provided to override any configuration settings. --rotate-to=<file> Start showing the diff for the given path, the paths before it will move to end and output. --skip-to=<file> Start showing the diff for the given path, skipping all the paths before it. -t <tool>, --tool=<tool> Use the diff tool specified by <tool>. Valid values include emerge, kompare, meld, and vimdiff. Run git difftool --tool-help for the list of valid <tool> settings. If a diff tool is not specified, git difftool will use the configuration variable diff.tool. If the configuration variable diff.tool is not set, git difftool will pick a suitable default. You can explicitly provide a full path to the tool by setting the configuration variable difftool.<tool>.path. For example, you can configure the absolute path to kdiff3 by setting difftool.kdiff3.path. Otherwise, git difftool assumes the tool is available in PATH. Instead of running one of the known diff tools, git difftool can be customized to run an alternative program by specifying the command line to invoke in a configuration variable difftool.<tool>.cmd. When git difftool is invoked with this tool (either through the -t or --tool option or the diff.tool configuration variable) the configured command line will be invoked with the following variables available: $LOCAL is set to the name of the temporary file containing the contents of the diff pre-image and $REMOTE is set to the name of the temporary file containing the contents of the diff post-image. $MERGED is the name of the file which is being compared. $BASE is provided for compatibility with custom merge tool commands and has the same value as $MERGED. --tool-help Print a list of diff tools that may be used with --tool. --[no-]symlinks git difftool's default behavior is create symlinks to the working tree when run in --dir-diff mode and the right-hand side of the comparison yields the same content as the file in the working tree. Specifying --no-symlinks instructs git difftool to create copies instead. --no-symlinks is the default on Windows. -x <command>, --extcmd=<command> Specify a custom command for viewing diffs. git-difftool ignores the configured defaults and runs $command $LOCAL $REMOTE when this option is specified. Additionally, $BASE is set in the environment. -g, --[no-]gui When git-difftool is invoked with the -g or --gui option the default diff tool will be read from the configured diff.guitool variable instead of diff.tool. This may be selected automatically using the configuration variable difftool.guiDefault. The --no-gui option can be used to override these settings. If diff.guitool is not set, we will fallback in the order of merge.guitool, diff.tool, merge.tool until a tool is found. --[no-]trust-exit-code git-difftool invokes a diff tool individually on each file. Errors reported by the diff tool are ignored by default. Use --trust-exit-code to make git-difftool exit when an invoked diff tool returns a non-zero exit code. git-difftool will forward the exit code of the invoked tool when --trust-exit-code is used. See git-diff(1) for the full list of supported options. "
  },
  {
    "command": "wc",
    "description": " Print newline, word, and byte counts for each FILE, and a total line if more than one FILE is specified. A word is a non-zero-length sequence of printable characters delimited by white space. With no FILE, or when FILE is -, read standard input. The options below may be used to select which counts are printed, always in the following order: newline, word, character, byte, maximum line length. -c, --bytes print the byte counts -m, --chars print the character counts -l, --lines print the newline counts --files0-from=F read input from the files specified by NUL-terminated names in file F; If F is - then read names from standard input -L, --max-line-length print the maximum display width -w, --words print the word counts --total=WHEN when to print a line with total counts; WHEN can be: auto, always, only, never --help display this help and exit --version output version information and exit "
  },
  {
    "command": "passwd",
    "description": " The passwd command changes passwords for user accounts. A normal user may only change the password for their own account, while the superuser may change the password for any account. passwd also changes the account or associated password validity period. Password Changes The user is first prompted for their old password, if one is present. This password is then encrypted and compared against the stored password. The user has only one chance to enter the correct password. The superuser is permitted to bypass this step so that forgotten passwords may be changed. After the password has been entered, password aging information is checked to see if the user is permitted to change the password at this time. If not, passwd refuses to change the password and exits. The user is then prompted twice for a replacement password. The second entry is compared against the first and both are required to match in order for the password to be changed. Then, the password is tested for complexity. passwd will reject any password which is not suitably complex. Care must be taken not to include the system default erase or kill characters. Hints for user passwords The security of a password depends upon the strength of the encryption algorithm and the size of the key space. The legacy UNIX System encryption method is based on the NBS DES algorithm. More recent methods are now recommended (see ENCRYPT_METHOD). The size of the key space depends upon the randomness of the password which is selected. Compromises in password security normally result from careless password selection or handling. For this reason, you should not select a password which appears in a dictionary or which must be written down. The password should also not be a proper name, your license number, birth date, or street address. Any of these may be used as guesses to violate system security. As a general guideline, passwords should be long and random. It's fine to use simple character sets, such as passwords consisting only of lowercase letters, if that helps memorizing longer passwords. For a password consisting only of lowercase English letters randomly chosen, and a length of 32, there are 26^32 (approximately 2^150) different possible combinations. Being an exponential equation, it's apparent that the exponent (the length) is more important than the base (the size of the character set). You can find advice on how to choose a strong password on http://en.wikipedia.org/wiki/Password_strength The options which apply to the passwd command are: -a, --all This option can be used only with -S and causes show status for all users. -d, --delete Delete a user's password (make it empty). This is a quick way to disable a password for an account. It will set the named account passwordless. -e, --expire Immediately expire an account's password. This in effect can force a user to change their password at the user's next login. -h, --help Display help message and exit. -i, --inactive INACTIVE This option is used to disable an account after the password has been expired for a number of days. After a user account has had an expired password for INACTIVE days, the user may no longer sign on to the account. -k, --keep-tokens Indicate password change should be performed only for expired authentication tokens (passwords). The user wishes to keep their non-expired tokens as before. -l, --lock Lock the password of the named account. This option disables a password by changing it to a value which matches no possible encrypted value (it adds a \u00b4!\u00b4 at the beginning of the password). Note that this does not disable the account. The user may still be able to login using another authentication token (e.g. an SSH key). To disable the account, administrators should use usermod --expiredate 1 (this set the account's expire date to Jan 2, 1970). Users with a locked password are not allowed to change their password. -n, --mindays MIN_DAYS Set the minimum number of days between password changes to MIN_DAYS. A value of zero for this field indicates that the user may change their password at any time. -q, --quiet Quiet mode. -r, --repository REPOSITORY change password in REPOSITORY repository -R, --root CHROOT_DIR Apply changes in the CHROOT_DIR directory and use the configuration files from the CHROOT_DIR directory. Only absolute paths are supported. -S, --status Display account status information. The status information consists of 7 fields. The first field is the user's login name. The second field indicates if the user account has a locked password (L), has no password (NP), or has a usable password (P). The third field gives the date of the last password change. The next four fields are the minimum age, maximum age, warning period, and inactivity period for the password. These ages are expressed in days. -u, --unlock Unlock the password of the named account. This option re-enables a password by changing the password back to its previous value (to the value before using the -l option). -w, --warndays WARN_DAYS Set the number of days of warning before a password change is required. The WARN_DAYS option is the number of days prior to the password expiring that a user will be warned that their password is about to expire. -x, --maxdays MAX_DAYS Set the maximum number of days a password remains valid. After MAX_DAYS, the password is required to be changed. Passing the number -1 as MAX_DAYS will remove checking a password's validity. "
  },
  {
    "command": "command",
    "description": " The command utility shall cause the shell to treat the arguments as a simple command, suppressing the shell function lookup that is described in Section 2.9.1.1, Command Search and Execution, item 1b. If the command_name is the same as the name of one of the special built-in utilities, the special properties in the enumerated list at the beginning of Section 2.14, Special Built-In Utilities shall not occur. In every other respect, if command_name is not the name of a function, the effect of command (with no options) shall be the same as omitting command. When the -v or -V option is used, the command utility shall provide information concerning how a command name is interpreted by the shell. The command utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -p Perform the command search using a default value for PATH that is guaranteed to find all of the standard utilities. -v Write a string to standard output that indicates the pathname or command that will be used by the shell, in the current shell execution environment (see Section 2.12, Shell Execution Environment), to invoke command_name, but do not invoke command_name. * Utilities, regular built-in utilities, command_names including a <slash> character, and any implementation-defined functions that are found using the PATH variable (as described in Section 2.9.1.1, Command Search and Execution), shall be written as absolute pathnames. * Shell functions, special built-in utilities, regular built-in utilities not associated with a PATH search, and shell reserved words shall be written as just their names. * An alias shall be written as a command line that represents its alias definition. * Otherwise, no output shall be written and the exit status shall reflect that the name was not found. -V Write a string to standard output that indicates how the name given in the command_name operand will be interpreted by the shell, in the current shell execution environment (see Section 2.12, Shell Execution Environment), but do not invoke command_name. Although the format of this string is unspecified, it shall indicate in which of the following categories command_name falls and shall include the information stated: * Utilities, regular built-in utilities, and any implementation-defined functions that are found using the PATH variable (as described in Section 2.9.1.1, Command Search and Execution), shall be identified as such and include the absolute pathname in the string. * Other shell functions shall be identified as functions. * Aliases shall be identified as aliases and their definitions included in the string. * Special built-in utilities shall be identified as special built-in utilities. * Regular built-in utilities not associated with a PATH search shall be identified as regular built-in utilities. (The term ``regular'' need not be used.) * Shell reserved words shall be identified as reserved words. "
  },
  {
    "command": "getent",
    "description": " The getent command displays entries from databases supported by the Name Service Switch libraries, which are configured in /etc/nsswitch.conf. If one or more key arguments are provided, then only the entries that match the supplied keys will be displayed. Otherwise, if no key is provided, all entries will be displayed (unless the database does not support enumeration). The database may be any of those supported by the GNU C Library, listed below: ahosts When no key is provided, use sethostent(3), gethostent(3), and endhostent(3) to enumerate the hosts database. This is identical to using hosts. When one or more key arguments are provided, pass each key in succession to getaddrinfo(3) with the address family AF_UNSPEC, enumerating each socket address structure returned. ahostsv4 Same as ahosts, but use the address family AF_INET. ahostsv6 Same as ahosts, but use the address family AF_INET6. The call to getaddrinfo(3) in this case includes the AI_V4MAPPED flag. aliases When no key is provided, use setaliasent(3), getaliasent(3), and endaliasent(3) to enumerate the aliases database. When one or more key arguments are provided, pass each key in succession to getaliasbyname(3) and display the result. ethers When one or more key arguments are provided, pass each key in succession to ether_aton(3) and ether_hostton(3) until a result is obtained, and display the result. Enumeration is not supported on ethers, so a key must be provided. group When no key is provided, use setgrent(3), getgrent(3), and endgrent(3) to enumerate the group database. When one or more key arguments are provided, pass each numeric key to getgrgid(3) and each nonnumeric key to getgrnam(3) and display the result. gshadow When no key is provided, use setsgent(3), getsgent(3), and endsgent(3) to enumerate the gshadow database. When one or more key arguments are provided, pass each key in succession to getsgnam(3) and display the result. hosts When no key is provided, use sethostent(3), gethostent(3), and endhostent(3) to enumerate the hosts database. When one or more key arguments are provided, pass each key to gethostbyaddr(3) or gethostbyname2(3), depending on whether a call to inet_pton(3) indicates that the key is an IPv6 or IPv4 address or not, and display the result. initgroups When one or more key arguments are provided, pass each key in succession to getgrouplist(3) and display the result. Enumeration is not supported on initgroups, so a key must be provided. netgroup When one key is provided, pass the key to setnetgrent(3) and, using getnetgrent(3) display the resulting string triple (hostname, username, domainname). Alternatively, three keys may be provided, which are interpreted as the hostname, username, and domainname to match to a netgroup name via innetgr(3). Enumeration is not supported on netgroup, so either one or three keys must be provided. networks When no key is provided, use setnetent(3), getnetent(3), and endnetent(3) to enumerate the networks database. When one or more key arguments are provided, pass each numeric key to getnetbyaddr(3) and each nonnumeric key to getnetbyname(3) and display the result. passwd When no key is provided, use setpwent(3), getpwent(3), and endpwent(3) to enumerate the passwd database. When one or more key arguments are provided, pass each numeric key to getpwuid(3) and each nonnumeric key to getpwnam(3) and display the result. protocols When no key is provided, use setprotoent(3), getprotoent(3), and endprotoent(3) to enumerate the protocols database. When one or more key arguments are provided, pass each numeric key to getprotobynumber(3) and each nonnumeric key to getprotobyname(3) and display the result. rpc When no key is provided, use setrpcent(3), getrpcent(3), and endrpcent(3) to enumerate the rpc database. When one or more key arguments are provided, pass each numeric key to getrpcbynumber(3) and each nonnumeric key to getrpcbyname(3) and display the result. services When no key is provided, use setservent(3), getservent(3), and endservent(3) to enumerate the services database. When one or more key arguments are provided, pass each numeric key to getservbynumber(3) and each nonnumeric key to getservbyname(3) and display the result. shadow When no key is provided, use setspent(3), getspent(3), and endspent(3) to enumerate the shadow database. When one or more key arguments are provided, pass each key in succession to getspnam(3) and display the result. -s service, --service service Override all databases with the specified service. (Since glibc 2.2.5.) -s database:service, --service database:service Override only specified databases with the specified service. The option may be used multiple times, but only the last service for each database will be used. (Since glibc 2.4.) -i, --no-idn Disables IDN encoding in lookups for ahosts/getaddrinfo(3) (Since glibc-2.13.) -?, --help Print a usage summary and exit. --usage Print a short usage summary and exit. -V, --version Print the version number, license, and disclaimer of warranty for getent. "
  },
  {
    "command": "dd",
    "description": " Copy a file, converting and formatting according to the operands. bs=BYTES read and write up to BYTES bytes at a time (default: 512); overrides ibs and obs cbs=BYTES convert BYTES bytes at a time conv=CONVS convert the file as per the comma separated symbol list count=N copy only N input blocks ibs=BYTES read up to BYTES bytes at a time (default: 512) if=FILE read from FILE instead of stdin iflag=FLAGS read as per the comma separated symbol list obs=BYTES write BYTES bytes at a time (default: 512) of=FILE write to FILE instead of stdout oflag=FLAGS write as per the comma separated symbol list seek=N (or oseek=N) skip N obs-sized output blocks skip=N (or iseek=N) skip N ibs-sized input blocks status=LEVEL The LEVEL of information to print to stderr; 'none' suppresses everything but error messages, 'noxfer' suppresses the final transfer statistics, 'progress' shows periodic transfer statistics N and BYTES may be followed by the following multiplicative suffixes: c=1, w=2, b=512, kB=1000, K=1024, MB=1000*1000, M=1024*1024, xM=M, GB=1000*1000*1000, G=1024*1024*1024, and so on for T, P, E, Z, Y, R, Q. Binary prefixes can be used, too: KiB=K, MiB=M, and so on. If N ends in 'B', it counts bytes not blocks. Each CONV symbol may be: ascii from EBCDIC to ASCII ebcdic from ASCII to EBCDIC ibm from ASCII to alternate EBCDIC block pad newline-terminated records with spaces to cbs-size unblock replace trailing spaces in cbs-size records with newline lcase change upper case to lower case ucase change lower case to upper case sparse try to seek rather than write all-NUL output blocks swab swap every pair of input bytes sync pad every input block with NULs to ibs-size; when used with block or unblock, pad with spaces rather than NULs excl fail if the output file already exists nocreat do not create the output file notrunc do not truncate the output file noerror continue after read errors fdatasync physically write output file data before finishing fsync likewise, but also write metadata Each FLAG symbol may be: append append mode (makes sense only for output; conv=notrunc suggested) direct use direct I/O for data directory fail unless a directory dsync use synchronized I/O for data sync likewise, but also for metadata fullblock accumulate full blocks of input (iflag only) nonblock use non-blocking I/O noatime do not update access time nocache Request to drop cache. See also oflag=sync noctty do not assign controlling terminal from file nofollow do not follow symlinks Sending a USR1 signal to a running 'dd' process makes it print I/O statistics to standard error and then resume copying. Options are: --help display this help and exit --version output version information and exit "
  },
  {
    "command": "join",
    "description": " For each pair of input lines with identical join fields, write a line to standard output. The default join field is the first, delimited by blanks. When FILE1 or FILE2 (not both) is -, read standard input. -a FILENUM also print unpairable lines from file FILENUM, where FILENUM is 1 or 2, corresponding to FILE1 or FILE2 -e STRING replace missing (empty) input fields with STRING; I.e., missing fields specified with '-12jo' options -i, --ignore-case ignore differences in case when comparing fields -j FIELD equivalent to '-1 FIELD -2 FIELD' -o FORMAT obey FORMAT while constructing output line -t CHAR use CHAR as input and output field separator -v FILENUM like -a FILENUM, but suppress joined output lines -1 FIELD join on this FIELD of file 1 -2 FIELD join on this FIELD of file 2 --check-order check that the input is correctly sorted, even if all input lines are pairable --nocheck-order do not check that the input is correctly sorted --header treat the first line in each file as field headers, print them without trying to pair them -z, --zero-terminated line delimiter is NUL, not newline --help display this help and exit --version output version information and exit Unless -t CHAR is given, leading blanks separate fields and are ignored, else fields are separated by CHAR. Any FIELD is a field number counted from 1. FORMAT is one or more comma or blank separated specifications, each being 'FILENUM.FIELD' or '0'. Default FORMAT outputs the join field, the remaining fields from FILE1, the remaining fields from FILE2, all separated by CHAR. If FORMAT is the keyword 'auto', then the first line of each file determines the number of fields output for each line. Important: FILE1 and FILE2 must be sorted on the join fields. E.g., use \"sort -k 1b,1\" if 'join' has no options, or use \"join -t ''\" if 'sort' has no options. Note, comparisons honor the rules specified by 'LC_COLLATE'. If the input is not sorted and some lines cannot be joined, a warning message will be given. "
  },
  {
    "command": "bg",
    "description": " If job control is enabled (see the description of set -m), the bg utility shall resume suspended jobs from the current environment (see Section 2.12, Shell Execution Environment) by running them as background jobs. If the job specified by job_id is already a running background job, the bg utility shall have no effect and shall exit successfully. Using bg to place a job into the background shall cause its process ID to become ``known in the current shell execution environment'', as if it had been started as an asynchronous list; see Section 2.9.3.1, Examples. None. "
  },
  {
    "command": "git-var",
    "description": " Prints a Git logical variable. Exits with code 1 if the variable has no value. -l Cause the logical variables to be listed. In addition, all the variables of the Git configuration file .git/config are listed as well. (However, the configuration variables listing functionality is deprecated in favor of git config -l.) "
  },
  {
    "command": "make",
    "description": " The make utility will determine automatically which pieces of a large program need to be recompiled, and issue the commands to recompile them. The manual describes the GNU implementation of make, which was written by Richard Stallman and Roland McGrath, and is currently maintained by Paul Smith. Our examples show C programs, since they are very common, but you can use make with any programming language whose compiler can be run with a shell command. In fact, make is not limited to programs. You can use it to describe any task where some files must be updated automatically from others whenever the others change. To prepare to use make, you must write a file called the makefile that describes the relationships among files in your program, and provides commands for updating each file. In a program, typically the executable file is updated from object files, which are in turn made by compiling source files. Once a suitable makefile exists, each time you change some source files, this simple shell command: make suffices to perform all necessary recompilations. The make program uses the makefile description and the last-modification times of the files to decide which of the files need to be updated. For each of those files, it issues the commands recorded in the makefile. make executes commands in the makefile to update one or more targets, where target is typically a program. If no -f option is present, make will look for the makefiles GNUmakefile, makefile, and Makefile, in that order. Normally you should call your makefile either makefile or Makefile. (We recommend Makefile because it appears prominently near the beginning of a directory listing, right near other important files such as README.) The first name checked, GNUmakefile, is not recommended for most makefiles. You should use this name if you have a makefile that is specific to GNU make, and will not be understood by other versions of make. If makefile is '-', the standard input is read. make updates a target if it depends on prerequisite files that have been modified since the target was last modified, or if the target does not exist. -b, -m These options are ignored for compatibility with other versions of make. -B, --always-make Unconditionally make all targets. -C dir, --directory=dir Change to directory dir before reading the makefiles or doing anything else. If multiple -C options are specified, each is interpreted relative to the previous one: -C / -C etc is equivalent to -C /etc. This is typically used with recursive invocations of make. -d Print debugging information in addition to normal processing. The debugging information says which files are being considered for remaking, which file-times are being compared and with what results, which files actually need to be remade, which implicit rules are considered and which are applied---everything interesting about how make decides what to do. --debug[=FLAGS] Print debugging information in addition to normal processing. If the FLAGS are omitted, then the behavior is the same as if -d was specified. FLAGS may be any or all of the following names, comma- or space-separated. Only the first character is significant: the rest may be omitted: all for all debugging output (same as using -d), basic for basic debugging, verbose for more verbose basic debugging, implicit for showing implicit rule search operations, jobs for details on invocation of commands, makefile for debugging while remaking makefiles, print shows all recipes that are run even if they are silent, and why shows the reason make decided to rebuild each target. Use none to disable all previous debugging flags. -e, --environment-overrides Give variables taken from the environment precedence over variables from makefiles. -E string, --eval string Interpret string using the eval function, before parsing any makefiles. -f file, --file=file, --makefile=FILE Use file as a makefile. -i, --ignore-errors Ignore all errors in commands executed to remake files. -I dir, --include-dir=dir Specifies a directory dir to search for included makefiles. If several -I options are used to specify several directories, the directories are searched in the order specified. Unlike the arguments to other flags of make, directories given with -I flags may come directly after the flag: -Idir is allowed, as well as -I dir. This syntax is allowed for compatibility with the C preprocessor's -I flag. -j [jobs], --jobs[=jobs] Specifies the number of jobs (commands) to run simultaneously. If there is more than one -j option, the last one is effective. If the -j option is given without an argument, make will not limit the number of jobs that can run simultaneously. --jobserver-style=style The style of jobserver to use. The style may be one of fifo, pipe, or sem (Windows only). -k, --keep-going Continue as much as possible after an error. While the target that failed, and those that depend on it, cannot be remade, the other dependencies of these targets can be processed all the same. -l [load], --load-average[=load] Specifies that no new jobs (commands) should be started if there are others jobs running and the load average is at least load (a floating-point number). With no argument, removes a previous load limit. -L, --check-symlink-times Use the latest mtime between symlinks and target. -n, --just-print, --dry-run, --recon Print the commands that would be executed, but do not execute them (except in certain circumstances). -o file, --old-file=file, --assume-old=file Do not remake the file file even if it is older than its dependencies, and do not remake anything on account of changes in file. Essentially the file is treated as very old and its rules are ignored. -O[type], --output-sync[=type] When running multiple jobs in parallel with -j, ensure the output of each job is collected together rather than interspersed with output from other jobs. If type is not specified or is target the output from the entire recipe for each target is grouped together. If type is line the output from each command line within a recipe is grouped together. If type is recurse output from an entire recursive make is grouped together. If type is none output synchronization is disabled. -p, --print-data-base Print the data base (rules and variable values) that results from reading the makefiles; then execute as usual or as otherwise specified. This also prints the version information given by the -v switch (see below). To print the data base without trying to remake any files, use make -p -f/dev/null. -q, --question ``Question mode''. Do not run any commands, or print anything; just return an exit status that is zero if the specified targets are already up to date, nonzero otherwise. -r, --no-builtin-rules Eliminate use of the built-in implicit rules. Also clear out the default list of suffixes for suffix rules. -R, --no-builtin-variables Don't define any built-in variables. -s, --silent, --quiet Silent operation; do not print the commands as they are executed. --no-silent Cancel the effect of the -s option. -S, --no-keep-going, --stop Cancel the effect of the -k option. -t, --touch Touch files (mark them up to date without really changing them) instead of running their commands. This is used to pretend that the commands were done, in order to fool future invocations of make. --trace Information about the disposition of each target is printed (why the target is being rebuilt and what commands are run to rebuild it). -v, --version Print the version of the make program plus a copyright, a list of authors and a notice that there is no warranty. -w, --print-directory Print a message containing the working directory before and after other processing. This may be useful for tracking down errors from complicated nests of recursive make commands. --no-print-directory Turn off -w, even if it was turned on implicitly. --shuffle[=MODE] Enable shuffling of goal and prerequisite ordering. MODE is one of none to disable shuffle mode, random to shuffle prerequisites in random order, reverse to consider prerequisites in reverse order, or an integer <seed> which enables random mode with a specific seed value. If MODE is omitted the default is random. -W file, --what-if=file, --new-file=file, --assume-new=file Pretend that the target file has just been modified. When used with the -n flag, this shows you what would happen if you were to modify that file. Without -n, it is almost the same as running a touch command on the given file before running make, except that the modification time is changed only in the imagination of make. --warn-undefined-variables Warn when an undefined variable is referenced. "
  },
  {
    "command": "uudecode",
    "description": " The uudecode utility shall read a file, or standard input if no file is specified, that includes data created by the uuencode utility. The uudecode utility shall scan the input file, searching for data compatible with one of the formats specified in uuencode, and attempt to create or overwrite the file described by the data (or overridden by the -o option). The pathname shall be contained in the data or specified by the -o option. The file access permission bits and contents for the file to be produced shall be contained in that data. The mode bits of the created file (other than standard output) shall be set from the file access permission bits contained in the data; that is, other attributes of the mode, including the file mode creation mask (see umask), shall not affect the file being produced. If either of the op characters '+' and '-' (see chmod) are specified in symbolic mode, the initial mode on which those operations are based is unspecified. If the pathname of the file resolves to an existing file and the user does not have write permission on that file, uudecode shall terminate with an error. If the pathname of the file resolves to an existing file and the user has write permission on that file, the existing file shall be overwritten and, if possible, the mode bits of the file (other than standard output) shall be set as described above; if the mode bits cannot be set, uudecode shall not treat this as an error. If the input data was produced by uuencode on a system with a different number of bits per byte than on the target system, the results of uudecode are unspecified. The uudecode utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported by the implementation: -o outfile A pathname of a file that shall be used instead of any pathname contained in the input data. Specifying an outfile option-argument of /dev/stdout shall indicate standard output. "
  },
  {
    "command": "diff",
    "description": " The diff utility shall compare the contents of file1 and file2 and write to standard output a list of changes necessary to convert file1 into file2. This list should be minimal. No output shall be produced if the files are identical. The diff utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -b Cause any amount of white space at the end of a line to be treated as a single <newline> (that is, the white- space characters preceding the <newline> are ignored) and other strings of white-space characters, not including <newline> characters, to compare equal. -c Produce output in a form that provides three lines of copied context. -C n Produce output in a form that provides n lines of copied context (where n shall be interpreted as a positive decimal integer). -e Produce output in a form suitable as input for the ed utility, which can then be used to convert file1 into file2. -f Produce output in an alternative form, similar in format to -e, but not intended to be suitable as input for the ed utility, and in the opposite order. -r Apply diff recursively to files and directories of the same name when file1 and file2 are both directories. The diff utility shall detect infinite loops; that is, entering a previously visited directory that is an ancestor of the last file encountered. When it detects an infinite loop, diff shall write a diagnostic message to standard error and shall either recover its position in the hierarchy or terminate. -u Produce output in a form that provides three lines of unified context. -U n Produce output in a form that provides n lines of unified context (where n shall be interpreted as a non- negative decimal integer). "
  },
  {
    "command": "ln",
    "description": " In the first synopsis form, the ln utility shall create a new directory entry (link) at the destination path specified by the target_file operand. If the -s option is specified, a symbolic link shall be created for the file specified by the source_file operand. This first synopsis form shall be assumed when the final operand does not name an existing directory; if more than two operands are specified and the final is not an existing directory, an error shall result. In the second synopsis form, the ln utility shall create a new directory entry (link), or if the -s option is specified a symbolic link, for each file specified by a source_file operand, at a destination path in the existing directory named by target_dir. If the last operand specifies an existing file of a type not specified by the System Interfaces volume of POSIX.1\u20102017, the behavior is implementation-defined. The corresponding destination path for each source_file shall be the concatenation of the target directory pathname, a <slash> character if the target directory pathname did not end in a <slash>, and the last pathname component of the source_file. The second synopsis form shall be assumed when the final operand names an existing directory. For each source_file: 1. If the destination path exists and was created by a previous step, it is unspecified whether ln shall write a diagnostic message to standard error, do nothing more with the current source_file, and go on to any remaining source_files; or will continue processing the current source_file. If the destination path exists: a. If the -f option is not specified, ln shall write a diagnostic message to standard error, do nothing more with the current source_file, and go on to any remaining source_files. b. If the destination path names the same directory entry as the current source_file ln shall write a diagnostic message to standard error, do nothing more with the current source_file, and go on to any remaining source_files. c. Actions shall be performed equivalent to the unlink() function defined in the System Interfaces volume of POSIX.1\u20102017, called using the destination path as the path argument. If this fails for any reason, ln shall write a diagnostic message to standard error, do nothing more with the current source_file, and go on to any remaining source_files. 2. If the -s option is specified, actions shall be performed equivalent to the symlink() function with source_file as the path1 argument and the destination path as the path2 argument. The ln utility shall do nothing more with source_file and shall go on to any remaining files. 3. If source_file is a symbolic link: a. If the -P option is in effect, actions shall be performed equivalent to the linkat() function with source_file as the path1 argument, the destination path as the path2 argument, AT_FDCWD as the fd1 and fd2 arguments, and zero as the flag argument. b. If the -L option is in effect, actions shall be performed equivalent to the linkat() function with source_file as the path1 argument, the destination path as the path2 argument, AT_FDCWD as the fd1 and fd2 arguments, and AT_SYMLINK_FOLLOW as the flag argument. The ln utility shall do nothing more with source_file and shall go on to any remaining files. 4. Actions shall be performed equivalent to the link() function defined in the System Interfaces volume of POSIX.1\u20102017 using source_file as the path1 argument, and the destination path as the path2 argument. The ln utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -f Force existing destination pathnames to be removed to allow the link. -L For each source_file operand that names a file of type symbolic link, create a (hard) link to the file referenced by the symbolic link. -P For each source_file operand that names a file of type symbolic link, create a (hard) link to the symbolic link itself. -s Create symbolic links instead of hard links. If the -s option is specified, the -L and -P options shall be silently ignored. Specifying more than one of the mutually-exclusive options -L and -P shall not be considered an error. The last option specified shall determine the behavior of the utility (unless the -s option causes it to be ignored). If the -s option is not specified and neither a -L nor a -P option is specified, it is implementation-defined which of the -L and -P options will be used as the default. "
  },
  {
    "command": "cal",
    "description": " cal displays a simple calendar. If no arguments are specified, the current month is displayed. The month may be specified as a number (1-12), as a month name or as an abbreviated month name according to the current locales. Two different calendar systems are used, Gregorian and Julian. These are nearly identical systems with Gregorian making a small adjustment to the frequency of leap years; this facilitates improved synchronization with solar events like the equinoxes. The Gregorian calendar reform was introduced in 1582, but its adoption continued up to 1923. By default cal uses the adoption date of 3 Sept 1752. From that date forward the Gregorian calendar is displayed; previous dates use the Julian calendar system. 11 days were removed at the time of adoption to bring the calendar in sync with solar events. So Sept 1752 has a mix of Julian and Gregorian dates by which the 2nd is followed by the 14th (the 3rd through the 13th are absent). Optionally, either the proleptic Gregorian calendar or the Julian calendar may be used exclusively. See --reform below. -1, --one Display single month output. (This is the default.) -3, --three Display three months spanning the date. -n , --months number Display number of months, starting from the month containing the date. -S, --span Display months spanning the date. -s, --sunday Display Sunday as the first day of the week. -m, --monday Display Monday as the first day of the week. -v, --vertical Display using a vertical layout (aka ncal(1) mode). --iso Display the proleptic Gregorian calendar exclusively. This option does not affect week numbers and the first day of the week. See --reform below. -j, --julian Use day-of-year numbering for all calendars. These are also called ordinal days. Ordinal days range from 1 to 366. This option does not switch from the Gregorian to the Julian calendar system, that is controlled by the --reform option. Sometimes Gregorian calendars using ordinal dates are referred to as Julian calendars. This can be confusing due to the many date related conventions that use Julian in their name: (ordinal) julian date, julian (calendar) date, (astronomical) julian date, (modified) julian date, and more. This option is named julian, because ordinal days are identified as julian by the POSIX standard. However, be aware that cal also uses the Julian calendar system. See DESCRIPTION above. --reform val This option sets the adoption date of the Gregorian calendar reform. Calendar dates previous to reform use the Julian calendar system. Calendar dates after reform use the Gregorian calendar system. The argument val can be: \u2022 1752 - sets 3 September 1752 as the reform date (default). This is when the Gregorian calendar reform was adopted by the British Empire. \u2022 gregorian - display Gregorian calendars exclusively. This special placeholder sets the reform date below the smallest year that cal can use; meaning all calendar output uses the Gregorian calendar system. This is called the proleptic Gregorian calendar, because dates prior to the calendar system\u2019s creation use extrapolated values. \u2022 iso - alias of gregorian. The ISO 8601 standard for the representation of dates and times in information interchange requires using the proleptic Gregorian calendar. \u2022 julian - display Julian calendars exclusively. This special placeholder sets the reform date above the largest year that cal can use; meaning all calendar output uses the Julian calendar system. See DESCRIPTION above. -y, --year Display a calendar for the whole year. -Y, --twelve Display a calendar for the next twelve months. -w, --week[=number] Display week numbers in the calendar (US or ISO-8601). See the NOTES section for more details. --color[=when] Colorize the output. The optional argument when can be auto, never or always. If the when argument is omitted, it defaults to auto. The colors can be disabled; for the current built-in default see the --help output. See also the COLORS section. -c, --columns=columns Number of columns to use. auto uses as many as fit the terminal. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "file",
    "description": " This manual page documents version 5.44 of the file command. file tests each argument in an attempt to classify it. There are three sets of tests, performed in this order: filesystem tests, magic tests, and language tests. The first test that succeeds causes the file type to be printed. The type printed will usually contain one of the words text (the file contains only printing characters and a few common control characters and is probably safe to read on an ASCII terminal), executable (the file contains the result of compiling a program in a form understandable to some UNIX kernel or another), or data meaning anything else (data is usually \u201cbinary\u201d or non-printable). Exceptions are well-known file formats (core files, tar archives) that are known to contain binary data. When modifying magic files or the program itself, make sure to preserve these keywords. Users depend on knowing that all the readable files in a directory have the word \u201ctext\u201d printed. Don't do as Berkeley did and change \u201cshell commands text\u201d to \u201cshell script\u201d. The filesystem tests are based on examining the return from a stat(2) system call. The program checks to see if the file is empty, or if it's some sort of special file. Any known file types appropriate to the system you are running on (sockets, symbolic links, or named pipes (FIFOs) on those systems that implement them) are intuited if they are defined in the system header file <sys/stat.h>. The magic tests are used to check for files with data in particular fixed formats. The canonical example of this is a binary executable (compiled program) a.out file, whose format is defined in <elf.h>, <a.out.h> and possibly <exec.h> in the standard include directory. These files have a \u201cmagic number\u201d stored in a particular place near the beginning of the file that tells the UNIX operating system that the file is a binary executable, and which of several types thereof. The concept of a \u201cmagic number\u201d has been applied by extension to data files. Any file with some invariant identifier at a small fixed offset into the file can usually be described in this way. The information identifying these files is read from the compiled magic file /usr/local/share/misc/magic.mgc, or the files in the directory /usr/local/share/misc/magic if the compiled file does not exist. In addition, if $HOME/.magic.mgc or $HOME/.magic exists, it will be used in preference to the system magic files. If a file does not match any of the entries in the magic file, it is examined to see if it seems to be a text file. ASCII, ISO-8859-x, non-ISO 8-bit extended-ASCII character sets (such as those used on Macintosh and IBM PC systems), UTF-8-encoded Unicode, UTF-16-encoded Unicode, and EBCDIC character sets can be distinguished by the different ranges and sequences of bytes that constitute printable text in each set. If a file passes any of these tests, its character set is reported. ASCII, ISO-8859-x, UTF-8, and extended-ASCII files are identified as \u201ctext\u201d because they will be mostly readable on nearly any terminal; UTF-16 and EBCDIC are only \u201ccharacter data\u201d because, while they contain text, it is text that will require translation before it can be read. In addition, file will attempt to determine other characteristics of text-type files. If the lines of a file are terminated by CR, CRLF, or NEL, instead of the Unix-standard LF, this will be reported. Files that contain embedded escape sequences or overstriking will also be identified. Once file has determined the character set used in a text-type file, it will attempt to determine in what language the file is written. The language tests look for particular strings (cf. <names.h>) that can appear anywhere in the first few blocks of a file. For example, the keyword .br indicates that the file is most likely a troff(1) input file, just as the keyword struct indicates a C program. These tests are less reliable than the previous two groups, so they are performed last. The language test routines also test for some miscellany (such as tar(1) archives, JSON files). Any file that cannot be identified as having been written in any of the character sets listed above is simply said to be \u201cdata\u201d. --apple Causes the file command to output the file type and creator code as used by older MacOS versions. The code consists of eight letters, the first describing the file type, the latter the creator. This option works properly only for file formats that have the apple-style output defined. -b, --brief Do not prepend filenames to output lines (brief mode). -C, --compile Write a magic.mgc output file that contains a pre-parsed version of the magic file or directory. -c, --checking-printout Cause a checking printout of the parsed form of the magic file. This is usually used in conjunction with the -m option to debug a new magic file before installing it. -d Prints internal debugging information to stderr. -E On filesystem errors (file not found etc), instead of handling the error as regular output as POSIX mandates and keep going, issue an error message and exit. -e, --exclude testname Exclude the test named in testname from the list of tests made to determine the file type. Valid test names are: apptype EMX application type (only on EMX). ascii Various types of text files (this test will try to guess the text encoding, irrespective of the setting of the \u2018encoding\u2019 option). encoding Different text encodings for soft magic tests. tokens Ignored for backwards compatibility. cdf Prints details of Compound Document Files. compress Checks for, and looks inside, compressed files. csv Checks Comma Separated Value files. elf Prints ELF file details, provided soft magic tests are enabled and the elf magic is found. json Examines JSON (RFC-7159) files by parsing them for compliance. soft Consults magic files. simh Examines SIMH tape files. tar Examines tar files by verifying the checksum of the 512 byte tar header. Excluding this test can provide more detailed content description by using the soft magic method. text A synonym for \u2018ascii\u2019. --exclude-quiet Like --exclude but ignore tests that file does not know about. This is intended for compatibility with older versions of file. --extension Print a slash-separated list of valid extensions for the file type found. -F, --separator separator Use the specified string as the separator between the filename and the file result returned. Defaults to \u2018:\u2019. -f, --files-from namefile Read the names of the files to be examined from namefile (one per line) before the argument list. Either namefile or at least one filename argument must be present; to test the standard input, use \u2018-\u2019 as a filename argument. Please note that namefile is unwrapped and the enclosed filenames are processed when this option is encountered and before any further options processing is done. This allows one to process multiple lists of files with different command line arguments on the same file invocation. Thus if you want to set the delimiter, you need to do it before you specify the list of files, like: \u201c-F @ -f namefile\u201d, instead of: \u201c-f namefile -F @\u201d. -h, --no-dereference This option causes symlinks not to be followed (on systems that support symbolic links). This is the default if the environment variable POSIXLY_CORRECT is not defined. -i, --mime Causes the file command to output mime type strings rather than the more traditional human readable ones. Thus it may say \u2018text/plain; charset=us-ascii\u2019 rather than \u201cASCII text\u201d. --mime-type, --mime-encoding Like -i, but print only the specified element(s). -k, --keep-going Don't stop at the first match, keep going. Subsequent matches will be have the string \u2018\\012- \u2019 prepended. (If you want a newline, see the -r option.) The magic pattern with the highest strength (see the -l option) comes first. -l, --list Shows a list of patterns and their strength sorted descending by magic(4) strength which is used for the matching (see also the -k option). -L, --dereference This option causes symlinks to be followed, as the like- named option in ls(1) (on systems that support symbolic links). This is the default if the environment variable POSIXLY_CORRECT is defined. -m, --magic-file magicfiles Specify an alternate list of files and directories containing magic. This can be a single item, or a colon- separated list. If a compiled magic file is found alongside a file or directory, it will be used instead. -N, --no-pad Don't pad filenames so that they align in the output. -n, --no-buffer Force stdout to be flushed after checking each file. This is only useful if checking a list of files. It is intended to be used by programs that want filetype output from a pipe. -p, --preserve-date On systems that support utime(3) or utimes(2), attempt to preserve the access time of files analyzed, to pretend that file never read them. -P, --parameter name=value Set various parameter limits. Name Default Explanation bytes 1M max number of bytes to read from file elf_notes 256 max ELF notes processed elf_phnum 2K max ELF program sections processed elf_shnum 32K max ELF sections processed elf_shsize 128MB max ELF section size processed encoding 65K max number of bytes to determine encoding indir 50 recursion limit for indirect magic name 50 use count limit for name/use magic regex 8K length limit for regex searches -r, --raw Don't translate unprintable characters to \\ooo. Normally file translates unprintable characters to their octal representation. -s, --special-files Normally, file only attempts to read and determine the type of argument files which stat(2) reports are ordinary files. This prevents problems, because reading special files may have peculiar consequences. Specifying the -s option causes file to also read argument files which are block or character special files. This is useful for determining the filesystem types of the data in raw disk partitions, which are block special files. This option also causes file to disregard the file size as reported by stat(2) since on some systems it reports a zero size for raw disk partitions. -S, --no-sandbox On systems where libseccomp (https://github.com/seccomp/libseccomp ) is available, the -S option disables sandboxing which is enabled by default. This option is needed for file to execute external decompressing programs, i.e. when the -z option is specified and the built-in decompressors are not available. On systems where sandboxing is not available, this option has no effect. -v, --version Print the version of the program and exit. -z, --uncompress Try to look inside compressed files. -Z, --uncompress-noreport Try to look inside compressed files, but report information about the contents only not the compression. -0, --print0 Output a null character \u2018\\0\u2019 after the end of the filename. Nice to cut(1) the output. This does not affect the separator, which is still printed. If this option is repeated more than once, then file prints just the filename followed by a NUL followed by the description (or ERROR: text) followed by a second NUL for each entry. --help Print a help message and exit. "
  },
  {
    "command": "vi",
    "description": " This utility shall be provided on systems that both support the User Portability Utilities option and define the POSIX2_CHAR_TERM symbol. On other systems it is optional. The vi (visual) utility is a screen-oriented text editor. Only the open and visual modes of the editor are described in POSIX.1\u20102008; see the line editor ex for additional editing capabilities used in vi. The user can switch back and forth between vi and ex and execute ex commands from within vi. This reference page uses the term edit buffer to describe the current working text. No specific implementation is implied by this term. All editing changes are performed on the edit buffer, and no changes to it shall affect any file until an editor command writes the file. When using vi, the terminal screen acts as a window into the editing buffer. Changes made to the editing buffer shall be reflected in the screen display; the position of the cursor on the screen shall indicate the position within the editing buffer. Certain terminals do not have all the capabilities necessary to support the complete vi definition. When these commands cannot be supported on such terminals, this condition shall not produce an error message such as ``not an editor command'' or report a syntax error. The implementation may either accept the commands and produce results on the screen that are the result of an unsuccessful attempt to meet the requirements of this volume of POSIX.1\u20102017 or report an error describing the terminal-related deficiency. The vi utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except that '+' may be recognized as an option delimiter as well as '-'. The following options shall be supported: -c command See the ex command description of the -c option. -r See the ex command description of the -r option. -R See the ex command description of the -R option. -t tagstring See the ex command description of the -t option. -w size See the ex command description of the -w option. "
  },
  {
    "command": "pwdx",
    "description": "man7.org > Linux > man-pages Linux/UNIX system programming training * * * # pwdx(1) -- Linux manual page NAME | SYNOPSIS | OPTIONS | SEE ALSO | STANDARDS | AUTHOR | REPORTING BUGS | COLOPHON PWDX(1) User Commands PWDX(1) ## NAME top pwdx - report current working directory of a process ## SYNOPSIS top pwdx [options] pid [...] ## OPTIONS top -V, --version Output version information and exit. -h, --help Output help screen and exit. ## SEE ALSO top ps(1), pgrep(1) ## STANDARDS top No standards apply, but pwdx looks an awful lot like a SunOS command. ## AUTHOR top Nicholas Miell \u27e8nmiell@gmail.com\u27e9 wrote pwdx in 2004. ## REPORTING BUGS top Please send bug reports to \u27e8procps@freelists.org\u27e9 ## COLOPHON top This page is part of the procps-ng (/proc filesystem utilities) project. Information about the project can be found at \u27e8https://gitlab.com/procps-ng/procps\u27e9. If you have a bug report for this manual page, see \u27e8https://gitlab.com/procps-ng/procps/blob/master/Documentation/bugs.md\u27e9. This page was obtained from the project's upstream Git repository \u27e8https://gitlab.com/procps-ng/procps.git\u27e9 on 2023-06-23. (At that time, the date of the most recent commit that was found in the repository was 2023-06-13.) If you discover any rendering problems in this HTML version of the page, or you believe there is a better or more up-to-date source for the page, or you have corrections or improvements to the information in this COLOPHON (which is not part of the original manual page), send a mail to man-pages@man7.org procps-ng 2020-06-04 PWDX(1) * * * Pages that refer to this page: pslog(1) * * * * * * HTML rendering created 2023-06-24 by Michael Kerrisk, author of The Linux Programming Interface. For details of in-depth Linux/UNIX system programming training courses that I teach, look here. Hosting by jambit GmbH. * * * -V, --version Output version information and exit. -h, --help Output help screen and exit. "
  },
  {
    "command": "locate",
    "description": " This manual page documents the GNU version of locate. For each given pattern, locate searches one or more databases of file names and displays the file names that contain the pattern. Patterns can contain shell-style metacharacters: `*', `?', and `[]'. The metacharacters do not treat `/' or `.' specially. Therefore, a pattern `foo*bar' can match a file name that contains `foo3/bar', and a pattern `*duck*' can match a file name that contains `lake/.ducky'. Patterns that contain metacharacters should be quoted to protect them from expansion by the shell. If a pattern is a plain string \u2014 it contains no metacharacters \u2014 locate displays all file names in the database that contain that string anywhere. If a pattern does contain metacharacters, locate only displays file names that match the pattern exactly. As a result, patterns that contain metacharacters should usually begin with a `*', and will most often end with one as well. The exceptions are patterns that are intended to explicitly match the beginning or end of a file name. The file name databases contain lists of files that were on the system when the databases were last updated. The system administrator can choose the file name of the default database, the frequency with which the databases are updated, and the directories for which they contain entries; see updatedb(1). If locate's output is going to a terminal, unusual characters in the output are escaped in the same way as for the -print action of the find command. If the output is not going to a terminal, file names are printed exactly as-is. -0, --null Use ASCII NUL as a separator, instead of newline. -A, --all Print only names which match all non-option arguments, not those matching one or more non-option arguments. -b, --basename Results are considered to match if the pattern specified matches the final component of the name of a file as listed in the database. This final component is usually referred to as the `base name'. -c, --count Instead of printing the matched filenames, just print the total number of matches we found, unless --print (-p) is also present. -d path, --database=path Instead of searching the default file name database, search the file name databases in path, which is a colon- separated list of database file names. You can also use the environment variable LOCATE_PATH to set the list of database files to search. The option overrides the environment variable if both are used. Empty elements in the path are taken to be synonyms for the file name of the default database. A database can be supplied on stdin, using `-' as an element of path. If more than one element of path is `-', later instances are ignored (and a warning message is printed). The file name database format changed starting with GNU find and locate version 4.0 to allow machines with different byte orderings to share the databases. This version of locate can automatically recognize and read databases produced for older versions of GNU locate or Unix versions of locate or find. Support for the old locate database format will be discontinued in a future release. -e, --existing Only print out such names that currently exist (instead of such names that existed when the database was created). Note that this may slow down the program a lot, if there are many matches in the database. If you are using this option within a program, please note that it is possible for the file to be deleted after locate has checked that it exists, but before you use it. -E, --non-existing Only print out such names that currently do not exist (instead of such names that existed when the database was created). Note that this may slow down the program a lot, if there are many matches in the database. --help Print a summary of the options to locate and exit. -i, --ignore-case Ignore case distinctions in both the pattern and the file names. -l N, --limit=N Limit the number of matches to N. If a limit is set via this option, the number of results printed for the -c option will never be larger than this number. -L, --follow If testing for the existence of files (with the -e or -E options), consider broken symbolic links to be non- existing. This is the default. --max-database-age D Normally, locate will issue a warning message when it searches a database which is more than 8 days old. This option changes that value to something other than 8. The effect of specifying a negative value is undefined. -m, --mmap Accepted but does nothing, for compatibility with BSD locate. -P, -H, --nofollow If testing for the existence of files (with the -e or -E options), treat broken symbolic links as if they were existing files. The -H form of this option is provided purely for similarity with find; the use of -P is recommended over -H. -p, --print Print search results when they normally would not, because of the presence of --statistics (-S) or --count (-c). -r, --regex The pattern specified on the command line is understood to be a regular expression, as opposed to a glob pattern. The Regular expressions work in the same was as in emacs except for the fact that \".\" will match a newline. GNU find uses the same regular expressions. Filenames whose full paths match the specified regular expression are printed (or, in the case of the -c option, counted). If you wish to anchor your regular expression at the ends of the full path name, then as is usual with regular expressions, you should use the characters ^ and $ to signify this. --regextype R Use regular expression dialect R. Supported dialects include `findutils-default', `posix-awk', `posix-basic', `posix-egrep', `posix-extended', `posix-minimal-basic', `awk', `ed', `egrep', `emacs', `gnu-awk', `grep' and `sed'. See the Texinfo documentation for a detailed explanation of these dialects. -s, --stdio Accepted but does nothing, for compatibility with BSD locate. -S, --statistics Print various statistics about each locate database and then exit without performing a search, unless non-option arguments are given. For compatibility with BSD, -S is accepted as a synonym for --statistics. However, the output of locate -S is different for the GNU and BSD implementations of locate. --version Print the version number of locate and exit. -w, --wholename Match against the whole name of the file as listed in the database. This is the default. "
  },
  {
    "command": "rm",
    "description": " The rm utility shall remove the directory entry specified by each file argument. If either of the files dot or dot-dot are specified as the basename portion of an operand (that is, the final pathname component) or if an operand resolves to the root directory, rm shall write a diagnostic message to standard error and do nothing more with such operands. For each file the following steps shall be taken: 1. If the file does not exist: a. If the -f option is not specified, rm shall write a diagnostic message to standard error. b. Go on to any remaining files. 2. If file is of type directory, the following steps shall be taken: a. If neither the -R option nor the -r option is specified, rm shall write a diagnostic message to standard error, do nothing more with file, and go on to any remaining files. b. If file is an empty directory, rm may skip to step 2d. If the -f option is not specified, and either the permissions of file do not permit writing and the standard input is a terminal or the -i option is specified, rm shall write a prompt to standard error and read a line from the standard input. If the response is not affirmative, rm shall do nothing more with the current file and go on to any remaining files. c. For each entry contained in file, other than dot or dot- dot, the four steps listed here (1 to 4) shall be taken with the entry as if it were a file operand. The rm utility shall not traverse directories by following symbolic links into other parts of the hierarchy, but shall remove the links themselves. d. If the -i option is specified, rm shall write a prompt to standard error and read a line from the standard input. If the response is not affirmative, rm shall do nothing more with the current file, and go on to any remaining files. 3. If file is not of type directory, the -f option is not specified, and either the permissions of file do not permit writing and the standard input is a terminal or the -i option is specified, rm shall write a prompt to the standard error and read a line from the standard input. If the response is not affirmative, rm shall do nothing more with the current file and go on to any remaining files. 4. If the current file is a directory, rm shall perform actions equivalent to the rmdir() function defined in the System Interfaces volume of POSIX.1\u20102017 called with a pathname of the current file used as the path argument. If the current file is not a directory, rm shall perform actions equivalent to the unlink() function defined in the System Interfaces volume of POSIX.1\u20102017 called with a pathname of the current file used as the path argument. If this fails for any reason, rm shall write a diagnostic message to standard error, do nothing more with the current file, and go on to any remaining files. The rm utility shall be able to descend to arbitrary depths in a file hierarchy, and shall not fail due to path length limitations (unless an operand specified by the user exceeds system limitations). The rm utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -f Do not prompt for confirmation. Do not write diagnostic messages or modify the exit status in the case of no file operands, or in the case of operands that do not exist. Any previous occurrences of the -i option shall be ignored. -i Prompt for confirmation as described previously. Any previous occurrences of the -f option shall be ignored. -R Remove file hierarchies. See the DESCRIPTION. -r Equivalent to -R. "
  },
  {
    "command": "ldapsearch",
    "description": " ldapsearch is a shell-accessible interface to the ldap_search_ext(3) library call. ldapsearch opens a connection to an LDAP server, binds, and performs a search using specified parameters. The filter should conform to the string representation for search filters as defined in RFC 4515. If not provided, the default filter, (objectClass=*), is used. If ldapsearch finds one or more entries, the attributes specified by attrs are returned. If * is listed, all user attributes are returned. If + is listed, all operational attributes are returned. If no attrs are listed, all user attributes are returned. If only 1.1 is listed, no attributes will be returned. The search results are displayed using an extended version of LDIF. Option -L controls the format of the output. -V[V] Print version info. If -VV is given, exit after providing version info. Otherwise proceed with the specified search -d debuglevel Set the LDAP debugging level to debuglevel. ldapsearch must be compiled with LDAP_DEBUG defined for this option to have any effect. -n Show what would be done, but don't actually perform the search. Useful for debugging in conjunction with -v. -v Run in verbose mode, with many diagnostics written to standard output. -c Continuous operation mode. Errors are reported, but ldapsearch will continue with searches. The default is to exit after reporting an error. Only useful in conjunction with -f. -u Include the User Friendly Name form of the Distinguished Name (DN) in the output. -t[t] A single -t writes retrieved non-printable values to a set of temporary files. This is useful for dealing with values containing non-character data such as jpegPhoto or audio. A second -t writes all retrieved values to files. -T path Write temporary files to directory specified by path (default: system default tmp directory). The environment variables TMPDIR, TMP, or TEMP will override the default path. -F prefix URL prefix for temporary files. Default is file://path where path is the system default tmp directory or the value specified with -T. -A Retrieve attributes only (no values). This is useful when you just want to see if an attribute is present in an entry and are not interested in the specific values. -L Search results are display in LDAP Data Interchange Format detailed in ldif(5). A single -L restricts the output to LDIFv1. A second -L disables comments. A third -L disables printing of the LDIF version. The default is to use an extended version of LDIF. -S attribute Sort the entries returned based on attribute. The default is not to sort entries returned. If attribute is a zero- length string (\"\"), the entries are sorted by the components of their Distinguished Name. See ldap_sort(3) for more details. Note that ldapsearch normally prints out entries as it receives them. The use of the -S option defeats this behavior, causing all entries to be retrieved, then sorted, then printed. -b searchbase Use searchbase as the starting point for the search instead of the default. -s {base|one|sub|children} Specify the scope of the search to be one of base, one, sub, or children to specify a base object, one-level, subtree, or children search. The default is sub. Note: children scope requires LDAPv3 subordinate feature extension. -a {never|always|search|find} Specify how aliases dereferencing is done. Should be one of never, always, search, or find to specify that aliases are never dereferenced, always dereferenced, dereferenced when searching, or dereferenced only when locating the base object for the search. The default is to never dereference aliases. -l timelimit wait at most timelimit seconds for a search to complete. A timelimit of 0 (zero) or none means no limit. A timelimit of max means the maximum integer allowable by the protocol. A server may impose a maximal timelimit which only the root user may override. -z sizelimit retrieve at most sizelimit entries for a search. A sizelimit of 0 (zero) or none means no limit. A sizelimit of max means the maximum integer allowable by the protocol. A server may impose a maximal sizelimit which only the root user may override. -f file Read a series of lines from file, performing one LDAP search for each line. In this case, the filter given on the command line is treated as a pattern where the first and only occurrence of %s is replaced with a line from file. Any other occurrence of the the % character in the pattern will be regarded as an error. Where it is desired that the search filter include a % character, the character should be encoded as \\25 (see RFC 4515). If file is a single - character, then the lines are read from standard input. ldapsearch will exit when the first non- successful search result is returned, unless -c is used. -M[M] Enable manage DSA IT control. -MM makes control critical. -x Use simple authentication instead of SASL. -D binddn Use the Distinguished Name binddn to bind to the LDAP directory. For SASL binds, the server is expected to ignore this value. -W Prompt for simple authentication. This is used instead of specifying the password on the command line. -w passwd Use passwd as the password for simple authentication. -y passwdfile Use complete contents of passwdfile as the password for simple authentication. -H ldapuri Specify URI(s) referring to the ldap server(s); a list of URI, separated by whitespace or commas is expected; only the protocol/host/port fields are allowed. As an exception, if no host/port is specified, but a DN is, the DN is used to look up the corresponding host(s) using the DNS SRV records, according to RFC 2782. The DN must be a non-empty sequence of AVAs whose attribute type is \"dc\" (domain component), and must be escaped according to RFC 2396. -P {2|3} Specify the LDAP protocol version to use. -e [!]ext[=extparam] -E [!]ext[=extparam] Specify general extensions with -e and search extensions with -E. \u00b4!\u00b4 indicates criticality. General extensions: [!]assert=<filter> (an RFC 4515 Filter) !authzid=<authzid> (\"dn:<dn>\" or \"u:<user>\") [!]bauthzid (RFC 3829 authzid control) [!]chaining[=<resolve>[/<cont>]] [!]manageDSAit [!]noop ppolicy [!]postread[=<attrs>] (a comma-separated attribute list) [!]preread[=<attrs>] (a comma-separated attribute list) [!]relax sessiontracking[=<username>] abandon,cancel,ignore (SIGINT sends abandon/cancel, or ignores response; if critical, doesn't wait for SIGINT. not really controls) Search extensions: !dontUseCopy [!]domainScope (domain scope) [!]mv=<filter> (matched values filter) [!]pr=<size>[/prompt|noprompt] (paged results/prompt) [!]sss=[-]<attr[:OID]>[/[-]<attr[:OID]>...] (server side sorting) [!]subentries[=true|false] (subentries) [!]sync=ro[/<cookie>] (LDAP Sync refreshOnly) rp[/<cookie>][/<slimit>] (LDAP Sync refreshAndPersist) [!]vlv=<before>/<after>(/<offset>/<count>|:<value>) (virtual list view) [!]deref=derefAttr:attr[,attr[...]][;derefAttr:attr[,attr[...]]] [!]<oid>[=:<value>|::<b64value>] -o opt[=optparam] Specify any ldap.conf(5) option or one of the following: nettimeout=<timeout> (in seconds, or \"none\" or \"max\") ldif_wrap=<width> (in columns, or \"no\" for no wrapping) -O security-properties Specify SASL security properties. -I Enable SASL Interactive mode. Always prompt. Default is to prompt only as needed. -Q Enable SASL Quiet mode. Never prompt. -N Do not use reverse DNS to canonicalize SASL host name. -U authcid Specify the authentication ID for SASL bind. The form of the ID depends on the actual SASL mechanism used. -R realm Specify the realm of authentication ID for SASL bind. The form of the realm depends on the actual SASL mechanism used. -X authzid Specify the requested authorization ID for SASL bind. authzid must be one of the following formats: dn:<distinguished name> or u:<username> -Y mech Specify the SASL mechanism to be used for authentication. If it's not specified, the program will choose the best mechanism the server knows. -Z[Z] Issue StartTLS (Transport Layer Security) extended operation. If you use -ZZ, the command will require the operation to be successful. "
  },
  {
    "command": "git-clean",
    "description": " Cleans the working tree by recursively removing files that are not under version control, starting from the current directory. Normally, only files unknown to Git are removed, but if the -x option is specified, ignored files are also removed. This can, for example, be useful to remove all build products. If any optional <pathspec>... arguments are given, only those paths that match the pathspec are affected. -d Normally, when no <pathspec> is specified, git clean will not recurse into untracked directories to avoid removing too much. Specify -d to have it recurse into such directories as well. If a <pathspec> is specified, -d is irrelevant; all untracked files matching the specified paths (with exceptions for nested git directories mentioned under --force) will be removed. -f, --force If the Git configuration variable clean.requireForce is not set to false, git clean will refuse to delete files or directories unless given -f or -i. Git will refuse to modify untracked nested git repositories (directories with a .git subdirectory) unless a second -f is given. -i, --interactive Show what would be done and clean files interactively. See \u201cInteractive mode\u201d for details. -n, --dry-run Don\u2019t actually remove anything, just show what would be done. -q, --quiet Be quiet, only report errors, but not the files that are successfully removed. -e <pattern>, --exclude=<pattern> Use the given exclude pattern in addition to the standard ignore rules (see gitignore(5)). -x Don\u2019t use the standard ignore rules (see gitignore(5)), but still use the ignore rules given with -e options from the command line. This allows removing all untracked files, including build products. This can be used (possibly in conjunction with git restore or git reset) to create a pristine working directory to test a clean build. -X Remove only files ignored by Git. This may be useful to rebuild everything from scratch, but keep manually created files. "
  },
  {
    "command": "git-bugreport",
    "description": " Captures information about the user\u2019s machine, Git client, and repository state, as well as a form requesting information about the behavior the user observed, into a single text file which the user can then share, for example to the Git mailing list, in order to report an observed bug. The following information is requested from the user: \u2022 Reproduction steps \u2022 Expected behavior \u2022 Actual behavior The following information is captured automatically: \u2022 git version --build-options \u2022 uname sysname, release, version, and machine strings \u2022 Compiler-specific info string \u2022 A list of enabled hooks \u2022 $SHELL Additional information may be gathered into a separate zip archive using the --diagnose option, and can be attached alongside the bugreport document to provide additional context to readers. This tool is invoked via the typical Git setup process, which means that in some cases, it might not be able to launch - for example, if a relevant config file is unreadable. In this kind of scenario, it may be helpful to manually gather the kind of information listed above when manually asking for help. -o <path>, --output-directory <path> Place the resulting bug report file in <path> instead of the current directory. -s <format>, --suffix <format> Specify an alternate suffix for the bugreport name, to create a file named git-bugreport-<formatted suffix>. This should take the form of a strftime(3) format string; the current local time will be used. --no-diagnose, --diagnose[=<mode>] Create a zip archive of supplemental information about the user\u2019s machine, Git client, and repository state. The archive is written to the same output directory as the bug report and is named git-diagnostics-<formatted suffix>. Without mode specified, the diagnostic archive will contain the default set of statistics reported by git diagnose. An optional mode value may be specified to change which information is included in the archive. See git-diagnose(1) for the list of valid values for mode and details about their usage. "
  },
  {
    "command": "keyctl",
    "description": " This program is used to control the key management facility in various ways using a variety of subcommands. "
  },
  {
    "command": "dpkg-query",
    "description": " dpkg-query is a tool to show information about packages listed in the dpkg database. --admindir=dir Change the location of the dpkg database. The default location is /usr/local/var/lib/dpkg. --root=directory Set the root directory to directory, which sets the administrative directory to \u00abdirectory/usr/local/var/lib/dpkg\u00bb (since dpkg 1.21.0). --load-avail Also load the available file when using the --show and --list commands, which now default to only querying the status file (since dpkg 1.16.2). --no-pager Disables the use of any pager when showing information (since dpkg 1.19.2). -f, --showformat=format This option is used to specify the format of the output --show will produce (short option since dpkg 1.13.1). The format is a string that will be output for each package listed. In the format string, \u201c\\\u201d introduces escapes: \\n newline \\r carriage return \\t tab \u201c\\\u201d before any other character suppresses any special meaning of the following character, which is useful for \u201c\\\u201d and \u201c$\u201d. Package information can be included by inserting variable references to package fields using the syntax \u201c${field[;width]}\u201d. Fields are printed right-aligned unless the width is negative in which case left alignment will be used. The following fields are recognized but they are not necessarily available in the status file (only internal fields or fields stored in the binary package end up in it): Architecture Bugs Conffiles (internal) Config-Version (internal) Conflicts Breaks Depends Description Enhances Protected Essential Filename (internal, front-end related) Homepage Installed-Size MD5sum (internal, front-end related) MSDOS-Filename (internal, front-end related) Maintainer Origin Package Pre-Depends Priority Provides Recommends Replaces Revision (obsolete) Section Size (internal, front-end related) Source Status (internal) Suggests Tag (usually not in .deb but in repository Packages files) Triggers-Awaited (internal) Triggers-Pending (internal) Version The following are virtual fields, generated by dpkg-query from values from other fields (note that these do not use valid names for fields in control files): binary:Package It contains the binary package name with a possible architecture qualifier like \u201clibc6:amd64\u201d (since dpkg 1.16.2). An architecture qualifier will be present to make the package name unambiguous, for packages with a Multi-Arch field with the value same or with a foreign architecture, which is an architecture that is neither the native one nor all. binary:Synopsis It contains the package short description (since dpkg 1.19.1). binary:Summary This is an alias for binary:Synopsis (since dpkg 1.16.2). db:Status-Abbrev It contains the abbreviated package status (as three characters), such as \u201cii \u201d or \u201ciHR\u201d (since dpkg 1.16.2). See the --list command description for more details. db:Status-Want It contains the package wanted status, part of the Status field (since dpkg 1.17.11). db:Status-Status It contains the package status word, part of the Status field (since dpkg 1.17.11). db:Status-Eflag It contains the package status error flag, part of the Status field (since dpkg 1.17.11). db-fsys:Files It contains the list of the package filesystem entries separated by newlines (since dpkg 1.19.3). db-fsys:Last-Modified It contains the timestamp in seconds of the last time the package filesystem entries were modified (since dpkg 1.19.3). source:Package It contains the source package name for this binary package (since dpkg 1.16.2). source:Version It contains the source package version for this binary package (since dpkg 1.16.2) source:Upstream-Version It contains the source package upstream version for this binary package (since dpkg 1.18.16) The default format string is \u201c${binary:Package}\\t${Version}\\n\u201d. Actually, all other fields found in the status file (i.e. user defined fields) can be requested, too. They will be printed as-is, though, no conversion nor error checking is done on them. To get the name of the dpkg maintainer and the installed version, you could run: dpkg-query -f='${binary:Package} ${Version}\\t${Maintainer}\\n' \\ -W dpkg "
  },
  {
    "command": "git-blame",
    "description": " Annotates each line in the given file with information from the revision which last modified the line. Optionally, start annotating from the given revision. When specified one or more times, -L restricts annotation to the requested lines. The origin of lines is automatically followed across whole-file renames (currently there is no option to turn the rename-following off). To follow lines moved from one file to another, or to follow lines that were copied and pasted from another file, etc., see the -C and -M options. The report does not tell you anything about lines which have been deleted or replaced; you need to use a tool such as git diff or the \"pickaxe\" interface briefly mentioned in the following paragraph. Apart from supporting file annotation, Git also supports searching the development history for when a code snippet occurred in a change. This makes it possible to track when a code snippet was added to a file, moved or copied between files, and eventually deleted or replaced. It works by searching for a text string in the diff. A small example of the pickaxe interface that searches for blame_usage: $ git log --pretty=oneline -S'blame_usage' 5040f17eba15504bad66b14a645bddd9b015ebb7 blame -S <ancestry-file> ea4c7f9bf69e781dd0cd88d2bccb2bf5cc15c9a7 git-blame: Make the output -b Show blank SHA-1 for boundary commits. This can also be controlled via the blame.blankBoundary config option. --root Do not treat root commits as boundaries. This can also be controlled via the blame.showRoot config option. --show-stats Include additional statistics at the end of blame output. -L <start>,<end>, -L :<funcname> Annotate only the line range given by <start>,<end>, or by the function name regex <funcname>. May be specified multiple times. Overlapping ranges are allowed. <start> and <end> are optional. -L <start> or -L <start>, spans from <start> to end of file. -L ,<end> spans from start of file to <end>. <start> and <end> can take one of these forms: \u2022 number If <start> or <end> is a number, it specifies an absolute line number (lines count from 1). \u2022 /regex/ This form will use the first line matching the given POSIX regex. If <start> is a regex, it will search from the end of the previous -L range, if any, otherwise from the start of file. If <start> is ^/regex/, it will search from the start of file. If <end> is a regex, it will search starting at the line given by <start>. \u2022 +offset or -offset This is only valid for <end> and will specify a number of lines before or after the line given by <start>. If :<funcname> is given in place of <start> and <end>, it is a regular expression that denotes the range from the first funcname line that matches <funcname>, up to the next funcname line. :<funcname> searches from the end of the previous -L range, if any, otherwise from the start of file. ^:<funcname> searches from the start of file. The function names are determined in the same way as git diff works out patch hunk headers (see Defining a custom hunk-header in gitattributes(5)). -l Show long rev (Default: off). -t Show raw timestamp (Default: off). -S <revs-file> Use revisions from revs-file instead of calling git-rev-list(1). --reverse <rev>..<rev> Walk history forward instead of backward. Instead of showing the revision in which a line appeared, this shows the last revision in which a line has existed. This requires a range of revision like START..END where the path to blame exists in START. git blame --reverse START is taken as git blame --reverse START..HEAD for convenience. --first-parent Follow only the first parent commit upon seeing a merge commit. This option can be used to determine when a line was introduced to a particular integration branch, rather than when it was introduced to the history overall. -p, --porcelain Show in a format designed for machine consumption. --line-porcelain Show the porcelain format, but output commit information for each line, not just the first time a commit is referenced. Implies --porcelain. --incremental Show the result incrementally in a format designed for machine consumption. --encoding=<encoding> Specifies the encoding used to output author names and commit summaries. Setting it to none makes blame output unconverted data. For more information see the discussion about encoding in the git-log(1) manual page. --contents <file> Annotate using the contents from the named file, starting from <rev> if it is specified, and HEAD otherwise. You may specify - to make the command read from the standard input for the file contents. --date <format> Specifies the format used to output dates. If --date is not provided, the value of the blame.date config variable is used. If the blame.date config variable is also not set, the iso format is used. For supported values, see the discussion of the --date option at git-log(1). --[no-]progress Progress status is reported on the standard error stream by default when it is attached to a terminal. This flag enables progress reporting even if not attached to a terminal. Can\u2019t use --progress together with --porcelain or --incremental. -M[<num>] Detect moved or copied lines within a file. When a commit moves or copies a block of lines (e.g. the original file has A and then B, and the commit changes it to B and then A), the traditional blame algorithm notices only half of the movement and typically blames the lines that were moved up (i.e. B) to the parent and assigns blame to the lines that were moved down (i.e. A) to the child commit. With this option, both groups of lines are blamed on the parent by running extra passes of inspection. <num> is optional but it is the lower bound on the number of alphanumeric characters that Git must detect as moving/copying within a file for it to associate those lines with the parent commit. The default value is 20. -C[<num>] In addition to -M, detect lines moved or copied from other files that were modified in the same commit. This is useful when you reorganize your program and move code around across files. When this option is given twice, the command additionally looks for copies from other files in the commit that creates the file. When this option is given three times, the command additionally looks for copies from other files in any commit. <num> is optional but it is the lower bound on the number of alphanumeric characters that Git must detect as moving/copying between files for it to associate those lines with the parent commit. And the default value is 40. If there are more than one -C options given, the <num> argument of the last -C will take effect. --ignore-rev <rev> Ignore changes made by the revision when assigning blame, as if the change never happened. Lines that were changed or added by an ignored commit will be blamed on the previous commit that changed that line or nearby lines. This option may be specified multiple times to ignore more than one revision. If the blame.markIgnoredLines config option is set, then lines that were changed by an ignored commit and attributed to another commit will be marked with a ? in the blame output. If the blame.markUnblamableLines config option is set, then those lines touched by an ignored commit that we could not attribute to another revision are marked with a *. --ignore-revs-file <file> Ignore revisions listed in file, which must be in the same format as an fsck.skipList. This option may be repeated, and these files will be processed after any files specified with the blame.ignoreRevsFile config option. An empty file name, \"\", will clear the list of revs from previously processed files. --color-lines Color line annotations in the default format differently if they come from the same commit as the preceding line. This makes it easier to distinguish code blocks introduced by different commits. The color defaults to cyan and can be adjusted using the color.blame.repeatedLines config option. --color-by-age Color line annotations depending on the age of the line in the default format. The color.blame.highlightRecent config option controls what color is used for each range of age. -h Show help message. -c Use the same output mode as git-annotate(1) (Default: off). --score-debug Include debugging information related to the movement of lines between files (see -C) and lines moved within a file (see -M). The first number listed is the score. This is the number of alphanumeric characters detected as having been moved between or within files. This must be above a certain threshold for git blame to consider those lines of code to have been moved. -f, --show-name Show the filename in the original commit. By default the filename is shown if there is any line that came from a file with a different name, due to rename detection. -n, --show-number Show the line number in the original commit (Default: off). -s Suppress the author name and timestamp from the output. -e, --show-email Show the author email instead of author name (Default: off). This can also be controlled via the blame.showEmail config option. -w Ignore whitespace when comparing the parent\u2019s version and the child\u2019s to find where the lines came from. --abbrev=<n> Instead of using the default 7+1 hexadecimal digits as the abbreviated object name, use <m>+1 digits, where <m> is at least <n> but ensures the commit object names are unique. Note that 1 column is used for a caret to mark the boundary commit. "
  },
  {
    "command": "login",
    "description": " The login program is used to establish a new session with the system. It is normally invoked automatically by responding to the login: prompt on the user's terminal. login may be special to the shell and may not be invoked as a sub-process. When called from a shell, login should be executed as exec login which will cause the user to exit from the current shell (and thus will prevent the new logged in user to return to the session of the caller). Attempting to execute login from any shell but the login shell will produce an error message. The user is then prompted for a password, where appropriate. Echoing is disabled to prevent revealing the password. Only a small number of password failures are permitted before login exits and the communications link is severed. If password aging has been enabled for your account, you may be prompted for a new password before proceeding. You will be forced to provide your old password and the new password before continuing. Please refer to passwd(1) for more information. Your user and group ID will be set according to their values in the /etc/passwd file. The value for $HOME, $SHELL, $PATH, $LOGNAME, and $MAIL are set according to the appropriate fields in the password entry. Ulimit, umask and nice values may also be set according to entries in the GECOS field. On some installations, the environmental variable $TERM will be initialized to the terminal type on your tty line, as specified in /etc/ttytype. An initialization script for your command interpreter may also be executed. Please see the appropriate manual section for more information on this function. A subsystem login is indicated by the presence of a \"*\" as the first character of the login shell. The given home directory will be used as the root of a new file system which the user is actually logged into. The login program is NOT responsible for removing users from the utmp file. It is the responsibility of getty(8) and init(8) to clean up apparent ownership of a terminal session. If you use login from the shell prompt without exec, the user you use will continue to appear to be logged in even after you log out of the \"subsession\". -f Do not perform authentication, user is preauthenticated. Note: In that case, username is mandatory. -h Name of the remote host for this login. -p Preserve environment. -r Perform autologin protocol for rlogin. The -r, -h and -f options are only used when login is invoked by root. "
  },
  {
    "command": "git-show-index",
    "description": " Read the .idx file for a Git packfile (created with git-pack-objects(1) or git-index-pack(1)) from the standard input, and dump its contents. The output consists of one object per line, with each line containing two or three space-separated columns: \u2022 the first column is the offset in bytes of the object within the corresponding packfile \u2022 the second column is the object id of the object \u2022 if the index version is 2 or higher, the third column contains the CRC32 of the object data The objects are output in the order in which they are found in the index file, which should be (in a correctly constructed file) sorted by object id. Note that you can get more information on a packfile by calling git-verify-pack(1). However, as this command considers only the index file itself, it\u2019s both faster and more flexible. --object-format=<hash-algorithm> Specify the given object format (hash algorithm) for the index file. The valid values are sha1 and (if enabled) sha256. The default is the algorithm for the current repository (set by extensions.objectFormat), or sha1 if no value is set or outside a repository.. THIS OPTION IS EXPERIMENTAL! SHA-256 support is experimental and still in an early stage. A SHA-256 repository will in general not be able to share work with \"regular\" SHA-1 repositories. It should be assumed that, e.g., Git internal file formats in relation to SHA-256 repositories may change in backwards-incompatible ways. Only use --object-format=sha256 for testing purposes. "
  },
  {
    "command": "crontab",
    "description": " Crontab is the program used to install a crontab table file, remove or list the existing tables used to serve the cron(8) daemon. Each user can have their own crontab, and though these are files in /var/spool/, they are not intended to be edited directly. For SELinux in MLS mode, you can define more crontabs for each range. For more information, see selinux(8). In this version of Cron it is possible to use a network-mounted shared /var/spool/cron across a cluster of hosts and specify that only one of the hosts should run the crontab jobs in the particular directory at any one time. You may also use crontab from any of these hosts to edit the same shared set of crontab files, and to set and query which host should run the crontab jobs. Scheduling cron jobs with crontab can be allowed or disallowed for different users. For this purpose, use the cron.allow and cron.deny files. If the cron.allow file exists, a user must be listed in it to be allowed to use crontab. If the cron.allow file does not exist but the cron.deny file does exist, then a user must not be listed in the cron.deny file in order to use crontab. If neither of these files exist, then only the super user is allowed to use crontab. Another way to restrict the scheduling of cron jobs beyond crontab is to use PAM authentication in /etc/security/access.conf to set up users, which are allowed or disallowed to use crontab or modify system cron jobs in the /etc/cron.d/ directory. The temporary directory can be set in an environment variable. If it is not set by the user, the /tmp directory is used. When listing a crontab on a terminal the output will be colorized unless an environment variable NO_COLOR is set. On edition or deletion of the crontab, a backup of the last crontab will be saved to $XDG_CACHE_HOME/crontab/crontab.bak or $XDG_CACHE_HOME/crontab/crontab.<user>.bak if -u is used. If the XDG_CACHE_HOME environment variable is not set, $HOME/.cache will be used instead. -u Specifies the name of the user whose crontab is to be modified. If this option is not used, crontab examines \"your\" crontab, i.e., the crontab of the person executing the command. If no crontab exists for a particular user, it is created for them the first time the crontab -u command is used under their username. -T Test the crontab file syntax without installing it. Once an issue is found, the validation is interrupted, so this will not return all the existing issues at the same execution. -l Displays the current crontab on standard output. -r Removes the current crontab. -e Edits the current crontab using the editor specified by the VISUAL or EDITOR environment variables. After you exit from the editor, the modified crontab will be installed automatically. -i This option modifies the -r option to prompt the user for a 'y/Y' response before actually removing the crontab. -s Appends the current SELinux security context string as an MLS_LEVEL setting to the crontab file before editing / replacement occurs - see the documentation of MLS_LEVEL in crontab(5). -n This option is relevant only if cron(8) was started with the -c option, to enable clustering support. It is used to set the host in the cluster which should run the jobs specified in the crontab files in the /var/spool/cron directory. If a hostname is supplied, the host whose hostname returned by gethostname(2) matches the supplied hostname, will be selected to run the selected cron jobs subsequently. If there is no host in the cluster matching the supplied hostname, or you explicitly specify an empty hostname, then the selected jobs will not be run at all. If the hostname is omitted, the name of the local host returned by gethostname(2) is used. Using this option has no effect on the /etc/crontab file and the files in the /etc/cron.d directory, which are always run, and considered host-specific. For more information on clustering support, see cron(8). -c This option is only relevant if cron(8) was started with the -c option, to enable clustering support. It is used to query which host in the cluster is currently set to run the jobs specified in the crontab files in the directory /var/spool/cron , as set using the -n option. -V Print version and exit. "
  },
  {
    "command": "install",
    "description": " This install program copies files (often just compiled) into destination locations you choose. If you want to download and install a ready-to-use package on a GNU/Linux system, you should instead be using a package manager like yum(1) or apt-get(1). In the first three forms, copy SOURCE to DEST or multiple SOURCE(s) to the existing DIRECTORY, while setting permission modes and owner/group. In the 4th form, create all components of the given DIRECTORY(ies). Mandatory arguments to long options are mandatory for short options too. --backup[=CONTROL] make a backup of each existing destination file -b like --backup but does not accept an argument -c (ignored) -C, --compare compare content of source and destination files, and if no change to content, ownership, and permissions, do not modify the destination at all -d, --directory treat all arguments as directory names; create all components of the specified directories -D create all leading components of DEST except the last, or all components of --target-directory, then copy SOURCE to DEST --debug explain how a file is copied. Implies -v -g, --group=GROUP set group ownership, instead of process' current group -m, --mode=MODE set permission mode (as in chmod), instead of rwxr-xr-x -o, --owner=OWNER set ownership (super-user only) -p, --preserve-timestamps apply access/modification times of SOURCE files to corresponding destination files -s, --strip strip symbol tables --strip-program=PROGRAM program used to strip binaries -S, --suffix=SUFFIX override the usual backup suffix -t, --target-directory=DIRECTORY copy all SOURCE arguments into DIRECTORY -T, --no-target-directory treat DEST as a normal file -v, --verbose print the name of each created file or directory --preserve-context preserve SELinux security context -Z set SELinux security context of destination file and each created directory to default type --context[=CTX] like -Z, or if CTX is specified then set the SELinux or SMACK security context to CTX --help display this help and exit --version output version information and exit The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX. The version control method may be selected via the --backup option or through the VERSION_CONTROL environment variable. Here are the values: none, off never make backups (even if --backup is given) numbered, t make numbered backups existing, nil numbered if numbered backups exist, simple otherwise simple, never always make simple backups "
  },
  {
    "command": "colrm",
    "description": " colrm removes selected columns from a file. Input is taken from standard input. Output is sent to standard output. If called with one parameter the columns of each line will be removed starting with the specified first column. If called with two parameters the columns from the first column to the last column will be removed. Column numbering starts with column 1. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "resolvectl",
    "description": " resolvectl may be used to resolve domain names, IPv4 and IPv6 addresses, DNS resource records and services with the systemd-resolved.service(8) resolver service. By default, the specified list of parameters will be resolved as hostnames, retrieving their IPv4 and IPv6 addresses. If the parameters specified are formatted as IPv4 or IPv6 addresses the reverse operation is done, and a hostname is retrieved for the specified addresses. The program's output contains information about the protocol used for the look-up and on which network interface the data was discovered. It also contains information on whether the information could be authenticated. All data for which local DNSSEC validation succeeds is considered authenticated. Moreover all data originating from local, trusted sources is also reported authenticated, including resolution of the local host name, the \"localhost\" hostname or all data from /etc/hosts. -4, -6 By default, when resolving a hostname, both IPv4 and IPv6 addresses are acquired. By specifying -4 only IPv4 addresses are requested, by specifying -6 only IPv6 addresses are requested. -i INTERFACE, --interface=INTERFACE Specifies the network interface to execute the query on. This may either be specified as numeric interface index or as network interface string (e.g. \"en0\"). Note that this option has no effect if system-wide DNS configuration (as configured in /etc/resolv.conf or /etc/systemd/resolved.conf) in place of per-link configuration is used. -p PROTOCOL, --protocol=PROTOCOL Specifies the network protocol for the query. May be one of \"dns\" (i.e. classic unicast DNS), \"llmnr\" (Link-Local Multicast Name Resolution[5]), \"llmnr-ipv4\", \"llmnr-ipv6\" (LLMNR via the indicated underlying IP protocols), \"mdns\" (Multicast DNS[6]), \"mdns-ipv4\", \"mdns-ipv6\" (MDNS via the indicated underlying IP protocols). By default the lookup is done via all protocols suitable for the lookup. If used, limits the set of protocols that may be used. Use this option multiple times to enable resolving via multiple protocols at the same time. The setting \"llmnr\" is identical to specifying this switch once with \"llmnr-ipv4\" and once via \"llmnr-ipv6\". Note that this option does not force the service to resolve the operation with the specified protocol, as that might require a suitable network interface and configuration. The special value \"help\" may be used to list known values. -t TYPE, --type=TYPE, -c CLASS, --class=CLASS When used in conjunction with the query command, specifies the DNS resource record type (e.g. A, AAAA, MX, ...) and class (e.g. IN, ANY, ...) to look up. If these options are used a DNS resource record set matching the specified class and type is requested. The class defaults to IN if only a type is specified. The special value \"help\" may be used to list known values. Without these options resolvectl query provides high-level domain name to address and address to domain name resolution. With these options it provides low-level DNS resource record resolution. The search domain logic is automatically turned off when these options are used, i.e. specified domain names need to be fully qualified domain names. Moreover, IDNA internal domain name translation is turned off as well, i.e. international domain names should be specified in \"xn--...\" notation, unless look-up in MulticastDNS/LLMNR is desired, in which case UTF-8 characters should be used. --service-address=BOOL Takes a boolean parameter. If true (the default), when doing a service lookup with --service the hostnames contained in the SRV resource records are resolved as well. --service-txt=BOOL Takes a boolean parameter. If true (the default), when doing a DNS-SD service lookup with --service the TXT service metadata record is resolved as well. --cname=BOOL Takes a boolean parameter. If true (the default), DNS CNAME or DNAME redirections are followed. Otherwise, if a CNAME or DNAME record is encountered while resolving, an error is returned. --validate=BOOL Takes a boolean parameter; used in conjunction with query. If true (the default), DNSSEC validation is applied as usual \u2014 under the condition that it is enabled for the network and for systemd-resolved.service as a whole. If false, DNSSEC validation is disabled for the specific query, regardless of whether it is enabled for the network or in the service. Note that setting this option to true does not force DNSSEC validation on systems/networks where DNSSEC is turned off. This option is only suitable to turn off such validation where otherwise enabled, not enable validation where otherwise disabled. --synthesize=BOOL Takes a boolean parameter; used in conjunction with query. If true (the default), select domains are resolved on the local system, among them \"localhost\", \"_gateway\", \"_outbound\", \"_localdnsstub\" and \"_localdnsproxy\" or entries from /etc/hosts. If false these domains are not resolved locally, and either fail (in case of \"localhost\", \"_gateway\" or \"_outbound\" and suchlike) or go to the network via regular DNS/mDNS/LLMNR lookups (in case of /etc/hosts entries). --cache=BOOL Takes a boolean parameter; used in conjunction with query. If true (the default), lookups use the local DNS resource record cache. If false, lookups are routed to the network instead, regardless if already available in the local cache. --zone=BOOL Takes a boolean parameter; used in conjunction with query. If true (the default), lookups are answered from locally registered LLMNR or mDNS resource records, if defined. If false, locally registered LLMNR/mDNS records are not considered for the lookup request. --trust-anchor=BOOL Takes a boolean parameter; used in conjunction with query. If true (the default), lookups for DS and DNSKEY are answered from the local DNSSEC trust anchors if possible. If false, the local trust store is not considered for the lookup request. --network=BOOL Takes a boolean parameter; used in conjunction with query. If true (the default), lookups are answered via DNS, LLMNR or mDNS network requests if they cannot be synthesized locally, or be answered from the local cache, zone or trust anchors (see above). If false, the request is not answered from the network and will thus fail if none of the indicated sources can answer them. --search=BOOL Takes a boolean parameter. If true (the default), any specified single-label hostnames will be searched in the domains configured in the search domain list, if it is non-empty. Otherwise, the search domain logic is disabled. Note that this option has no effect if --type= is used (see above), in which case the search domain logic is unconditionally turned off. --raw[=payload|packet] Dump the answer as binary data. If there is no argument or if the argument is \"payload\", the payload of the packet is exported. If the argument is \"packet\", the whole packet is dumped in wire format, prefixed by length specified as a little-endian 64-bit number. This format allows multiple packets to be dumped and unambiguously parsed. --legend=BOOL Takes a boolean parameter. If true (the default), column headers and meta information about the query response are shown. Otherwise, this output is suppressed. --stale-data=BOOL Takes a boolean parameter; used in conjunction with query. If true (the default), lookups are answered with stale data (expired resource records) if possible. If false, the stale data is not considered for the lookup request. --json=MODE Shows output formatted as JSON. Expects one of \"short\" (for the shortest possible output without any redundant whitespace or line breaks), \"pretty\" (for a pretty version of the same, with indentation and line breaks) or \"off\" (to turn off JSON output, the default). -j Short for --json=auto --no-pager Do not pipe output into a pager. -h, --help Print a short help text and exit. --version Print a short version string and exit. "
  },
  {
    "command": "ssh-keygen",
    "description": " ssh-keygen generates, manages and converts authentication keys for ssh(1). ssh-keygen can create keys for use by SSH protocol version 2. The type of key to be generated is specified with the -t option. If invoked without any arguments, ssh-keygen will generate an RSA key. ssh-keygen is also used to generate groups for use in Diffie- Hellman group exchange (DH-GEX). See the MODULI GENERATION section for details. Finally, ssh-keygen can be used to generate and update Key Revocation Lists, and to test whether given keys have been revoked by one. See the KEY REVOCATION LISTS section for details. Normally each user wishing to use SSH with public key authentication runs this once to create the authentication key in ~/.ssh/id_dsa, ~/.ssh/id_ecdsa, ~/.ssh/id_ecdsa_sk, ~/.ssh/id_ed25519, ~/.ssh/id_ed25519_sk or ~/.ssh/id_rsa. Additionally, the system administrator may use this to generate host keys, as seen in /etc/rc. Normally this program generates the key and asks for a file in which to store the private key. The public key is stored in a file with the same name but \u201c.pub\u201d appended. The program also asks for a passphrase. The passphrase may be empty to indicate no passphrase (host keys must have an empty passphrase), or it may be a string of arbitrary length. A passphrase is similar to a password, except it can be a phrase with a series of words, punctuation, numbers, whitespace, or any string of characters you want. Good passphrases are 10-30 characters long, are not simple sentences or otherwise easily guessable (English prose has only 1-2 bits of entropy per character, and provides very bad passphrases), and contain a mix of upper and lowercase letters, numbers, and non- alphanumeric characters. The passphrase can be changed later by using the -p option. There is no way to recover a lost passphrase. If the passphrase is lost or forgotten, a new key must be generated and the corresponding public key copied to other machines. ssh-keygen will by default write keys in an OpenSSH-specific format. This format is preferred as it offers better protection for keys at rest as well as allowing storage of key comments within the private key file itself. The key comment may be useful to help identify the key. The comment is initialized to \u201cuser@host\u201d when the key is created, but can be changed using the -c option. It is still possible for ssh-keygen to write the previously-used PEM format private keys using the -m flag. This may be used when generating new keys, and existing new-format keys may be converted using this option in conjunction with the -p (change passphrase) flag. After a key is generated, ssh-keygen will ask where the keys should be placed to be activated. The options are as follows: -A Generate host keys of all default key types (rsa, ecdsa, and ed25519) if they do not already exist. The host keys are generated with the default key file path, an empty passphrase, default bits for the key type, and default comment. If -f has also been specified, its argument is used as a prefix to the default path for the resulting host key files. This is used by /etc/rc to generate new host keys. -a rounds When saving a private key, this option specifies the number of KDF (key derivation function, currently bcrypt_pbkdf(3)) rounds used. Higher numbers result in slower passphrase verification and increased resistance to brute-force password cracking (should the keys be stolen). The default is 16 rounds. -B Show the bubblebabble digest of specified private or public key file. -b bits Specifies the number of bits in the key to create. For RSA keys, the minimum size is 1024 bits and the default is 3072 bits. Generally, 3072 bits is considered sufficient. DSA keys must be exactly 1024 bits as specified by FIPS 186-2. For ECDSA keys, the -b flag determines the key length by selecting from one of three elliptic curve sizes: 256, 384 or 521 bits. Attempting to use bit lengths other than these three values for ECDSA keys will fail. ECDSA-SK, Ed25519 and Ed25519-SK keys have a fixed length and the -b flag will be ignored. -C comment Provides a new comment. -c Requests changing the comment in the private and public key files. The program will prompt for the file containing the private keys, for the passphrase if the key has one, and for the new comment. -D pkcs11 Download the public keys provided by the PKCS#11 shared library pkcs11. When used in combination with -s, this option indicates that a CA key resides in a PKCS#11 token (see the CERTIFICATES section for details). -E fingerprint_hash Specifies the hash algorithm used when displaying key fingerprints. Valid options are: \u201cmd5\u201d and \u201csha256\u201d. The default is \u201csha256\u201d. -e This option will read a private or public OpenSSH key file and print to stdout a public key in one of the formats specified by the -m option. The default export format is \u201cRFC4716\u201d. This option allows exporting OpenSSH keys for use by other programs, including several commercial SSH implementations. -F hostname | [hostname]:port Search for the specified hostname (with optional port number) in a known_hosts file, listing any occurrences found. This option is useful to find hashed host names or addresses and may also be used in conjunction with the -H option to print found keys in a hashed format. -f filename Specifies the filename of the key file. -g Use generic DNS format when printing fingerprint resource records using the -r command. -H Hash a known_hosts file. This replaces all hostnames and addresses with hashed representations within the specified file; the original content is moved to a file with a .old suffix. These hashes may be used normally by ssh and sshd, but they do not reveal identifying information should the file's contents be disclosed. This option will not modify existing hashed hostnames and is therefore safe to use on files that mix hashed and non-hashed names. -h When signing a key, create a host certificate instead of a user certificate. See the CERTIFICATES section for details. -I certificate_identity Specify the key identity when signing a public key. See the CERTIFICATES section for details. -i This option will read an unencrypted private (or public) key file in the format specified by the -m option and print an OpenSSH compatible private (or public) key to stdout. This option allows importing keys from other software, including several commercial SSH implementations. The default import format is \u201cRFC4716\u201d. -K Download resident keys from a FIDO authenticator. Public and private key files will be written to the current directory for each downloaded key. If multiple FIDO authenticators are attached, keys will be downloaded from the first touched authenticator. See the FIDO AUTHENTICATOR section for more information. -k Generate a KRL file. In this mode, ssh-keygen will generate a KRL file at the location specified via the -f flag that revokes every key or certificate presented on the command line. Keys/certificates to be revoked may be specified by public key file or using the format described in the KEY REVOCATION LISTS section. -L Prints the contents of one or more certificates. -l Show fingerprint of specified public key file. For RSA and DSA keys ssh-keygen tries to find the matching public key file and prints its fingerprint. If combined with -v, a visual ASCII art representation of the key is supplied with the fingerprint. -M generate Generate candidate Diffie-Hellman Group Exchange (DH-GEX) parameters for eventual use by the \u2018diffie-hellman-group-exchange-*\u2019 key exchange methods. The numbers generated by this operation must be further screened before use. See the MODULI GENERATION section for more information. -M screen Screen candidate parameters for Diffie-Hellman Group Exchange. This will accept a list of candidate numbers and test that they are safe (Sophie Germain) primes with acceptable group generators. The results of this operation may be added to the /etc/moduli file. See the MODULI GENERATION section for more information. -m key_format Specify a key format for key generation, the -i (import), -e (export) conversion options, and the -p change passphrase operation. The latter may be used to convert between OpenSSH private key and PEM private key formats. The supported key formats are: \u201cRFC4716\u201d (RFC 4716/SSH2 public or private key), \u201cPKCS8\u201d (PKCS8 public or private key) or \u201cPEM\u201d (PEM public key). By default OpenSSH will write newly-generated private keys in its own format, but when converting public keys for export the default format is \u201cRFC4716\u201d. Setting a format of \u201cPEM\u201d when generating or updating a supported private key type will cause the key to be stored in the legacy PEM private key format. -N new_passphrase Provides the new passphrase. -n principals Specify one or more principals (user or host names) to be included in a certificate when signing a key. Multiple principals may be specified, separated by commas. See the CERTIFICATES section for details. -O option Specify a key/value option. These are specific to the operation that ssh-keygen has been requested to perform. When signing certificates, one of the options listed in the CERTIFICATES section may be specified here. When performing moduli generation or screening, one of the options listed in the MODULI GENERATION section may be specified. When generating FIDO authenticator-backed keys, the options listed in the FIDO AUTHENTICATOR section may be specified. When performing signature-related options using the -Y flag, the following options are accepted: hashalg=algorithm Selects the hash algorithm to use for hashing the message to be signed. Valid algorithms are \u201csha256\u201d and \u201csha512.\u201d The default is \u201csha512.\u201d print-pubkey Print the full public key to standard output after signature verification. verify-time=timestamp Specifies a time to use when validating signatures instead of the current time. The time may be specified as a date or time in the YYYYMMDD[Z] or in YYYYMMDDHHMM[SS][Z] formats. Dates and times will be interpreted in the current system time zone unless suffixed with a Z character, which causes them to be interpreted in the UTC time zone. When generating SSHFP DNS records from public keys using the -r flag, the following options are accepted: hashalg=algorithm Selects a hash algorithm to use when printing SSHFP records using the -D flag. Valid algorithms are \u201csha1\u201d and \u201csha256\u201d. The default is to print both. The -O option may be specified multiple times. -P passphrase Provides the (old) passphrase. -p Requests changing the passphrase of a private key file instead of creating a new private key. The program will prompt for the file containing the private key, for the old passphrase, and twice for the new passphrase. -Q Test whether keys have been revoked in a KRL. If the -l option is also specified then the contents of the KRL will be printed. -q Silence ssh-keygen. -R hostname | [hostname]:port Removes all keys belonging to the specified hostname (with optional port number) from a known_hosts file. This option is useful to delete hashed hosts (see the -H option above). -r hostname Print the SSHFP fingerprint resource record named hostname for the specified public key file. -s ca_key Certify (sign) a public key using the specified CA key. See the CERTIFICATES section for details. When generating a KRL, -s specifies a path to a CA public key file used to revoke certificates directly by key ID or serial number. See the KEY REVOCATION LISTS section for details. -t dsa | ecdsa | ecdsa-sk | ed25519 | ed25519-sk | rsa Specifies the type of key to create. The possible values are \u201cdsa\u201d, \u201cecdsa\u201d, \u201cecdsa-sk\u201d, \u201ced25519\u201d, \u201ced25519-sk\u201d, or \u201crsa\u201d. This flag may also be used to specify the desired signature type when signing certificates using an RSA CA key. The available RSA signature variants are \u201cssh-rsa\u201d (SHA1 signatures, not recommended), \u201crsa-sha2-256\u201d, and \u201crsa-sha2-512\u201d (the default). -U When used in combination with -s or -Y sign, this option indicates that a CA key resides in a ssh-agent(1). See the CERTIFICATES section for more information. -u Update a KRL. When specified with -k, keys listed via the command line are added to the existing KRL rather than a new KRL being created. -V validity_interval Specify a validity interval when signing a certificate. A validity interval may consist of a single time, indicating that the certificate is valid beginning now and expiring at that time, or may consist of two times separated by a colon to indicate an explicit time interval. The start time may be specified as: \u2022 The string \u201calways\u201d to indicate the certificate has no specified start time. \u2022 A date or time in the system time zone formatted as YYYYMMDD or YYYYMMDDHHMM[SS]. \u2022 A date or time in the UTC time zone as YYYYMMDDZ or YYYYMMDDHHMM[SS]Z. \u2022 A relative time before the current system time consisting of a minus sign followed by an interval in the format described in the TIME FORMATS section of sshd_config(5). \u2022 A raw seconds since epoch (Jan 1 1970 00:00:00 UTC) as a hexadecimal number beginning with \u201c0x\u201d. The end time may be specified similarly to the start time: \u2022 The string \u201cforever\u201d to indicate the certificate has no specified end time. \u2022 A date or time in the system time zone formatted as YYYYMMDD or YYYYMMDDHHMM[SS]. \u2022 A date or time in the UTC time zone as YYYYMMDDZ or YYYYMMDDHHMM[SS]Z. \u2022 A relative time after the current system time consisting of a plus sign followed by an interval in the format described in the TIME FORMATS section of sshd_config(5). \u2022 A raw seconds since epoch (Jan 1 1970 00:00:00 UTC) as a hexadecimal number beginning with \u201c0x\u201d. For example: +52w1d Valid from now to 52 weeks and one day from now. -4w:+4w Valid from four weeks ago to four weeks from now. 20100101123000:20110101123000 Valid from 12:30 PM, January 1st, 2010 to 12:30 PM, January 1st, 2011. 20100101123000Z:20110101123000Z Similar, but interpreted in the UTC time zone rather than the system time zone. -1d:20110101 Valid from yesterday to midnight, January 1st, 2011. 0x1:0x2000000000 Valid from roughly early 1970 to May 2033. -1m:forever Valid from one minute ago and never expiring. -v Verbose mode. Causes ssh-keygen to print debugging messages about its progress. This is helpful for debugging moduli generation. Multiple -v options increase the verbosity. The maximum is 3. -w provider Specifies a path to a library that will be used when creating FIDO authenticator-hosted keys, overriding the default of using the internal USB HID support. -Y find-principals Find the principal(s) associated with the public key of a signature, provided using the -s flag in an authorized signers file provided using the -f flag. The format of the allowed signers file is documented in the ALLOWED SIGNERS section below. If one or more matching principals are found, they are returned on standard output. -Y match-principals Find principal matching the principal name provided using the -I flag in the authorized signers file specified using the -f flag. If one or more matching principals are found, they are returned on standard output. -Y check-novalidate Checks that a signature generated using ssh-keygen -Y sign has a valid structure. This does not validate if a signature comes from an authorized signer. When testing a signature, ssh-keygen accepts a message on standard input and a signature namespace using -n. A file containing the corresponding signature must also be supplied using the -s flag. Successful testing of the signature is signalled by ssh-keygen returning a zero exit status. -Y sign Cryptographically sign a file or some data using a SSH key. When signing, ssh-keygen accepts zero or more files to sign on the command-line - if no files are specified then ssh-keygen will sign data presented on standard input. Signatures are written to the path of the input file with \u201c.sig\u201d appended, or to standard output if the message to be signed was read from standard input. The key used for signing is specified using the -f option and may refer to either a private key, or a public key with the private half available via ssh-agent(1). An additional signature namespace, used to prevent signature confusion across different domains of use (e.g. file signing vs email signing) must be provided via the -n flag. Namespaces are arbitrary strings, and may include: \u201cfile\u201d for file signing, \u201cemail\u201d for email signing. For custom uses, it is recommended to use names following a NAMESPACE@YOUR.DOMAIN pattern to generate unambiguous namespaces. -Y verify Request to verify a signature generated using ssh-keygen -Y sign as described above. When verifying a signature, ssh-keygen accepts a message on standard input and a signature namespace using -n. A file containing the corresponding signature must also be supplied using the -s flag, along with the identity of the signer using -I and a list of allowed signers via the -f flag. The format of the allowed signers file is documented in the ALLOWED SIGNERS section below. A file containing revoked keys can be passed using the -r flag. The revocation file may be a KRL or a one-per-line list of public keys. Successful verification by an authorized signer is signalled by ssh-keygen returning a zero exit status. -y This option will read a private OpenSSH format file and print an OpenSSH public key to stdout. -Z cipher Specifies the cipher to use for encryption when writing an OpenSSH-format private key file. The list of available ciphers may be obtained using \"ssh -Q cipher\". The default is \u201caes256-ctr\u201d. -z serial_number Specifies a serial number to be embedded in the certificate to distinguish this certificate from others from the same CA. If the serial_number is prefixed with a \u2018+\u2019 character, then the serial number will be incremented for each certificate signed on a single command-line. The default serial number is zero. When generating a KRL, the -z flag is used to specify a KRL version number. "
  },
  {
    "command": "pidstat",
    "description": " The pidstat command is used for monitoring individual tasks currently being managed by the Linux kernel. It writes to standard output activities for every task selected with option -p or for every task managed by the Linux kernel if option -p ALL has been used. Not selecting any tasks is equivalent to specifying -p ALL but only active tasks (tasks with non-zero statistics values) will appear in the report. The pidstat command can also be used for monitoring the child processes of selected tasks. Read about option -T below. The interval parameter specifies the amount of time in seconds between each report. A value of 0 (or no parameters at all) indicates that tasks statistics are to be reported for the time since system startup (boot). The count parameter can be specified in conjunction with the interval parameter if this one is not set to zero. The value of count determines the number of reports generated at interval seconds apart. If the interval parameter is specified without the count parameter, the pidstat command generates reports continuously. You can select information about specific task activities using flags. Not specifying any flags selects only CPU activity. -C comm Display only tasks whose command name includes the string comm. This string can be a regular expression. -d Report I/O statistics (kernels 2.6.20 and later only). The following values may be displayed: UID The real user identification number of the task being monitored. USER The name of the real user owning the task being monitored. PID The identification number of the task being monitored. kB_rd/s Number of kilobytes the task has caused to be read from disk per second. kB_wr/s Number of kilobytes the task has caused, or shall cause to be written to disk per second. kB_ccwr/s Number of kilobytes whose writing to disk has been cancelled by the task. This may occur when the task truncates some dirty pagecache. In this case, some IO which another task has been accounted for will not be happening. iodelay Block I/O delay of the task being monitored, measured in clock ticks. This metric includes the delays spent waiting for sync block I/O completion and for swapin block I/O completion. Command The command name of the task. --dec={ 0 | 1 | 2 } Specify the number of decimal places to use (0 to 2, default value is 2). -e program args Execute program with given arguments args and monitor it with pidstat. pidstat stops when program terminates. -G process_name Display only processes whose command name includes the string process_name. This string can be a regular expression. If option -t is used together with option -G then the threads belonging to that process are also displayed (even if their command name doesn't include the string process_name). -H Display timestamp in seconds since the epoch. -h Display all activities horizontally on a single line, with no average statistics at the end of the report. This is intended to make it easier to be parsed by other programs. --human Print sizes in human readable format (e.g. 1.0k, 1.2M, etc.) The units displayed with this option supersede any other default units (e.g. kilobytes, sectors...) associated with the metrics. -I In an SMP environment, indicate that tasks CPU usage (as displayed by option -u) should be divided by the total number of processors. -l Display the process command name and all its arguments. -p { pid[,...] | SELF | ALL } Select tasks (processes) for which statistics are to be reported. pid is the process identification number. The SELF keyword indicates that statistics are to be reported for the pidstat process itself, whereas the ALL keyword indicates that statistics are to be reported for all the tasks managed by the system. -R Report realtime priority and scheduling policy information. The following values may be displayed: UID The real user identification number of the task being monitored. USER The name of the real user owning the task being monitored. PID The identification number of the task being monitored. prio The realtime priority of the task being monitored. policy The scheduling policy of the task being monitored. Command The command name of the task. -r Report page faults and memory utilization. When reporting statistics for individual tasks, the following values may be displayed: UID The real user identification number of the task being monitored. USER The name of the real user owning the task being monitored. PID The identification number of the task being monitored. minflt/s Total number of minor faults the task has made per second, those which have not required loading a memory page from disk. majflt/s Total number of major faults the task has made per second, those which have required loading a memory page from disk. VSZ Virtual Size: The virtual memory usage of entire task in kilobytes. RSS Resident Set Size: The non-swapped physical memory used by the task in kilobytes. %MEM The tasks's currently used share of available physical memory. Command The command name of the task. When reporting global statistics for tasks and all their children, the following values may be displayed: UID The real user identification number of the task which is being monitored together with its children. USER The name of the real user owning the task which is being monitored together with its children. PID The identification number of the task which is being monitored together with its children. minflt-nr Total number of minor faults made by the task and all its children, and collected during the interval of time. majflt-nr Total number of major faults made by the task and all its children, and collected during the interval of time. Command The command name of the task which is being monitored together with its children. -s Report stack utilization. The following values may be displayed: UID The real user identification number of the task being monitored. USER The name of the real user owning the task being monitored. PID The identification number of the task being monitored. StkSize The amount of memory in kilobytes reserved for the task as stack, but not necessarily used. StkRef The amount of memory in kilobytes used as stack, referenced by the task. Command The command name of the task. -T { TASK | CHILD | ALL } This option specifies what has to be monitored by the pidstat command. The TASK keyword indicates that statistics are to be reported for individual tasks (this is the default option) whereas the CHILD keyword indicates that statistics are to be globally reported for the selected tasks and all their children. The ALL keyword indicates that statistics are to be reported for individual tasks and globally for the selected tasks and their children. Note: Global statistics for tasks and all their children are not available for all options of pidstat. Also these statistics are not necessarily relevant to current time interval: The statistics of a child process are collected only when it finishes or it is killed. -t Also display statistics for threads associated with selected tasks. This option adds the following values to the reports: TGID The identification number of the thread group leader. TID The identification number of the thread being monitored. -U [ username ] Display the real user name of the tasks being monitored instead of the UID. If username is specified, then only tasks belonging to the specified user are displayed. -u Report CPU utilization. When reporting statistics for individual tasks, the following values may be displayed: UID The real user identification number of the task being monitored. USER The name of the real user owning the task being monitored. PID The identification number of the task being monitored. %usr Percentage of CPU used by the task while executing at the user level (application), with or without nice priority. Note that this field does NOT include time spent running a virtual processor. %system Percentage of CPU used by the task while executing at the system level (kernel). %guest Percentage of CPU spent by the task in virtual machine (running a virtual processor). %wait Percentage of CPU spent by the task while waiting to run. %CPU Total percentage of CPU time used by the task. In an SMP environment, the task's CPU usage will be divided by the total number of CPU's if option -I has been entered on the command line. CPU Processor number to which the task is attached. Command The command name of the task. When reporting global statistics for tasks and all their children, the following values may be displayed: UID The real user identification number of the task which is being monitored together with its children. USER The name of the real user owning the task which is being monitored together with its children. PID The identification number of the task which is being monitored together with its children. usr-ms Total number of milliseconds spent by the task and all its children while executing at the user level (application), with or without nice priority, and collected during the interval of time. Note that this field does NOT include time spent running a virtual processor. system-ms Total number of milliseconds spent by the task and all its children while executing at the system level (kernel), and collected during the interval of time. guest-ms Total number of milliseconds spent by the task and all its children in virtual machine (running a virtual processor). Command The command name of the task which is being monitored together with its children. -V Print version number then exit. -v Report values of some kernel tables. The following values may be displayed: UID The real user identification number of the task being monitored. USER The name of the real user owning the task being monitored. PID The identification number of the task being monitored. threads Number of threads associated with current task. fd-nr Number of file descriptors associated with current task. Command The command name of the task. -w Report task switching activity (kernels 2.6.23 and later only). The following values may be displayed: UID The real user identification number of the task being monitored. USER The name of the real user owning the task being monitored. PID The identification number of the task being monitored. cswch/s Total number of voluntary context switches the task made per second. A voluntary context switch occurs when a task blocks because it requires a resource that is unavailable. nvcswch/s Total number of non voluntary context switches the task made per second. An involuntary context switch takes place when a task executes for the duration of its time slice and then is forced to relinquish the processor. Command The command name of the task. "
  },
  {
    "command": "git-stash",
    "description": " Use git stash when you want to record the current state of the working directory and the index, but want to go back to a clean working directory. The command saves your local modifications away and reverts the working directory to match the HEAD commit. The modifications stashed away by this command can be listed with git stash list, inspected with git stash show, and restored (potentially on top of a different commit) with git stash apply. Calling git stash without any arguments is equivalent to git stash push. A stash is by default listed as \"WIP on branchname ...\", but you can give a more descriptive message on the command line when you create one. The latest stash you created is stored in refs/stash; older stashes are found in the reflog of this reference and can be named using the usual reflog syntax (e.g. stash@{0} is the most recently created stash, stash@{1} is the one before it, stash@{2.hours.ago} is also possible). Stashes may also be referenced by specifying just the stash index (e.g. the integer n is equivalent to stash@{n}). -a, --all This option is only valid for push and save commands. All ignored and untracked files are also stashed and then cleaned up with git clean. -u, --include-untracked, --no-include-untracked When used with the push and save commands, all untracked files are also stashed and then cleaned up with git clean. When used with the show command, show the untracked files in the stash entry as part of the diff. --only-untracked This option is only valid for the show command. Show only the untracked files in the stash entry as part of the diff. --index This option is only valid for pop and apply commands. Tries to reinstate not only the working tree\u2019s changes, but also the index\u2019s ones. However, this can fail, when you have conflicts (which are stored in the index, where you therefore can no longer apply the changes as they were originally). -k, --keep-index, --no-keep-index This option is only valid for push and save commands. All changes already added to the index are left intact. -p, --patch This option is only valid for push and save commands. Interactively select hunks from the diff between HEAD and the working tree to be stashed. The stash entry is constructed such that its index state is the same as the index state of your repository, and its worktree contains only the changes you selected interactively. The selected changes are then rolled back from your worktree. See the \u201cInteractive Mode\u201d section of git-add(1) to learn how to operate the --patch mode. The --patch option implies --keep-index. You can use --no-keep-index to override this. -S, --staged This option is only valid for push and save commands. Stash only the changes that are currently staged. This is similar to basic git commit except the state is committed to the stash instead of current branch. The --patch option has priority over this one. --pathspec-from-file=<file> This option is only valid for push command. Pathspec is passed in <file> instead of commandline args. If <file> is exactly - then standard input is used. Pathspec elements are separated by LF or CR/LF. Pathspec elements can be quoted as explained for the configuration variable core.quotePath (see git-config(1)). See also --pathspec-file-nul and global --literal-pathspecs. --pathspec-file-nul This option is only valid for push command. Only meaningful with --pathspec-from-file. Pathspec elements are separated with NUL character and all other characters are taken literally (including newlines and quotes). -q, --quiet This option is only valid for apply, drop, pop, push, save, store commands. Quiet, suppress feedback messages. -- This option is only valid for push command. Separates pathspec from options for disambiguation purposes. <pathspec>... This option is only valid for push command. The new stash entry records the modified states only for the files that match the pathspec. The index entries and working tree files are then rolled back to the state in HEAD only for these files, too, leaving files that do not match the pathspec intact. For more details, see the pathspec entry in gitglossary(7). <stash> This option is only valid for apply, branch, drop, pop, show commands. A reference of the form stash@{<revision>}. When no <stash> is given, the latest stash is assumed (that is, stash@{0}). "
  },
  {
    "command": "git-bisect",
    "description": " The command takes various subcommands, and different options depending on the subcommand: git bisect start [--term-{new,bad}=<term> --term-{old,good}=<term>] [--no-checkout] [--first-parent] [<bad> [<good>...]] [--] [<paths>...] git bisect (bad|new|<term-new>) [<rev>] git bisect (good|old|<term-old>) [<rev>...] git bisect terms [--term-good | --term-bad] git bisect skip [(<rev>|<range>)...] git bisect reset [<commit>] git bisect (visualize|view) git bisect replay <logfile> git bisect log git bisect run <cmd>... git bisect help This command uses a binary search algorithm to find which commit in your project\u2019s history introduced a bug. You use it by first telling it a \"bad\" commit that is known to contain the bug, and a \"good\" commit that is known to be before the bug was introduced. Then git bisect picks a commit between those two endpoints and asks you whether the selected commit is \"good\" or \"bad\". It continues narrowing down the range until it finds the exact commit that introduced the change. In fact, git bisect can be used to find the commit that changed any property of your project; e.g., the commit that fixed a bug, or the commit that caused a benchmark\u2019s performance to improve. To support this more general usage, the terms \"old\" and \"new\" can be used in place of \"good\" and \"bad\", or you can choose your own terms. See section \"Alternate terms\" below for more information. Basic bisect commands: start, bad, good As an example, suppose you are trying to find the commit that broke a feature that was known to work in version v2.6.13-rc2 of your project. You start a bisect session as follows: $ git bisect start $ git bisect bad # Current version is bad $ git bisect good v2.6.13-rc2 # v2.6.13-rc2 is known to be good Once you have specified at least one bad and one good commit, git bisect selects a commit in the middle of that range of history, checks it out, and outputs something similar to the following: Bisecting: 675 revisions left to test after this (roughly 10 steps) You should now compile the checked-out version and test it. If that version works correctly, type $ git bisect good If that version is broken, type $ git bisect bad Then git bisect will respond with something like Bisecting: 337 revisions left to test after this (roughly 9 steps) Keep repeating the process: compile the tree, test it, and depending on whether it is good or bad run git bisect good or git bisect bad to ask for the next commit that needs testing. Eventually there will be no more revisions left to inspect, and the command will print out a description of the first bad commit. The reference refs/bisect/bad will be left pointing at that commit. Bisect reset After a bisect session, to clean up the bisection state and return to the original HEAD, issue the following command: $ git bisect reset By default, this will return your tree to the commit that was checked out before git bisect start. (A new git bisect start will also do that, as it cleans up the old bisection state.) With an optional argument, you can return to a different commit instead: $ git bisect reset <commit> For example, git bisect reset bisect/bad will check out the first bad revision, while git bisect reset HEAD will leave you on the current bisection commit and avoid switching commits at all. Alternate terms Sometimes you are not looking for the commit that introduced a breakage, but rather for a commit that caused a change between some other \"old\" state and \"new\" state. For example, you might be looking for the commit that introduced a particular fix. Or you might be looking for the first commit in which the source-code filenames were finally all converted to your company\u2019s naming standard. Or whatever. In such cases it can be very confusing to use the terms \"good\" and \"bad\" to refer to \"the state before the change\" and \"the state after the change\". So instead, you can use the terms \"old\" and \"new\", respectively, in place of \"good\" and \"bad\". (But note that you cannot mix \"good\" and \"bad\" with \"old\" and \"new\" in a single session.) In this more general usage, you provide git bisect with a \"new\" commit that has some property and an \"old\" commit that doesn\u2019t have that property. Each time git bisect checks out a commit, you test if that commit has the property. If it does, mark the commit as \"new\"; otherwise, mark it as \"old\". When the bisection is done, git bisect will report which commit introduced the property. To use \"old\" and \"new\" instead of \"good\" and bad, you must run git bisect start without commits as argument and then run the following commands to add the commits: git bisect old [<rev>] to indicate that a commit was before the sought change, or git bisect new [<rev>...] to indicate that it was after. To get a reminder of the currently used terms, use git bisect terms You can get just the old (respectively new) term with git bisect terms --term-old or git bisect terms --term-good. If you would like to use your own terms instead of \"bad\"/\"good\" or \"new\"/\"old\", you can choose any names you like (except existing bisect subcommands like reset, start, ...) by starting the bisection using git bisect start --term-old <term-old> --term-new <term-new> For example, if you are looking for a commit that introduced a performance regression, you might use git bisect start --term-old fast --term-new slow Or if you are looking for the commit that fixed a bug, you might use git bisect start --term-new fixed --term-old broken Then, use git bisect <term-old> and git bisect <term-new> instead of git bisect good and git bisect bad to mark commits. Bisect visualize/view To see the currently remaining suspects in gitk, issue the following command during the bisection process (the subcommand view can be used as an alternative to visualize): $ git bisect visualize If the DISPLAY environment variable is not set, git log is used instead. You can also give command-line options such as -p and --stat. $ git bisect visualize --stat Bisect log and bisect replay After having marked revisions as good or bad, issue the following command to show what has been done so far: $ git bisect log If you discover that you made a mistake in specifying the status of a revision, you can save the output of this command to a file, edit it to remove the incorrect entries, and then issue the following commands to return to a corrected state: $ git bisect reset $ git bisect replay that-file Avoiding testing a commit If, in the middle of a bisect session, you know that the suggested revision is not a good one to test (e.g. it fails to build and you know that the failure does not have anything to do with the bug you are chasing), you can manually select a nearby commit and test that one instead. For example: $ git bisect good/bad # previous round was good or bad. Bisecting: 337 revisions left to test after this (roughly 9 steps) $ git bisect visualize # oops, that is uninteresting. $ git reset --hard HEAD~3 # try 3 revisions before what # was suggested Then compile and test the chosen revision, and afterwards mark the revision as good or bad in the usual manner. Bisect skip Instead of choosing a nearby commit by yourself, you can ask Git to do it for you by issuing the command: $ git bisect skip # Current version cannot be tested However, if you skip a commit adjacent to the one you are looking for, Git will be unable to tell exactly which of those commits was the first bad one. You can also skip a range of commits, instead of just one commit, using range notation. For example: $ git bisect skip v2.5..v2.6 This tells the bisect process that no commit after v2.5, up to and including v2.6, should be tested. Note that if you also want to skip the first commit of the range you would issue the command: $ git bisect skip v2.5 v2.5..v2.6 This tells the bisect process that the commits between v2.5 and v2.6 (inclusive) should be skipped. Cutting down bisection by giving more parameters to bisect start You can further cut down the number of trials, if you know what part of the tree is involved in the problem you are tracking down, by specifying path parameters when issuing the bisect start command: $ git bisect start -- arch/i386 include/asm-i386 If you know beforehand more than one good commit, you can narrow the bisect space down by specifying all of the good commits immediately after the bad commit when issuing the bisect start command: $ git bisect start v2.6.20-rc6 v2.6.20-rc4 v2.6.20-rc1 -- # v2.6.20-rc6 is bad # v2.6.20-rc4 and v2.6.20-rc1 are good Bisect run If you have a script that can tell if the current source code is good or bad, you can bisect by issuing the command: $ git bisect run my_script arguments Note that the script (my_script in the above example) should exit with code 0 if the current source code is good/old, and exit with a code between 1 and 127 (inclusive), except 125, if the current source code is bad/new. Any other exit code will abort the bisect process. It should be noted that a program that terminates via exit(-1) leaves $? = 255, (see the exit(3) manual page), as the value is chopped with & 0377. The special exit code 125 should be used when the current source code cannot be tested. If the script exits with this code, the current revision will be skipped (see git bisect skip above). 125 was chosen as the highest sensible value to use for this purpose, because 126 and 127 are used by POSIX shells to signal specific error status (127 is for command not found, 126 is for command found but not executable\u2014these details do not matter, as they are normal errors in the script, as far as bisect run is concerned). You may often find that during a bisect session you want to have temporary modifications (e.g. s/#define DEBUG 0/#define DEBUG 1/ in a header file, or \"revision that does not have this commit needs this patch applied to work around another problem this bisection is not interested in\") applied to the revision being tested. To cope with such a situation, after the inner git bisect finds the next revision to test, the script can apply the patch before compiling, run the real test, and afterwards decide if the revision (possibly with the needed patch) passed the test and then rewind the tree to the pristine state. Finally the script should exit with the status of the real test to let the git bisect run command loop determine the eventual outcome of the bisect session. --no-checkout Do not checkout the new working tree at each iteration of the bisection process. Instead just update a special reference named BISECT_HEAD to make it point to the commit that should be tested. This option may be useful when the test you would perform in each step does not require a checked out tree. If the repository is bare, --no-checkout is assumed. --first-parent Follow only the first parent commit upon seeing a merge commit. In detecting regressions introduced through the merging of a branch, the merge commit will be identified as introduction of the bug and its ancestors will be ignored. This option is particularly useful in avoiding false positives when a merged branch contained broken or non-buildable commits, but the merge itself was OK. "
  },
  {
    "command": "systemd-ac-power",
    "description": " systemd-ac-power may be used to check whether the system is running on AC power or not. By default it will simply return success (if we can detect that we are running on AC power) or failure, with no output. This can be useful for example to debug ConditionACPower= (see systemd.unit(5)). The following options are understood: -v, --verbose Show result as text instead of just returning success or failure. --low Instead of showing AC power state, show low battery state. In this case will return zero if all batteries are currently discharging and below 5% of maximum charge. Returns non-zero otherwise. -h, --help Print a short help text and exit. --version Print a short version string and exit. "
  },
  {
    "command": "getopt",
    "description": " getopt is used to break up (parse) options in command lines for easy parsing by shell procedures, and to check for valid options. It uses the GNU getopt(3) routines to do this. The parameters getopt is called with can be divided into two parts: options which modify the way getopt will do the parsing (the options and the optstring in the SYNOPSIS), and the parameters which are to be parsed (parameters in the SYNOPSIS). The second part will start at the first non-option parameter that is not an option argument, or after the first occurrence of '--'. If no '-o' or '--options' option is found in the first part, the first parameter of the second part is used as the short options string. If the environment variable GETOPT_COMPATIBLE is set, or if the first parameter is not an option (does not start with a '-', the first format in the SYNOPSIS), getopt will generate output that is compatible with that of other versions of getopt(1). It will still do parameter shuffling and recognize optional arguments (see the COMPATIBILITY section for more information). Traditional implementations of getopt(1) are unable to cope with whitespace and other (shell-specific) special characters in arguments and non-option parameters. To solve this problem, this implementation can generate quoted output which must once again be interpreted by the shell (usually by using the eval command). This has the effect of preserving those characters, but you must call getopt in a way that is no longer compatible with other versions (the second or third format in the SYNOPSIS). To determine whether this enhanced version of getopt(1) is installed, a special test option (-T) can be used. -a, --alternative Allow long options to start with a single '-'. -l, --longoptions longopts The long (multi-character) options to be recognized. More than one option name may be specified at once, by separating the names with commas. This option may be given more than once, the longopts are cumulative. Each long option name in longopts may be followed by one colon to indicate it has a required argument, and by two colons to indicate it has an optional argument. -n, --name progname The name that will be used by the getopt(3) routines when it reports errors. Note that errors of getopt(1) are still reported as coming from getopt. -o, --options shortopts The short (one-character) options to be recognized. If this option is not found, the first parameter of getopt that does not start with a '-' (and is not an option argument) is used as the short options string. Each short option character in shortopts may be followed by one colon to indicate it has a required argument, and by two colons to indicate it has an optional argument. The first character of shortopts may be '+' or '-' to influence the way options are parsed and output is generated (see the SCANNING MODES section for details). -q, --quiet Disable error reporting by getopt(3). -Q, --quiet-output Do not generate normal output. Errors are still reported by getopt(3), unless you also use -q. -s, --shell shell Set quoting conventions to those of shell. If the -s option is not given, the BASH conventions are used. Valid arguments are currently 'sh', 'bash', 'csh', and 'tcsh'. -T, --test Test if your getopt(1) is this enhanced version or an old version. This generates no output, and sets the error status to 4. Other implementations of getopt(1), and this version if the environment variable GETOPT_COMPATIBLE is set, will return '--' and error status 0. -u, --unquoted Do not quote the output. Note that whitespace and special (shell-dependent) characters can cause havoc in this mode (like they do with other getopt(1) implementations). -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "pkill",
    "description": " pgrep looks through the currently running processes and lists the process IDs which match the selection criteria to stdout. All the criteria have to match. For example, $ pgrep -u root sshd will only list the processes called sshd AND owned by root. On the other hand, $ pgrep -u root,daemon will list the processes owned by root OR daemon. pkill will send the specified signal (by default SIGTERM) to each process instead of listing them on stdout. pidwait will wait for each process instead of listing them on stdout. -signal --signal signal Defines the signal to send to each matched process. Either the numeric or the symbolic signal name can be used. In pgrep or pidwait mode only the long option can be used and has no effect unless used in conjunction with --require-handler to filter to processes with a userspace signal handler present for a particular signal. -c, --count Suppress normal output; instead print a count of matching processes. When count does not match anything, e.g. returns zero, the command will return non-zero value. Note that for pkill and pidwait, the count is the number of matching processes, not the processes that were successfully signaled or waited for. -d, --delimiter delimiter Sets the string used to delimit each process ID in the output (by default a newline). (pgrep only.) -e, --echo Display name and PID of the process being killed. (pkill only.) -f, --full The pattern is normally only matched against the process name. When -f is set, the full command line is used. -g, --pgroup pgrp,... Only match processes in the process group IDs listed. Process group 0 is translated into pgrep's, pkill's, or pidwait's own process group. -G, --group gid,... Only match processes whose real group ID is listed. Either the numerical or symbolical value may be used. -i, --ignore-case Match processes case-insensitively. -l, --list-name List the process name as well as the process ID. (pgrep only.) -a, --list-full List the full command line as well as the process ID. (pgrep only.) -n, --newest Select only the newest (most recently started) of the matching processes. -o, --oldest Select only the oldest (least recently started) of the matching processes. -O, --older secs Select processes older than secs. -P, --parent ppid,... Only match processes whose parent process ID is listed. -s, --session sid,... Only match processes whose process session ID is listed. Session ID 0 is translated into pgrep's, pkill's, or pidwait's own session ID. -t, --terminal term,... Only match processes whose controlling terminal is listed. The terminal name should be specified without the \"/dev/\" prefix. -u, --euid euid,... Only match processes whose effective user ID is listed. Either the numerical or symbolical value may be used. -U, --uid uid,... Only match processes whose real user ID is listed. Either the numerical or symbolical value may be used. -v, --inverse Negates the matching. This option is usually used in pgrep's or pidwait's context. In pkill's context the short option is disabled to avoid accidental usage of the option. -w, --lightweight Shows all thread ids instead of pids in pgrep's or pidwait's context. In pkill's context this option is disabled. -x, --exact Only match processes whose names (or command lines if -f is specified) exactly match the pattern. -F, --pidfile file Read PIDs from file. This option is more useful for pkill or pidwait than pgrep. -L, --logpidfile Fail if pidfile (see -F) not locked. -r, --runstates D,R,S,Z,... Match only processes which match the process state. -A, --ignore-ancestors Ignore all ancestors of pgrep, pkill, or pidwait. For example, this can be useful when elevating with sudo or similar tools. -H, --require-handler Only match processes with a userspace signal handler present for the signal to be sent. --cgroup name,... Match on provided control group (cgroup) v2 name. See cgroups(8) --ns pid Match processes that belong to the same namespaces. Required to run as root to match processes from other users. See --nslist for how to limit which namespaces to match. --nslist name,... Match only the provided namespaces. Available namespaces: ipc, mnt, net, pid, user, uts. -q, --queue value Use sigqueue(3) rather than kill(2) and the value argument is used to specify an integer to be sent with the signal. If the receiving process has installed a handler for this signal using the SA_SIGINFO flag to sigaction(2), then it can obtain this data via the si_value field of the siginfo_t structure. -V, --version Display version information and exit. -h, --help Display help and exit. "
  },
  {
    "command": "ssh-keyscan",
    "description": " ssh-keyscan is a utility for gathering the public SSH host keys of a number of hosts. It was designed to aid in building and verifying ssh_known_hosts files, the format of which is documented in sshd(8). ssh-keyscan provides a minimal interface suitable for use by shell and perl scripts. ssh-keyscan uses non-blocking socket I/O to contact as many hosts as possible in parallel, so it is very efficient. The keys from a domain of 1,000 hosts can be collected in tens of seconds, even when some of those hosts are down or do not run sshd(8). For scanning, one does not need login access to the machines that are being scanned, nor does the scanning process involve any encryption. Hosts to be scanned may be specified by hostname, address or by CIDR network range (e.g. 192.168.16/28). If a network range is specified, then all addresses in that range will be scanned. The options are as follows: -4 Force ssh-keyscan to use IPv4 addresses only. -6 Force ssh-keyscan to use IPv6 addresses only. -c Request certificates from target hosts instead of plain keys. -D Print keys found as SSHFP DNS records. The default is to print keys in a format usable as a ssh(1) known_hosts file. -f file Read hosts or \u201caddrlist namelist\u201d pairs from file, one per line. If \u2018-\u2019 is supplied instead of a filename, ssh-keyscan will read from the standard input. Names read from a file must start with an address, hostname or CIDR network range to be scanned. Addresses and hostnames may optionally be followed by comma-separated name or address aliases that will be copied to the output. For example: 192.168.11.0/24 10.20.1.1 happy.example.org 10.0.0.1,sad.example.org -H Hash all hostnames and addresses in the output. Hashed names may be used normally by ssh(1) and sshd(8), but they do not reveal identifying information should the file's contents be disclosed. -O option Specify a key/value option. At present, only a single option is supported: hashalg=algorithm Selects a hash algorithm to use when printing SSHFP records using the -D flag. Valid algorithms are \u201csha1\u201d and \u201csha256\u201d. The default is to print both. -p port Connect to port on the remote host. -T timeout Set the timeout for connection attempts. If timeout seconds have elapsed since a connection was initiated to a host or since the last time anything was read from that host, the connection is closed and the host in question considered unavailable. The default is 5 seconds. -t type Specify the type of the key to fetch from the scanned hosts. The possible values are \u201cdsa\u201d, \u201cecdsa\u201d, \u201ced25519\u201d, \u201cecdsa-sk\u201d, \u201ced25519-sk\u201d, or \u201crsa\u201d. Multiple values may be specified by separating them with commas. The default is to fetch \u201crsa\u201d, \u201cecdsa\u201d, \u201ced25519\u201d, \u201cecdsa-sk\u201d, and \u201ced25519-sk\u201d keys. -v Verbose mode: print debugging messages about progress. If an ssh_known_hosts file is constructed using ssh-keyscan without verifying the keys, users will be vulnerable to man in the middle attacks. On the other hand, if the security model allows such a risk, ssh-keyscan can help in the detection of tampered keyfiles or man in the middle attacks which have begun after the ssh_known_hosts file was created. "
  },
  {
    "command": "test",
    "description": " The test utility shall evaluate the expression and indicate the result of the evaluation by its exit status. An exit status of zero indicates that the expression evaluated as true and an exit status of 1 indicates that the expression evaluated as false. In the second form of the utility, where the utility name used is [ rather than test, the application shall ensure that the closing square bracket is a separate argument. The test and [ utilities may be implemented as a single linked utility which examines the basename of the zeroth command line argument to determine whether to behave as the test or [ variant. Applications using the exec() family of functions to execute these utilities shall ensure that the argument passed in arg0 or argv[0] is '[' when executing the [ utility and has a basename of \"test\" when executing the test utility. The test utility shall not recognize the \"--\" argument in the manner specified by Guideline 10 in the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. No options shall be supported. "
  },
  {
    "command": "systemd-notify",
    "description": " systemd-notify may be called by service scripts to notify the invoking service manager about status changes. It can be used to send arbitrary information, encoded in an environment-block-like list of strings. Most importantly, it can be used for start-up completion notification. This is mostly just a wrapper around sd_notify() and makes this functionality available to shell scripts. For details see sd_notify(3). The command line may carry a list of environment variables to send as part of the status update. Note that systemd will refuse reception of status updates from this command unless NotifyAccess= is appropriately set for the service unit this command is called from. See systemd.service(5) for details. Note that sd_notify() notifications may be attributed to units correctly only if either the sending process is still around at the time the service manager processes the message, or if the sending process is explicitly runtime-tracked by the service manager. The latter is the case if the service manager originally forked off the process, i.e. on all processes that match NotifyAccess=main or NotifyAccess=exec. Conversely, if an auxiliary process of the unit sends an sd_notify() message and immediately exits, the service manager might not be able to properly attribute the message to the unit, and thus will ignore it, even if NotifyAccess=all is set for it. To address this systemd-notify will wait until the notification message has been processed by the service manager. When --no-block is used, this synchronization for reception of notifications is disabled, and hence the aforementioned race may occur if the invoking process is not the service manager or spawned by the service manager. systemd-notify will first attempt to invoke sd_notify() pretending to have the PID of the parent process of systemd-notify (i.e. the invoking process). This will only succeed when invoked with sufficient privileges. On failure, it will then fall back to invoking it under its own PID. This behaviour is useful in order that when the tool is invoked from a shell script the shell process \u2014 and not the systemd-notify process \u2014 appears as sender of the message, which in turn is helpful if the shell process is the main process of a service, due to the limitations of NotifyAccess=all. Use the --pid= switch to tweak this behaviour. The following options are understood: --ready Inform the invoking service manager about service start-up or configuration reload completion. This is equivalent to systemd-notify READY=1. For details about the semantics of this option see sd_notify(3). --reloading Inform the invoking service manager about the beginning of a configuration reload cycle. This is equivalent to systemd-notify RELOADING=1 (but implicitly also sets a MONOTONIC_USEC= field as required for Type=notify-reload services, see systemd.service(5) for details). For details about the semantics of this option see sd_notify(3). --stopping Inform the invoking service manager about the beginning of the shutdown phase of the service. This is equivalent to systemd-notify STOPPING=1. For details about the semantics of this option see sd_notify(3). --pid= Inform the service manager about the main PID of the service. Takes a PID as argument. If the argument is specified as \"auto\" or omitted, the PID of the process that invoked systemd-notify is used, except if that's the service manager. If the argument is specified as \"self\", the PID of the systemd-notify command itself is used, and if \"parent\" is specified the calling process' PID is used \u2014 even if it is the service manager. The latter is equivalent to systemd-notify MAINPID=$PID. For details about the semantics of this option see sd_notify(3). If this switch is used in an systemd-notify invocation from a process that shall become the new main process of a service \u2014 and which is not the process forked off by the service manager (or the current main process) \u2014, then it is essential to set NotifyAccess=all in the service unit file, or otherwise the notification will be ignored for security reasons. See systemd.service(5) for details. --uid=USER Set the user ID to send the notification from. Takes a UNIX user name or numeric UID. When specified the notification message will be sent with the specified UID as sender, in place of the user the command was invoked as. This option requires sufficient privileges in order to be able manipulate the user identity of the process. --status= Send a free-form human readable status string for the daemon to the service manager. This option takes the status string as argument. This is equivalent to systemd-notify STATUS=.... For details about the semantics of this option see sd_notify(3). This information is shown in systemctl(1)'s status output, among other places. --booted Returns 0 if the system was booted up with systemd, non-zero otherwise. If this option is passed, no message is sent. This option is hence unrelated to the other options. For details about the semantics of this option, see sd_booted(3). An alternate way to check for this state is to call systemctl(1) with the is-system-running command. It will return \"offline\" if the system was not booted with systemd. --no-block Do not synchronously wait for the requested operation to finish. Use of this option is only recommended when systemd-notify is spawned by the service manager, or when the invoking process is directly spawned by the service manager and has enough privileges to allow systemd-notify to send the notification on its behalf. Sending notifications with this option set is prone to race conditions in all other cases. --exec If specified systemd-notify will execute another command line after it completed its operation, replacing its own process. If used, the list of assignments to include in the message sent must be followed by a \";\" character (as separate argument), followed by the command line to execute. This permits \"chaining\" of commands, i.e. issuing one operation, followed immediately by another, without changing PIDs. Note that many shells interpret \";\" as their own separator for command lines, hence when systemd-notify is invoked from a shell the semicolon must usually be escaped as \"\\;\". --fd= Send a file descriptor along with the notification message. This is useful when invoked in services that have the FileDescriptorStoreMax= setting enabled, see systemd.service(5) for details. The specified file descriptor must be passed to systemd-notify when invoked. This option may be used multiple times to pass multiple file descriptors in a single notification message. To use this functionality from a bash shell, use an expression like the following: systemd-notify --fd=4 --fd=5 4</some/file 5</some/other/file --fdname= Set a name to assign to the file descriptors passed via --fd= (see above). This controls the \"FDNAME=\" field. This setting may only be specified once, and applies to all file descriptors passed. Invoke this tool multiple times in case multiple file descriptors with different file descriptor names shall be submitted. -h, --help Print a short help text and exit. --version Print a short version string and exit. "
  },
  {
    "command": "pr",
    "description": " Paginate or columnate FILE(s) for printing. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. +FIRST_PAGE[:LAST_PAGE], --pages=FIRST_PAGE[:LAST_PAGE] begin [stop] printing with page FIRST_[LAST_]PAGE -COLUMN, --columns=COLUMN output COLUMN columns and print columns down, unless -a is used. Balance number of lines in the columns on each page -a, --across print columns across rather than down, used together with -COLUMN -c, --show-control-chars use hat notation (^G) and octal backslash notation -d, --double-space double space the output -D, --date-format=FORMAT use FORMAT for the header date -e[CHAR[WIDTH]], --expand-tabs[=CHAR[WIDTH]] expand input CHARs (TABs) to tab WIDTH (8) -F, -f, --form-feed use form feeds instead of newlines to separate pages (by a 3-line page header with -F or a 5-line header and trailer without -F) -h, --header=HEADER use a centered HEADER instead of filename in page header, -h \"\" prints a blank line, don't use -h\"\" -i[CHAR[WIDTH]], --output-tabs[=CHAR[WIDTH]] replace spaces with CHARs (TABs) to tab WIDTH (8) -J, --join-lines merge full lines, turns off -W line truncation, no column alignment, --sep-string[=STRING] sets separators -l, --length=PAGE_LENGTH set the page length to PAGE_LENGTH (66) lines (default number of lines of text 56, and with -F 63). implies -t if PAGE_LENGTH <= 10 -m, --merge print all files in parallel, one in each column, truncate lines, but join lines of full length with -J -n[SEP[DIGITS]], --number-lines[=SEP[DIGITS]] number lines, use DIGITS (5) digits, then SEP (TAB), default counting starts with 1st line of input file -N, --first-line-number=NUMBER start counting with NUMBER at 1st line of first page printed (see +FIRST_PAGE) -o, --indent=MARGIN offset each line with MARGIN (zero) spaces, do not affect -w or -W, MARGIN will be added to PAGE_WIDTH -r, --no-file-warnings omit warning when a file cannot be opened -s[CHAR], --separator[=CHAR] separate columns by a single character, default for CHAR is the <TAB> character without -w and 'no char' with -w. -s[CHAR] turns off line truncation of all 3 column options (-COLUMN|-a -COLUMN|-m) except -w is set -S[STRING], --sep-string[=STRING] separate columns by STRING, without -S: Default separator <TAB> with -J and <space> otherwise (same as -S\" \"), no effect on column options -t, --omit-header omit page headers and trailers; implied if PAGE_LENGTH <= 10 -T, --omit-pagination omit page headers and trailers, eliminate any pagination by form feeds set in input files -v, --show-nonprinting use octal backslash notation -w, --width=PAGE_WIDTH set page width to PAGE_WIDTH (72) characters for multiple text-column output only, -s[char] turns off (72) -W, --page-width=PAGE_WIDTH set page width to PAGE_WIDTH (72) characters always, truncate lines, except -J option is set, no interference with -S or -s --help display this help and exit --version output version information and exit "
  },
  {
    "command": "git-symbolic-ref",
    "description": " Given one argument, reads which branch head the given symbolic ref refers to and outputs its path, relative to the .git/ directory. Typically you would give HEAD as the <name> argument to see which branch your working tree is on. Given two arguments, creates or updates a symbolic ref <name> to point at the given branch <ref>. Given --delete and an additional argument, deletes the given symbolic ref. A symbolic ref is a regular file that stores a string that begins with ref: refs/. For example, your .git/HEAD is a regular file whose contents is ref: refs/heads/master. -d, --delete Delete the symbolic ref <name>. -q, --quiet Do not issue an error message if the <name> is not a symbolic ref but a detached HEAD; instead exit with non-zero status silently. --short When showing the value of <name> as a symbolic ref, try to shorten the value, e.g. from refs/heads/master to master. --recurse, --no-recurse When showing the value of <name> as a symbolic ref, if <name> refers to another symbolic ref, follow such a chain of symbolic refs until the result no longer points at a symbolic ref (--recurse, which is the default). --no-recurse stops after dereferencing only a single level of symbolic ref. -m Update the reflog for <name> with <reason>. This is valid only when creating or updating a symbolic ref. "
  },
  {
    "command": "tty",
    "description": " Print the file name of the terminal connected to standard input. -s, --silent, --quiet print nothing, only return an exit status --help display this help and exit --version output version information and exit "
  },
  {
    "command": "git-instaweb",
    "description": " A simple script to set up gitweb and a web server for browsing the local repository. -l, --local Only bind the web server to the local IP (127.0.0.1). -d, --httpd The HTTP daemon command-line that will be executed. Command-line options may be specified here, and the configuration file will be added at the end of the command-line. Currently apache2, lighttpd, mongoose, plackup, python and webrick are supported. (Default: lighttpd) -m, --module-path The module path (only needed if httpd is Apache). (Default: /usr/lib/apache2/modules) -p, --port The port number to bind the httpd to. (Default: 1234) -b, --browser The web browser that should be used to view the gitweb page. This will be passed to the git web--browse helper script along with the URL of the gitweb instance. See git-web--browse(1) for more information about this. If the script fails, the URL will be printed to stdout. start, --start Start the httpd instance and exit. Regenerate configuration files as necessary for spawning a new instance. stop, --stop Stop the httpd instance and exit. This does not generate any of the configuration files for spawning a new instance, nor does it close the browser. restart, --restart Restart the httpd instance and exit. Regenerate configuration files as necessary for spawning a new instance. "
  },
  {
    "command": "newgrp",
    "description": " The newgrp utility shall create a new shell execution environment with a new real and effective group identification. Of the attributes listed in Section 2.12, Shell Execution Environment, the new shell execution environment shall retain the working directory, file creation mask, and exported variables from the previous environment (that is, open files, traps, unexported variables, alias definitions, shell functions, and set options may be lost). All other aspects of the process environment that are preserved by the exec family of functions defined in the System Interfaces volume of POSIX.1\u20102017 shall also be preserved by newgrp; whether other aspects are preserved is unspecified. A failure to assign the new group identifications (for example, for security or password-related reasons) shall not prevent the new shell execution environment from being created. The newgrp utility shall affect the supplemental groups for the process as follows: * On systems where the effective group ID is normally in the supplementary group list (or whenever the old effective group ID actually is in the supplementary group list): -- If the new effective group ID is also in the supplementary group list, newgrp shall change the effective group ID. -- If the new effective group ID is not in the supplementary group list, newgrp shall add the new effective group ID to the list, if there is room to add it. * On systems where the effective group ID is not normally in the supplementary group list (or whenever the old effective group ID is not in the supplementary group list): -- If the new effective group ID is in the supplementary group list, newgrp shall delete it. -- If the old effective group ID is not in the supplementary list, newgrp shall add it if there is room. Note: The System Interfaces volume of POSIX.1\u20102017 does not specify whether the effective group ID of a process is included in its supplementary group list. With no operands, newgrp shall change the effective group back to the groups identified in the user's user entry, and shall set the list of supplementary groups to that set in the user's group database entries. If the first argument is '-', the results are unspecified. If a password is required for the specified group, and the user is not listed as a member of that group in the group database, the user shall be prompted to enter the correct password for that group. If the user is listed as a member of that group, no password shall be requested. If no password is required for the specified group, it is implementation-defined whether users not listed as members of that group can change to that group. Whether or not a password is required, implementation-defined system accounting or security mechanisms may impose additional authorization restrictions that may cause newgrp to write a diagnostic message and suppress the changing of the group identification. The newgrp utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for the unspecified usage of '-'. The following option shall be supported: -l (The letter ell.) Change the environment to what would be expected if the user actually logged in again. "
  },
  {
    "command": "dircolors",
    "description": " Output commands to set the LS_COLORS environment variable. Determine format of output: -b, --sh, --bourne-shell output Bourne shell code to set LS_COLORS -c, --csh, --c-shell output C shell code to set LS_COLORS -p, --print-database output defaults --print-ls-colors output fully escaped colors for display --help display this help and exit --version output version information and exit If FILE is specified, read it to determine which colors to use for which file types and extensions. Otherwise, a precompiled database is used. For details on the format of these files, run 'dircolors --print-database'. "
  },
  {
    "command": "utmpdump",
    "description": " utmpdump is a simple program to dump UTMP and WTMP files in raw format, so they can be examined. utmpdump reads from stdin unless a filename is passed. -f, --follow Output appended data as the file grows. -o, --output file Write command output to file instead of standard output. -r, --reverse Undump, write back edited login information into the utmp or wtmp files. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "lp",
    "description": " lp submits files for printing or alters a pending job. Use a filename of \"-\" to force printing from the standard input. THE DEFAULT DESTINATION CUPS provides many ways to set the default destination. The LPDEST and PRINTER environment variables are consulted first. If neither are set, the current default set using the lpoptions(1) command is used, followed by the default set using the lpadmin(8) command. The following options are recognized by lp: -- Marks the end of options; use this to print a file whose name begins with a dash (-). -E Forces encryption when connecting to the server. -U username Specifies the username to use when connecting to the server. -c This option is provided for backwards-compatibility only. On systems that support it, this option forces the print file to be copied to the spool directory before printing. In CUPS, print files are always sent to the scheduler via IPP which has the same effect. -d destination Prints files to the named printer. -h hostname[:port] Chooses an alternate server. -i job-id Specifies an existing job to modify. -m Sends an email when the job is completed. -n copies Sets the number of copies to print. -o \"name=value [ ... name=value ]\" Sets one or more job options. See \"COMMON JOB OPTIONS\" below. -q priority Sets the job priority from 1 (lowest) to 100 (highest). The default priority is 50. -s Do not report the resulting job IDs (silent mode.) -t \"name\" Sets the job name. -H hh:mm -H hold -H immediate -H restart -H resume Specifies when the job should be printed. A value of immediate will print the file immediately, a value of hold will hold the job indefinitely, and a UTC time value (HH:MM) will hold the job until the specified UTC (not local) time. Use a value of resume with the -i option to resume a held job. Use a value of restart with the -i option to restart a completed job. -P page-list Specifies which pages to print in the document. The list can contain a list of numbers and ranges (#-#) separated by commas, e.g., \"1,3-5,16\". The page numbers refer to the output pages and not the document's original pages - options like \"number-up\" can affect the numbering of the pages. COMMON JOB OPTIONS Aside from the printer-specific options reported by the lpoptions(1) command, the following generic options are available: -o job-sheets=name Prints a cover page (banner) with the document. The \"name\" can be \"classified\", \"confidential\", \"secret\", \"standard\", \"topsecret\", or \"unclassified\". -o media=size Sets the page size to size. Most printers support at least the size names \"a4\", \"letter\", and \"legal\". -o number-up={2|4|6|9|16} Prints 2, 4, 6, 9, or 16 document (input) pages on each output page. -o orientation-requested=4 Prints the job in landscape (rotated 90 degrees counter- clockwise). -o orientation-requested=5 Prints the job in landscape (rotated 90 degrees clockwise). -o orientation-requested=6 Prints the job in reverse portrait (rotated 180 degrees). -o print-quality=3 -o print-quality=4 -o print-quality=5 Specifies the output quality - draft (3), normal (4), or best (5). -o sides=one-sided Prints on one side of the paper. -o sides=two-sided-long-edge Prints on both sides of the paper for portrait output. -o sides=two-sided-short-edge Prints on both sides of the paper for landscape output. "
  },
  {
    "command": "git-verify-tag",
    "description": " Validates the gpg signature created by git tag. --raw Print the raw gpg status output to standard error instead of the normal human-readable output. -v, --verbose Print the contents of the tag object before validating it. <tag>... SHA-1 identifiers of Git tag objects. "
  },
  {
    "command": "du",
    "description": " By default, the du utility shall write to standard output the size of the file space allocated to, and the size of the file space allocated to each subdirectory of, the file hierarchy rooted in each of the specified files. By default, when a symbolic link is encountered on the command line or in the file hierarchy, du shall count the size of the symbolic link (rather than the file referenced by the link), and shall not follow the link to another portion of the file hierarchy. The size of the file space allocated to a file of type directory shall be defined as the sum total of space allocated to all files in the file hierarchy rooted in the directory plus the space allocated to the directory itself. When du cannot stat() files or stat() or read directories, it shall report an error condition and the final exit status is affected. A file that occurs multiple times under one file operand and that has a link count greater than 1 shall be counted and written for only one entry. It is implementation-defined whether a file that has a link count no greater than 1 is counted and written just once, or is counted and written for each occurrence. It is implementation-defined whether a file that occurs under one file operand is counted for other file operands. The directory entry that is selected in the report is unspecified. By default, file sizes shall be written in 512-byte units, rounded up to the next 512-byte unit. The du utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -a In addition to the default output, report the size of each file not of type directory in the file hierarchy rooted in the specified file. The -a option shall not affect whether non-directories given as file operands are listed. -H If a symbolic link is specified on the command line, du shall count the size of the file or file hierarchy referenced by the link. -k Write the files sizes in units of 1024 bytes, rather than the default 512-byte units. -L If a symbolic link is specified on the command line or encountered during the traversal of a file hierarchy, du shall count the size of the file or file hierarchy referenced by the link. -s Instead of the default output, report only the total sum for each of the specified files. -x When evaluating file sizes, evaluate only those files that have the same device as the file specified by the file operand. Specifying more than one of the mutually-exclusive options -H and -L shall not be considered an error. The last option specified shall determine the behavior of the utility. "
  },
  {
    "command": "pgrep",
    "description": " pgrep looks through the currently running processes and lists the process IDs which match the selection criteria to stdout. All the criteria have to match. For example, $ pgrep -u root sshd will only list the processes called sshd AND owned by root. On the other hand, $ pgrep -u root,daemon will list the processes owned by root OR daemon. pkill will send the specified signal (by default SIGTERM) to each process instead of listing them on stdout. pidwait will wait for each process instead of listing them on stdout. -signal --signal signal Defines the signal to send to each matched process. Either the numeric or the symbolic signal name can be used. In pgrep or pidwait mode only the long option can be used and has no effect unless used in conjunction with --require-handler to filter to processes with a userspace signal handler present for a particular signal. -c, --count Suppress normal output; instead print a count of matching processes. When count does not match anything, e.g. returns zero, the command will return non-zero value. Note that for pkill and pidwait, the count is the number of matching processes, not the processes that were successfully signaled or waited for. -d, --delimiter delimiter Sets the string used to delimit each process ID in the output (by default a newline). (pgrep only.) -e, --echo Display name and PID of the process being killed. (pkill only.) -f, --full The pattern is normally only matched against the process name. When -f is set, the full command line is used. -g, --pgroup pgrp,... Only match processes in the process group IDs listed. Process group 0 is translated into pgrep's, pkill's, or pidwait's own process group. -G, --group gid,... Only match processes whose real group ID is listed. Either the numerical or symbolical value may be used. -i, --ignore-case Match processes case-insensitively. -l, --list-name List the process name as well as the process ID. (pgrep only.) -a, --list-full List the full command line as well as the process ID. (pgrep only.) -n, --newest Select only the newest (most recently started) of the matching processes. -o, --oldest Select only the oldest (least recently started) of the matching processes. -O, --older secs Select processes older than secs. -P, --parent ppid,... Only match processes whose parent process ID is listed. -s, --session sid,... Only match processes whose process session ID is listed. Session ID 0 is translated into pgrep's, pkill's, or pidwait's own session ID. -t, --terminal term,... Only match processes whose controlling terminal is listed. The terminal name should be specified without the \"/dev/\" prefix. -u, --euid euid,... Only match processes whose effective user ID is listed. Either the numerical or symbolical value may be used. -U, --uid uid,... Only match processes whose real user ID is listed. Either the numerical or symbolical value may be used. -v, --inverse Negates the matching. This option is usually used in pgrep's or pidwait's context. In pkill's context the short option is disabled to avoid accidental usage of the option. -w, --lightweight Shows all thread ids instead of pids in pgrep's or pidwait's context. In pkill's context this option is disabled. -x, --exact Only match processes whose names (or command lines if -f is specified) exactly match the pattern. -F, --pidfile file Read PIDs from file. This option is more useful for pkill or pidwait than pgrep. -L, --logpidfile Fail if pidfile (see -F) not locked. -r, --runstates D,R,S,Z,... Match only processes which match the process state. -A, --ignore-ancestors Ignore all ancestors of pgrep, pkill, or pidwait. For example, this can be useful when elevating with sudo or similar tools. -H, --require-handler Only match processes with a userspace signal handler present for the signal to be sent. --cgroup name,... Match on provided control group (cgroup) v2 name. See cgroups(8) --ns pid Match processes that belong to the same namespaces. Required to run as root to match processes from other users. See --nslist for how to limit which namespaces to match. --nslist name,... Match only the provided namespaces. Available namespaces: ipc, mnt, net, pid, user, uts. -q, --queue value Use sigqueue(3) rather than kill(2) and the value argument is used to specify an integer to be sent with the signal. If the receiving process has installed a handler for this signal using the SA_SIGINFO flag to sigaction(2), then it can obtain this data via the si_value field of the siginfo_t structure. -V, --version Display version information and exit. -h, --help Display help and exit. "
  },
  {
    "command": "bc",
    "description": " The bc utility shall implement an arbitrary precision calculator. It shall take input from any files given, then read from the standard input. If the standard input and standard output to bc are attached to a terminal, the invocation of bc shall be considered to be interactive, causing behavioral constraints described in the following sections. The bc utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -l (The letter ell.) Define the math functions and initialize scale to 20, instead of the default zero; see the EXTENDED DESCRIPTION section. "
  },
  {
    "command": "git-credential-cache",
    "description": " This command caches credentials for use by future Git programs. The stored credentials are kept in memory of the cache-daemon process (instead of written to a file) and are forgotten after a configurable timeout. Credentials are forgotten sooner if the cache-daemon dies, for example if the system restarts. The cache is accessible over a Unix domain socket, restricted to the current user by filesystem permissions. You probably don\u2019t want to invoke this command directly; it is meant to be used as a credential helper by other parts of Git. See gitcredentials(7) or EXAMPLES below. --timeout <seconds> Number of seconds to cache credentials (default: 900). --socket <path> Use <path> to contact a running cache daemon (or start a new cache daemon if one is not started). Defaults to $XDG_CACHE_HOME/git/credential/socket unless ~/.git-credential-cache/ exists in which case ~/.git-credential-cache/socket is used instead. If your home directory is on a network-mounted filesystem, you may need to change this to a local filesystem. You must specify an absolute path. "
  },
  {
    "command": "git-log",
    "description": " Shows the commit logs. List commits that are reachable by following the parent links from the given commit(s), but exclude commits that are reachable from the one(s) given with a ^ in front of them. The output is given in reverse chronological order by default. You can think of this as a set operation. Commits reachable from any of the commits given on the command line form a set, and then commits reachable from any of the ones given with ^ in front are subtracted from that set. The remaining commits are what comes out in the command\u2019s output. Various other options and paths parameters can be used to further limit the result. Thus, the following command: $ git log foo bar ^baz means \"list all the commits which are reachable from foo or bar, but not from baz\". A special notation \"<commit1>..<commit2>\" can be used as a short-hand for \"^<commit1> <commit2>\". For example, either of the following may be used interchangeably: $ git log origin..HEAD $ git log HEAD ^origin Another special notation is \"<commit1>...<commit2>\" which is useful for merges. The resulting set of commits is the symmetric difference between the two operands. The following two commands are equivalent: $ git log A B --not $(git merge-base --all A B) $ git log A...B The command takes options applicable to the git-rev-list(1) command to control what is shown and how, and options applicable to the git-diff(1) command to control how the changes each commit introduces are shown. --follow Continue listing the history of a file beyond renames (works only for a single file). --no-decorate, --decorate[=short|full|auto|no] Print out the ref names of any commits that are shown. If short is specified, the ref name prefixes refs/heads/, refs/tags/ and refs/remotes/ will not be printed. If full is specified, the full ref name (including prefix) will be printed. If auto is specified, then if the output is going to a terminal, the ref names are shown as if short were given, otherwise no ref names are shown. The option --decorate is short-hand for --decorate=short. Default to configuration value of log.decorate if configured, otherwise, auto. --decorate-refs=<pattern>, --decorate-refs-exclude=<pattern> For each candidate reference, do not use it for decoration if it matches any patterns given to --decorate-refs-exclude or if it doesn\u2019t match any of the patterns given to --decorate-refs. The log.excludeDecoration config option allows excluding refs from the decorations, but an explicit --decorate-refs pattern will override a match in log.excludeDecoration. If none of these options or config settings are given, then references are used as decoration if they match HEAD, refs/heads/, refs/remotes/, refs/stash/, or refs/tags/. --clear-decorations When specified, this option clears all previous --decorate-refs or --decorate-refs-exclude options and relaxes the default decoration filter to include all references. This option is assumed if the config value log.initialDecorationSet is set to all. --source Print out the ref name given on the command line by which each commit was reached. --[no-]mailmap, --[no-]use-mailmap Use mailmap file to map author and committer names and email addresses to canonical real names and email addresses. See git-shortlog(1). --full-diff Without this flag, git log -p <path>... shows commits that touch the specified paths, and diffs about the same specified paths. With this, the full diff is shown for commits that touch the specified paths; this means that \"<path>...\" limits only commits, and doesn\u2019t limit diff for those commits. Note that this affects all diff-based output types, e.g. those produced by --stat, etc. --log-size Include a line \u201clog size <number>\u201d in the output for each commit, where <number> is the length of that commit\u2019s message in bytes. Intended to speed up tools that read log messages from git log output by allowing them to allocate space in advance. -L<start>,<end>:<file>, -L:<funcname>:<file> Trace the evolution of the line range given by <start>,<end>, or by the function name regex <funcname>, within the <file>. You may not give any pathspec limiters. This is currently limited to a walk starting from a single revision, i.e., you may only give zero or one positive revision arguments, and <start> and <end> (or <funcname>) must exist in the starting revision. You can specify this option more than once. Implies --patch. Patch output can be suppressed using --no-patch, but other diff formats (namely --raw, --numstat, --shortstat, --dirstat, --summary, --name-only, --name-status, --check) are not currently implemented. <start> and <end> can take one of these forms: \u2022 number If <start> or <end> is a number, it specifies an absolute line number (lines count from 1). \u2022 /regex/ This form will use the first line matching the given POSIX regex. If <start> is a regex, it will search from the end of the previous -L range, if any, otherwise from the start of file. If <start> is ^/regex/, it will search from the start of file. If <end> is a regex, it will search starting at the line given by <start>. \u2022 +offset or -offset This is only valid for <end> and will specify a number of lines before or after the line given by <start>. If :<funcname> is given in place of <start> and <end>, it is a regular expression that denotes the range from the first funcname line that matches <funcname>, up to the next funcname line. :<funcname> searches from the end of the previous -L range, if any, otherwise from the start of file. ^:<funcname> searches from the start of file. The function names are determined in the same way as git diff works out patch hunk headers (see Defining a custom hunk-header in gitattributes(5)). <revision-range> Show only commits in the specified revision range. When no <revision-range> is specified, it defaults to HEAD (i.e. the whole history leading to the current commit). origin..HEAD specifies all the commits reachable from the current commit (i.e. HEAD), but not from origin. For a complete list of ways to spell <revision-range>, see the Specifying Ranges section of gitrevisions(7). [--] <path>... Show only commits that are enough to explain how the files that match the specified paths came to be. See History Simplification below for details and other simplification modes. Paths may need to be prefixed with -- to separate them from options or the revision range, when confusion arises. Commit Limiting Besides specifying a range of commits that should be listed using the special notations explained in the description, additional commit limiting may be applied. Using more options generally further limits the output (e.g. --since=<date1> limits to commits newer than <date1>, and using it with --grep=<pattern> further limits to commits whose log message has a line that matches <pattern>), unless otherwise noted. Note that these are applied before commit ordering and formatting options, such as --reverse. -<number>, -n <number>, --max-count=<number> Limit the number of commits to output. --skip=<number> Skip number commits before starting to show the commit output. --since=<date>, --after=<date> Show commits more recent than a specific date. --since-as-filter=<date> Show all commits more recent than a specific date. This visits all commits in the range, rather than stopping at the first commit which is older than a specific date. --until=<date>, --before=<date> Show commits older than a specific date. --author=<pattern>, --committer=<pattern> Limit the commits output to ones with author/committer header lines that match the specified pattern (regular expression). With more than one --author=<pattern>, commits whose author matches any of the given patterns are chosen (similarly for multiple --committer=<pattern>). --grep-reflog=<pattern> Limit the commits output to ones with reflog entries that match the specified pattern (regular expression). With more than one --grep-reflog, commits whose reflog message matches any of the given patterns are chosen. It is an error to use this option unless --walk-reflogs is in use. --grep=<pattern> Limit the commits output to ones with log message that matches the specified pattern (regular expression). With more than one --grep=<pattern>, commits whose message matches any of the given patterns are chosen (but see --all-match). When --notes is in effect, the message from the notes is matched as if it were part of the log message. --all-match Limit the commits output to ones that match all given --grep, instead of ones that match at least one. --invert-grep Limit the commits output to ones with log message that do not match the pattern specified with --grep=<pattern>. -i, --regexp-ignore-case Match the regular expression limiting patterns without regard to letter case. --basic-regexp Consider the limiting patterns to be basic regular expressions; this is the default. -E, --extended-regexp Consider the limiting patterns to be extended regular expressions instead of the default basic regular expressions. -F, --fixed-strings Consider the limiting patterns to be fixed strings (don\u2019t interpret pattern as a regular expression). -P, --perl-regexp Consider the limiting patterns to be Perl-compatible regular expressions. Support for these types of regular expressions is an optional compile-time dependency. If Git wasn\u2019t compiled with support for them providing this option will cause it to die. --remove-empty Stop when a given path disappears from the tree. --merges Print only merge commits. This is exactly the same as --min-parents=2. --no-merges Do not print commits with more than one parent. This is exactly the same as --max-parents=1. --min-parents=<number>, --max-parents=<number>, --no-min-parents, --no-max-parents Show only commits which have at least (or at most) that many parent commits. In particular, --max-parents=1 is the same as --no-merges, --min-parents=2 is the same as --merges. --max-parents=0 gives all root commits and --min-parents=3 all octopus merges. --no-min-parents and --no-max-parents reset these limits (to no limit) again. Equivalent forms are --min-parents=0 (any commit has 0 or more parents) and --max-parents=-1 (negative numbers denote no upper limit). --first-parent When finding commits to include, follow only the first parent commit upon seeing a merge commit. This option can give a better overview when viewing the evolution of a particular topic branch, because merges into a topic branch tend to be only about adjusting to updated upstream from time to time, and this option allows you to ignore the individual commits brought in to your history by such a merge. This option also changes default diff format for merge commits to first-parent, see --diff-merges=first-parent for details. --exclude-first-parent-only When finding commits to exclude (with a ^), follow only the first parent commit upon seeing a merge commit. This can be used to find the set of changes in a topic branch from the point where it diverged from the remote branch, given that arbitrary merges can be valid topic branch changes. --not Reverses the meaning of the ^ prefix (or lack thereof) for all following revision specifiers, up to the next --not. --all Pretend as if all the refs in refs/, along with HEAD, are listed on the command line as <commit>. --branches[=<pattern>] Pretend as if all the refs in refs/heads are listed on the command line as <commit>. If <pattern> is given, limit branches to ones matching given shell glob. If pattern lacks ?, *, or [, /* at the end is implied. --tags[=<pattern>] Pretend as if all the refs in refs/tags are listed on the command line as <commit>. If <pattern> is given, limit tags to ones matching given shell glob. If pattern lacks ?, *, or [, /* at the end is implied. --remotes[=<pattern>] Pretend as if all the refs in refs/remotes are listed on the command line as <commit>. If <pattern> is given, limit remote-tracking branches to ones matching given shell glob. If pattern lacks ?, *, or [, /* at the end is implied. --glob=<glob-pattern> Pretend as if all the refs matching shell glob <glob-pattern> are listed on the command line as <commit>. Leading refs/, is automatically prepended if missing. If pattern lacks ?, *, or [, /* at the end is implied. --exclude=<glob-pattern> Do not include refs matching <glob-pattern> that the next --all, --branches, --tags, --remotes, or --glob would otherwise consider. Repetitions of this option accumulate exclusion patterns up to the next --all, --branches, --tags, --remotes, or --glob option (other options or arguments do not clear accumulated patterns). The patterns given should not begin with refs/heads, refs/tags, or refs/remotes when applied to --branches, --tags, or --remotes, respectively, and they must begin with refs/ when applied to --glob or --all. If a trailing /* is intended, it must be given explicitly. --exclude-hidden=[fetch|receive|uploadpack] Do not include refs that would be hidden by git-fetch, git-receive-pack or git-upload-pack by consulting the appropriate fetch.hideRefs, receive.hideRefs or uploadpack.hideRefs configuration along with transfer.hideRefs (see git-config(1)). This option affects the next pseudo-ref option --all or --glob and is cleared after processing them. --reflog Pretend as if all objects mentioned by reflogs are listed on the command line as <commit>. --alternate-refs Pretend as if all objects mentioned as ref tips of alternate repositories were listed on the command line. An alternate repository is any repository whose object directory is specified in objects/info/alternates. The set of included objects may be modified by core.alternateRefsCommand, etc. See git-config(1). --single-worktree By default, all working trees will be examined by the following options when there are more than one (see git-worktree(1)): --all, --reflog and --indexed-objects. This option forces them to examine the current working tree only. --ignore-missing Upon seeing an invalid object name in the input, pretend as if the bad input was not given. --bisect Pretend as if the bad bisection ref refs/bisect/bad was listed and as if it was followed by --not and the good bisection refs refs/bisect/good-* on the command line. --stdin In addition to the <commit> listed on the command line, read them from the standard input. If a -- separator is seen, stop reading commits and start reading paths to limit the result. --cherry-mark Like --cherry-pick (see below) but mark equivalent commits with = rather than omitting them, and inequivalent ones with +. --cherry-pick Omit any commit that introduces the same change as another commit on the \u201cother side\u201d when the set of commits are limited with symmetric difference. For example, if you have two branches, A and B, a usual way to list all commits on only one side of them is with --left-right (see the example below in the description of the --left-right option). However, it shows the commits that were cherry-picked from the other branch (for example, \u201c3rd on b\u201d may be cherry-picked from branch A). With this option, such pairs of commits are excluded from the output. --left-only, --right-only List only commits on the respective side of a symmetric difference, i.e. only those which would be marked < resp. > by --left-right. For example, --cherry-pick --right-only A...B omits those commits from B which are in A or are patch-equivalent to a commit in A. In other words, this lists the + commits from git cherry A B. More precisely, --cherry-pick --right-only --no-merges gives the exact list. --cherry A synonym for --right-only --cherry-mark --no-merges; useful to limit the output to the commits on our side and mark those that have been applied to the other side of a forked history with git log --cherry upstream...mybranch, similar to git cherry upstream mybranch. -g, --walk-reflogs Instead of walking the commit ancestry chain, walk reflog entries from the most recent one to older ones. When this option is used you cannot specify commits to exclude (that is, ^commit, commit1..commit2, and commit1...commit2 notations cannot be used). With --pretty format other than oneline and reference (for obvious reasons), this causes the output to have two extra lines of information taken from the reflog. The reflog designator in the output may be shown as ref@{Nth} (where Nth is the reverse-chronological index in the reflog) or as ref@{timestamp} (with the timestamp for that entry), depending on a few rules: 1. If the starting point is specified as ref@{Nth}, show the index format. 2. If the starting point was specified as ref@{now}, show the timestamp format. 3. If neither was used, but --date was given on the command line, show the timestamp in the format requested by --date. 4. Otherwise, show the index format. Under --pretty=oneline, the commit message is prefixed with this information on the same line. This option cannot be combined with --reverse. See also git-reflog(1). Under --pretty=reference, this information will not be shown at all. --merge After a failed merge, show refs that touch files having a conflict and don\u2019t exist on all heads to merge. --boundary Output excluded boundary commits. Boundary commits are prefixed with -. History Simplification Sometimes you are only interested in parts of the history, for example the commits modifying a particular <path>. But there are two parts of History Simplification, one part is selecting the commits and the other is how to do it, as there are various strategies to simplify the history. The following options select the commits to be shown: <paths> Commits modifying the given <paths> are selected. --simplify-by-decoration Commits that are referred by some branch or tag are selected. Note that extra commits can be shown to give a meaningful history. The following options affect the way the simplification is performed: Default mode Simplifies the history to the simplest history explaining the final state of the tree. Simplest because it prunes some side branches if the end result is the same (i.e. merging branches with the same content) --show-pulls Include all commits from the default mode, but also any merge commits that are not TREESAME to the first parent but are TREESAME to a later parent. This mode is helpful for showing the merge commits that \"first introduced\" a change to a branch. --full-history Same as the default mode, but does not prune some history. --dense Only the selected commits are shown, plus some to have a meaningful history. --sparse All commits in the simplified history are shown. --simplify-merges Additional option to --full-history to remove some needless merges from the resulting history, as there are no selected commits contributing to this merge. --ancestry-path[=<commit>] When given a range of commits to display (e.g. commit1..commit2 or commit2 ^commit1), only display commits in that range that are ancestors of <commit>, descendants of <commit>, or <commit> itself. If no commit is specified, use commit1 (the excluded part of the range) as <commit>. Can be passed multiple times; if so, a commit is included if it is any of the commits given or if it is an ancestor or descendant of one of them. A more detailed explanation follows. Suppose you specified foo as the <paths>. We shall call commits that modify foo !TREESAME, and the rest TREESAME. (In a diff filtered for foo, they look different and equal, respectively.) In the following, we will always refer to the same example history to illustrate the differences between simplification settings. We assume that you are filtering for a file foo in this commit graph: .-A---M---N---O---P---Q / / / / / / I B C D E Y \\ / / / / / `-------------' X The horizontal line of history A---Q is taken to be the first parent of each merge. The commits are: \u2022 I is the initial commit, in which foo exists with contents \u201casdf\u201d, and a file quux exists with contents \u201cquux\u201d. Initial commits are compared to an empty tree, so I is !TREESAME. \u2022 In A, foo contains just \u201cfoo\u201d. \u2022 B contains the same change as A. Its merge M is trivial and hence TREESAME to all parents. \u2022 C does not change foo, but its merge N changes it to \u201cfoobar\u201d, so it is not TREESAME to any parent. \u2022 D sets foo to \u201cbaz\u201d. Its merge O combines the strings from N and D to \u201cfoobarbaz\u201d; i.e., it is not TREESAME to any parent. \u2022 E changes quux to \u201cxyzzy\u201d, and its merge P combines the strings to \u201cquux xyzzy\u201d. P is TREESAME to O, but not to E. \u2022 X is an independent root commit that added a new file side, and Y modified it. Y is TREESAME to X. Its merge Q added side to P, and Q is TREESAME to P, but not to Y. rev-list walks backwards through history, including or excluding commits based on whether --full-history and/or parent rewriting (via --parents or --children) are used. The following settings are available. Default mode Commits are included if they are not TREESAME to any parent (though this can be changed, see --sparse below). If the commit was a merge, and it was TREESAME to one parent, follow only that parent. (Even if there are several TREESAME parents, follow only one of them.) Otherwise, follow all parents. This results in: .-A---N---O / / / I---------D Note how the rule to only follow the TREESAME parent, if one is available, removed B from consideration entirely. C was considered via N, but is TREESAME. Root commits are compared to an empty tree, so I is !TREESAME. Parent/child relations are only visible with --parents, but that does not affect the commits selected in default mode, so we have shown the parent lines. --full-history without parent rewriting This mode differs from the default in one point: always follow all parents of a merge, even if it is TREESAME to one of them. Even if more than one side of the merge has commits that are included, this does not imply that the merge itself is! In the example, we get I A B N D O P Q M was excluded because it is TREESAME to both parents. E, C and B were all walked, but only B was !TREESAME, so the others do not appear. Note that without parent rewriting, it is not really possible to talk about the parent/child relationships between the commits, so we show them disconnected. --full-history with parent rewriting Ordinary commits are only included if they are !TREESAME (though this can be changed, see --sparse below). Merges are always included. However, their parent list is rewritten: Along each parent, prune away commits that are not included themselves. This results in .-A---M---N---O---P---Q / / / / / I B / D / \\ / / / / `-------------' Compare to --full-history without rewriting above. Note that E was pruned away because it is TREESAME, but the parent list of P was rewritten to contain E's parent I. The same happened for C and N, and X, Y and Q. In addition to the above settings, you can change whether TREESAME affects inclusion: --dense Commits that are walked are included if they are not TREESAME to any parent. --sparse All commits that are walked are included. Note that without --full-history, this still simplifies merges: if one of the parents is TREESAME, we follow only that one, so the other sides of the merge are never walked. --simplify-merges First, build a history graph in the same way that --full-history with parent rewriting does (see above). Then simplify each commit C to its replacement C' in the final history according to the following rules: \u2022 Set C' to C. \u2022 Replace each parent P of C' with its simplification P'. In the process, drop parents that are ancestors of other parents or that are root commits TREESAME to an empty tree, and remove duplicates, but take care to never drop all parents that we are TREESAME to. \u2022 If after this parent rewriting, C' is a root or merge commit (has zero or >1 parents), a boundary commit, or !TREESAME, it remains. Otherwise, it is replaced with its only parent. The effect of this is best shown by way of comparing to --full-history with parent rewriting. The example turns into: .-A---M---N---O / / / I B D \\ / / `---------' Note the major differences in N, P, and Q over --full-history: \u2022 N's parent list had I removed, because it is an ancestor of the other parent M. Still, N remained because it is !TREESAME. \u2022 P's parent list similarly had I removed. P was then removed completely, because it had one parent and is TREESAME. \u2022 Q's parent list had Y simplified to X. X was then removed, because it was a TREESAME root. Q was then removed completely, because it had one parent and is TREESAME. There is another simplification mode available: --ancestry-path[=<commit>] Limit the displayed commits to those which are an ancestor of <commit>, or which are a descendant of <commit>, or are <commit> itself. As an example use case, consider the following commit history: D---E-------F / \\ \\ B---C---G---H---I---J / \\ A-------K---------------L--M A regular D..M computes the set of commits that are ancestors of M, but excludes the ones that are ancestors of D. This is useful to see what happened to the history leading to M since D, in the sense that \u201cwhat does M have that did not exist in D\u201d. The result in this example would be all the commits, except A and B (and D itself, of course). When we want to find out what commits in M are contaminated with the bug introduced by D and need fixing, however, we might want to view only the subset of D..M that are actually descendants of D, i.e. excluding C and K. This is exactly what the --ancestry-path option does. Applied to the D..M range, it results in: E-------F \\ \\ G---H---I---J \\ L--M We can also use --ancestry-path=D instead of --ancestry-path which means the same thing when applied to the D..M range but is just more explicit. If we instead are interested in a given topic within this range, and all commits affected by that topic, we may only want to view the subset of D..M which contain that topic in their ancestry path. So, using --ancestry-path=H D..M for example would result in: E \\ G---H---I---J \\ L--M Whereas --ancestry-path=K D..M would result in K---------------L--M Before discussing another option, --show-pulls, we need to create a new example history. A common problem users face when looking at simplified history is that a commit they know changed a file somehow does not appear in the file\u2019s simplified history. Let\u2019s demonstrate a new example and show how options such as --full-history and --simplify-merges works in that case: .-A---M-----C--N---O---P / / \\ \\ \\/ / / I B \\ R-'`-Z' / \\ / \\/ / \\ / /\\ / `---X--' `---Y--' For this example, suppose I created file.txt which was modified by A, B, and X in different ways. The single-parent commits C, Z, and Y do not change file.txt. The merge commit M was created by resolving the merge conflict to include both changes from A and B and hence is not TREESAME to either. The merge commit R, however, was created by ignoring the contents of file.txt at M and taking only the contents of file.txt at X. Hence, R is TREESAME to X but not M. Finally, the natural merge resolution to create N is to take the contents of file.txt at R, so N is TREESAME to R but not C. The merge commits O and P are TREESAME to their first parents, but not to their second parents, Z and Y respectively. When using the default mode, N and R both have a TREESAME parent, so those edges are walked and the others are ignored. The resulting history graph is: I---X When using --full-history, Git walks every edge. This will discover the commits A and B and the merge M, but also will reveal the merge commits O and P. With parent rewriting, the resulting graph is: .-A---M--------N---O---P / / \\ \\ \\/ / / I B \\ R-'`--' / \\ / \\/ / \\ / /\\ / `---X--' `------' Here, the merge commits O and P contribute extra noise, as they did not actually contribute a change to file.txt. They only merged a topic that was based on an older version of file.txt. This is a common issue in repositories using a workflow where many contributors work in parallel and merge their topic branches along a single trunk: many unrelated merges appear in the --full-history results. When using the --simplify-merges option, the commits O and P disappear from the results. This is because the rewritten second parents of O and P are reachable from their first parents. Those edges are removed and then the commits look like single-parent commits that are TREESAME to their parent. This also happens to the commit N, resulting in a history view as follows: .-A---M--. / / \\ I B R \\ / / \\ / / `---X--' In this view, we see all of the important single-parent changes from A, B, and X. We also see the carefully-resolved merge M and the not-so-carefully-resolved merge R. This is usually enough information to determine why the commits A and B \"disappeared\" from history in the default view. However, there are a few issues with this approach. The first issue is performance. Unlike any previous option, the --simplify-merges option requires walking the entire commit history before returning a single result. This can make the option difficult to use for very large repositories. The second issue is one of auditing. When many contributors are working on the same repository, it is important which merge commits introduced a change into an important branch. The problematic merge R above is not likely to be the merge commit that was used to merge into an important branch. Instead, the merge N was used to merge R and X into the important branch. This commit may have information about why the change X came to override the changes from A and B in its commit message. --show-pulls In addition to the commits shown in the default history, show each merge commit that is not TREESAME to its first parent but is TREESAME to a later parent. When a merge commit is included by --show-pulls, the merge is treated as if it \"pulled\" the change from another branch. When using --show-pulls on this example (and no other options) the resulting graph is: I---X---R---N Here, the merge commits R and N are included because they pulled the commits X and R into the base branch, respectively. These merges are the reason the commits A and B do not appear in the default history. When --show-pulls is paired with --simplify-merges, the graph includes all of the necessary information: .-A---M--. N / / \\ / I B R \\ / / \\ / / `---X--' Notice that since M is reachable from R, the edge from N to M was simplified away. However, N still appears in the history as an important commit because it \"pulled\" the change R into the main branch. The --simplify-by-decoration option allows you to view only the big picture of the topology of the history, by omitting commits that are not referenced by tags. Commits are marked as !TREESAME (in other words, kept after history simplification rules described above) if (1) they are referenced by tags, or (2) they change the contents of the paths given on the command line. All other commits are marked as TREESAME (subject to be simplified away). Commit Ordering By default, the commits are shown in reverse chronological order. --date-order Show no parents before all of its children are shown, but otherwise show commits in the commit timestamp order. --author-date-order Show no parents before all of its children are shown, but otherwise show commits in the author timestamp order. --topo-order Show no parents before all of its children are shown, and avoid showing commits on multiple lines of history intermixed. For example, in a commit history like this: ---1----2----4----7 \\ \\ 3----5----6----8--- where the numbers denote the order of commit timestamps, git rev-list and friends with --date-order show the commits in the timestamp order: 8 7 6 5 4 3 2 1. With --topo-order, they would show 8 6 5 3 7 4 2 1 (or 8 7 4 2 6 5 3 1); some older commits are shown before newer ones in order to avoid showing the commits from two parallel development track mixed together. --reverse Output the commits chosen to be shown (see Commit Limiting section above) in reverse order. Cannot be combined with --walk-reflogs. Object Traversal These options are mostly targeted for packing of Git repositories. --no-walk[=(sorted|unsorted)] Only show the given commits, but do not traverse their ancestors. This has no effect if a range is specified. If the argument unsorted is given, the commits are shown in the order they were given on the command line. Otherwise (if sorted or no argument was given), the commits are shown in reverse chronological order by commit time. Cannot be combined with --graph. --do-walk Overrides a previous --no-walk. Commit Formatting --pretty[=<format>], --format=<format> Pretty-print the contents of the commit logs in a given format, where <format> can be one of oneline, short, medium, full, fuller, reference, email, raw, format:<string> and tformat:<string>. When <format> is none of the above, and has %placeholder in it, it acts as if --pretty=tformat:<format> were given. See the \"PRETTY FORMATS\" section for some additional details for each format. When =<format> part is omitted, it defaults to medium. Note: you can specify the default pretty format in the repository configuration (see git-config(1)). --abbrev-commit Instead of showing the full 40-byte hexadecimal commit object name, show a prefix that names the object uniquely. \"--abbrev=<n>\" (which also modifies diff output, if it is displayed) option can be used to specify the minimum length of the prefix. This should make \"--pretty=oneline\" a whole lot more readable for people using 80-column terminals. --no-abbrev-commit Show the full 40-byte hexadecimal commit object name. This negates --abbrev-commit, either explicit or implied by other options such as \"--oneline\". It also overrides the log.abbrevCommit variable. --oneline This is a shorthand for \"--pretty=oneline --abbrev-commit\" used together. --encoding=<encoding> Commit objects record the character encoding used for the log message in their encoding header; this option can be used to tell the command to re-code the commit log message in the encoding preferred by the user. For non plumbing commands this defaults to UTF-8. Note that if an object claims to be encoded in X and we are outputting in X, we will output the object verbatim; this means that invalid sequences in the original commit may be copied to the output. Likewise, if iconv(3) fails to convert the commit, we will quietly output the original object verbatim. --expand-tabs=<n>, --expand-tabs, --no-expand-tabs Perform a tab expansion (replace each tab with enough spaces to fill to the next display column that is multiple of <n>) in the log message before showing it in the output. --expand-tabs is a short-hand for --expand-tabs=8, and --no-expand-tabs is a short-hand for --expand-tabs=0, which disables tab expansion. By default, tabs are expanded in pretty formats that indent the log message by 4 spaces (i.e. medium, which is the default, full, and fuller). --notes[=<ref>] Show the notes (see git-notes(1)) that annotate the commit, when showing the commit log message. This is the default for git log, git show and git whatchanged commands when there is no --pretty, --format, or --oneline option given on the command line. By default, the notes shown are from the notes refs listed in the core.notesRef and notes.displayRef variables (or corresponding environment overrides). See git-config(1) for more details. With an optional <ref> argument, use the ref to find the notes to display. The ref can specify the full refname when it begins with refs/notes/; when it begins with notes/, refs/ and otherwise refs/notes/ is prefixed to form a full name of the ref. Multiple --notes options can be combined to control which notes are being displayed. Examples: \"--notes=foo\" will show only notes from \"refs/notes/foo\"; \"--notes=foo --notes\" will show both notes from \"refs/notes/foo\" and from the default notes ref(s). --no-notes Do not show notes. This negates the above --notes option, by resetting the list of notes refs from which notes are shown. Options are parsed in the order given on the command line, so e.g. \"--notes --notes=foo --no-notes --notes=bar\" will only show notes from \"refs/notes/bar\". --show-notes[=<ref>], --[no-]standard-notes These options are deprecated. Use the above --notes/--no-notes options instead. --show-signature Check the validity of a signed commit object by passing the signature to gpg --verify and show the output. --relative-date Synonym for --date=relative. --date=<format> Only takes effect for dates shown in human-readable format, such as when using --pretty. log.date config variable sets a default value for the log command\u2019s --date option. By default, dates are shown in the original time zone (either committer\u2019s or author\u2019s). If -local is appended to the format (e.g., iso-local), the user\u2019s local time zone is used instead. --date=relative shows dates relative to the current time, e.g. \u201c2 hours ago\u201d. The -local option has no effect for --date=relative. --date=local is an alias for --date=default-local. --date=iso (or --date=iso8601) shows timestamps in a ISO 8601-like format. The differences to the strict ISO 8601 format are: \u2022 a space instead of the T date/time delimiter \u2022 a space between time and time zone \u2022 no colon between hours and minutes of the time zone --date=iso-strict (or --date=iso8601-strict) shows timestamps in strict ISO 8601 format. --date=rfc (or --date=rfc2822) shows timestamps in RFC 2822 format, often found in email messages. --date=short shows only the date, but not the time, in YYYY-MM-DD format. --date=raw shows the date as seconds since the epoch (1970-01-01 00:00:00 UTC), followed by a space, and then the timezone as an offset from UTC (a + or - with four digits; the first two are hours, and the second two are minutes). I.e., as if the timestamp were formatted with strftime(\"%s %z\")). Note that the -local option does not affect the seconds-since-epoch value (which is always measured in UTC), but does switch the accompanying timezone value. --date=human shows the timezone if the timezone does not match the current time-zone, and doesn\u2019t print the whole date if that matches (ie skip printing year for dates that are \"this year\", but also skip the whole date itself if it\u2019s in the last few days and we can just say what weekday it was). For older dates the hour and minute is also omitted. --date=unix shows the date as a Unix epoch timestamp (seconds since 1970). As with --raw, this is always in UTC and therefore -local has no effect. --date=format:... feeds the format ... to your system strftime, except for %s, %z, and %Z, which are handled internally. Use --date=format:%c to show the date in your system locale\u2019s preferred format. See the strftime manual for a complete list of format placeholders. When using -local, the correct syntax is --date=format-local:.... --date=default is the default format, and is based on ctime(3) output. It shows a single line with three-letter day of the week, three-letter month, day-of-month, hour-minute-seconds in \"HH:MM:SS\" format, followed by 4-digit year, plus timezone information, unless the local time zone is used, e.g. Thu Jan 1 00:00:00 1970 +0000. --parents Print also the parents of the commit (in the form \"commit parent...\"). Also enables parent rewriting, see History Simplification above. --children Print also the children of the commit (in the form \"commit child...\"). Also enables parent rewriting, see History Simplification above. --left-right Mark which side of a symmetric difference a commit is reachable from. Commits from the left side are prefixed with < and those from the right with >. If combined with --boundary, those commits are prefixed with -. For example, if you have this topology: y---b---b branch B / \\ / / . / / \\ o---x---a---a branch A you would get an output like this: $ git rev-list --left-right --boundary --pretty=oneline A...B >bbbbbbb... 3rd on b >bbbbbbb... 2nd on b <aaaaaaa... 3rd on a <aaaaaaa... 2nd on a -yyyyyyy... 1st on b -xxxxxxx... 1st on a --graph Draw a text-based graphical representation of the commit history on the left hand side of the output. This may cause extra lines to be printed in between commits, in order for the graph history to be drawn properly. Cannot be combined with --no-walk. This enables parent rewriting, see History Simplification above. This implies the --topo-order option by default, but the --date-order option may also be specified. --show-linear-break[=<barrier>] When --graph is not used, all history branches are flattened which can make it hard to see that the two consecutive commits do not belong to a linear branch. This option puts a barrier in between them in that case. If <barrier> is specified, it is the string that will be shown instead of the default one. "
  },
  {
    "command": "quota",
    "description": " quota displays users' disk usage and limits. By default only the user quotas are printed. By default space usage and limits are shown in kbytes (and are named blocks for historical reasons). quota reports the quotas of all the filesystems listed in /etc/mtab. For filesystems that are NFS-mounted a call to the rpc.rquotad on the server machine is performed to get the information. -F, --format=format-name Show quota for specified format (ie. don't perform format autodetection). Possible format names are: vfsold Original quota format with 16-bit UIDs / GIDs, vfsv0 Quota format with 32-bit UIDs / GIDs, 64-bit space usage, 32-bit inode usage and limits, vfsv1 Quota format with 64-bit quota limits and usage, rpc (quota over NFS), xfs (quota on XFS filesystem) -g, --group Print group quotas for the group of which the user is a member. The optional group argument(s) restricts the display to the specified group(s). -u, --user flag is equivalent to the default. -P, --project Print project quotas for the specified project. -v, --verbose will display quotas on filesystems where no storage is allocated. -s, --human-readable[=units] option will make quota(1) try to choose units for showing limits, used space and used inodes. Units can be also specified explicitely by an optional argument in format [ kgt ],[ kgt ] where the first character specifies space units and the second character specifies inode units. --always-resolve Always try to translate user / group name to uid / gid even if the name is composed of digits only. -p, --raw-grace When user is in grace period, report time in seconds since epoch when his grace time runs out (or has run out). Field is '0' when no grace time is in effect. This is especially useful when parsing output by a script. -i, --no-autofs ignore mountpoints mounted by automounter -l, --local-only report quotas only on local filesystems (ie. ignore NFS mounted filesystems). -A, --all-nfs report quotas for all NFS filesystems even if they report to be on the same device. -f, --filesystem-list report quotas only for filesystems specified on command line. --filesystem=path report quotas only for filesystem path. This option can be specified multiple types and quota will be reported for each specified filesystem. Unlike command line option -f remaining command like arguments are still treated as user / group / project names to report. -m, --no-mixed-pathnames Currently, pathnames of NFSv4 mountpoints are sent without leading slash in the path. rpc.rquotad uses this to recognize NFSv4 mounts and properly prepend pseudoroot of NFS filesystem to the path. If you specify this option, quota will always send paths with a leading slash. This can be useful for legacy reasons but be aware that quota over RPC will stop working if you are using new rpc.rquotad. -q, --quiet Print a more terse message, containing only information on filesystems where usage is over quota. -Q, --quiet-refuse Do not print error message if connection to rpc.rquotad is refused (usually this happens when rpc.rquotad is not running on the server). -w, --no-wrap Do not wrap the line if the device name is too long. This can be useful when parsing the output of quota(1) by a script. --show-mntpoint Show also mount point as a filesystem identification. --hide-device Do not show device name in a filesystem identification. Specifying both -g and -u displays both the user quotas and the group quotas (for the user). Only the super-user may use the -u flag and the optional user argument to view the limits of other users. Also viewing of project quota usage and limits is limited to super-user only. Non-super-users can use the -g flag and optional group argument to view only the limits of groups of which they are members. The -q flag takes precedence over the -v flag. "
  },
  {
    "command": "git-format-patch",
    "description": " Prepare each non-merge commit with its \"patch\" in one \"message\" per commit, formatted to resemble a UNIX mailbox. The output of this command is convenient for e-mail submission or for use with git am. A \"message\" generated by the command consists of three parts: \u2022 A brief metadata header that begins with From <commit> with a fixed Mon Sep 17 00:00:00 2001 datestamp to help programs like \"file(1)\" to recognize that the file is an output from this command, fields that record the author identity, the author date, and the title of the change (taken from the first paragraph of the commit log message). \u2022 The second and subsequent paragraphs of the commit log message. \u2022 The \"patch\", which is the \"diff -p --stat\" output (see git-diff(1)) between the commit and its parent. The log message and the patch is separated by a line with a three-dash line. There are two ways to specify which commits to operate on. 1. A single commit, <since>, specifies that the commits leading to the tip of the current branch that are not in the history that leads to the <since> to be output. 2. Generic <revision range> expression (see \"SPECIFYING REVISIONS\" section in gitrevisions(7)) means the commits in the specified range. The first rule takes precedence in the case of a single <commit>. To apply the second rule, i.e., format everything since the beginning of history up until <commit>, use the --root option: git format-patch --root <commit>. If you want to format only <commit> itself, you can do this with git format-patch -1 <commit>. By default, each output file is numbered sequentially from 1, and uses the first line of the commit message (massaged for pathname safety) as the filename. With the --numbered-files option, the output file names will only be numbers, without the first line of the commit appended. The names of the output files are printed to standard output, unless the --stdout option is specified. If -o is specified, output files are created in <dir>. Otherwise they are created in the current working directory. The default path can be set with the format.outputDirectory configuration option. The -o option takes precedence over format.outputDirectory. To store patches in the current working directory even when format.outputDirectory points elsewhere, use -o .. All directory components will be created. By default, the subject of a single patch is \"[PATCH] \" followed by the concatenation of lines from the commit message up to the first blank line (see the DISCUSSION section of git-commit(1)). When multiple patches are output, the subject prefix will instead be \"[PATCH n/m] \". To force 1/1 to be added for a single patch, use -n. To omit patch numbers from the subject, use -N. If given --thread, git-format-patch will generate In-Reply-To and References headers to make the second and subsequent patch mails appear as replies to the first mail; this also generates a Message-ID header to reference. -p, --no-stat Generate plain patches without any diffstats. -U<n>, --unified=<n> Generate diffs with <n> lines of context instead of the usual three. --output=<file> Output to a specific file instead of stdout. --output-indicator-new=<char>, --output-indicator-old=<char>, --output-indicator-context=<char> Specify the character used to indicate new, old or context lines in the generated patch. Normally they are +, - and ' ' respectively. --indent-heuristic Enable the heuristic that shifts diff hunk boundaries to make patches easier to read. This is the default. --no-indent-heuristic Disable the indent heuristic. --minimal Spend extra time to make sure the smallest possible diff is produced. --patience Generate a diff using the \"patience diff\" algorithm. --histogram Generate a diff using the \"histogram diff\" algorithm. --anchored=<text> Generate a diff using the \"anchored diff\" algorithm. This option may be specified more than once. If a line exists in both the source and destination, exists only once, and starts with this text, this algorithm attempts to prevent it from appearing as a deletion or addition in the output. It uses the \"patience diff\" algorithm internally. --diff-algorithm={patience|minimal|histogram|myers} Choose a diff algorithm. The variants are as follows: default, myers The basic greedy diff algorithm. Currently, this is the default. minimal Spend extra time to make sure the smallest possible diff is produced. patience Use \"patience diff\" algorithm when generating patches. histogram This algorithm extends the patience algorithm to \"support low-occurrence common elements\". For instance, if you configured the diff.algorithm variable to a non-default value and want to use the default one, then you have to use --diff-algorithm=default option. --stat[=<width>[,<name-width>[,<count>]]] Generate a diffstat. By default, as much space as necessary will be used for the filename part, and the rest for the graph part. Maximum width defaults to terminal width, or 80 columns if not connected to a terminal, and can be overridden by <width>. The width of the filename part can be limited by giving another width <name-width> after a comma. The width of the graph part can be limited by using --stat-graph-width=<width> (affects all commands generating a stat graph) or by setting diff.statGraphWidth=<width> (does not affect git format-patch). By giving a third parameter <count>, you can limit the output to the first <count> lines, followed by ... if there are more. These parameters can also be set individually with --stat-width=<width>, --stat-name-width=<name-width> and --stat-count=<count>. --compact-summary Output a condensed summary of extended header information such as file creations or deletions (\"new\" or \"gone\", optionally \"+l\" if it\u2019s a symlink) and mode changes (\"+x\" or \"-x\" for adding or removing executable bit respectively) in diffstat. The information is put between the filename part and the graph part. Implies --stat. --numstat Similar to --stat, but shows number of added and deleted lines in decimal notation and pathname without abbreviation, to make it more machine friendly. For binary files, outputs two - instead of saying 0 0. --shortstat Output only the last line of the --stat format containing total number of modified files, as well as number of added and deleted lines. -X[<param1,param2,...>], --dirstat[=<param1,param2,...>] Output the distribution of relative amount of changes for each sub-directory. The behavior of --dirstat can be customized by passing it a comma separated list of parameters. The defaults are controlled by the diff.dirstat configuration variable (see git-config(1)). The following parameters are available: changes Compute the dirstat numbers by counting the lines that have been removed from the source, or added to the destination. This ignores the amount of pure code movements within a file. In other words, rearranging lines in a file is not counted as much as other changes. This is the default behavior when no parameter is given. lines Compute the dirstat numbers by doing the regular line-based diff analysis, and summing the removed/added line counts. (For binary files, count 64-byte chunks instead, since binary files have no natural concept of lines). This is a more expensive --dirstat behavior than the changes behavior, but it does count rearranged lines within a file as much as other changes. The resulting output is consistent with what you get from the other --*stat options. files Compute the dirstat numbers by counting the number of files changed. Each changed file counts equally in the dirstat analysis. This is the computationally cheapest --dirstat behavior, since it does not have to look at the file contents at all. cumulative Count changes in a child directory for the parent directory as well. Note that when using cumulative, the sum of the percentages reported may exceed 100%. The default (non-cumulative) behavior can be specified with the noncumulative parameter. <limit> An integer parameter specifies a cut-off percent (3% by default). Directories contributing less than this percentage of the changes are not shown in the output. Example: The following will count changed files, while ignoring directories with less than 10% of the total amount of changed files, and accumulating child directory counts in the parent directories: --dirstat=files,10,cumulative. --cumulative Synonym for --dirstat=cumulative --dirstat-by-file[=<param1,param2>...] Synonym for --dirstat=files,param1,param2... --summary Output a condensed summary of extended header information such as creations, renames and mode changes. --no-renames Turn off rename detection, even when the configuration file gives the default to do so. --[no-]rename-empty Whether to use empty blobs as rename source. --full-index Instead of the first handful of characters, show the full pre- and post-image blob object names on the \"index\" line when generating patch format output. --binary In addition to --full-index, output a binary diff that can be applied with git-apply. --abbrev[=<n>] Instead of showing the full 40-byte hexadecimal object name in diff-raw format output and diff-tree header lines, show the shortest prefix that is at least <n> hexdigits long that uniquely refers the object. In diff-patch output format, --full-index takes higher precedence, i.e. if --full-index is specified, full blob names will be shown regardless of --abbrev. Non default number of digits can be specified with --abbrev=<n>. -B[<n>][/<m>], --break-rewrites[=[<n>][/<m>]] Break complete rewrite changes into pairs of delete and create. This serves two purposes: It affects the way a change that amounts to a total rewrite of a file not as a series of deletion and insertion mixed together with a very few lines that happen to match textually as the context, but as a single deletion of everything old followed by a single insertion of everything new, and the number m controls this aspect of the -B option (defaults to 60%). -B/70% specifies that less than 30% of the original should remain in the result for Git to consider it a total rewrite (i.e. otherwise the resulting patch will be a series of deletion and insertion mixed together with context lines). When used with -M, a totally-rewritten file is also considered as the source of a rename (usually -M only considers a file that disappeared as the source of a rename), and the number n controls this aspect of the -B option (defaults to 50%). -B20% specifies that a change with addition and deletion compared to 20% or more of the file\u2019s size are eligible for being picked up as a possible source of a rename to another file. -M[<n>], --find-renames[=<n>] Detect renames. If n is specified, it is a threshold on the similarity index (i.e. amount of addition/deletions compared to the file\u2019s size). For example, -M90% means Git should consider a delete/add pair to be a rename if more than 90% of the file hasn\u2019t changed. Without a % sign, the number is to be read as a fraction, with a decimal point before it. I.e., -M5 becomes 0.5, and is thus the same as -M50%. Similarly, -M05 is the same as -M5%. To limit detection to exact renames, use -M100%. The default similarity index is 50%. -C[<n>], --find-copies[=<n>] Detect copies as well as renames. See also --find-copies-harder. If n is specified, it has the same meaning as for -M<n>. --find-copies-harder For performance reasons, by default, -C option finds copies only if the original file of the copy was modified in the same changeset. This flag makes the command inspect unmodified files as candidates for the source of copy. This is a very expensive operation for large projects, so use it with caution. Giving more than one -C option has the same effect. -D, --irreversible-delete Omit the preimage for deletes, i.e. print only the header but not the diff between the preimage and /dev/null. The resulting patch is not meant to be applied with patch or git apply; this is solely for people who want to just concentrate on reviewing the text after the change. In addition, the output obviously lacks enough information to apply such a patch in reverse, even manually, hence the name of the option. When used together with -B, omit also the preimage in the deletion part of a delete/create pair. -l<num> The -M and -C options involve some preliminary steps that can detect subsets of renames/copies cheaply, followed by an exhaustive fallback portion that compares all remaining unpaired destinations to all relevant sources. (For renames, only remaining unpaired sources are relevant; for copies, all original sources are relevant.) For N sources and destinations, this exhaustive check is O(N^2). This option prevents the exhaustive portion of rename/copy detection from running if the number of source/destination files involved exceeds the specified number. Defaults to diff.renameLimit. Note that a value of 0 is treated as unlimited. -O<orderfile> Control the order in which files appear in the output. This overrides the diff.orderFile configuration variable (see git-config(1)). To cancel diff.orderFile, use -O/dev/null. The output order is determined by the order of glob patterns in <orderfile>. All files with pathnames that match the first pattern are output first, all files with pathnames that match the second pattern (but not the first) are output next, and so on. All files with pathnames that do not match any pattern are output last, as if there was an implicit match-all pattern at the end of the file. If multiple pathnames have the same rank (they match the same pattern but no earlier patterns), their output order relative to each other is the normal order. <orderfile> is parsed as follows: \u2022 Blank lines are ignored, so they can be used as separators for readability. \u2022 Lines starting with a hash (\"#\") are ignored, so they can be used for comments. Add a backslash (\"\\\") to the beginning of the pattern if it starts with a hash. \u2022 Each other line contains a single pattern. Patterns have the same syntax and semantics as patterns used for fnmatch(3) without the FNM_PATHNAME flag, except a pathname also matches a pattern if removing any number of the final pathname components matches the pattern. For example, the pattern \"foo*bar\" matches \"fooasdfbar\" and \"foo/bar/baz/asdf\" but not \"foobarx\". --skip-to=<file>, --rotate-to=<file> Discard the files before the named <file> from the output (i.e. skip to), or move them to the end of the output (i.e. rotate to). These were invented primarily for use of the git difftool command, and may not be very useful otherwise. --relative[=<path>], --no-relative When run from a subdirectory of the project, it can be told to exclude changes outside the directory and show pathnames relative to it with this option. When you are not in a subdirectory (e.g. in a bare repository), you can name which subdirectory to make the output relative to by giving a <path> as an argument. --no-relative can be used to countermand both diff.relative config option and previous --relative. -a, --text Treat all files as text. --ignore-cr-at-eol Ignore carriage-return at the end of line when doing a comparison. --ignore-space-at-eol Ignore changes in whitespace at EOL. -b, --ignore-space-change Ignore changes in amount of whitespace. This ignores whitespace at line end, and considers all other sequences of one or more whitespace characters to be equivalent. -w, --ignore-all-space Ignore whitespace when comparing lines. This ignores differences even if one line has whitespace where the other line has none. --ignore-blank-lines Ignore changes whose lines are all blank. -I<regex>, --ignore-matching-lines=<regex> Ignore changes whose all lines match <regex>. This option may be specified more than once. --inter-hunk-context=<lines> Show the context between diff hunks, up to the specified number of lines, thereby fusing hunks that are close to each other. Defaults to diff.interHunkContext or 0 if the config option is unset. -W, --function-context Show whole function as context lines for each change. The function names are determined in the same way as git diff works out patch hunk headers (see Defining a custom hunk-header in gitattributes(5)). --ext-diff Allow an external diff helper to be executed. If you set an external diff driver with gitattributes(5), you need to use this option with git-log(1) and friends. --no-ext-diff Disallow external diff drivers. --textconv, --no-textconv Allow (or disallow) external text conversion filters to be run when comparing binary files. See gitattributes(5) for details. Because textconv filters are typically a one-way conversion, the resulting diff is suitable for human consumption, but cannot be applied. For this reason, textconv filters are enabled by default only for git-diff(1) and git-log(1), but not for git-format-patch(1) or diff plumbing commands. --ignore-submodules[=<when>] Ignore changes to submodules in the diff generation. <when> can be either \"none\", \"untracked\", \"dirty\" or \"all\", which is the default. Using \"none\" will consider the submodule modified when it either contains untracked or modified files or its HEAD differs from the commit recorded in the superproject and can be used to override any settings of the ignore option in git-config(1) or gitmodules(5). When \"untracked\" is used submodules are not considered dirty when they only contain untracked content (but they are still scanned for modified content). Using \"dirty\" ignores all changes to the work tree of submodules, only changes to the commits stored in the superproject are shown (this was the behavior until 1.7.0). Using \"all\" hides all changes to submodules. --src-prefix=<prefix> Show the given source prefix instead of \"a/\". --dst-prefix=<prefix> Show the given destination prefix instead of \"b/\". --no-prefix Do not show any source or destination prefix. --default-prefix Use the default source and destination prefixes (\"a/\" and \"b/\"). This is usually the default already, but may be used to override config such as diff.noprefix. --line-prefix=<prefix> Prepend an additional prefix to every line of output. --ita-invisible-in-index By default entries added by \"git add -N\" appear as an existing empty file in \"git diff\" and a new file in \"git diff --cached\". This option makes the entry appear as a new file in \"git diff\" and non-existent in \"git diff --cached\". This option could be reverted with --ita-visible-in-index. Both options are experimental and could be removed in future. For more detailed explanation on these common options, see also gitdiffcore(7). -<n> Prepare patches from the topmost <n> commits. -o <dir>, --output-directory <dir> Use <dir> to store the resulting files, instead of the current working directory. -n, --numbered Name output in [PATCH n/m] format, even with a single patch. -N, --no-numbered Name output in [PATCH] format. --start-number <n> Start numbering the patches at <n> instead of 1. --numbered-files Output file names will be a simple number sequence without the default first line of the commit appended. -k, --keep-subject Do not strip/add [PATCH] from the first line of the commit log message. -s, --signoff Add a Signed-off-by trailer to the commit message, using the committer identity of yourself. See the signoff option in git-commit(1) for more information. --stdout Print all commits to the standard output in mbox format, instead of creating a file for each one. --attach[=<boundary>] Create multipart/mixed attachment, the first part of which is the commit message and the patch itself in the second part, with Content-Disposition: attachment. --no-attach Disable the creation of an attachment, overriding the configuration setting. --inline[=<boundary>] Create multipart/mixed attachment, the first part of which is the commit message and the patch itself in the second part, with Content-Disposition: inline. --thread[=<style>], --no-thread Controls addition of In-Reply-To and References headers to make the second and subsequent mails appear as replies to the first. Also controls generation of the Message-ID header to reference. The optional <style> argument can be either shallow or deep. shallow threading makes every mail a reply to the head of the series, where the head is chosen from the cover letter, the --in-reply-to, and the first patch mail, in this order. deep threading makes every mail a reply to the previous one. The default is --no-thread, unless the format.thread configuration is set. --thread without an argument is equivalent to --thread=shallow. Beware that the default for git send-email is to thread emails itself. If you want git format-patch to take care of threading, you will want to ensure that threading is disabled for git send-email. --in-reply-to=<message id> Make the first mail (or all the mails with --no-thread) appear as a reply to the given <message id>, which avoids breaking threads to provide a new patch series. --ignore-if-in-upstream Do not include a patch that matches a commit in <until>..<since>. This will examine all patches reachable from <since> but not from <until> and compare them with the patches being generated, and any patch that matches is ignored. --always Include patches for commits that do not introduce any change, which are omitted by default. --cover-from-description=<mode> Controls which parts of the cover letter will be automatically populated using the branch\u2019s description. If <mode> is message or default, the cover letter subject will be populated with placeholder text. The body of the cover letter will be populated with the branch\u2019s description. This is the default mode when no configuration nor command line option is specified. If <mode> is subject, the first paragraph of the branch description will populate the cover letter subject. The remainder of the description will populate the body of the cover letter. If <mode> is auto, if the first paragraph of the branch description is greater than 100 bytes, then the mode will be message, otherwise subject will be used. If <mode> is none, both the cover letter subject and body will be populated with placeholder text. --subject-prefix=<subject prefix> Instead of the standard [PATCH] prefix in the subject line, instead use [<subject prefix>]. This allows for useful naming of a patch series, and can be combined with the --numbered option. --filename-max-length=<n> Instead of the standard 64 bytes, chomp the generated output filenames at around <n> bytes (too short a value will be silently raised to a reasonable length). Defaults to the value of the format.filenameMaxLength configuration variable, or 64 if unconfigured. --rfc Alias for --subject-prefix=\"RFC PATCH\". RFC means \"Request For Comments\"; use this when sending an experimental patch for discussion rather than application. -v <n>, --reroll-count=<n> Mark the series as the <n>-th iteration of the topic. The output filenames have v<n> prepended to them, and the subject prefix (\"PATCH\" by default, but configurable via the --subject-prefix option) has ` v<n>` appended to it. E.g. --reroll-count=4 may produce v4-0001-add-makefile.patch file that has \"Subject: [PATCH v4 1/20] Add makefile\" in it. <n> does not have to be an integer (e.g. \"--reroll-count=4.4\", or \"--reroll-count=4rev2\" are allowed), but the downside of using such a reroll-count is that the range-diff/interdiff with the previous version does not state exactly which version the new iteration is compared against. --to=<email> Add a To: header to the email headers. This is in addition to any configured headers, and may be used multiple times. The negated form --no-to discards all To: headers added so far (from config or command line). --cc=<email> Add a Cc: header to the email headers. This is in addition to any configured headers, and may be used multiple times. The negated form --no-cc discards all Cc: headers added so far (from config or command line). --from, --from=<ident> Use ident in the From: header of each commit email. If the author ident of the commit is not textually identical to the provided ident, place a From: header in the body of the message with the original author. If no ident is given, use the committer ident. Note that this option is only useful if you are actually sending the emails and want to identify yourself as the sender, but retain the original author (and git am will correctly pick up the in-body header). Note also that git send-email already handles this transformation for you, and this option should not be used if you are feeding the result to git send-email. --[no-]force-in-body-from With the e-mail sender specified via the --from option, by default, an in-body \"From:\" to identify the real author of the commit is added at the top of the commit log message if the sender is different from the author. With this option, the in-body \"From:\" is added even when the sender and the author have the same name and address, which may help if the mailing list software mangles the sender\u2019s identity. Defaults to the value of the format.forceInBodyFrom configuration variable. --add-header=<header> Add an arbitrary header to the email headers. This is in addition to any configured headers, and may be used multiple times. For example, --add-header=\"Organization: git-foo\". The negated form --no-add-header discards all (To:, Cc:, and custom) headers added so far from config or command line. --[no-]cover-letter In addition to the patches, generate a cover letter file containing the branch description, shortlog and the overall diffstat. You can fill in a description in the file before sending it out. --encode-email-headers, --no-encode-email-headers Encode email headers that have non-ASCII characters with \"Q-encoding\" (described in RFC 2047), instead of outputting the headers verbatim. Defaults to the value of the format.encodeEmailHeaders configuration variable. --interdiff=<previous> As a reviewer aid, insert an interdiff into the cover letter, or as commentary of the lone patch of a 1-patch series, showing the differences between the previous version of the patch series and the series currently being formatted. previous is a single revision naming the tip of the previous series which shares a common base with the series being formatted (for example git format-patch --cover-letter --interdiff=feature/v1 -3 feature/v2). --range-diff=<previous> As a reviewer aid, insert a range-diff (see git-range-diff(1)) into the cover letter, or as commentary of the lone patch of a 1-patch series, showing the differences between the previous version of the patch series and the series currently being formatted. previous can be a single revision naming the tip of the previous series if it shares a common base with the series being formatted (for example git format-patch --cover-letter --range-diff=feature/v1 -3 feature/v2), or a revision range if the two versions of the series are disjoint (for example git format-patch --cover-letter --range-diff=feature/v1~3..feature/v1 -3 feature/v2). Note that diff options passed to the command affect how the primary product of format-patch is generated, and they are not passed to the underlying range-diff machinery used to generate the cover-letter material (this may change in the future). --creation-factor=<percent> Used with --range-diff, tweak the heuristic which matches up commits between the previous and current series of patches by adjusting the creation/deletion cost fudge factor. See git-range-diff(1)) for details. --notes[=<ref>], --no-notes Append the notes (see git-notes(1)) for the commit after the three-dash line. The expected use case of this is to write supporting explanation for the commit that does not belong to the commit log message proper, and include it with the patch submission. While one can simply write these explanations after format-patch has run but before sending, keeping them as Git notes allows them to be maintained between versions of the patch series (but see the discussion of the notes.rewrite configuration options in git-notes(1) to use this workflow). The default is --no-notes, unless the format.notes configuration is set. --[no-]signature=<signature> Add a signature to each message produced. Per RFC 3676 the signature is separated from the body by a line with '-- ' on it. If the signature option is omitted the signature defaults to the Git version number. --signature-file=<file> Works just like --signature except the signature is read from a file. --suffix=.<sfx> Instead of using .patch as the suffix for generated filenames, use specified suffix. A common alternative is --suffix=.txt. Leaving this empty will remove the .patch suffix. Note that the leading character does not have to be a dot; for example, you can use --suffix=-patch to get 0001-description-of-my-change-patch. -q, --quiet Do not print the names of the generated files to standard output. --no-binary Do not output contents of changes in binary files, instead display a notice that those files changed. Patches generated using this option cannot be applied properly, but they are still useful for code review. --zero-commit Output an all-zero hash in each patch\u2019s From header instead of the hash of the commit. --[no-]base[=<commit>] Record the base tree information to identify the state the patch series applies to. See the BASE TREE INFORMATION section below for details. If <commit> is \"auto\", a base commit is automatically chosen. The --no-base option overrides a format.useAutoBase configuration. --root Treat the revision argument as a <revision range>, even if it is just a single commit (that would normally be treated as a <since>). Note that root commits included in the specified range are always formatted as creation patches, independently of this flag. --progress Show progress reports on stderr as patches are generated. "
  },
  {
    "command": "false",
    "description": " Exit with a status code indicating failure. --help display this help and exit --version output version information and exit NOTE: your shell may have its own version of false, which usually supersedes the version described here. Please refer to your shell's documentation for details about the options it supports. "
  },
  {
    "command": "iconv",
    "description": " The iconv utility shall convert the encoding of characters in file from one codeset to another and write the results to standard output. When the options indicate that charmap files are used to specify the codesets (see OPTIONS), the codeset conversion shall be accomplished by performing a logical join on the symbolic character names in the two charmaps. The implementation need not support the use of charmap files for codeset conversion unless the POSIX2_LOCALEDEF symbol is defined on the system. The iconv utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -c Omit any characters that are invalid in the codeset of the input file from the output. When -c is not used, the results of encountering invalid characters in the input stream (either those that are not characters in the codeset of the input file or that have no corresponding character in the codeset of the output file) shall be specified in the system documentation. The presence or absence of -c shall not affect the exit status of iconv. -f fromcodeset Identify the codeset of the input file. The implementation shall recognize the following two forms of the fromcodeset option-argument: fromcode The fromcode option-argument must not contain a <slash> character. It shall be interpreted as the name of one of the codeset descriptions provided by the implementation in an unspecified format. Valid values of fromcode are implementation-defined. frommap The frommap option-argument must contain a <slash> character. It shall be interpreted as the pathname of a charmap file as defined in the Base Definitions volume of POSIX.1\u20102017, Section 6.4, Character Set Description File. If the pathname does not represent a valid, readable charmap file, the results are undefined. If this option is omitted, the codeset of the current locale shall be used. -l Write all supported fromcode and tocode values to standard output in an unspecified format. -s Suppress any messages written to standard error concerning invalid characters. When -s is not used, the results of encountering invalid characters in the input stream (either those that are not valid characters in the codeset of the input file or that have no corresponding character in the codeset of the output file) shall be specified in the system documentation. The presence or absence of -s shall not affect the exit status of iconv. -t tocodeset Identify the codeset to be used for the output file. The implementation shall recognize the following two forms of the tocodeset option-argument: tocode The semantics shall be equivalent to the -f fromcode option. tomap The semantics shall be equivalent to the -f frommap option. If this option is omitted, the codeset of the current locale shall be used. If either -f or -t represents a charmap file, but the other does not (or is omitted), or both -f and -t are omitted, the results are undefined. "
  },
  {
    "command": "sync",
    "description": " Synchronize cached writes to persistent storage If one or more files are specified, sync only them, or their containing file systems. -d, --data sync only file data, no unneeded metadata -f, --file-system sync the file systems that contain the files --help display this help and exit --version output version information and exit "
  },
  {
    "command": "diff",
    "description": " The diff utility shall compare the contents of file1 and file2 and write to standard output a list of changes necessary to convert file1 into file2. This list should be minimal. No output shall be produced if the files are identical. The diff utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -b Cause any amount of white space at the end of a line to be treated as a single <newline> (that is, the white- space characters preceding the <newline> are ignored) and other strings of white-space characters, not including <newline> characters, to compare equal. -c Produce output in a form that provides three lines of copied context. -C n Produce output in a form that provides n lines of copied context (where n shall be interpreted as a positive decimal integer). -e Produce output in a form suitable as input for the ed utility, which can then be used to convert file1 into file2. -f Produce output in an alternative form, similar in format to -e, but not intended to be suitable as input for the ed utility, and in the opposite order. -r Apply diff recursively to files and directories of the same name when file1 and file2 are both directories. The diff utility shall detect infinite loops; that is, entering a previously visited directory that is an ancestor of the last file encountered. When it detects an infinite loop, diff shall write a diagnostic message to standard error and shall either recover its position in the hierarchy or terminate. -u Produce output in a form that provides three lines of unified context. -U n Produce output in a form that provides n lines of unified context (where n shall be interpreted as a non- negative decimal integer). "
  },
  {
    "command": "rmdir",
    "description": " Remove the DIRECTORY(ies), if they are empty. --ignore-fail-on-non-empty ignore each failure to remove a non-empty directory -p, --parents remove DIRECTORY and its ancestors; e.g., 'rmdir -p a/b' is similar to 'rmdir a/b a' -v, --verbose output a diagnostic for every directory processed --help display this help and exit --version output version information and exit "
  },
  {
    "command": "shuf",
    "description": " Write a random permutation of the input lines to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -e, --echo treat each ARG as an input line -i, --input-range=LO-HI treat each number LO through HI as an input line -n, --head-count=COUNT output at most COUNT lines -o, --output=FILE write result to FILE instead of standard output --random-source=FILE get random bytes from FILE -r, --repeat output lines can be repeated -z, --zero-terminated line delimiter is NUL, not newline --help display this help and exit --version output version information and exit "
  },
  {
    "command": "git-bundle",
    "description": " Create, unpack, and manipulate \"bundle\" files. Bundles are used for the \"offline\" transfer of Git objects without an active \"server\" sitting on the other side of the network connection. They can be used to create both incremental and full backups of a repository, and to relay the state of the references in one repository to another. Git commands that fetch or otherwise \"read\" via protocols such as ssh:// and https:// can also operate on bundle files. It is possible git-clone(1) a new repository from a bundle, to use git-fetch(1) to fetch from one, and to list the references contained within it with git-ls-remote(1). There\u2019s no corresponding \"write\" support, i.e.a git push into a bundle is not supported. See the \"EXAMPLES\" section below for examples of how to use bundles. create [options] <file> <git-rev-list-args> Used to create a bundle named file. This requires the <git-rev-list-args> arguments to define the bundle contents. options contains the options specific to the git bundle create subcommand. If file is -, the bundle is written to stdout. verify <file> Used to check that a bundle file is valid and will apply cleanly to the current repository. This includes checks on the bundle format itself as well as checking that the prerequisite commits exist and are fully linked in the current repository. Then, git bundle prints a list of missing commits, if any. Finally, information about additional capabilities, such as \"object filter\", is printed. See \"Capabilities\" in gitformat-bundle(5) for more information. The exit code is zero for success, but will be nonzero if the bundle file is invalid. If file is -, the bundle is read from stdin. list-heads <file> Lists the references defined in the bundle. If followed by a list of references, only references matching those given are printed out. If file is -, the bundle is read from stdin. unbundle <file> Passes the objects in the bundle to git index-pack for storage in the repository, then prints the names of all defined references. If a list of references is given, only references matching those in the list are printed. This command is really plumbing, intended to be called only by git fetch. If file is -, the bundle is read from stdin. <git-rev-list-args> A list of arguments, acceptable to git rev-parse and git rev-list (and containing a named ref, see SPECIFYING REFERENCES below), that specifies the specific objects and references to transport. For example, master~10..master causes the current master reference to be packaged along with all objects added since its 10th ancestor commit. There is no explicit limit to the number of references and objects that may be packaged. [<refname>...] A list of references used to limit the references reported as available. This is principally of use to git fetch, which expects to receive only those references asked for and not necessarily everything in the pack (in this case, git bundle acts like git fetch-pack). --progress Progress status is reported on the standard error stream by default when it is attached to a terminal, unless -q is specified. This flag forces progress status even if the standard error stream is not directed to a terminal. --version=<version> Specify the bundle version. Version 2 is the older format and can only be used with SHA-1 repositories; the newer version 3 contains capabilities that permit extensions. The default is the oldest supported format, based on the hash algorithm in use. -q, --quiet This flag makes the command not to report its progress on the standard error stream. "
  },
  {
    "command": "link",
    "description": " Call the link function to create a link named FILE2 to an existing FILE1. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "systemd-delta",
    "description": " systemd-delta may be used to identify and compare configuration files that override other configuration files. Files in /etc/ have highest priority, files in /run/ have the second highest priority, ..., files in /usr/lib/ have lowest priority. Files in a directory with higher priority override files with the same name in directories of lower priority. In addition, certain configuration files can have \".d\" directories which contain \"drop-in\" files with configuration snippets which augment the main configuration file. \"Drop-in\" files can be overridden in the same way by placing files with the same name in a directory of higher priority (except that, in case of \"drop-in\" files, both the \"drop-in\" file name and the name of the containing directory, which corresponds to the name of the main configuration file, must match). For a fuller explanation, see systemd.unit(5). The command line argument will be split into a prefix and a suffix. Either is optional. The prefix must be one of the directories containing configuration files (/etc/, /run/, /usr/lib/, ...). If it is given, only overriding files contained in this directory will be shown. Otherwise, all overriding files will be shown. The suffix must be a name of a subdirectory containing configuration files like tmpfiles.d, sysctl.d or systemd/system. If it is given, only configuration files in this subdirectory (across all configuration paths) will be analyzed. Otherwise, all configuration files will be analyzed. If the command line argument is not given at all, all configuration files will be analyzed. See below for some examples. The following options are understood: -t, --type= When listing the differences, only list those that are asked for. The list itself is a comma-separated list of desired difference types. Recognized types are: masked Show masked files equivalent Show overridden files that while overridden, do not differ in content. redirected Show files that are redirected to another. overridden Show overridden, and changed files. extended Show *.conf files in drop-in directories for units. unchanged Show unmodified files too. --diff= When showing modified files, when a file is overridden show a diff as well. This option takes a boolean argument. If omitted, it defaults to true. -h, --help Print a short help text and exit. --version Print a short version string and exit. --no-pager Do not pipe output into a pager. "
  },
  {
    "command": "namei",
    "description": " namei interprets its arguments as pathnames to any type of Unix file (symlinks, files, directories, and so forth). namei then follows each pathname until an endpoint is found (a file, a directory, a device node, etc). If it finds a symbolic link, it shows the link, and starts following it, indenting the output to show the context. This program is useful for finding \"too many levels of symbolic links\" problems. For each line of output, namei uses the following characters to identify the file type found: f: = the pathname currently being resolved d = directory l = symbolic link (both the link and its contents are output) s = socket b = block device c = character device p = FIFO (named pipe) - = regular file ? = an error of some kind namei prints an informative message when the maximum number of symbolic links this system can have has been exceeded. -l, --long Use the long listing format (same as -m -o -v). -m, --modes Show the mode bits of each file type in the style of ls(1), for example 'rwxr-xr-x'. -n, --nosymlinks Don\u2019t follow symlinks. -o, --owners Show owner and group name of each file. -v, --vertical Vertically align the modes and owners. -x, --mountpoints Show mountpoint directories with a 'D' rather than a 'd'. -Z, --context Show security context of the file or \"?\" if not available. The support for security contexts is optional and does not have to be compiled to the namei binary. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "lastcomm",
    "description": " lastcomm prints out information about previously executed commands. If no arguments are specified, lastcomm will print info about all of the commands in acct (the record file). If called with one or more of command-name, user-name, or terminal- name, only records containing those items will be displayed. For example, to find out which users used command `a.out' and which users were logged into `tty0', type: lastcomm a.out tty0 This will print any entry for which `a.out' or `tty0' matches in any of the record's fields (command, name, or terminal). If you want to find only items that match *all* of the arguments on the command line, you must use the '-strict-match' option. For example, to list all of the executions of command a.out by user root on terminal tty0, type: lastcomm --strict-match --command a.out --user root --tty tty0 The order of the arguments is not important. For each entry the following information is printed: + command name of the process + flags, as recorded by the system accounting routines: S -- command executed by super-user F -- command executed after a fork but without a following exec C -- command run in PDP-11 compatibility mode (VAX only) D -- command terminated with the generation of a core file X -- command was terminated with the signal SIGTERM + the name of the user who ran the process + time the process started --strict-match Print only entries that match *all* of the arguments on the command line. --print-controls Print control characters. --user name List records for user with name. This is useful if you're trying to match a username that happens to be the same as a command (e.g., ed ). --command name List records for command name. --tty name List records for tty name. --forwards Read file forwards instead of backwards. This avoids trying to seek on the file and can be used to read from a pipe. This must be specified prior to any -f arguments. -f filename, --file filename Read from the file filename instead of acct. A filename of \"-\" will result in reading from stdin. This must either be the first -f option, or --forwards must precede all -f options. --ahz hz Use this flag to tell the program what AHZ should be (in hertz). This option is useful if you are trying to view an acct file created on another machine which has the same byte order and file format as your current machine, but has a different value for AHZ. -p, --show-paging Print paging statistics. --pid Show PID and PPID of the process if acct version 3 format is supported by kernel. --pid Add pid of the process and pid of the process parent to the output (pid is the last but one and parent pid the last column). These values are shown only when they are generated by acct function (depends on the version of kernel) --debug Print verbose internal information. -V, --version Print the version number of lastcomm. -h, --help Prints the usage string and default locations of system files to standard output and exits. "
  },
  {
    "command": "egrep",
    "description": " grep searches for PATTERNS in each FILE. PATTERNS is one or more patterns separated by newline characters, and grep prints each line that matches a pattern. Typically PATTERNS should be quoted when grep is used in a shell command. A FILE of \u201c-\u201d stands for standard input. If no FILE is given, recursive searches examine the working directory, and nonrecursive searches read standard input. Generic Program Information --help Output a usage message and exit. -V, --version Output the version number of grep and exit. Pattern Syntax -E, --extended-regexp Interpret PATTERNS as extended regular expressions (EREs, see below). -F, --fixed-strings Interpret PATTERNS as fixed strings, not regular expressions. -G, --basic-regexp Interpret PATTERNS as basic regular expressions (BREs, see below). This is the default. -P, --perl-regexp Interpret PATTERNS as Perl-compatible regular expressions (PCREs). This option is experimental when combined with the -z (--null-data) option, and grep -P may warn of unimplemented features. Matching Control -e PATTERNS, --regexp=PATTERNS Use PATTERNS as the patterns. If this option is used multiple times or is combined with the -f (--file) option, search for all patterns given. This option can be used to protect a pattern beginning with \u201c-\u201d. -f FILE, --file=FILE Obtain patterns from FILE, one per line. If this option is used multiple times or is combined with the -e (--regexp) option, search for all patterns given. The empty file contains zero patterns, and therefore matches nothing. If FILE is - , read patterns from standard input. -i, --ignore-case Ignore case distinctions in patterns and input data, so that characters that differ only in case match each other. --no-ignore-case Do not ignore case distinctions in patterns and input data. This is the default. This option is useful for passing to shell scripts that already use -i, to cancel its effects because the two options override each other. -v, --invert-match Invert the sense of matching, to select non-matching lines. -w, --word-regexp Select only those lines containing matches that form whole words. The test is that the matching substring must either be at the beginning of the line, or preceded by a non-word constituent character. Similarly, it must be either at the end of the line or followed by a non-word constituent character. Word-constituent characters are letters, digits, and the underscore. This option has no effect if -x is also specified. -x, --line-regexp Select only those matches that exactly match the whole line. For a regular expression pattern, this is like parenthesizing the pattern and then surrounding it with ^ and $. General Output Control -c, --count Suppress normal output; instead print a count of matching lines for each input file. With the -v, --invert-match option (see above), count non-matching lines. --color[=WHEN], --colour[=WHEN] Surround the matched (non-empty) strings, matching lines, context lines, file names, line numbers, byte offsets, and separators (for fields and groups of context lines) with escape sequences to display them in color on the terminal. The colors are defined by the environment variable GREP_COLORS. WHEN is never, always, or auto. -L, --files-without-match Suppress normal output; instead print the name of each input file from which no output would normally have been printed. -l, --files-with-matches Suppress normal output; instead print the name of each input file from which output would normally have been printed. Scanning each input file stops upon first match. -m NUM, --max-count=NUM Stop reading a file after NUM matching lines. If NUM is zero, grep stops right away without reading input. A NUM of -1 is treated as infinity and grep does not stop; this is the default. If the input is standard input from a regular file, and NUM matching lines are output, grep ensures that the standard input is positioned to just after the last matching line before exiting, regardless of the presence of trailing context lines. This enables a calling process to resume a search. When grep stops after NUM matching lines, it outputs any trailing context lines. When the -c or --count option is also used, grep does not output a count greater than NUM. When the -v or --invert-match option is also used, grep stops after outputting NUM non-matching lines. -o, --only-matching Print only the matched (non-empty) parts of a matching line, with each such part on a separate output line. -q, --quiet, --silent Quiet; do not write anything to standard output. Exit immediately with zero status if any match is found, even if an error was detected. Also see the -s or --no-messages option. -s, --no-messages Suppress error messages about nonexistent or unreadable files. Output Line Prefix Control -b, --byte-offset Print the 0-based byte offset within the input file before each line of output. If -o (--only-matching) is specified, print the offset of the matching part itself. -H, --with-filename Print the file name for each match. This is the default when there is more than one file to search. This is a GNU extension. -h, --no-filename Suppress the prefixing of file names on output. This is the default when there is only one file (or only standard input) to search. --label=LABEL Display input actually coming from standard input as input coming from file LABEL. This can be useful for commands that transform a file's contents before searching, e.g., gzip -cd foo.gz | grep --label=foo -H 'some pattern'. See also the -H option. -n, --line-number Prefix each line of output with the 1-based line number within its input file. -T, --initial-tab Make sure that the first character of actual line content lies on a tab stop, so that the alignment of tabs looks normal. This is useful with options that prefix their output to the actual content: -H,-n, and -b. In order to improve the probability that lines from a single file will all start at the same column, this also causes the line number and byte offset (if present) to be printed in a minimum size field width. -Z, --null Output a zero byte (the ASCII NUL character) instead of the character that normally follows a file name. For example, grep -lZ outputs a zero byte after each file name instead of the usual newline. This option makes the output unambiguous, even in the presence of file names containing unusual characters like newlines. This option can be used with commands like find -print0, perl -0, sort -z, and xargs -0 to process arbitrary file names, even those that contain newline characters. Context Line Control -A NUM, --after-context=NUM Print NUM lines of trailing context after matching lines. Places a line containing a group separator (--) between contiguous groups of matches. With the -o or --only-matching option, this has no effect and a warning is given. -B NUM, --before-context=NUM Print NUM lines of leading context before matching lines. Places a line containing a group separator (--) between contiguous groups of matches. With the -o or --only-matching option, this has no effect and a warning is given. -C NUM, -NUM, --context=NUM Print NUM lines of output context. Places a line containing a group separator (--) between contiguous groups of matches. With the -o or --only-matching option, this has no effect and a warning is given. --group-separator=SEP When -A, -B, or -C are in use, print SEP instead of -- between groups of lines. --no-group-separator When -A, -B, or -C are in use, do not print a separator between groups of lines. File and Directory Selection -a, --text Process a binary file as if it were text; this is equivalent to the --binary-files=text option. --binary-files=TYPE If a file's data or metadata indicate that the file contains binary data, assume that the file is of type TYPE. Non-text bytes indicate binary data; these are either output bytes that are improperly encoded for the current locale, or null input bytes when the -z option is not given. By default, TYPE is binary, and grep suppresses output after null input binary data is discovered, and suppresses output lines that contain improperly encoded data. When some output is suppressed, grep follows any output with a message to standard error saying that a binary file matches. If TYPE is without-match, when grep discovers null input binary data it assumes that the rest of the file does not match; this is equivalent to the -I option. If TYPE is text, grep processes a binary file as if it were text; this is equivalent to the -a option. When type is binary, grep may treat non-text bytes as line terminators even without the -z option. This means choosing binary versus text can affect whether a pattern matches a file. For example, when type is binary the pattern q$ might match q immediately followed by a null byte, even though this is not matched when type is text. Conversely, when type is binary the pattern . (period) might not match a null byte. Warning: The -a option might output binary garbage, which can have nasty side effects if the output is a terminal and if the terminal driver interprets some of it as commands. On the other hand, when reading files whose text encodings are unknown, it can be helpful to use -a or to set LC_ALL='C' in the environment, in order to find more matches even if the matches are unsafe for direct display. -D ACTION, --devices=ACTION If an input file is a device, FIFO or socket, use ACTION to process it. By default, ACTION is read, which means that devices are read just as if they were ordinary files. If ACTION is skip, devices are silently skipped. -d ACTION, --directories=ACTION If an input file is a directory, use ACTION to process it. By default, ACTION is read, i.e., read directories just as if they were ordinary files. If ACTION is skip, silently skip directories. If ACTION is recurse, read all files under each directory, recursively, following symbolic links only if they are on the command line. This is equivalent to the -r option. --exclude=GLOB Skip any command-line file with a name suffix that matches the pattern GLOB, using wildcard matching; a name suffix is either the whole name, or a trailing part that starts with a non-slash character immediately after a slash (/) in the name. When searching recursively, skip any subfile whose base name matches GLOB; the base name is the part after the last slash. A pattern can use *, ?, and [...] as wildcards, and \\ to quote a wildcard or backslash character literally. --exclude-from=FILE Skip files whose base name matches any of the file-name globs read from FILE (using wildcard matching as described under --exclude). --exclude-dir=GLOB Skip any command-line directory with a name suffix that matches the pattern GLOB. When searching recursively, skip any subdirectory whose base name matches GLOB. Ignore any redundant trailing slashes in GLOB. -I Process a binary file as if it did not contain matching data; this is equivalent to the --binary-files=without-match option. --include=GLOB Search only files whose base name matches GLOB (using wildcard matching as described under --exclude). If contradictory --include and --exclude options are given, the last matching one wins. If no --include or --exclude options match, a file is included unless the first such option is --include. -r, --recursive Read all files under each directory, recursively, following symbolic links only if they are on the command line. Note that if no file operand is given, grep searches the working directory. This is equivalent to the -d recurse option. -R, --dereference-recursive Read all files under each directory, recursively. Follow all symbolic links, unlike -r. Other Options --line-buffered Use line buffering on output. This can cause a performance penalty. -U, --binary Treat the file(s) as binary. By default, under MS-DOS and MS-Windows, grep guesses whether a file is text or binary as described for the --binary-files option. If grep decides the file is a text file, it strips the CR characters from the original file contents (to make regular expressions with ^ and $ work correctly). Specifying -U overrules this guesswork, causing all files to be read and passed to the matching mechanism verbatim; if the file is a text file with CR/LF pairs at the end of each line, this will cause some regular expressions to fail. This option has no effect on platforms other than MS-DOS and MS-Windows. -z, --null-data Treat input and output data as sequences of lines, each terminated by a zero byte (the ASCII NUL character) instead of a newline. Like the -Z or --null option, this option can be used with commands like sort -z to process arbitrary file names. "
  },
  {
    "command": "setfacl",
    "description": " This utility sets Access Control Lists (ACLs) of files and directories. On the command line, a sequence of commands is followed by a sequence of files (which in turn can be followed by another sequence of commands, ...). The -m and -x options expect an ACL on the command line. Multiple ACL entries are separated by comma characters (`,'). The -M and -X options read an ACL from a file or from standard input. The ACL entry format is described in Section ACL ENTRIES. The --set and --set-file options set the ACL of a file or a directory. The previous ACL is replaced. ACL entries for this operation must include permissions. The -m (--modify) and -M (--modify-file) options modify the ACL of a file or directory. ACL entries for this operation must include permissions. The -x (--remove) and -X (--remove-file) options remove ACL entries. It is not an error to remove an entry which does not exist. Only ACL entries without the perms field are accepted as parameters, unless POSIXLY_CORRECT is defined. When reading from files using the -M and -X options, setfacl accepts the output getfacl produces. There is at most one ACL entry per line. After a Pound sign (`#'), everything up to the end of the line is treated as a comment. If setfacl is used on a file system which does not support ACLs, setfacl operates on the file mode permission bits. If the ACL does not fit completely in the permission bits, setfacl modifies the file mode permission bits to reflect the ACL as closely as possible, writes an error message to standard error, and returns with an exit status greater than 0. PERMISSIONS The file owner and processes capable of CAP_FOWNER are granted the right to modify ACLs of a file. This is analogous to the permissions required for accessing the file mode. (On current Linux systems, root is the only user with the CAP_FOWNER capability.) -b, --remove-all Remove all extended ACL entries. The base ACL entries of the owner, group and others are retained. -k, --remove-default Remove the Default ACL. If no Default ACL exists, no warnings are issued. -n, --no-mask Do not recalculate the effective rights mask. The default behavior of setfacl is to recalculate the ACL mask entry, unless a mask entry was explicitly given. The mask entry is set to the union of all permissions of the owning group, and all named user and group entries. (These are exactly the entries affected by the mask entry). --mask Do recalculate the effective rights mask, even if an ACL mask entry was explicitly given. (See the -n option.) -d, --default All operations apply to the Default ACL. Regular ACL entries in the input set are promoted to Default ACL entries. Default ACL entries in the input set are discarded. (A warning is issued if that happens). --restore={file|-} Restore a permission backup created by `getfacl -R' or similar. All permissions of a complete directory subtree are restored using this mechanism. If the input contains owner comments or group comments, setfacl attempts to restore the owner and owning group. If the input contains flags comments (which define the setuid, setgid, and sticky bits), setfacl sets those three bits accordingly; otherwise, it clears them. This option cannot be mixed with other options except `--test'. If the file specified is '-', then it will be read from standard input. --test Test mode. Instead of changing the ACLs of any files, the resulting ACLs are listed. -R, --recursive Apply operations to all files and directories recursively. This option cannot be mixed with `--restore'. -L, --logical Logical walk, follow symbolic links to directories. The default behavior is to follow symbolic link arguments, and skip symbolic links encountered in subdirectories. Only effective in combination with -R. This option cannot be mixed with `--restore'. -P, --physical Physical walk, do not follow symbolic links to directories. This also skips symbolic link arguments. Only effective in combination with -R. This option cannot be mixed with `--restore'. -v, --version Print the version of setfacl and exit. -h, --help Print help explaining the command line options. -- End of command line options. All remaining parameters are interpreted as file names, even if they start with a dash. - If the file name parameter is a single dash, setfacl reads a list of files from standard input. ACL ENTRIES The setfacl utility recognizes the following ACL entry formats (blanks inserted for clarity): [d[efault]:] [u[ser]:]uid [:perms] Permissions of a named user. Permissions of the file owner if uid is empty. [d[efault]:] g[roup]:gid [:perms] Permissions of a named group. Permissions of the owning group if gid is empty. [d[efault]:] m[ask][:] [:perms] Effective rights mask [d[efault]:] o[ther][:] [:perms] Permissions of others. Whitespace between delimiter characters and non-delimiter characters is ignored. Proper ACL entries including permissions are used in modify and set operations. (options -m, -M, --set and --set-file). Entries without the perms field are used for deletion of entries (options -x and -X). For uid and gid you can specify either a name or a number. Character literals may be specified with a backslash followed by the 3-digit octal digits corresponding to the ASCII code for the character (e.g., \\101 for 'A'). If the name contains a literal backslash followed by 3 digits, the backslash must be escaped (i.e., \\\\). The perms field is a combination of characters that indicate the read (r), write (w), execute (x) permissions. Dash characters in the perms field (-) are ignored. The character X stands for the execute permission if the file is a directory or already has execute permission for some user. Alternatively, the perms field can define the permissions numerically, as a bit-wise combination of read (4), write (2), and execute (1). Zero perms fields or perms fields that only consist of dashes indicate no permissions. AUTOMATICALLY CREATED ENTRIES Initially, files and directories contain only the three base ACL entries for the owner, the group, and others. There are some rules that need to be satisfied in order for an ACL to be valid: * The three base entries cannot be removed. There must be exactly one entry of each of these base entry types. * Whenever an ACL contains named user entries or named group objects, it must also contain an effective rights mask. * Whenever an ACL contains any Default ACL entries, the three Default ACL base entries (default owner, default group, and default others) must also exist. * Whenever a Default ACL contains named user entries or named group objects, it must also contain a default effective rights mask. To help the user ensure these rules, setfacl creates entries from existing entries under the following conditions: * If an ACL contains named user or named group entries, and no mask entry exists, a mask entry containing the same permissions as the group entry is created. Unless the -n option is given, the permissions of the mask entry are further adjusted to include the union of all permissions affected by the mask entry. (See the -n option description). * If a Default ACL entry is created, and the Default ACL contains no owner, owning group, or others entry, a copy of the ACL owner, owning group, or others entry is added to the Default ACL. * If a Default ACL contains named user entries or named group entries, and no mask entry exists, a mask entry containing the same permissions as the default Default ACL's group entry is added. Unless the -n option is given, the permissions of the mask entry are further adjusted to include the union of all permissions affected by the mask entry. (See the -n option description). "
  },
  {
    "command": "paste",
    "description": " The paste utility shall concatenate the corresponding lines of the given input files, and write the resulting lines to standard output. The default operation of paste shall concatenate the corresponding lines of the input files. The <newline> of every line except the line from the last input file shall be replaced with a <tab>. If an end-of-file condition is detected on one or more input files, but not all input files, paste shall behave as though empty lines were read from the files on which end-of-file was detected, unless the -s option is specified. The paste utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -d list Unless a <backslash> character appears in list, each character in list is an element specifying a delimiter character. If a <backslash> character appears in list, the <backslash> character and one or more characters following it are an element specifying a delimiter character as described below. These elements specify one or more delimiters to use, instead of the default <tab>, to replace the <newline> of the input lines. The elements in list shall be used circularly; that is, when the list is exhausted the first element from the list is reused. When the -s option is specified: * The last <newline> in a file shall not be modified. * The delimiter shall be reset to the first element of list after each file operand is processed. When the -s option is not specified: * The <newline> characters in the file specified by the last file operand shall not be modified. * The delimiter shall be reset to the first element of list each time a line is processed from each file. If a <backslash> character appears in list, it and the character following it shall be used to represent the following delimiter characters: \\n <newline>. \\t <tab>. \\\\ <backslash> character. \\0 Empty string (not a null character). If '\\0' is immediately followed by the character 'x', the character 'X', or any character defined by the LC_CTYPE digit keyword (see the Base Definitions volume of POSIX.1\u20102017, Chapter 7, Locale), the results are unspecified. If any other characters follow the <backslash>, the results are unspecified. -s Concatenate all of the lines from each input file into one line of output per file, in command line order. The <newline> of every line except the last line in each input file shall be replaced with a <tab>, unless otherwise specified by the -d option. If an input file is empty, the output line corresponding to that file shall consist of only a <newline> character. "
  },
  {
    "command": "busctl",
    "description": " busctl may be used to introspect and monitor the D-Bus bus. The following options are understood: --address=ADDRESS Connect to the bus specified by ADDRESS instead of using suitable defaults for either the system or user bus (see --system and --user options). --show-machine When showing the list of peers, show a column containing the names of containers they belong to. See systemd-machined.service(8). --unique When showing the list of peers, show only \"unique\" names (of the form \":number.number\"). --acquired The opposite of --unique \u2014 only \"well-known\" names will be shown. --activatable When showing the list of peers, show only peers which have actually not been activated yet, but may be started automatically if accessed. --match=MATCH When showing messages being exchanged, show only the subset matching MATCH. See sd_bus_add_match(3). --size= When used with the capture command, specifies the maximum bus message size to capture (\"snaplen\"). Defaults to 4096 bytes. --list When used with the tree command, shows a flat list of object paths instead of a tree. -q, --quiet When used with the call command, suppresses display of the response message payload. Note that even if this option is specified, errors returned will still be printed and the tool will indicate success or failure with the process exit code. --verbose When used with the call or get-property command, shows output in a more verbose format. --xml-interface When used with the introspect call, dump the XML description received from the D-Bus org.freedesktop.DBus.Introspectable.Introspect call instead of the normal output. --json=MODE When used with the call or get-property command, shows output formatted as JSON. Expects one of \"short\" (for the shortest possible output without any redundant whitespace or line breaks) or \"pretty\" (for a pretty version of the same, with indentation and line breaks). Note that transformation from D-Bus marshalling to JSON is done in a loss-less way, which means type information is embedded into the JSON object tree. -j Equivalent to --json=pretty when invoked interactively from a terminal. Otherwise equivalent to --json=short, in particular when the output is piped to some other program. --expect-reply=BOOL When used with the call command, specifies whether busctl shall wait for completion of the method call, output the returned method response data, and return success or failure via the process exit code. If this is set to \"no\", the method call will be issued but no response is expected, the tool terminates immediately, and thus no response can be shown, and no success or failure is returned via the exit code. To only suppress output of the reply message payload, use --quiet above. Defaults to \"yes\". --auto-start=BOOL When used with the call or emit command, specifies whether the method call should implicitly activate the called service, should it not be running yet but is configured to be auto-started. Defaults to \"yes\". --allow-interactive-authorization=BOOL When used with the call command, specifies whether the services may enforce interactive authorization while executing the operation, if the security policy is configured for this. Defaults to \"yes\". --timeout=SECS When used with the call command, specifies the maximum time to wait for method call completion. If no time unit is specified, assumes seconds. The usual other units are understood, too (ms, us, s, min, h, d, w, month, y). Note that this timeout does not apply if --expect-reply=no is used, as the tool does not wait for any reply message then. When not specified or when set to 0, the default of \"25s\" is assumed. --augment-creds=BOOL Controls whether credential data reported by list or status shall be augmented with data from /proc/. When this is turned on, the data shown is possibly inconsistent, as the data read from /proc/ might be more recent than the rest of the credential information. Defaults to \"yes\". --watch-bind=BOOL Controls whether to wait for the specified AF_UNIX bus socket to appear in the file system before connecting to it. Defaults to off. When enabled, the tool will watch the file system until the socket is created and then connect to it. --destination=SERVICE Takes a service name. When used with the emit command, a signal is emitted to the specified service. --user Talk to the service manager of the calling user, rather than the service manager of the system. --system Talk to the service manager of the system. This is the implied default. -H, --host= Execute the operation remotely. Specify a hostname, or a username and hostname separated by \"@\", to connect to. The hostname may optionally be suffixed by a port ssh is listening on, separated by \":\", and then a container name, separated by \"/\", which connects directly to a specific container on the specified host. This will use SSH to talk to the remote machine manager instance. Container names may be enumerated with machinectl -H HOST. Put IPv6 addresses in brackets. -M, --machine= Execute operation on a local container. Specify a container name to connect to, optionally prefixed by a user name to connect as and a separating \"@\" character. If the special string \".host\" is used in place of the container name, a connection to the local system is made (which is useful to connect to a specific user's user bus: \"--user --machine=lennart@.host\"). If the \"@\" syntax is not used, the connection is made as root user. If the \"@\" syntax is used either the left hand side or the right hand side may be omitted (but not both) in which case the local user name and \".host\" are implied. -l, --full Do not ellipsize the output in list command. --no-pager Do not pipe output into a pager. --no-legend Do not print the legend, i.e. column headers and the footer with hints. -h, --help Print a short help text and exit. --version Print a short version string and exit. "
  },
  {
    "command": "readlink",
    "description": " Note realpath(1) is the preferred command to use for canonicalization functionality. Print value of a symbolic link or canonical file name -f, --canonicalize canonicalize by following every symlink in every component of the given name recursively; all but the last component must exist -e, --canonicalize-existing canonicalize by following every symlink in every component of the given name recursively, all components must exist -m, --canonicalize-missing canonicalize by following every symlink in every component of the given name recursively, without requirements on components existence -n, --no-newline do not output the trailing delimiter -q, --quiet -s, --silent suppress most error messages (on by default) -v, --verbose report error messages -z, --zero end each output line with NUL, not newline --help display this help and exit --version output version information and exit "
  },
  {
    "command": "sh",
    "description": " The sh utility is a command language interpreter that shall execute commands read from a command line string, the standard input, or a specified file. The application shall ensure that the commands to be executed are expressed in the language described in Chapter 2, Shell Command Language. Pathname expansion shall not fail due to the size of a file. Shell input and output redirections have an implementation- defined offset maximum that is established in the open file description. The sh utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, with an extension for support of a leading <plus-sign> ('+') as noted below. The -a, -b, -C, -e, -f, -m, -n, -o option, -u, -v, and -x options are described as part of the set utility in Section 2.14, Special Built-In Utilities. The option letters derived from the set special built-in shall also be accepted with a leading <plus- sign> ('+') instead of a leading <hyphen-minus> (meaning the reverse case of the option as described in this volume of POSIX.1\u20102017). The following additional options shall be supported: -c Read commands from the command_string operand. Set the value of special parameter 0 (see Section 2.5.2, Special Parameters) from the value of the command_name operand and the positional parameters ($1, $2, and so on) in sequence from the remaining argument operands. No commands shall be read from the standard input. -i Specify that the shell is interactive; see below. An implementation may treat specifying the -i option as an error if the real user ID of the calling process does not equal the effective user ID or if the real group ID does not equal the effective group ID. -s Read commands from the standard input. If there are no operands and the -c option is not specified, the -s option shall be assumed. If the -i option is present, or if there are no operands and the shell's standard input and standard error are attached to a terminal, the shell is considered to be interactive. "
  },
  {
    "command": "mpstat",
    "description": " The mpstat command writes to standard output activities for each available processor, processor 0 being the first one. Global average activities among all processors are also reported. The mpstat command can be used on both SMP and UP machines, but in the latter, only global average activities will be printed. If no activity has been selected, then the default report is the CPU utilization report. The interval parameter specifies the amount of time in seconds between each report. A value of 0 (or no parameters at all) indicates that processors statistics are to be reported for the time since system startup (boot). The count parameter can be specified in conjunction with the interval parameter if this one is not set to zero. The value of count determines the number of reports generated at interval seconds apart. If the interval parameter is specified without the count parameter, the mpstat command generates reports continuously. -A This option is equivalent to specifying -n -u -I ALL. This option also implies specifying -N ALL -P ALL unless these options are explicitly set on the command line. --dec={ 0 | 1 | 2 } Specify the number of decimal places to use (0 to 2, default value is 2). -H Also detect and display statistics for physically hotplugged vCPUs. -I { keyword[,...] | ALL } Report interrupts statistics. Possible keywords are CPU, SCPU, and SUM. With the CPU keyword, the number of each individual interrupt received per second by the CPU or CPUs is displayed. Interrupts are those listed in /proc/interrupts file. With the SCPU keyword, the number of each individual software interrupt received per second by the CPU or CPUs is displayed. This option works only with kernels 2.6.31 and later. Software interrupts are those listed in /proc/softirqs file. With the SUM keyword, the mpstat command reports the total number of interrupts per processor. The following values are displayed: CPU Processor number. The keyword all indicates that statistics are calculated as averages among all processors. intr/s Show the total number of interrupts received per second by the CPU or CPUs. The ALL keyword is equivalent to specifying all the keywords above and therefore all the interrupts statistics are displayed. -N { node_list | ALL } Indicate the NUMA nodes for which statistics are to be reported. node_list is a list of comma-separated values or range of values (e.g., 0,2,4-7,12-). Note that node all is the global average among all nodes. The ALL keyword indicates that statistics are to be reported for all nodes. -n Report summary CPU statistics based on NUMA node placement. The following values are displayed: NODE Logical NUMA node number. The keyword all indicates that statistics are calculated as averages among all nodes. All the other fields are the same as those displayed with option -u (see below). -o JSON Display the statistics in JSON (JavaScript Object Notation) format. JSON output field order is undefined, and new fields may be added in the future. -P { cpu_list | ALL } Indicate the processors for which statistics are to be reported. cpu_list is a list of comma-separated values or range of values (e.g., 0,2,4-7,12-). Note that processor 0 is the first processor, and processor all is the global average among all processors. The ALL keyword indicates that statistics are to be reported for all processors. Offline processors are not displayed. -T Display topology elements in the CPU report (see option -u below). The following elements are displayed: CORE Logical core number. SOCK Logical socket number. NODE Logical NUMA node number. -u Report CPU utilization. The following values are displayed: CPU Processor number. The keyword all indicates that statistics are calculated as averages among all processors. %usr Show the percentage of CPU utilization that occurred while executing at the user level (application). %nice Show the percentage of CPU utilization that occurred while executing at the user level with nice priority. %sys Show the percentage of CPU utilization that occurred while executing at the system level (kernel). Note that this does not include time spent servicing hardware and software interrupts. %iowait Show the percentage of time that the CPU or CPUs were idle during which the system had an outstanding disk I/O request. %irq Show the percentage of time spent by the CPU or CPUs to service hardware interrupts. %soft Show the percentage of time spent by the CPU or CPUs to service software interrupts. %steal Show the percentage of time spent in involuntary wait by the virtual CPU or CPUs while the hypervisor was servicing another virtual processor. %guest Show the percentage of time spent by the CPU or CPUs to run a virtual processor. %gnice Show the percentage of time spent by the CPU or CPUs to run a niced guest. %idle Show the percentage of time that the CPU or CPUs were idle and the system did not have an outstanding disk I/O request. -V Print version number then exit. "
  },
  {
    "command": "nm",
    "description": " The nm utility shall display symbolic information appearing in the object file, executable file, or object-file library named by file. If no symbolic information is available for a valid input file, the nm utility shall report that fact, but not consider it an error condition. The default base used when numeric values are written is unspecified. On XSI-conformant systems, it shall be decimal if the -P option is not specified. The nm utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -A Write the full pathname or library name of an object on each line. -e Write only external (global) and static symbol information. -f Produce full output. Write redundant symbols (.text, .data, and .bss), normally suppressed. -g Write only external (global) symbol information. -o Write numeric values in octal (equivalent to -t o). -P Write information in a portable output format, as specified in the STDOUT section. -t format Write each numeric value in the specified format. The format shall be dependent on the single character used as the format option-argument: d decimal (default if -P is not specified). o octal. x hexadecimal (default if -P is specified). -u Write only undefined symbols. -v Sort output by value instead of by symbol name. -x Write numeric values in hexadecimal (equivalent to -t x). "
  },
  {
    "command": "logger",
    "description": " The logger utility saves a message, in an unspecified manner and format, containing the string operands provided by the user. The messages are expected to be evaluated later by personnel performing system administration tasks. It is implementation-defined whether messages written in locales other than the POSIX locale are effective. None. "
  },
  {
    "command": "fallocate",
    "description": " fallocate is used to manipulate the allocated disk space for a file, either to deallocate or preallocate it. For filesystems which support the fallocate(2) system call, preallocation is done quickly by allocating blocks and marking them as uninitialized, requiring no IO to the data blocks. This is much faster than creating a file by filling it with zeroes. The exit status returned by fallocate is 0 on success and 1 on failure. The length and offset arguments may be followed by the multiplicative suffixes KiB (=1024), MiB (=1024*1024), and so on for GiB, TiB, PiB, EiB, ZiB, and YiB (the \"iB\" is optional, e.g., \"K\" has the same meaning as \"KiB\") or the suffixes KB (=1000), MB (=1000*1000), and so on for GB, TB, PB, EB, ZB, and YB. The options --collapse-range, --dig-holes, --punch-hole, and --zero-range are mutually exclusive. -c, --collapse-range Removes a byte range from a file, without leaving a hole. The byte range to be collapsed starts at offset and continues for length bytes. At the completion of the operation, the contents of the file starting at the location offset+length will be appended at the location offset, and the file will be length bytes smaller. The option --keep-size may not be specified for the collapse-range operation. Available since Linux 3.15 for ext4 (only for extent-based files) and XFS. A filesystem may place limitations on the granularity of the operation, in order to ensure efficient implementation. Typically, offset and length must be a multiple of the filesystem logical block size, which varies according to the filesystem type and configuration. If a filesystem has such a requirement, the operation will fail with the error EINVAL if this requirement is violated. -d, --dig-holes Detect and dig holes. This makes the file sparse in-place, without using extra disk space. The minimum size of the hole depends on filesystem I/O block size (usually 4096 bytes). Also, when using this option, --keep-size is implied. If no range is specified by --offset and --length, then the entire file is analyzed for holes. You can think of this option as doing a \"cp --sparse\" and then renaming the destination file to the original, without the need for extra disk space. See --punch-hole for a list of supported filesystems. -i, --insert-range Insert a hole of length bytes from offset, shifting existing data. -l, --length length Specifies the length of the range, in bytes. -n, --keep-size Do not modify the apparent length of the file. This may effectively allocate blocks past EOF, which can be removed with a truncate. -o, --offset offset Specifies the beginning offset of the range, in bytes. -p, --punch-hole Deallocates space (i.e., creates a hole) in the byte range starting at offset and continuing for length bytes. Within the specified range, partial filesystem blocks are zeroed, and whole filesystem blocks are removed from the file. After a successful call, subsequent reads from this range will return zeroes. This option may not be specified at the same time as the --zero-range option. Also, when using this option, --keep-size is implied. Supported for XFS (since Linux 2.6.38), ext4 (since Linux 3.0), Btrfs (since Linux 3.7), tmpfs (since Linux 3.5) and gfs2 (since Linux 4.16). -v, --verbose Enable verbose mode. -x, --posix Enable POSIX operation mode. In that mode allocation operation always completes, but it may take longer time when fast allocation is not supported by the underlying filesystem. -z, --zero-range Zeroes space in the byte range starting at offset and continuing for length bytes. Within the specified range, blocks are preallocated for the regions that span the holes in the file. After a successful call, subsequent reads from this range will return zeroes. Zeroing is done within the filesystem preferably by converting the range into unwritten extents. This approach means that the specified range will not be physically zeroed out on the device (except for partial blocks at the either end of the range), and I/O is (otherwise) required only to update metadata. Option --keep-size can be specified to prevent file length modification. Available since Linux 3.14 for ext4 (only for extent-based files) and XFS. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "mkfifo",
    "description": " Create named pipes (FIFOs) with the given NAMEs. Mandatory arguments to long options are mandatory for short options too. -m, --mode=MODE set file permission bits to MODE, not a=rw - umask -Z set the SELinux security context to default type --context[=CTX] like -Z, or if CTX is specified then set the SELinux or SMACK security context to CTX --help display this help and exit --version output version information and exit "
  },
  {
    "command": "git-credential-store",
    "description": " Note Using this helper will store your passwords unencrypted on disk, protected only by filesystem permissions. If this is not an acceptable security tradeoff, try git-credential-cache(1), or find a helper that integrates with secure storage provided by your operating system. This command stores credentials indefinitely on disk for use by future Git programs. You probably don\u2019t want to invoke this command directly; it is meant to be used as a credential helper by other parts of git. See gitcredentials(7) or EXAMPLES below. --file=<path> Use <path> to lookup and store credentials. The file will have its filesystem permissions set to prevent other users on the system from reading it, but will not be encrypted or otherwise protected. If not specified, credentials will be searched for from ~/.git-credentials and $XDG_CONFIG_HOME/git/credentials, and credentials will be written to ~/.git-credentials if it exists, or $XDG_CONFIG_HOME/git/credentials if it exists and the former does not. See also the section called \u201cFILES\u201d. "
  },
  {
    "command": "kill",
    "description": " The default signal for kill is TERM. Use -l or -L to list available signals. Particularly useful signals include HUP, INT, KILL, STOP, CONT, and 0. Alternate signals may be specified in three ways: -9, -SIGKILL or -KILL. Negative PID values may be used to choose whole process groups; see the PGID column in ps command output. A PID of -1 is special; it indicates all processes except the kill process itself and init. <pid> [...] Send signal to every <pid> listed. -<signal> -s <signal> --signal <signal> Specify the signal to be sent. The signal can be specified by using name or number. The behavior of signals is explained in signal(7) manual page. -q, --queue value Use sigqueue(3) rather than kill(2) and the value argument is used to specify an integer to be sent with the signal. If the receiving process has installed a handler for this signal using the SA_SIGINFO flag to sigaction(2), then it can obtain this data via the si_value field of the siginfo_t structure. -l, --list [signal] List signal names. This option has optional argument, which will convert signal number to signal name, or other way round. -L, --table List signal names in a nice table. "
  },
  {
    "command": "exec",
    "description": " The exec utility shall open, close, and/or copy file descriptors as specified by any redirections as part of the command. If exec is specified without command or arguments, and any file descriptors with numbers greater than 2 are opened with associated redirection statements, it is unspecified whether those file descriptors remain open when the shell invokes another utility. Scripts concerned that child shells could misuse open file descriptors can always close them explicitly, as shown in one of the following examples. If exec is specified with command, it shall replace the shell with command without creating a new process. If arguments are specified, they shall be arguments to command. Redirection affects the current shell execution environment. None. "
  },
  {
    "command": "ln",
    "description": " In the first synopsis form, the ln utility shall create a new directory entry (link) at the destination path specified by the target_file operand. If the -s option is specified, a symbolic link shall be created for the file specified by the source_file operand. This first synopsis form shall be assumed when the final operand does not name an existing directory; if more than two operands are specified and the final is not an existing directory, an error shall result. In the second synopsis form, the ln utility shall create a new directory entry (link), or if the -s option is specified a symbolic link, for each file specified by a source_file operand, at a destination path in the existing directory named by target_dir. If the last operand specifies an existing file of a type not specified by the System Interfaces volume of POSIX.1\u20102017, the behavior is implementation-defined. The corresponding destination path for each source_file shall be the concatenation of the target directory pathname, a <slash> character if the target directory pathname did not end in a <slash>, and the last pathname component of the source_file. The second synopsis form shall be assumed when the final operand names an existing directory. For each source_file: 1. If the destination path exists and was created by a previous step, it is unspecified whether ln shall write a diagnostic message to standard error, do nothing more with the current source_file, and go on to any remaining source_files; or will continue processing the current source_file. If the destination path exists: a. If the -f option is not specified, ln shall write a diagnostic message to standard error, do nothing more with the current source_file, and go on to any remaining source_files. b. If the destination path names the same directory entry as the current source_file ln shall write a diagnostic message to standard error, do nothing more with the current source_file, and go on to any remaining source_files. c. Actions shall be performed equivalent to the unlink() function defined in the System Interfaces volume of POSIX.1\u20102017, called using the destination path as the path argument. If this fails for any reason, ln shall write a diagnostic message to standard error, do nothing more with the current source_file, and go on to any remaining source_files. 2. If the -s option is specified, actions shall be performed equivalent to the symlink() function with source_file as the path1 argument and the destination path as the path2 argument. The ln utility shall do nothing more with source_file and shall go on to any remaining files. 3. If source_file is a symbolic link: a. If the -P option is in effect, actions shall be performed equivalent to the linkat() function with source_file as the path1 argument, the destination path as the path2 argument, AT_FDCWD as the fd1 and fd2 arguments, and zero as the flag argument. b. If the -L option is in effect, actions shall be performed equivalent to the linkat() function with source_file as the path1 argument, the destination path as the path2 argument, AT_FDCWD as the fd1 and fd2 arguments, and AT_SYMLINK_FOLLOW as the flag argument. The ln utility shall do nothing more with source_file and shall go on to any remaining files. 4. Actions shall be performed equivalent to the link() function defined in the System Interfaces volume of POSIX.1\u20102017 using source_file as the path1 argument, and the destination path as the path2 argument. The ln utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -f Force existing destination pathnames to be removed to allow the link. -L For each source_file operand that names a file of type symbolic link, create a (hard) link to the file referenced by the symbolic link. -P For each source_file operand that names a file of type symbolic link, create a (hard) link to the symbolic link itself. -s Create symbolic links instead of hard links. If the -s option is specified, the -L and -P options shall be silently ignored. Specifying more than one of the mutually-exclusive options -L and -P shall not be considered an error. The last option specified shall determine the behavior of the utility (unless the -s option causes it to be ignored). If the -s option is not specified and neither a -L nor a -P option is specified, it is implementation-defined which of the -L and -P options will be used as the default. "
  },
  {
    "command": "sha224sum",
    "description": " Print or check SHA224 (224-bit) checksums. With no FILE, or when FILE is -, read standard input. -b, --binary read in binary mode -c, --check read checksums from the FILEs and check them --tag create a BSD-style checksum -t, --text read in text mode (default) -z, --zero end each output line with NUL, not newline, and disable file name escaping The following five options are useful only when verifying checksums: --ignore-missing don't fail or report status for missing files --quiet don't print OK for each successfully verified file --status don't output anything, status code shows success --strict exit non-zero for improperly formatted checksum lines -w, --warn warn about improperly formatted checksum lines --help display this help and exit --version output version information and exit The sums are computed as described in RFC 3874. When checking, the input should be a former output of this program. The default mode is to print a line with: checksum, a space, a character indicating input mode ('*' for binary, ' ' for text or where binary is insignificant), and name for each FILE. Note: There is no difference between binary mode and text mode on GNU systems. "
  },
  {
    "command": "tr",
    "description": " The tr utility shall copy the standard input to the standard output with substitution or deletion of selected characters. The options specified and the string1 and string2 operands shall control translations that occur while copying characters and single-character collating elements. The tr utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -c Complement the set of values specified by string1. See the EXTENDED DESCRIPTION section. -C Complement the set of characters specified by string1. See the EXTENDED DESCRIPTION section. -d Delete all occurrences of input characters that are specified by string1. -s Replace instances of repeated characters with a single character, as described in the EXTENDED DESCRIPTION section. "
  },
  {
    "command": "chattr",
    "description": " chattr changes the file attributes on a Linux file system. The format of a symbolic mode is +-=[aAcCdDeFijmPsStTux]. The operator '+' causes the selected attributes to be added to the existing attributes of the files; '-' causes them to be removed; and '=' causes them to be the only attributes that the files have. The letters 'aAcCdDeFijmPsStTux' select the new attributes for the files: append only (a), no atime updates (A), compressed (c), no copy on write (C), no dump (d), synchronous directory updates (D), extent format (e), case-insensitive directory lookups (F), immutable (i), data journaling (j), don't compress (m), project hierarchy (P), secure deletion (s), synchronous updates (S), no tail-merging (t), top of directory hierarchy (T), undeletable (u), and direct access for files (x). The following attributes are read-only, and may be listed by lsattr(1) but not modified by chattr: encrypted (E), indexed directory (I), inline data (N), and verity (V). Not all flags are supported or utilized by all file systems; refer to file system-specific man pages such as btrfs(5), ext4(5), mkfs.f2fs(8), and xfs(5) for more file system-specific details. -R Recursively change attributes of directories and their contents. -V Be verbose with chattr's output and print the program version. -f Suppress most error messages. -v version Set the file's version/generation number. -p project Set the file's project number. "
  },
  {
    "command": "git-reset",
    "description": " In the first three forms, copy entries from <tree-ish> to the index. In the last form, set the current branch head (HEAD) to <commit>, optionally modifying index and working tree to match. The <tree-ish>/<commit> defaults to HEAD in all forms. git reset [-q] [<tree-ish>] [--] <pathspec>..., git reset [-q] [--pathspec-from-file=<file> [--pathspec-file-nul]] [<tree-ish>] These forms reset the index entries for all paths that match the <pathspec> to their state at <tree-ish>. (It does not affect the working tree or the current branch.) This means that git reset <pathspec> is the opposite of git add <pathspec>. This command is equivalent to git restore [--source=<tree-ish>] --staged <pathspec>.... After running git reset <pathspec> to update the index entry, you can use git-restore(1) to check the contents out of the index to the working tree. Alternatively, using git-restore(1) and specifying a commit with --source, you can copy the contents of a path out of a commit to the index and to the working tree in one go. git reset (--patch | -p) [<tree-ish>] [--] [<pathspec>...] Interactively select hunks in the difference between the index and <tree-ish> (defaults to HEAD). The chosen hunks are applied in reverse to the index. This means that git reset -p is the opposite of git add -p, i.e. you can use it to selectively reset hunks. See the \u201cInteractive Mode\u201d section of git-add(1) to learn how to operate the --patch mode. git reset [<mode>] [<commit>] This form resets the current branch head to <commit> and possibly updates the index (resetting it to the tree of <commit>) and the working tree depending on <mode>. Before the operation, ORIG_HEAD is set to the tip of the current branch. If <mode> is omitted, defaults to --mixed. The <mode> must be one of the following: --soft Does not touch the index file or the working tree at all (but resets the head to <commit>, just like all modes do). This leaves all your changed files \"Changes to be committed\", as git status would put it. --mixed Resets the index but not the working tree (i.e., the changed files are preserved but not marked for commit) and reports what has not been updated. This is the default action. If -N is specified, removed paths are marked as intent-to-add (see git-add(1)). --hard Resets the index and working tree. Any changes to tracked files in the working tree since <commit> are discarded. Any untracked files or directories in the way of writing any tracked files are simply deleted. --merge Resets the index and updates the files in the working tree that are different between <commit> and HEAD, but keeps those which are different between the index and working tree (i.e. which have changes which have not been added). If a file that is different between <commit> and the index has unstaged changes, reset is aborted. In other words, --merge does something like a git read-tree -u -m <commit>, but carries forward unmerged index entries. --keep Resets index entries and updates files in the working tree that are different between <commit> and HEAD. If a file that is different between <commit> and HEAD has local changes, reset is aborted. --[no-]recurse-submodules When the working tree is updated, using --recurse-submodules will also recursively reset the working tree of all active submodules according to the commit recorded in the superproject, also setting the submodules' HEAD to be detached at that commit. See \"Reset, restore and revert\" in git(1) for the differences between the three commands. -q, --quiet Be quiet, only report errors. --refresh, --no-refresh Refresh the index after a mixed reset. Enabled by default. --pathspec-from-file=<file> Pathspec is passed in <file> instead of commandline args. If <file> is exactly - then standard input is used. Pathspec elements are separated by LF or CR/LF. Pathspec elements can be quoted as explained for the configuration variable core.quotePath (see git-config(1)). See also --pathspec-file-nul and global --literal-pathspecs. --pathspec-file-nul Only meaningful with --pathspec-from-file. Pathspec elements are separated with NUL character and all other characters are taken literally (including newlines and quotes). -- Do not interpret any more arguments as options. <pathspec>... Limits the paths affected by the operation. For more details, see the pathspec entry in gitglossary(7). "
  },
  {
    "command": "uuidgen",
    "description": " The uuidgen program creates (and prints) a new universally unique identifier (UUID) using the libuuid(3) library. The new UUID can reasonably be considered unique among all UUIDs created on the local system, and among UUIDs created on other systems in the past and in the future. There are three types of UUIDs which uuidgen can generate: time-based UUIDs, random-based UUIDs, and hash-based UUIDs. By default uuidgen will generate a random-based UUID if a high-quality random number generator is present. Otherwise, it will choose a time-based UUID. It is possible to force the generation of one of these first two UUID types by using the --random or --time options. The third type of UUID is generated with the --md5 or --sha1 options, followed by --namespace namespace and --name name. The namespace may either be a well-known UUID, or else an alias to one of the well-known UUIDs defined in RFC 4122, that is @dns, @url, @oid, or @x500. The name is an arbitrary string value. The generated UUID is the digest of the concatenation of the namespace UUID and the name value, hashed with the MD5 or SHA1 algorithms. It is, therefore, a predictable value which may be useful when UUIDs are being used as handles or nonces for more complex values or values which shouldn\u2019t be disclosed directly. See the RFC for more information. -r, --random Generate a random-based UUID. This method creates a UUID consisting mostly of random bits. It requires that the operating system has a high quality random number generator, such as /dev/random. -t, --time Generate a time-based UUID. This method creates a UUID based on the system clock plus the system\u2019s ethernet hardware address, if present. -h, --help Display help text and exit. -V, --version Print version and exit. -m, --md5 Use MD5 as the hash algorithm. -s, --sha1 Use SHA1 as the hash algorithm. -n, --namespace namespace Generate the hash with the namespace prefix. The namespace is UUID, or '@ns' where \"ns\" is well-known predefined UUID addressed by namespace name (see above). -N, --name name Generate the hash of the name. -x, --hex Interpret name name as a hexadecimal string. "
  },
  {
    "command": "git-clone",
    "description": " Clones a repository into a newly created directory, creates remote-tracking branches for each branch in the cloned repository (visible using git branch --remotes), and creates and checks out an initial branch that is forked from the cloned repository\u2019s currently active branch. After the clone, a plain git fetch without arguments will update all the remote-tracking branches, and a git pull without arguments will in addition merge the remote master branch into the current master branch, if any (this is untrue when \"--single-branch\" is given; see below). This default configuration is achieved by creating references to the remote branch heads under refs/remotes/origin and by initializing remote.origin.url and remote.origin.fetch configuration variables. -l, --local When the repository to clone from is on a local machine, this flag bypasses the normal \"Git aware\" transport mechanism and clones the repository by making a copy of HEAD and everything under objects and refs directories. The files under .git/objects/ directory are hardlinked to save space when possible. If the repository is specified as a local path (e.g., /path/to/repo), this is the default, and --local is essentially a no-op. If the repository is specified as a URL, then this flag is ignored (and we never use the local optimizations). Specifying --no-local will override the default when /path/to/repo is given, using the regular Git transport instead. If the repository\u2019s $GIT_DIR/objects has symbolic links or is a symbolic link, the clone will fail. This is a security measure to prevent the unintentional copying of files by dereferencing the symbolic links. NOTE: this operation can race with concurrent modification to the source repository, similar to running cp -r src dst while modifying src. --no-hardlinks Force the cloning process from a repository on a local filesystem to copy the files under the .git/objects directory instead of using hardlinks. This may be desirable if you are trying to make a back-up of your repository. -s, --shared When the repository to clone is on the local machine, instead of using hard links, automatically setup .git/objects/info/alternates to share the objects with the source repository. The resulting repository starts out without any object of its own. NOTE: this is a possibly dangerous operation; do not use it unless you understand what it does. If you clone your repository using this option and then delete branches (or use any other Git command that makes any existing commit unreferenced) in the source repository, some objects may become unreferenced (or dangling). These objects may be removed by normal Git operations (such as git commit) which automatically call git maintenance run --auto. (See git-maintenance(1).) If these objects are removed and were referenced by the cloned repository, then the cloned repository will become corrupt. Note that running git repack without the --local option in a repository cloned with --shared will copy objects from the source repository into a pack in the cloned repository, removing the disk space savings of clone --shared. It is safe, however, to run git gc, which uses the --local option by default. If you want to break the dependency of a repository cloned with --shared on its source repository, you can simply run git repack -a to copy all objects from the source repository into a pack in the cloned repository. --reference[-if-able] <repository> If the reference repository is on the local machine, automatically setup .git/objects/info/alternates to obtain objects from the reference repository. Using an already existing repository as an alternate will require fewer objects to be copied from the repository being cloned, reducing network and local storage costs. When using the --reference-if-able, a non existing directory is skipped with a warning instead of aborting the clone. NOTE: see the NOTE for the --shared option, and also the --dissociate option. --dissociate Borrow the objects from reference repositories specified with the --reference options only to reduce network transfer, and stop borrowing from them after a clone is made by making necessary local copies of borrowed objects. This option can also be used when cloning locally from a repository that already borrows objects from another repository\u2014the new repository will borrow objects from the same repository, and this option can be used to stop the borrowing. -q, --quiet Operate quietly. Progress is not reported to the standard error stream. -v, --verbose Run verbosely. Does not affect the reporting of progress status to the standard error stream. --progress Progress status is reported on the standard error stream by default when it is attached to a terminal, unless --quiet is specified. This flag forces progress status even if the standard error stream is not directed to a terminal. --server-option=<option> Transmit the given string to the server when communicating using protocol version 2. The given string must not contain a NUL or LF character. The server\u2019s handling of server options, including unknown ones, is server-specific. When multiple --server-option=<option> are given, they are all sent to the other side in the order listed on the command line. -n, --no-checkout No checkout of HEAD is performed after the clone is complete. --[no-]reject-shallow Fail if the source repository is a shallow repository. The clone.rejectShallow configuration variable can be used to specify the default. --bare Make a bare Git repository. That is, instead of creating <directory> and placing the administrative files in <directory>/.git, make the <directory> itself the $GIT_DIR. This obviously implies the --no-checkout because there is nowhere to check out the working tree. Also the branch heads at the remote are copied directly to corresponding local branch heads, without mapping them to refs/remotes/origin/. When this option is used, neither remote-tracking branches nor the related configuration variables are created. --sparse Employ a sparse-checkout, with only files in the toplevel directory initially being present. The git-sparse-checkout(1) command can be used to grow the working directory as needed. --filter=<filter-spec> Use the partial clone feature and request that the server sends a subset of reachable objects according to a given object filter. When using --filter, the supplied <filter-spec> is used for the partial clone filter. For example, --filter=blob:none will filter out all blobs (file contents) until needed by Git. Also, --filter=blob:limit=<size> will filter out all blobs of size at least <size>. For more details on filter specifications, see the --filter option in git-rev-list(1). --also-filter-submodules Also apply the partial clone filter to any submodules in the repository. Requires --filter and --recurse-submodules. This can be turned on by default by setting the clone.filterSubmodules config option. --mirror Set up a mirror of the source repository. This implies --bare. Compared to --bare, --mirror not only maps local branches of the source to local branches of the target, it maps all refs (including remote-tracking branches, notes etc.) and sets up a refspec configuration such that all these refs are overwritten by a git remote update in the target repository. -o <name>, --origin <name> Instead of using the remote name origin to keep track of the upstream repository, use <name>. Overrides clone.defaultRemoteName from the config. -b <name>, --branch <name> Instead of pointing the newly created HEAD to the branch pointed to by the cloned repository\u2019s HEAD, point to <name> branch instead. In a non-bare repository, this is the branch that will be checked out. --branch can also take tags and detaches the HEAD at that commit in the resulting repository. -u <upload-pack>, --upload-pack <upload-pack> When given, and the repository to clone from is accessed via ssh, this specifies a non-default path for the command run on the other end. --template=<template-directory> Specify the directory from which templates will be used; (See the \"TEMPLATE DIRECTORY\" section of git-init(1).) -c <key>=<value>, --config <key>=<value> Set a configuration variable in the newly-created repository; this takes effect immediately after the repository is initialized, but before the remote history is fetched or any files checked out. The key is in the same format as expected by git-config(1) (e.g., core.eol=true). If multiple values are given for the same key, each value will be written to the config file. This makes it safe, for example, to add additional fetch refspecs to the origin remote. Due to limitations of the current implementation, some configuration variables do not take effect until after the initial fetch and checkout. Configuration variables known to not take effect are: remote.<name>.mirror and remote.<name>.tagOpt. Use the corresponding --mirror and --no-tags options instead. --depth <depth> Create a shallow clone with a history truncated to the specified number of commits. Implies --single-branch unless --no-single-branch is given to fetch the histories near the tips of all branches. If you want to clone submodules shallowly, also pass --shallow-submodules. --shallow-since=<date> Create a shallow clone with a history after the specified time. --shallow-exclude=<revision> Create a shallow clone with a history, excluding commits reachable from a specified remote branch or tag. This option can be specified multiple times. --[no-]single-branch Clone only the history leading to the tip of a single branch, either specified by the --branch option or the primary branch remote\u2019s HEAD points at. Further fetches into the resulting repository will only update the remote-tracking branch for the branch this option was used for the initial cloning. If the HEAD at the remote did not point at any branch when --single-branch clone was made, no remote-tracking branch is created. --no-tags Don\u2019t clone any tags, and set remote.<remote>.tagOpt=--no-tags in the config, ensuring that future git pull and git fetch operations won\u2019t follow any tags. Subsequent explicit tag fetches will still work, (see git-fetch(1)). Can be used in conjunction with --single-branch to clone and maintain a branch with no references other than a single cloned branch. This is useful e.g. to maintain minimal clones of the default branch of some repository for search indexing. --recurse-submodules[=<pathspec>] After the clone is created, initialize and clone submodules within based on the provided pathspec. If no pathspec is provided, all submodules are initialized and cloned. This option can be given multiple times for pathspecs consisting of multiple entries. The resulting clone has submodule.active set to the provided pathspec, or \".\" (meaning all submodules) if no pathspec is provided. Submodules are initialized and cloned using their default settings. This is equivalent to running git submodule update --init --recursive <pathspec> immediately after the clone is finished. This option is ignored if the cloned repository does not have a worktree/checkout (i.e. if any of --no-checkout/-n, --bare, or --mirror is given) --[no-]shallow-submodules All submodules which are cloned will be shallow with a depth of 1. --[no-]remote-submodules All submodules which are cloned will use the status of the submodule\u2019s remote-tracking branch to update the submodule, rather than the superproject\u2019s recorded SHA-1. Equivalent to passing --remote to git submodule update. --separate-git-dir=<git-dir> Instead of placing the cloned repository where it is supposed to be, place the cloned repository at the specified directory, then make a filesystem-agnostic Git symbolic link to there. The result is Git repository can be separated from working tree. -j <n>, --jobs <n> The number of submodules fetched at the same time. Defaults to the submodule.fetchJobs option. <repository> The (possibly remote) repository to clone from. See the GIT URLS section below for more information on specifying repositories. <directory> The name of a new directory to clone into. The \"humanish\" part of the source repository is used if no directory is explicitly given (repo for /path/to/repo.git and foo for host.xz:foo/.git). Cloning into an existing directory is only allowed if the directory is empty. --bundle-uri=<uri> Before fetching from the remote, fetch a bundle from the given <uri> and unbundle the data into the local repository. The refs in the bundle will be stored under the hidden refs/bundle/* namespace. This option is incompatible with --depth, --shallow-since, and --shallow-exclude. "
  },
  {
    "command": "cups-config",
    "description": " The cups-config command allows application developers to determine the necessary command-line options for the compiler and linker, as well as the installation directories for filters, configuration files, and drivers. All values are reported to the standard output. The cups-config command accepts the following command-line options: --api-version Reports the current API version (major.minor). --build Reports a system-specific build number. --cflags Reports the necessary compiler options. --datadir Reports the default CUPS data directory. --help Reports the program usage message. --ldflags Reports the necessary linker options. --libs Reports the necessary libraries to link to. --serverbin Reports the default CUPS binary directory, where filters and backends are stored. --serverroot Reports the default CUPS configuration file directory. --static When used with --libs, reports the static libraries instead of the default (shared) libraries. --version Reports the full version number of the CUPS installation (major.minor.patch). "
  },
  {
    "command": "mkfifo",
    "description": " Create named pipes (FIFOs) with the given NAMEs. Mandatory arguments to long options are mandatory for short options too. -m, --mode=MODE set file permission bits to MODE, not a=rw - umask -Z set the SELinux security context to default type --context[=CTX] like -Z, or if CTX is specified then set the SELinux or SMACK security context to CTX --help display this help and exit --version output version information and exit "
  },
  {
    "command": "logger",
    "description": " The logger utility saves a message, in an unspecified manner and format, containing the string operands provided by the user. The messages are expected to be evaluated later by personnel performing system administration tasks. It is implementation-defined whether messages written in locales other than the POSIX locale are effective. None. "
  },
  {
    "command": "git-apply",
    "description": " Reads the supplied diff output (i.e. \"a patch\") and applies it to files. When running from a subdirectory in a repository, patched paths outside the directory are ignored. With the --index option the patch is also applied to the index, and with the --cached option the patch is only applied to the index. Without these options, the command applies the patch only to files, and does not require them to be in a Git repository. This command applies the patch but does not create a commit. Use git-am(1) to create commits from patches generated by git-format-patch(1) and/or received by email. <patch>... The files to read the patch from. - can be used to read from the standard input. --stat Instead of applying the patch, output diffstat for the input. Turns off \"apply\". --numstat Similar to --stat, but shows the number of added and deleted lines in decimal notation and the pathname without abbreviation, to make it more machine friendly. For binary files, outputs two - instead of saying 0 0. Turns off \"apply\". --summary Instead of applying the patch, output a condensed summary of information obtained from git diff extended headers, such as creations, renames and mode changes. Turns off \"apply\". --check Instead of applying the patch, see if the patch is applicable to the current working tree and/or the index file and detects errors. Turns off \"apply\". --index Apply the patch to both the index and the working tree (or merely check that it would apply cleanly to both if --check is in effect). Note that --index expects index entries and working tree copies for relevant paths to be identical (their contents and metadata such as file mode must match), and will raise an error if they are not, even if the patch would apply cleanly to both the index and the working tree in isolation. --cached Apply the patch to just the index, without touching the working tree. If --check is in effect, merely check that it would apply cleanly to the index entry. --intent-to-add When applying the patch only to the working tree, mark new files to be added to the index later (see --intent-to-add option in git-add(1)). This option is ignored unless running in a Git repository and --index is not specified. Note that --index could be implied by other options such as --cached or --3way. -3, --3way Attempt 3-way merge if the patch records the identity of blobs it is supposed to apply to and we have those blobs available locally, possibly leaving the conflict markers in the files in the working tree for the user to resolve. This option implies the --index option unless the --cached option is used, and is incompatible with the --reject option. When used with the --cached option, any conflicts are left at higher stages in the cache. --build-fake-ancestor=<file> Newer git diff output has embedded index information for each blob to help identify the original version that the patch applies to. When this flag is given, and if the original versions of the blobs are available locally, builds a temporary index containing those blobs. When a pure mode change is encountered (which has no index information), the information is read from the current index instead. -R, --reverse Apply the patch in reverse. --reject For atomicity, git apply by default fails the whole patch and does not touch the working tree when some of the hunks do not apply. This option makes it apply the parts of the patch that are applicable, and leave the rejected hunks in corresponding *.rej files. -z When --numstat has been given, do not munge pathnames, but use a NUL-terminated machine-readable format. Without this option, pathnames with \"unusual\" characters are quoted as explained for the configuration variable core.quotePath (see git-config(1)). -p<n> Remove <n> leading path components (separated by slashes) from traditional diff paths. E.g., with -p2, a patch against a/dir/file will be applied directly to file. The default is 1. -C<n> Ensure at least <n> lines of surrounding context match before and after each change. When fewer lines of surrounding context exist they all must match. By default no context is ever ignored. --unidiff-zero By default, git apply expects that the patch being applied is a unified diff with at least one line of context. This provides good safety measures, but breaks down when applying a diff generated with --unified=0. To bypass these checks use --unidiff-zero. Note, for the reasons stated above usage of context-free patches is discouraged. --apply If you use any of the options marked \"Turns off apply\" above, git apply reads and outputs the requested information without actually applying the patch. Give this flag after those flags to also apply the patch. --no-add When applying a patch, ignore additions made by the patch. This can be used to extract the common part between two files by first running diff on them and applying the result with this option, which would apply the deletion part but not the addition part. --allow-binary-replacement, --binary Historically we did not allow binary patch applied without an explicit permission from the user, and this flag was the way to do so. Currently we always allow binary patch application, so this is a no-op. --exclude=<path-pattern> Don\u2019t apply changes to files matching the given path pattern. This can be useful when importing patchsets, where you want to exclude certain files or directories. --include=<path-pattern> Apply changes to files matching the given path pattern. This can be useful when importing patchsets, where you want to include certain files or directories. When --exclude and --include patterns are used, they are examined in the order they appear on the command line, and the first match determines if a patch to each path is used. A patch to a path that does not match any include/exclude pattern is used by default if there is no include pattern on the command line, and ignored if there is any include pattern. --ignore-space-change, --ignore-whitespace When applying a patch, ignore changes in whitespace in context lines if necessary. Context lines will preserve their whitespace, and they will not undergo whitespace fixing regardless of the value of the --whitespace option. New lines will still be fixed, though. --whitespace=<action> When applying a patch, detect a new or modified line that has whitespace errors. What are considered whitespace errors is controlled by core.whitespace configuration. By default, trailing whitespaces (including lines that solely consist of whitespaces) and a space character that is immediately followed by a tab character inside the initial indent of the line are considered whitespace errors. By default, the command outputs warning messages but applies the patch. When git-apply is used for statistics and not applying a patch, it defaults to nowarn. You can use different <action> values to control this behavior: \u2022 nowarn turns off the trailing whitespace warning. \u2022 warn outputs warnings for a few such errors, but applies the patch as-is (default). \u2022 fix outputs warnings for a few such errors, and applies the patch after fixing them (strip is a synonym \u2014 the tool used to consider only trailing whitespace characters as errors, and the fix involved stripping them, but modern Gits do more). \u2022 error outputs warnings for a few such errors, and refuses to apply the patch. \u2022 error-all is similar to error but shows all errors. --inaccurate-eof Under certain circumstances, some versions of diff do not correctly detect a missing new-line at the end of the file. As a result, patches created by such diff programs do not record incomplete lines correctly. This option adds support for applying such patches by working around this bug. -v, --verbose Report progress to stderr. By default, only a message about the current patch being applied will be printed. This option will cause additional information to be reported. -q, --quiet Suppress stderr output. Messages about patch status and progress will not be printed. --recount Do not trust the line counts in the hunk headers, but infer them by inspecting the patch (e.g. after editing the patch without adjusting the hunk headers appropriately). --directory=<root> Prepend <root> to all filenames. If a \"-p\" argument was also passed, it is applied before prepending the new root. For example, a patch that talks about updating a/git-gui.sh to b/git-gui.sh can be applied to the file in the working tree modules/git-gui/git-gui.sh by running git apply --directory=modules/git-gui. --unsafe-paths By default, a patch that affects outside the working area (either a Git controlled working tree, or the current working directory when \"git apply\" is used as a replacement of GNU patch) is rejected as a mistake (or a mischief). When git apply is used as a \"better GNU patch\", the user can pass the --unsafe-paths option to override this safety check. This option has no effect when --index or --cached is in use. --allow-empty Don\u2019t return error for patches containing no diff. This includes empty patches and patches with commit text only. "
  },
  {
    "command": "strings",
    "description": " The strings utility shall look for printable strings in regular files and shall write those strings to standard output. A printable string is any sequence of four (by default) or more printable characters terminated by a <newline> or NUL character. Additional implementation-defined strings may be written; see localedef. If the first argument is '-', the results are unspecified. The strings utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for the unspecified usage of '-'. The following options shall be supported: -a Scan files in their entirety. If -a is not specified, it is implementation-defined what portion of each file is scanned for strings. -n number Specify the minimum string length, where the number argument is a positive decimal integer. The default shall be 4. -t format Write each string preceded by its byte offset from the start of the file. The format shall be dependent on the single character used as the format option-argument: d The offset shall be written in decimal. o The offset shall be written in octal. x The offset shall be written in hexadecimal. "
  },
  {
    "command": "hexdump",
    "description": " The hexdump utility is a filter which displays the specified files, or standard input if no files are specified, in a user-specified format. Below, the length and offset arguments may be followed by the multiplicative suffixes KiB (=1024), MiB (=1024*1024), and so on for GiB, TiB, PiB, EiB, ZiB and YiB (the \"iB\" is optional, e.g., \"K\" has the same meaning as \"KiB\"), or the suffixes KB (=1000), MB (=1000*1000), and so on for GB, TB, PB, EB, ZB and YB. -b, --one-byte-octal One-byte octal display. Display the input offset in hexadecimal, followed by sixteen space-separated, three-column, zero-filled bytes of input data, in octal, per line. -X, --one-byte-hex One-byte hexadecimal display. Display the input offset in hexadecimal, followed by sixteen space-separated, two-column, zero-filled bytes of input data, in hexadecimal, per line. -c, --one-byte-char One-byte character display. Display the input offset in hexadecimal, followed by sixteen space-separated, three-column, space-filled characters of input data per line. -C, --canonical Canonical hex+ASCII display. Display the input offset in hexadecimal, followed by sixteen space-separated, two-column, hexadecimal bytes, followed by the same sixteen bytes in %_p format enclosed in | characters. Invoking the program as hd implies this option. -d, --two-bytes-decimal Two-byte decimal display. Display the input offset in hexadecimal, followed by eight space-separated, five-column, zero-filled, two-byte units of input data, in unsigned decimal, per line. -e, --format format_string Specify a format string to be used for displaying data. -f, --format-file file Specify a file that contains one or more newline-separated format strings. Empty lines and lines whose first non-blank character is a hash mark (#) are ignored. -L, --color[=when] Accept color units for the output. The optional argument when can be auto, never or always. If the when argument is omitted, it defaults to auto. The colors can be disabled; for the current built-in default see the --help output. See also the Colors subsection and the COLORS section below. -n, --length length Interpret only length bytes of input. -o, --two-bytes-octal Two-byte octal display. Display the input offset in hexadecimal, followed by eight space-separated, six-column, zero-filled, two-byte quantities of input data, in octal, per line. -s, --skip offset Skip offset bytes from the beginning of the input. -v, --no-squeezing The -v option causes hexdump to display all input data. Without the -v option, any number of groups of output lines which would be identical to the immediately preceding group of output lines (except for the input offsets), are replaced with a line comprised of a single asterisk. -x, --two-bytes-hex Two-byte hexadecimal display. Display the input offset in hexadecimal, followed by eight space-separated, four-column, zero-filled, two-byte quantities of input data, in hexadecimal, per line. -h, --help Display help text and exit. -V, --version Print version and exit. For each input file, hexdump sequentially copies the input to standard output, transforming the data according to the format strings specified by the -e and -f options, in the order that they were specified. "
  },
  {
    "command": "git-update-index",
    "description": " Modifies the index. Each file mentioned is updated into the index and any unmerged or needs updating state is cleared. See also git-add(1) for a more user-friendly way to do some of the most common operations on the index. The way git update-index handles files it is told about can be modified using the various options: --add If a specified file isn\u2019t in the index already then it\u2019s added. Default behaviour is to ignore new files. --remove If a specified file is in the index but is missing then it\u2019s removed. Default behavior is to ignore removed file. --refresh Looks at the current index and checks to see if merges or updates are needed by checking stat() information. -q Quiet. If --refresh finds that the index needs an update, the default behavior is to error out. This option makes git update-index continue anyway. --ignore-submodules Do not try to update submodules. This option is only respected when passed before --refresh. --unmerged If --refresh finds unmerged changes in the index, the default behavior is to error out. This option makes git update-index continue anyway. --ignore-missing Ignores missing files during a --refresh --cacheinfo <mode>,<object>,<path>, --cacheinfo <mode> <object> <path> Directly insert the specified info into the index. For backward compatibility, you can also give these three arguments as three separate parameters, but new users are encouraged to use a single-parameter form. --index-info Read index information from stdin. --chmod=(+|-)x Set the execute permissions on the updated files. --[no-]assume-unchanged When this flag is specified, the object names recorded for the paths are not updated. Instead, this option sets/unsets the \"assume unchanged\" bit for the paths. When the \"assume unchanged\" bit is on, the user promises not to change the file and allows Git to assume that the working tree file matches what is recorded in the index. If you want to change the working tree file, you need to unset the bit to tell Git. This is sometimes helpful when working with a big project on a filesystem that has very slow lstat(2) system call (e.g. cifs). Git will fail (gracefully) in case it needs to modify this file in the index e.g. when merging in a commit; thus, in case the assumed-untracked file is changed upstream, you will need to handle the situation manually. --really-refresh Like --refresh, but checks stat information unconditionally, without regard to the \"assume unchanged\" setting. --[no-]skip-worktree When one of these flags is specified, the object name recorded for the paths are not updated. Instead, these options set and unset the \"skip-worktree\" bit for the paths. See section \"Skip-worktree bit\" below for more information. --[no-]ignore-skip-worktree-entries Do not remove skip-worktree (AKA \"index-only\") entries even when the --remove option was specified. --[no-]fsmonitor-valid When one of these flags is specified, the object name recorded for the paths are not updated. Instead, these options set and unset the \"fsmonitor valid\" bit for the paths. See section \"File System Monitor\" below for more information. -g, --again Runs git update-index itself on the paths whose index entries are different from those from the HEAD commit. --unresolve Restores the unmerged or needs updating state of a file during a merge if it was cleared by accident. --info-only Do not create objects in the object database for all <file> arguments that follow this flag; just insert their object IDs into the index. --force-remove Remove the file from the index even when the working directory still has such a file. (Implies --remove.) --replace By default, when a file path exists in the index, git update-index refuses an attempt to add path/file. Similarly if a file path/file exists, a file path cannot be added. With --replace flag, existing entries that conflict with the entry being added are automatically removed with warning messages. --stdin Instead of taking list of paths from the command line, read list of paths from the standard input. Paths are separated by LF (i.e. one path per line) by default. --verbose Report what is being added and removed from index. --index-version <n> Write the resulting index out in the named on-disk format version. Supported versions are 2, 3 and 4. The current default version is 2 or 3, depending on whether extra features are used, such as git add -N. Version 4 performs a simple pathname compression that reduces index size by 30%-50% on large repositories, which results in faster load time. Version 4 is relatively young (first released in 1.8.0 in October 2012). Other Git implementations such as JGit and libgit2 may not support it yet. -z Only meaningful with --stdin or --index-info; paths are separated with NUL character instead of LF. --split-index, --no-split-index Enable or disable split index mode. If split-index mode is already enabled and --split-index is given again, all changes in $GIT_DIR/index are pushed back to the shared index file. These options take effect whatever the value of the core.splitIndex configuration variable (see git-config(1)). But a warning is emitted when the change goes against the configured value, as the configured value will take effect next time the index is read and this will remove the intended effect of the option. --untracked-cache, --no-untracked-cache Enable or disable untracked cache feature. Please use --test-untracked-cache before enabling it. These options take effect whatever the value of the core.untrackedCache configuration variable (see git-config(1)). But a warning is emitted when the change goes against the configured value, as the configured value will take effect next time the index is read and this will remove the intended effect of the option. --test-untracked-cache Only perform tests on the working directory to make sure untracked cache can be used. You have to manually enable untracked cache using --untracked-cache or --force-untracked-cache or the core.untrackedCache configuration variable afterwards if you really want to use it. If a test fails the exit code is 1 and a message explains what is not working as needed, otherwise the exit code is 0 and OK is printed. --force-untracked-cache Same as --untracked-cache. Provided for backwards compatibility with older versions of Git where --untracked-cache used to imply --test-untracked-cache but this option would enable the extension unconditionally. --fsmonitor, --no-fsmonitor Enable or disable files system monitor feature. These options take effect whatever the value of the core.fsmonitor configuration variable (see git-config(1)). But a warning is emitted when the change goes against the configured value, as the configured value will take effect next time the index is read and this will remove the intended effect of the option. -- Do not interpret any more arguments as options. <file> Files to act on. Note that files beginning with . are discarded. This includes ./file and dir/./file. If you don\u2019t want this, then use cleaner names. The same applies to directories ending / and paths with // "
  },
  {
    "command": "valgrind",
    "description": " Valgrind is a flexible program for debugging and profiling Linux executables. It consists of a core, which provides a synthetic CPU in software, and a series of debugging and profiling tools. The architecture is modular, so that new tools can be created easily and without disturbing the existing structure. Some of the options described below work with all Valgrind tools, and some only work with a few or one. The section MEMCHECK OPTIONS and those below it describe tool-specific options. This manual page covers only basic usage and options. For more comprehensive information, please see the HTML documentation on your system: $INSTALL/share/doc/valgrind/html/index.html, or online: http://www.valgrind.org/docs/manual/index.html. "
  },
  {
    "command": "od",
    "description": " Write an unambiguous representation, octal bytes by default, of FILE to standard output. With more than one FILE argument, concatenate them in the listed order to form the input. With no FILE, or when FILE is -, read standard input. If first and second call formats both apply, the second format is assumed if the last operand begins with + or (if there are 2 operands) a digit. An OFFSET operand means -j OFFSET. LABEL is the pseudo-address at first byte printed, incremented when dump is progressing. For OFFSET and LABEL, a 0x or 0X prefix indicates hexadecimal; suffixes may be . for octal and b for multiply by 512. Mandatory arguments to long options are mandatory for short options too. -A, --address-radix=RADIX output format for file offsets; RADIX is one of [doxn], for Decimal, Octal, Hex or None --endian={big|little} swap input bytes according the specified order -j, --skip-bytes=BYTES skip BYTES input bytes first -N, --read-bytes=BYTES limit dump to BYTES input bytes -S BYTES, --strings[=BYTES] output strings of at least BYTES graphic chars; 3 is implied when BYTES is not specified -t, --format=TYPE select output format or formats -v, --output-duplicates do not use * to mark line suppression -w[BYTES], --width[=BYTES] output BYTES bytes per output line; 32 is implied when BYTES is not specified --traditional accept arguments in third form above --help display this help and exit --version output version information and exit Traditional format specifications may be intermixed; they accumulate: -a same as -t a, select named characters, ignoring high-order bit -b same as -t o1, select octal bytes -c same as -t c, select printable characters or backslash escapes -d same as -t u2, select unsigned decimal 2-byte units -f same as -t fF, select floats -i same as -t dI, select decimal ints -l same as -t dL, select decimal longs -o same as -t o2, select octal 2-byte units -s same as -t d2, select decimal 2-byte units -x same as -t x2, select hexadecimal 2-byte units TYPE is made up of one or more of these specifications: a named character, ignoring high-order bit c printable character or backslash escape d[SIZE] signed decimal, SIZE bytes per integer f[SIZE] floating point, SIZE bytes per float o[SIZE] octal, SIZE bytes per integer u[SIZE] unsigned decimal, SIZE bytes per integer x[SIZE] hexadecimal, SIZE bytes per integer SIZE is a number. For TYPE in [doux], SIZE may also be C for sizeof(char), S for sizeof(short), I for sizeof(int) or L for sizeof(long). If TYPE is f, SIZE may also be F for sizeof(float), D for sizeof(double) or L for sizeof(long double). Adding a z suffix to any type displays printable characters at the end of each output line. BYTES is hex with 0x or 0X prefix, and may have a multiplier suffix: b 512 KB 1000 K 1024 MB 1000*1000 M 1024*1024 and so on for G, T, P, E, Z, Y, R, Q. Binary prefixes can be used, too: KiB=K, MiB=M, and so on. "
  },
  {
    "command": "uuencode",
    "description": " The uuencode utility shall write an encoded version of the named input file, or standard input if no file is specified, to standard output. The output shall be encoded using one of the algorithms described in the STDOUT section and shall include the file access permission bits (in chmod octal or symbolic notation) of the input file and the decode_pathname, for re-creation of the file on another system that conforms to this volume of POSIX.1\u20102017. The uuencode utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported by the implementation: -m Encode the output using the MIME Base64 algorithm described in STDOUT. If -m is not specified, the historical algorithm described in STDOUT shall be used. "
  },
  {
    "command": "cmp",
    "description": " Compare two files byte by byte. The optional SKIP1 and SKIP2 specify the number of bytes to skip at the beginning of each file (zero by default). Mandatory arguments to long options are mandatory for short options too. -b, --print-bytes print differing bytes -i, --ignore-initial=SKIP skip first SKIP bytes of both inputs -i, --ignore-initial=SKIP1:SKIP2 skip first SKIP1 bytes of FILE1 and first SKIP2 bytes of FILE2 -l, --verbose output byte numbers and differing byte values -n, --bytes=LIMIT compare at most LIMIT bytes -s, --quiet, --silent suppress all normal output --help display this help and exit -v, --version output version information and exit SKIP values may be followed by the following multiplicative suffixes: kB 1000, K 1024, MB 1,000,000, M 1,048,576, GB 1,000,000,000, G 1,073,741,824, and so on for T, P, E, Z, Y. If a FILE is '-' or missing, read standard input. Exit status is 0 if inputs are the same, 1 if different, 2 if trouble. "
  },
  {
    "command": "hostname",
    "description": " Print or set the hostname of the current system. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "od",
    "description": " Write an unambiguous representation, octal bytes by default, of FILE to standard output. With more than one FILE argument, concatenate them in the listed order to form the input. With no FILE, or when FILE is -, read standard input. If first and second call formats both apply, the second format is assumed if the last operand begins with + or (if there are 2 operands) a digit. An OFFSET operand means -j OFFSET. LABEL is the pseudo-address at first byte printed, incremented when dump is progressing. For OFFSET and LABEL, a 0x or 0X prefix indicates hexadecimal; suffixes may be . for octal and b for multiply by 512. Mandatory arguments to long options are mandatory for short options too. -A, --address-radix=RADIX output format for file offsets; RADIX is one of [doxn], for Decimal, Octal, Hex or None --endian={big|little} swap input bytes according the specified order -j, --skip-bytes=BYTES skip BYTES input bytes first -N, --read-bytes=BYTES limit dump to BYTES input bytes -S BYTES, --strings[=BYTES] output strings of at least BYTES graphic chars; 3 is implied when BYTES is not specified -t, --format=TYPE select output format or formats -v, --output-duplicates do not use * to mark line suppression -w[BYTES], --width[=BYTES] output BYTES bytes per output line; 32 is implied when BYTES is not specified --traditional accept arguments in third form above --help display this help and exit --version output version information and exit Traditional format specifications may be intermixed; they accumulate: -a same as -t a, select named characters, ignoring high-order bit -b same as -t o1, select octal bytes -c same as -t c, select printable characters or backslash escapes -d same as -t u2, select unsigned decimal 2-byte units -f same as -t fF, select floats -i same as -t dI, select decimal ints -l same as -t dL, select decimal longs -o same as -t o2, select octal 2-byte units -s same as -t d2, select decimal 2-byte units -x same as -t x2, select hexadecimal 2-byte units TYPE is made up of one or more of these specifications: a named character, ignoring high-order bit c printable character or backslash escape d[SIZE] signed decimal, SIZE bytes per integer f[SIZE] floating point, SIZE bytes per float o[SIZE] octal, SIZE bytes per integer u[SIZE] unsigned decimal, SIZE bytes per integer x[SIZE] hexadecimal, SIZE bytes per integer SIZE is a number. For TYPE in [doux], SIZE may also be C for sizeof(char), S for sizeof(short), I for sizeof(int) or L for sizeof(long). If TYPE is f, SIZE may also be F for sizeof(float), D for sizeof(double) or L for sizeof(long double). Adding a z suffix to any type displays printable characters at the end of each output line. BYTES is hex with 0x or 0X prefix, and may have a multiplier suffix: b 512 KB 1000 K 1024 MB 1000*1000 M 1024*1024 and so on for G, T, P, E, Z, Y, R, Q. Binary prefixes can be used, too: KiB=K, MiB=M, and so on. "
  },
  {
    "command": "b2sum",
    "description": " Print or check BLAKE2b (512-bit) checksums. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -b, --binary read in binary mode -c, --check read checksums from the FILEs and check them -l, --length=BITS digest length in bits; must not exceed the max for the blake2 algorithm and must be a multiple of 8 --tag create a BSD-style checksum -t, --text read in text mode (default) -z, --zero end each output line with NUL, not newline, and disable file name escaping The following five options are useful only when verifying checksums: --ignore-missing don't fail or report status for missing files --quiet don't print OK for each successfully verified file --status don't output anything, status code shows success --strict exit non-zero for improperly formatted checksum lines -w, --warn warn about improperly formatted checksum lines --help display this help and exit --version output version information and exit The sums are computed as described in RFC 7693. When checking, the input should be a former output of this program. The default mode is to print a line with: checksum, a space, a character indicating input mode ('*' for binary, ' ' for text or where binary is insignificant), and name for each FILE. Note: There is no difference between binary mode and text mode on GNU systems. "
  },
  {
    "command": "git-status",
    "description": " Displays paths that have differences between the index file and the current HEAD commit, paths that have differences between the working tree and the index file, and paths in the working tree that are not tracked by Git (and are not ignored by gitignore(5)). The first are what you would commit by running git commit; the second and third are what you could commit by running git add before running git commit. -s, --short Give the output in the short-format. -b, --branch Show the branch and tracking info even in short-format. --show-stash Show the number of entries currently stashed away. --porcelain[=<version>] Give the output in an easy-to-parse format for scripts. This is similar to the short output, but will remain stable across Git versions and regardless of user configuration. See below for details. The version parameter is used to specify the format version. This is optional and defaults to the original version v1 format. --long Give the output in the long-format. This is the default. -v, --verbose In addition to the names of files that have been changed, also show the textual changes that are staged to be committed (i.e., like the output of git diff --cached). If -v is specified twice, then also show the changes in the working tree that have not yet been staged (i.e., like the output of git diff). -u[<mode>], --untracked-files[=<mode>] Show untracked files. The mode parameter is used to specify the handling of untracked files. It is optional: it defaults to all, and if specified, it must be stuck to the option (e.g. -uno, but not -u no). The possible options are: \u2022 no - Show no untracked files. \u2022 normal - Shows untracked files and directories. \u2022 all - Also shows individual files in untracked directories. When -u option is not used, untracked files and directories are shown (i.e. the same as specifying normal), to help you avoid forgetting to add newly created files. Because it takes extra work to find untracked files in the filesystem, this mode may take some time in a large working tree. Consider enabling untracked cache and split index if supported (see git update-index --untracked-cache and git update-index --split-index), Otherwise you can use no to have git status return more quickly without showing untracked files. The default can be changed using the status.showUntrackedFiles configuration variable documented in git-config(1). --ignore-submodules[=<when>] Ignore changes to submodules when looking for changes. <when> can be either \"none\", \"untracked\", \"dirty\" or \"all\", which is the default. Using \"none\" will consider the submodule modified when it either contains untracked or modified files or its HEAD differs from the commit recorded in the superproject and can be used to override any settings of the ignore option in git-config(1) or gitmodules(5). When \"untracked\" is used submodules are not considered dirty when they only contain untracked content (but they are still scanned for modified content). Using \"dirty\" ignores all changes to the work tree of submodules, only changes to the commits stored in the superproject are shown (this was the behavior before 1.7.0). Using \"all\" hides all changes to submodules (and suppresses the output of submodule summaries when the config option status.submoduleSummary is set). --ignored[=<mode>] Show ignored files as well. The mode parameter is used to specify the handling of ignored files. It is optional: it defaults to traditional. The possible options are: \u2022 traditional - Shows ignored files and directories, unless --untracked-files=all is specified, in which case individual files in ignored directories are displayed. \u2022 no - Show no ignored files. \u2022 matching - Shows ignored files and directories matching an ignore pattern. When matching mode is specified, paths that explicitly match an ignored pattern are shown. If a directory matches an ignore pattern, then it is shown, but not paths contained in the ignored directory. If a directory does not match an ignore pattern, but all contents are ignored, then the directory is not shown, but all contents are shown. -z Terminate entries with NUL, instead of LF. This implies the --porcelain=v1 output format if no other format is given. --column[=<options>], --no-column Display untracked files in columns. See configuration variable column.status for option syntax. --column and --no-column without options are equivalent to always and never respectively. --ahead-behind, --no-ahead-behind Display or do not display detailed ahead/behind counts for the branch relative to its upstream branch. Defaults to true. --renames, --no-renames Turn on/off rename detection regardless of user configuration. See also git-diff(1) --no-renames. --find-renames[=<n>] Turn on rename detection, optionally setting the similarity threshold. See also git-diff(1) --find-renames. <pathspec>... See the pathspec entry in gitglossary(7). "
  },
  {
    "command": "time",
    "description": " The time utility shall invoke the utility named by the utility operand with arguments supplied as the argument operands and write a message to standard error that lists timing statistics for the utility. The message shall include the following information: * The elapsed (real) time between invocation of utility and its termination. * The User CPU time, equivalent to the sum of the tms_utime and tms_cutime fields returned by the times() function defined in the System Interfaces volume of POSIX.1\u20102017 for the process in which utility is executed. * The System CPU time, equivalent to the sum of the tms_stime and tms_cstime fields returned by the times() function for the process in which utility is executed. The precision of the timing shall be no less than the granularity defined for the size of the clock tick unit on the system, but the results shall be reported in terms of standard time units (for example, 0.02 seconds, 00:00:00.02, 1m33.75s, 365.21 seconds), not numbers of clock ticks. When time is used as part of a pipeline, the times reported are unspecified, except when it is the sole command within a grouping command (see Section 2.9.4.1, Grouping Commands) in that pipeline. For example, the commands on the left are unspecified; those on the right report on utilities a and c, respectively: time a | b | c { time a; } | b | c a | b | time c a | b | (time c) The time utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -p Write the timing output to standard error in the format shown in the STDERR section. "
  },
  {
    "command": "split",
    "description": " The split utility shall read an input file and write zero or more output files. The default size of each output file shall be 1000 lines. The size of the output files can be modified by specification of the -b or -l options. Each output file shall be created with a unique suffix. The suffix shall consist of exactly suffix_length lowercase letters from the POSIX locale. The letters of the suffix shall be used as if they were a base-26 digit system, with the first suffix to be created consisting of all 'a' characters, the second with a 'b' replacing the last 'a', and so on, until a name of all 'z' characters is created. By default, the names of the output files shall be 'x', followed by a two-character suffix from the character set as described above, starting with \"aa\", \"ab\", \"ac\", and so on, and continuing until the suffix \"zz\", for a maximum of 676 files. If the number of files required exceeds the maximum allowed by the suffix length provided, such that the last allowable file would be larger than the requested size, the split utility shall fail after creating the last file with a valid suffix; split shall not delete the files it created with valid suffixes. If the file limit is not exceeded, the last file created shall contain the remainder of the input file, and may be smaller than the requested size. If the input is an empty file, no output file shall be created and this shall not be considered to be an error. The split utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -a suffix_length Use suffix_length letters to form the suffix portion of the filenames of the split file. If -a is not specified, the default suffix length shall be two. If the sum of the name operand and the suffix_length option-argument would create a filename exceeding {NAME_MAX} bytes, an error shall result; split shall exit with a diagnostic message and no files shall be created. -b n Split a file into pieces n bytes in size. -b nk Split a file into pieces n*1024 bytes in size. -b nm Split a file into pieces n*1048576 bytes in size. -l line_count Specify the number of lines in each resulting file piece. The line_count argument is an unsigned decimal integer. The default is 1000. If the input does not end with a <newline>, the partial line shall be included in the last output file. "
  },
  {
    "command": "su",
    "description": " su allows commands to be run with a substitute user and group ID. When called with no user specified, su defaults to running an interactive shell as root. When user is specified, additional arguments can be supplied, in which case they are passed to the shell. For backward compatibility, su defaults to not change the current directory and to only set the environment variables HOME and SHELL (plus USER and LOGNAME if the target user is not root). It is recommended to always use the --login option (instead of its shortcut -) to avoid side effects caused by mixing environments. This version of su uses PAM for authentication, account and session management. Some configuration options found in other su implementations, such as support for a wheel group, have to be configured via PAM. su is mostly designed for unprivileged users, the recommended solution for privileged users (e.g., scripts executed by root) is to use non-set-user-ID command runuser(1) that does not require authentication and provides separate PAM configuration. If the PAM session is not required at all then the recommended solution is to use command setpriv(1). Note that su in all cases uses PAM (pam_getenvlist(3)) to do the final environment modification. Command-line options such as --login and --preserve-environment affect the environment before it is modified by PAM. Since version 2.38 su resets process resource limits RLIMIT_NICE, RLIMIT_RTPRIO, RLIMIT_FSIZE, RLIMIT_AS and RLIMIT_NOFILE. -c, --command=command Pass command to the shell with the -c option. -f, --fast Pass -f to the shell, which may or may not be useful, depending on the shell. -g, --group=group Specify the primary group. This option is available to the root user only. -G, --supp-group=group Specify a supplementary group. This option is available to the root user only. The first specified supplementary group is also used as a primary group if the option --group is not specified. -, -l, --login Start the shell as a login shell with an environment similar to a real login: \u2022 clears all the environment variables except TERM and variables specified by --whitelist-environment \u2022 initializes the environment variables HOME, SHELL, USER, LOGNAME, and PATH \u2022 changes to the target user\u2019s home directory \u2022 sets argv[0] of the shell to '-' in order to make the shell a login shell -m, -p, --preserve-environment Preserve the entire environment, i.e., do not set HOME, SHELL, USER or LOGNAME. This option is ignored if the option --login is specified. -P, --pty Create a pseudo-terminal for the session. The independent terminal provides better security as the user does not share a terminal with the original session. This can be used to avoid TIOCSTI ioctl terminal injection and other security attacks against terminal file descriptors. The entire session can also be moved to the background (e.g., su --pty - username -c application &). If the pseudo-terminal is enabled, then su works as a proxy between the sessions (sync stdin and stdout). This feature is mostly designed for interactive sessions. If the standard input is not a terminal, but for example a pipe (e.g., echo \"date\" | su --pty), then the ECHO flag for the pseudo-terminal is disabled to avoid messy output. -s, --shell=shell Run the specified shell instead of the default. The shell to run is selected according to the following rules, in order: \u2022 the shell specified with --shell \u2022 the shell specified in the environment variable SHELL, if the --preserve-environment option is used \u2022 the shell listed in the passwd entry of the target user \u2022 /bin/sh If the target user has a restricted shell (i.e., not listed in /etc/shells), the --shell option and the SHELL environment variables are ignored unless the calling user is root. --session-command=command Same as -c, but do not create a new session. (Discouraged.) -w, --whitelist-environment=list Don\u2019t reset the environment variables specified in the comma-separated list when clearing the environment for --login. The whitelist is ignored for the environment variables HOME, SHELL, USER, LOGNAME, and PATH. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "w",
    "description": " w displays information about the users currently on the machine, and their processes. The header shows, in this order, the current time, how long the system has been running, how many users are currently logged on, and the system load averages for the past 1, 5, and 15 minutes. The following entries are displayed for each user: login name, the tty name, the remote host, login time, idle time, JCPU, PCPU, and the command line of their current process. The JCPU time is the time used by all processes attached to the tty. It does not include past background jobs, but does include currently running background jobs. The PCPU time is the time used by the current process, named in the \"what\" field. "
  },
  {
    "command": "git-reflog",
    "description": " This command manages the information recorded in the reflogs. Reference logs, or \"reflogs\", record when the tips of branches and other references were updated in the local repository. Reflogs are useful in various Git commands, to specify the old value of a reference. For example, HEAD@{2} means \"where HEAD used to be two moves ago\", master@{one.week.ago} means \"where master used to point to one week ago in this local repository\", and so on. See gitrevisions(7) for more details. The command takes various subcommands, and different options depending on the subcommand: The \"show\" subcommand (which is also the default, in the absence of any subcommands) shows the log of the reference provided in the command-line (or HEAD, by default). The reflog covers all recent actions, and in addition the HEAD reflog records branch switching. git reflog show is an alias for git log -g --abbrev-commit --pretty=oneline; see git-log(1) for more information. The \"expire\" subcommand prunes older reflog entries. Entries older than expire time, or entries older than expire-unreachable time and not reachable from the current tip, are removed from the reflog. This is typically not used directly by end users \u2014 instead, see git-gc(1). The \"delete\" subcommand deletes single entries from the reflog. Its argument must be an exact entry (e.g. \"git reflog delete master@{2}\"). This subcommand is also typically not used directly by end users. The \"exists\" subcommand checks whether a ref has a reflog. It exits with zero status if the reflog exists, and non-zero status if it does not. Options for show git reflog show accepts any of the options accepted by git log. Options for expire --all Process the reflogs of all references. --single-worktree By default when --all is specified, reflogs from all working trees are processed. This option limits the processing to reflogs from the current working tree only. --expire=<time> Prune entries older than the specified time. If this option is not specified, the expiration time is taken from the configuration setting gc.reflogExpire, which in turn defaults to 90 days. --expire=all prunes entries regardless of their age; --expire=never turns off pruning of reachable entries (but see --expire-unreachable). --expire-unreachable=<time> Prune entries older than <time> that are not reachable from the current tip of the branch. If this option is not specified, the expiration time is taken from the configuration setting gc.reflogExpireUnreachable, which in turn defaults to 30 days. --expire-unreachable=all prunes unreachable entries regardless of their age; --expire-unreachable=never turns off early pruning of unreachable entries (but see --expire). --updateref Update the reference to the value of the top reflog entry (i.e. <ref>@{0}) if the previous top entry was pruned. (This option is ignored for symbolic references.) --rewrite If a reflog entry\u2019s predecessor is pruned, adjust its \"old\" SHA-1 to be equal to the \"new\" SHA-1 field of the entry that now precedes it. --stale-fix Prune any reflog entries that point to \"broken commits\". A broken commit is a commit that is not reachable from any of the reference tips and that refers, directly or indirectly, to a missing commit, tree, or blob object. This computation involves traversing all the reachable objects, i.e. it has the same cost as git prune. It is primarily intended to fix corruption caused by garbage collecting using older versions of Git, which didn\u2019t protect objects referred to by reflogs. -n, --dry-run Do not actually prune any entries; just show what would have been pruned. --verbose Print extra information on screen. Options for delete git reflog delete accepts options --updateref, --rewrite, -n, --dry-run, and --verbose, with the same meanings as when they are used with expire. "
  },
  {
    "command": "git-cat-file",
    "description": " In its first form, the command provides the content or the type of an object in the repository. The type is required unless -t or -p is used to find the object type, or -s is used to find the object size, or --textconv or --filters is used (which imply type \"blob\"). In the second form, a list of objects (separated by linefeeds) is provided on stdin, and the SHA-1, type, and size of each object is printed on stdout. The output format can be overridden using the optional <format> argument. If either --textconv or --filters was specified, the input is expected to list the object names followed by the path name, separated by a single whitespace, so that the appropriate drivers can be determined. <object> The name of the object to show. For a more complete list of ways to spell object names, see the \"SPECIFYING REVISIONS\" section in gitrevisions(7). -t Instead of the content, show the object type identified by <object>. -s Instead of the content, show the object size identified by <object>. If used with --use-mailmap option, will show the size of updated object after replacing idents using the mailmap mechanism. -e Exit with zero status if <object> exists and is a valid object. If <object> is of an invalid format exit with non-zero and emits an error on stderr. -p Pretty-print the contents of <object> based on its type. <type> Typically this matches the real type of <object> but asking for a type that can trivially be dereferenced from the given <object> is also permitted. An example is to ask for a \"tree\" with <object> being a commit object that contains it, or to ask for a \"blob\" with <object> being a tag object that points at it. --[no-]mailmap, --[no-]use-mailmap Use mailmap file to map author, committer and tagger names and email addresses to canonical real names and email addresses. See git-shortlog(1). --textconv Show the content as transformed by a textconv filter. In this case, <object> has to be of the form <tree-ish>:<path>, or :<path> in order to apply the filter to the content recorded in the index at <path>. --filters Show the content as converted by the filters configured in the current working tree for the given <path> (i.e. smudge filters, end-of-line conversion, etc). In this case, <object> has to be of the form <tree-ish>:<path>, or :<path>. --path=<path> For use with --textconv or --filters, to allow specifying an object name and a path separately, e.g. when it is difficult to figure out the revision from which the blob came. --batch, --batch=<format> Print object information and contents for each object provided on stdin. May not be combined with any other options or arguments except --textconv, --filters, or --use-mailmap. \u2022 When used with --textconv or --filters, the input lines must specify the path, separated by whitespace. See the section BATCH OUTPUT below for details. \u2022 When used with --use-mailmap, for commit and tag objects, the contents part of the output shows the identities replaced using the mailmap mechanism, while the information part of the output shows the size of the object as if it actually recorded the replacement identities. --batch-check, --batch-check=<format> Print object information for each object provided on stdin. May not be combined with any other options or arguments except --textconv, --filters or --use-mailmap. \u2022 When used with --textconv or --filters, the input lines must specify the path, separated by whitespace. See the section BATCH OUTPUT below for details. \u2022 When used with --use-mailmap, for commit and tag objects, the printed object information shows the size of the object as if the identities recorded in it were replaced by the mailmap mechanism. --batch-command, --batch-command=<format> Enter a command mode that reads commands and arguments from stdin. May only be combined with --buffer, --textconv, --use-mailmap or --filters. \u2022 When used with --textconv or --filters, the input lines must specify the path, separated by whitespace. See the section BATCH OUTPUT below for details. \u2022 When used with --use-mailmap, for commit and tag objects, the contents command shows the identities replaced using the mailmap mechanism, while the info command shows the size of the object as if it actually recorded the replacement identities. --batch-command recognizes the following commands: contents <object> Print object contents for object reference <object>. This corresponds to the output of --batch. info <object> Print object info for object reference <object>. This corresponds to the output of --batch-check. flush Used with --buffer to execute all preceding commands that were issued since the beginning or since the last flush was issued. When --buffer is used, no output will come until a flush is issued. When --buffer is not used, commands are flushed each time without issuing flush. --batch-all-objects Instead of reading a list of objects on stdin, perform the requested batch operation on all objects in the repository and any alternate object stores (not just reachable objects). Requires --batch or --batch-check be specified. By default, the objects are visited in order sorted by their hashes; see also --unordered below. Objects are presented as-is, without respecting the \"replace\" mechanism of git-replace(1). --buffer Normally batch output is flushed after each object is output, so that a process can interactively read and write from cat-file. With this option, the output uses normal stdio buffering; this is much more efficient when invoking --batch-check or --batch-command on a large number of objects. --unordered When --batch-all-objects is in use, visit objects in an order which may be more efficient for accessing the object contents than hash order. The exact details of the order are unspecified, but if you do not require a specific order, this should generally result in faster output, especially with --batch. Note that cat-file will still show each object only once, even if it is stored multiple times in the repository. --allow-unknown-type Allow -s or -t to query broken/corrupt objects of unknown type. --follow-symlinks With --batch or --batch-check, follow symlinks inside the repository when requesting objects with extended SHA-1 expressions of the form tree-ish:path-in-tree. Instead of providing output about the link itself, provide output about the linked-to object. If a symlink points outside the tree-ish (e.g. a link to /foo or a root-level link to ../foo), the portion of the link which is outside the tree will be printed. This option does not (currently) work correctly when an object in the index is specified (e.g. :link instead of HEAD:link) rather than one in the tree. This option cannot (currently) be used unless --batch or --batch-check is used. For example, consider a git repository containing: f: a file containing \"hello\\n\" link: a symlink to f dir/link: a symlink to ../f plink: a symlink to ../f alink: a symlink to /etc/passwd For a regular file f, echo HEAD:f | git cat-file --batch would print ce013625030ba8dba906f756967f9e9ca394464a blob 6 And echo HEAD:link | git cat-file --batch --follow-symlinks would print the same thing, as would HEAD:dir/link, as they both point at HEAD:f. Without --follow-symlinks, these would print data about the symlink itself. In the case of HEAD:link, you would see 4d1ae35ba2c8ec712fa2a379db44ad639ca277bd blob 1 Both plink and alink point outside the tree, so they would respectively print: symlink 4 ../f symlink 11 /etc/passwd -Z Only meaningful with --batch, --batch-check, or --batch-command; input and output is NUL-delimited instead of newline-delimited. -z Only meaningful with --batch, --batch-check, or --batch-command; input is NUL-delimited instead of newline-delimited. This option is deprecated in favor of -Z as the output can otherwise be ambiguous. "
  },
  {
    "command": "clear",
    "description": " @CLEAR@ clears your terminal's screen if this is possible, including the terminal's scrollback buffer (if the extended \u201cE3\u201d capability is defined). @CLEAR@ looks in the environment for the terminal type given by the environment variable TERM, and then in the terminfo database to determine how to clear the screen. @CLEAR@ writes to the standard output. You can redirect the standard output to a file (which prevents @CLEAR@ from actually clearing the screen), and later cat the file to the screen, clearing it at that point. -T type indicates the type of terminal. Normally this option is unnecessary, because the default is taken from the environment variable TERM. If -T is specified, then the shell variables LINES and COLUMNS will also be ignored. -V reports the version of ncurses which was used in this program, and exits. The options are as follows: -x do not attempt to clear the terminal's scrollback buffer using the extended \u201cE3\u201d capability. "
  },
  {
    "command": "tput",
    "description": " The @TPUT@ utility uses the terminfo database to make the values of terminal-dependent capabilities and information available to the shell (see sh(1)), to initialize or reset the terminal, or return the long name of the requested terminal type. The result depends upon the capability's type: string @TPUT@ writes the string to the standard output. No trailing newline is supplied. integer @TPUT@ writes the decimal value to the standard output, with a trailing newline. boolean @TPUT@ simply sets the exit code (0 for TRUE if the terminal has the capability, 1 for FALSE if it does not), and writes nothing to the standard output. Before using a value returned on the standard output, the application should test the exit code (e.g., $?, see sh(1)) to be sure it is 0. (See the EXIT CODES and DIAGNOSTICS sections.) For a complete list of capabilities and the capname associated with each, see terminfo(5). Options -S allows more than one capability per invocation of @TPUT@. The capabilities must be passed to @TPUT@ from the standard input instead of from the command line (see example). Only one capname is allowed per line. The -S option changes the meaning of the 0 and 1 boolean and string exit codes (see the EXIT CODES section). Because some capabilities may use string parameters rather than numbers, @TPUT@ uses a table and the presence of parameters in its input to decide whether to use tparm(3X), and how to interpret the parameters. -Ttype indicates the type of terminal. Normally this option is unnecessary, because the default is taken from the environment variable TERM. If -T is specified, then the shell variables LINES and COLUMNS will also be ignored. -V reports the version of ncurses which was used in this program, and exits. -x do not attempt to clear the terminal's scrollback buffer using the extended \u201cE3\u201d capability. Commands A few commands (init, reset and longname) are special; they are defined by the @TPUT@ program. The others are the names of capabilities from the terminal database (see terminfo(5) for a list). Although init and reset resemble capability names, @TPUT@ uses several capabilities to perform these special functions. capname indicates the capability from the terminal database. If the capability is a string that takes parameters, the arguments following the capability will be used as parameters for the string. Most parameters are numbers. Only a few terminal capabilities require string parameters; @TPUT@ uses a table to decide which to pass as strings. Normally @TPUT@ uses tparm(3X) to perform the substitution. If no parameters are given for the capability, @TPUT@ writes the string without performing the substitution. init If the terminal database is present and an entry for the user's terminal exists (see -Ttype, above), the following will occur: (1) first, @TPUT@ retrieves the current terminal mode settings for your terminal. It does this by successively testing \u2022 the standard error, \u2022 standard output, \u2022 standard input and \u2022 ultimately \u201c/dev/tty\u201d to obtain terminal settings. Having retrieved these settings, @TPUT@ remembers which file descriptor to use when updating settings. (2) if the window size cannot be obtained from the operating system, but the terminal description (or environment, e.g., LINES and COLUMNS variables specify this), update the operating system's notion of the window size. (3) the terminal modes will be updated: \u2022 any delays (e.g., newline) specified in the entry will be set in the tty driver, \u2022 tabs expansion will be turned on or off according to the specification in the entry, and \u2022 if tabs are not expanded, standard tabs will be set (every 8 spaces). (4) if present, the terminal's initialization strings will be output as detailed in the terminfo(5) section on Tabs and Initialization, (5) output is flushed. If an entry does not contain the information needed for any of these activities, that activity will silently be skipped. reset This is similar to init, with two differences: (1) before any other initialization, the terminal modes will be reset to a \u201csane\u201d state: \u2022 set cooked and echo modes, \u2022 turn off cbreak and raw modes, \u2022 turn on newline translation and \u2022 reset any unset special characters to their default values (2) Instead of putting out initialization strings, the terminal's reset strings will be output if present (rs1, rs2, rs3, rf). If the reset strings are not present, but initialization strings are, the initialization strings will be output. Otherwise, reset acts identically to init. longname If the terminal database is present and an entry for the user's terminal exists (see -Ttype above), then the long name of the terminal will be put out. The long name is the last name in the first line of the terminal's description in the terminfo database [see term(5)]. Aliases @TPUT@ handles the clear, init and reset commands specially: it allows for the possibility that it is invoked by a link with those names. If @TPUT@ is invoked by a link named reset, this has the same effect as @TPUT@ reset. The @TSET@(1) utility also treats a link named reset specially. Before ncurses 6.1, the two utilities were different from each other: \u2022 @TSET@ utility reset the terminal modes and special characters (not done with @TPUT@). \u2022 On the other hand, @TSET@'s repertoire of terminal capabilities for resetting the terminal was more limited, i.e., only reset_1string, reset_2string and reset_file in contrast to the tab-stops and margins which are set by this utility. \u2022 The reset program is usually an alias for @TSET@, because of this difference with resetting terminal modes and special characters. With the changes made for ncurses 6.1, the reset feature of the two programs is (mostly) the same. A few differences remain: \u2022 The @TSET@ program waits one second when resetting, in case it happens to be a hardware terminal. \u2022 The two programs write the terminal initialization strings to different streams (i.e., the standard error for @TSET@ and the standard output for @TPUT@). Note: although these programs write to different streams, redirecting their output to a file will capture only part of their actions. The changes to the terminal modes are not affected by redirecting the output. If @TPUT@ is invoked by a link named init, this has the same effect as @TPUT@ init. Again, you are less likely to use that link because another program named init has a more well- established use. Terminal Size Besides the special commands (e.g., clear), @TPUT@ treats certain terminfo capabilities specially: lines and cols. @TPUT@ calls setupterm(3X) to obtain the terminal size: \u2022 first, it gets the size from the terminal database (which generally is not provided for terminal emulators which do not have a fixed window size) \u2022 then it asks the operating system for the terminal's size (which generally works, unless connecting via a serial line which does not support NAWS: negotiations about window size). \u2022 finally, it inspects the environment variables LINES and COLUMNS which may override the terminal size. If the -T option is given @TPUT@ ignores the environment variables by calling use_tioctl(TRUE), relying upon the operating system (or finally, the terminal database). "
  },
  {
    "command": "nice",
    "description": " Run COMMAND with an adjusted niceness, which affects process scheduling. With no COMMAND, print the current niceness. Niceness values range from -20 (most favorable to the process) to 19 (least favorable to the process). Mandatory arguments to long options are mandatory for short options too. -n, --adjustment=N add integer N to the niceness (default 10) --help display this help and exit --version output version information and exit NOTE: your shell may have its own version of nice, which usually supersedes the version described here. Please refer to your shell's documentation for details about the options it supports. Exit status: 125 if the nice command itself fails 126 if COMMAND is found but cannot be invoked 127 if COMMAND cannot be found - the exit status of COMMAND otherwise "
  },
  {
    "command": "echo",
    "description": " Echo the STRING(s) to standard output. -n do not output the trailing newline -e enable interpretation of backslash escapes -E disable interpretation of backslash escapes (default) --help display this help and exit --version output version information and exit If -e is in effect, the following sequences are recognized: \\\\ backslash \\a alert (BEL) \\b backspace \\c produce no further output \\e escape \\f form feed \\n new line \\r carriage return \\t horizontal tab \\v vertical tab \\0NNN byte with octal value NNN (1 to 3 digits) \\xHH byte with hexadecimal value HH (1 to 2 digits) NOTE: your shell may have its own version of echo, which usually supersedes the version described here. Please refer to your shell's documentation for details about the options it supports. NOTE: printf(1) is a preferred alternative, which does not have issues outputting option-like strings. "
  },
  {
    "command": "expand",
    "description": " The expand utility shall write files or the standard input to the standard output with <tab> characters replaced with one or more <space> characters needed to pad to the next tab stop. Any <backspace> characters shall be copied to the output and cause the column position count for tab stop calculations to be decremented; the column position count shall not be decremented below zero. The expand utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -t tablist Specify the tab stops. The application shall ensure that the argument tablist consists of either a single positive decimal integer or a list of tabstops. If a single number is given, tabs shall be set that number of column positions apart instead of the default 8. If a list of tabstops is given, the application shall ensure that it consists of a list of two or more positive decimal integers, separated by <blank> or <comma> characters, in ascending order. The <tab> characters shall be set at those specific column positions. Each tab stop N shall be an integer value greater than zero, and the list is in strictly ascending order. This is taken to mean that, from the start of a line of output, tabbing to position N shall cause the next character output to be in the (N+1)th column position on that line. In the event of expand having to process a <tab> at a position beyond the last of those specified in a multiple tab-stop list, the <tab> shall be replaced by a single <space> in the output. "
  },
  {
    "command": "systemd-firstboot",
    "description": " systemd-firstboot initializes basic system settings interactively during the first boot, or non-interactively on an offline system image. The service is started during boot if ConditionFirstBoot=yes is met, which essentially means that /etc/ is empty, see systemd.unit(5) for details. The following settings may be configured: \u2022 The machine ID of the system \u2022 The system locale, more specifically the two locale variables LANG= and LC_MESSAGES \u2022 The system keyboard map \u2022 The system time zone \u2022 The system hostname \u2022 The kernel command line used when installing kernel images \u2022 The root user's password and shell Each of the fields may either be queried interactively by users, set non-interactively on the tool's command line, or be copied from a host system that is used to set up the system image. If a setting is already initialized, it will not be overwritten and the user will not be prompted for the setting. Note that this tool operates directly on the file system and does not involve any running system services, unlike localectl(1), timedatectl(1) or hostnamectl(1). This allows systemd-firstboot to operate on mounted but not booted disk images and in early boot. It is not recommended to use systemd-firstboot on the running system after it has been set up. The following options are understood: --root=root Takes a directory path as an argument. All paths will be prefixed with the given alternate root path, including config search paths. This is useful to operate on a system image mounted to the specified directory instead of the host system itself. --image=path Takes a path to a disk image file or block device node. If specified all operations are applied to file system in the indicated disk image. This is similar to --root= but operates on file systems stored in disk images or block devices. The disk image should either contain just a file system or a set of file systems within a GPT partition table, following the Discoverable Partitions Specification[1]. For further information on supported disk images, see systemd-nspawn(1)'s switch of the same name. --locale=LOCALE, --locale-messages=LOCALE Sets the system locale, more specifically the LANG= and LC_MESSAGES settings. The argument should be a valid locale identifier, such as \"de_DE.UTF-8\". This controls the locale.conf(5) configuration file. --keymap=KEYMAP Sets the system keyboard layout. The argument should be a valid keyboard map, such as \"de-latin1\". This controls the \"KEYMAP\" entry in the vconsole.conf(5) configuration file. --timezone=TIMEZONE Sets the system time zone. The argument should be a valid time zone identifier, such as \"Europe/Berlin\". This controls the localtime(5) symlink. --hostname=HOSTNAME Sets the system hostname. The argument should be a hostname, compatible with DNS. This controls the hostname(5) configuration file. --setup-machine-id Initialize the system's machine ID to a random ID. This controls the machine-id(5) file. This option only works in combination with --root= or --image=. On a running system, machine-id is written by the manager with help from systemd-machine-id-commit.service(8). --machine-id=ID Set the system's machine ID to the specified value. The same restrictions apply as to --setup-machine-id. --root-password=PASSWORD, --root-password-file=PATH, --root-password-hashed=HASHED_PASSWORD Sets the password of the system's root user. This creates/modifies the passwd(5) and shadow(5) files. This setting exists in three forms: --root-password= accepts the password to set directly on the command line, --root-password-file= reads it from a file and --root-password-hashed= accepts an already hashed password on the command line. See shadow(5) for more information on the format of the hashed password. Note that it is not recommended to specify plaintext passwords on the command line, as other users might be able to see them simply by invoking ps(1). --root-shell=SHELL Sets the shell of the system's root user. This creates/modifies the passwd(5) file. --kernel-command-line=CMDLINE Sets the system's kernel command line. This controls the /etc/kernel/cmdline file which is used by kernel-install(8). --prompt-locale, --prompt-keymap, --prompt-timezone, --prompt-hostname, --prompt-root-password, --prompt-root-shell Prompt the user interactively for a specific basic setting. Note that any explicit configuration settings specified on the command line take precedence, and the user is not prompted for it. --prompt Query the user for locale, keymap, timezone, hostname, root's password, and root's shell. This is equivalent to specifying --prompt-locale, --prompt-keymap, --prompt-timezone, --prompt-hostname, --prompt-root-password, --prompt-root-shell in combination. --copy-locale, --copy-keymap, --copy-timezone, --copy-root-password, --copy-root-shell Copy a specific basic setting from the host. This only works in combination with --root= or --image=. --copy Copy locale, keymap, time zone, root password and shell from the host. This is equivalent to specifying --copy-locale, --copy-keymap, --copy-timezone, --copy-root-password, --copy-root-shell in combination. --force Write configuration even if the relevant files already exist. Without this option, systemd-firstboot doesn't modify or replace existing files. Note that when configuring the root account, even with this option, systemd-firstboot only modifies the entry of the \"root\" user, leaving other entries in /etc/passwd and /etc/shadow intact. --reset If specified, all existing files that are configured by systemd-firstboot are removed. Note that the files are removed regardless of whether they'll be configured with a new value or not. This operation ensures that the next boot of the image will be considered a first boot, and systemd-firstboot will prompt again to configure each of the removed files. --delete-root-password Removes the password of the system's root user, enabling login as root without a password unless the root account is locked. Note that this is extremely insecure and hence this option should not be used lightly. --welcome= Takes a boolean argument. By default when prompting the user for configuration options a brief welcome text is shown before the first question is asked. Pass false to this option to turn off the welcome text. -h, --help Print a short help text and exit. --version Print a short version string and exit. "
  },
  {
    "command": "last",
    "description": " last looks through the file wtmp (which records all logins/logouts) and prints information about connect times of users. Records are printed from most recent to least recent. Records can be specified by tty and username. tty names can be abbreviated: last 0 is equivalent to last tty0. Multiple arguments can be specified: last root console will print all of the entries for the user root and all entries logged in on the console tty. The special users reboot and shutdown log in when the system reboots or (surprise) shuts down. last reboot will produce a record of reboot times. If last is interrupted by a quit signal, it prints out how far its search in the wtmp file had reached and then quits. -n num, --lines num Limit the number of lines that last outputs. This is different from u*x last, which lets you specify the number right after a dash. -f filename, --file filename Read from the file filename instead of the system's wtmp file. --complain When the wtmp file has a problem (a time-warp, missing record, or whatever), print out an appropriate error. --tw-leniency num Set the time warp leniency to num seconds. Records in wtmp files might be slightly out of order (most notably when two logins occur within a one-second period - the second one gets written first). By default, this value is set to 60. If the program notices this problem, time is not assigned to users unless the --timewarps flag is used. --tw-suspicious num Set the time warp suspicious value to num seconds. If two records in the wtmp file are farther than this number of seconds apart, there is a problem with the wtmp file (or your machine hasn't been used in a year). If the program notices this problem, time is not assigned to users unless the --timewarps flag is used. --no-truncate-ftp-entries When printing out the information, don't chop the number part off of `ftp'XXXX entries. -x, --more-records Print out run level changes, shutdowns, and time changes in addition to the normal records. -a, --all-records Print out all records in the wtmp file. -i, --ip-address Some machines store the IP address of a connection in a utmp record. Enabling this option makes last print the IP address instead of the hostname. -w, --wide By default, last tries to print each entry within in 80 columns. Use this option to instruct last to print out the fields in the wtmp file with full field widths. --debug Print verbose internal information. -s, --print-seconds Print seconds when displaying dates. -y, --print-year Print year when displaying dates. -V, --version Print last's version number. -h, --help Prints the usage string and default locations of system files to standard output and exits. "
  },
  {
    "command": "flatpak",
    "description": " Flatpak is a tool for managing applications and the runtimes they use. In the Flatpak model, applications can be built and distributed independently from the host system they are used on, and they are isolated from the host system ('sandboxed') to some degree, at runtime. Flatpak can operate in system-wide or per-user mode. The system-wide data (runtimes, applications and configuration) is located in $prefix/var/lib/flatpak/, and the per-user data is in $HOME/.local/share/flatpak/. Below these locations, there is a local repository in the repo/ subdirectory and installed runtimes and applications are in the corresponding runtime/ and app/ subdirectories. System-wide remotes can be statically preconfigured by dropping flatpakrepo files into /etc/flatpak/remotes.d/. In addition to the system-wide installation in $prefix/var/lib/flatpak/, which is always considered the default one unless overridden, more system-wide installations can be defined via configuration files in /etc/flatpak/installations.d/, which must define at least the id of the installation and the absolute path to it. Other optional parameters like DisplayName, Priority or StorageType are also supported. Flatpak uses OSTree to distribute and deploy data. The repositories it uses are OSTree repositories and can be manipulated with the ostree utility. Installed runtimes and applications are OSTree checkouts. Basic commands for building flatpaks such as build-init, build and build-finish are included in the flatpak utility. For higher-level build support, see the separate flatpak-builder(1) tool. Flatpak supports installing from sideload repos. These are partial copies of a repository (generated by flatpak create-usb) that are used as an installation source when offline (and online as a performance improvement). Such repositories are configured by creating symlinks to the sideload sources in the sideload-repos subdirectory of the installation directory (i.e. typically /var/lib/flatpak/sideload-repos or ~/.local/share/flatpak/sideload-repos). Additionally symlinks can be created in /run/flatpak/sideload-repos which is a better location for non-persistent sources (as it is cleared on reboot). These symlinks can point to either the directory given to flatpak create-usb which by default writes to the subpath .ostree/repo, or directly to an ostree repo. The following global options are understood. Individual commands have their own options. -h, --help Show help options and exit. -v, --verbose Show debug information during command processing. Use -vv for more detail. --ostree-verbose Show OSTree debug information during command processing. --version Print version information and exit. --default-arch Print the default arch and exit. --supported-arches Print the supported arches in priority order and exit. --gl-drivers Print the list of active gl drivers and exit. --installations Print paths of system installations and exit. --print-system-only When the flatpak --print-updated-env command is run, only print the environment for system flatpak installations, not including the user\u2019s home installation. --print-updated-env Print the set of environment variables needed to use flatpaks, amending the current set of environment variables. This is intended to be used in a systemd environment generator, and should not need to be run manually. "
  },
  {
    "command": "cksum",
    "description": " Print or verify checksums. By default use the 32 bit CRC algorithm. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -a, --algorithm=TYPE select the digest type to use. See DIGEST below. -b, --base64 emit base64-encoded digests, not hexadecimal -c, --check read checksums from the FILEs and check them -l, --length=BITS digest length in bits; must not exceed the max for the blake2 algorithm and must be a multiple of 8 --raw emit a raw binary digest, not hexadecimal --tag create a BSD-style checksum (the default) --untagged create a reversed style checksum, without digest type -z, --zero end each output line with NUL, not newline, and disable file name escaping The following five options are useful only when verifying checksums: --ignore-missing don't fail or report status for missing files --quiet don't print OK for each successfully verified file --status don't output anything, status code shows success --strict exit non-zero for improperly formatted checksum lines -w, --warn warn about improperly formatted checksum lines --debug indicate which implementation used --help display this help and exit --version output version information and exit DIGEST determines the digest algorithm and default output format: sysv (equivalent to sum -s) bsd (equivalent to sum -r) crc (equivalent to cksum) md5 (equivalent to md5sum) sha1 (equivalent to sha1sum) sha224 (equivalent to sha224sum) sha256 (equivalent to sha256sum) sha384 (equivalent to sha384sum) sha512 (equivalent to sha512sum) blake2b (equivalent to b2sum) sm3 (only available through cksum) When checking, the input should be a former output of this program, or equivalent standalone program. "
  },
  {
    "command": "git-for-each-repo",
    "description": " Run a Git command on a list of repositories. The arguments after the known options or -- indicator are used as the arguments for the Git subprocess. THIS COMMAND IS EXPERIMENTAL. THE BEHAVIOR MAY CHANGE. For example, we could run maintenance on each of a list of repositories stored in a maintenance.repo config variable using git for-each-repo --config=maintenance.repo maintenance run This will run git -C <repo> maintenance run for each value <repo> in the multi-valued config variable maintenance.repo. --config=<config> Use the given config variable as a multi-valued list storing absolute path names. Iterate on that list of paths to run the given arguments. These config values are loaded from system, global, and local Git config, as available. If git for-each-repo is run in a directory that is not a Git repository, then only the system and global config is used. "
  },
  {
    "command": "more",
    "description": " more is a filter for paging through text one screenful at a time. This version is especially primitive. Users should realize that less(1) provides more(1) emulation plus extensive enhancements. Options are also taken from the environment variable MORE (make sure to precede them with a dash (-)) but command-line options will override those. -d, --silent Prompt with \"[Press space to continue, 'q' to quit.]\", and display \"[Press 'h' for instructions.]\" instead of ringing the bell when an illegal key is pressed. -l, --logical Do not pause after any line containing a ^L (form feed). -e, --exit-on-eof Exit on End-Of-File, enabled by default if POSIXLY_CORRECT environment variable is not set or if not executed on terminal. -f, --no-pause Count logical lines, rather than screen lines (i.e., long lines are not folded). -p, --print-over Do not scroll. Instead, clear the whole screen and then display the text. Notice that this option is switched on automatically if the executable is named page. -c, --clean-print Do not scroll. Instead, paint each screen from the top, clearing the remainder of each line as it is displayed. -s, --squeeze Squeeze multiple blank lines into one. -u, --plain Suppress underlining. This option is silently ignored as backwards compatibility. -n, --lines number Specify the number of lines per screenful. The number argument is a positive decimal integer. The --lines option shall override any values obtained from any other source, such as number of lines reported by terminal. -number A numeric option means the same as --lines option argument. +number Start displaying each file at line number. +/string The string to be searched in each file before starting to display it. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "apropos",
    "description": " Each manual page has a short description available within it. apropos searches the descriptions for instances of keyword. keyword is usually a regular expression, as if (-r) was used, or may contain wildcards (-w), or match the exact keyword (-e). Using these options, it may be necessary to quote the keyword or escape (\\) the special characters to stop the shell from interpreting them. The standard matching rules allow matches to be made against the page name and word boundaries in the description. The database searched by apropos is updated by the mandb program. Depending on your installation, this may be run by a periodic cron job, or may need to be run manually after new manual pages have been installed. -d, --debug Print debugging information. -v, --verbose Print verbose warning messages. -r, --regex Interpret each keyword as a regular expression. This is the default behaviour. Each keyword will be matched against the page names and the descriptions independently. It can match any part of either. The match is not limited to word boundaries. -w, --wildcard Interpret each keyword as a pattern containing shell style wildcards. Each keyword will be matched against the page names and the descriptions independently. If --exact is also used, a match will only be found if an expanded keyword matches an entire description or page name. Otherwise the keyword is also allowed to match on word boundaries in the description. -e, --exact Each keyword will be exactly matched against the page names and the descriptions. -a, --and Only display items that match all the supplied keywords. The default is to display items that match any keyword. -l, --long Do not trim output to the terminal width. Normally, output will be truncated to the terminal width to avoid ugly results from poorly-written NAME sections. -s list, --sections=list, --section=list Search only the given manual sections. list is a colon- or comma-separated list of sections. If an entry in list is a simple section, for example \"3\", then the displayed list of descriptions will include pages in sections \"3\", \"3perl\", \"3x\", and so on; while if an entry in list has an extension, for example \"3perl\", then the list will only include pages in that exact part of the manual section. -m system[,...], --systems=system[,...] If this system has access to other operating systems' manual page descriptions, they can be searched using this option. To search NewOS's manual page descriptions, use the option -m NewOS. The system specified can be a combination of comma- delimited operating system names. To include a search of the native operating system's whatis descriptions, include the system name man in the argument string. This option will override the $SYSTEM environment variable. -M path, --manpath=path Specify an alternate set of colon-delimited manual page hierarchies to search. By default, apropos uses the $MANPATH environment variable, unless it is empty or unset, in which case it will determine an appropriate manpath based on your $PATH environment variable. This option overrides the contents of $MANPATH. -L locale, --locale=locale apropos will normally determine your current locale by a call to the C function setlocale(3) which interrogates various environment variables, possibly including $LC_MESSAGES and $LANG. To temporarily override the determined value, use this option to supply a locale string directly to apropos. Note that it will not take effect until the search for pages actually begins. Output such as the help message will always be displayed in the initially determined locale. -C file, --config-file=file Use this user configuration file rather than the default of ~/.manpath. -?, --help Print a help message and exit. --usage Print a short usage message and exit. -V, --version Display version information. "
  },
  {
    "command": "cat",
    "description": " The cat utility shall read files in sequence and shall write their contents to the standard output in the same sequence. The cat utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -u Write bytes from the input file to the standard output without delay as each is read. "
  },
  {
    "command": "arch",
    "description": " Print machine architecture. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "update-alternatives",
    "description": " update-alternatives creates, removes, maintains and displays information about the symbolic links comprising the Debian alternatives system. It is possible for several programs fulfilling the same or similar functions to be installed on a single system at the same time. For example, many systems have several text editors installed at once. This gives choice to the users of a system, allowing each to use a different editor, if desired, but makes it difficult for a program to make a good choice for an editor to invoke if the user has not specified a particular preference. Debian's alternatives system aims to solve this problem. A generic name in the filesystem is shared by all files providing interchangeable functionality. The alternatives system and the system administrator together determine which actual file is referenced by this generic name. For example, if the text editors ed(1) and nvi(1) are both installed on the system, the alternatives system will cause the generic name /usr/bin/editor to refer to /usr/bin/nvi by default. The system administrator can override this and cause it to refer to /usr/bin/ed instead, and the alternatives system will not alter this setting until explicitly requested to do so. The generic name is not a direct symbolic link to the selected alternative. Instead, it is a symbolic link to a name in the alternatives directory, which in turn is a symbolic link to the actual file referenced. This is done so that the system administrator's changes can be confined within the /usr/local/etc directory: the FHS (q.v.) gives reasons why this is a Good Thing. When each package providing a file with a particular functionality is installed, changed or removed, update- alternatives is called to update information about that file in the alternatives system. update-alternatives is usually called from the following Debian package maintainer scripts, postinst (configure) to install the alternative and from prerm and postrm (remove) to remove the alternative. Note: in most (if not all) cases no other maintainer script actions should call update- alternatives, in particular neither of upgrade nor disappear, as any other such action can lose the manual state of an alternative, or make the alternative temporarily flip-flop, or completely switch when several of them have the same priority. It is often useful for a number of alternatives to be synchronized, so that they are changed as a group; for example, when several versions of the vi(1) editor are installed, the manual page referenced by /usr/share/man/man1/vi.1 should correspond to the executable referenced by /usr/bin/vi. update- alternatives handles this by means of master and slave links; when the master is changed, any associated slaves are changed too. A master link and its associated slaves make up a link group. Each link group is, at any given time, in one of two modes: automatic or manual. When a group is in automatic mode, the alternatives system will automatically decide, as packages are installed and removed, whether and how to update the links. In manual mode, the alternatives system will retain the choice of the administrator and avoid changing the links (except when something is broken). Link groups are in automatic mode when they are first introduced to the system. If the system administrator makes changes to the system's automatic settings, this will be noticed the next time update-alternatives is run on the changed link's group, and the group will automatically be switched to manual mode. Each alternative has a priority associated with it. When a link group is in automatic mode, the alternatives pointed to by members of the group will be those which have the highest priority. When using the --config option, update-alternatives will list all of the choices for the link group of which given name is the master alternative name. The current choice is marked with a \u2018*\u2019. You will then be prompted for your choice regarding this link group. Depending on the choice made, the link group might no longer be in auto mode. You will need to use the --auto option in order to return to the automatic mode (or you can rerun --config and select the entry marked as automatic). If you want to configure non-interactively you can use the --set option instead (see below). Different packages providing the same file need to do so cooperatively. In other words, the usage of update-alternatives is mandatory for all involved packages in such case. It is not possible to override some file in a package that does not employ the update-alternatives mechanism. --altdir directory Specifies the alternatives directory, when this is to be different from the default. Defaults to \u00ab/usr/local/etc/alternatives\u00bb. --admindir directory Specifies the administrative directory, when this is to be different from the default. Defaults to \u00ab/usr/local/var/lib/dpkg/alternatives\u00bb if DPKG_ADMINDIR has not been set. --instdir directory Specifies the installation directory where alternatives links will be created (since version 1.20.1). Defaults to \u00ab/\u00bb if DPKG_ROOT has not been set. --root directory Specifies the root directory (since version 1.20.1). This also sets the alternatives, installation and administrative directories to match. Defaults to \u00ab/\u00bb if DPKG_ROOT has not been set. --log file Specifies the log file (since version 1.15.0), when this is to be different from the default (/usr/local/var/log/alternatives.log). --force Allow replacing or dropping any real file that is installed where an alternative link has to be installed or removed. --skip-auto Skip configuration prompt for alternatives which are properly configured in automatic mode. This option is only relevant with --config or --all. --quiet Do not generate any comments unless errors occur. --verbose Generate more comments about what is being done. --debug Generate even more comments, helpful for debugging, about what is being done (since version 1.19.3). "
  },
  {
    "command": "mailx",
    "description": " The mailx utility provides a message sending and receiving facility. It has two major modes, selected by the options used: Send Mode and Receive Mode. On systems that do not support the User Portability Utilities option, an application using mailx shall have the ability to send messages in an unspecified manner (Send Mode). Unless the first character of one or more lines is <tilde> ('~'), all characters in the input message shall appear in the delivered message, but additional characters may be inserted in the message before it is retrieved. On systems supporting the User Portability Utilities option, mail-receiving capabilities and other interactive features, Receive Mode, described below, also shall be enabled. Send Mode Send Mode can be used by applications or users to send messages from the text in standard input. Receive Mode Receive Mode is more oriented towards interactive users. Mail can be read and sent in this interactive mode. When reading mail, mailx provides commands to facilitate saving, deleting, and responding to messages. When sending mail, mailx allows editing, reviewing, and other modification of the message as it is entered. Incoming mail shall be stored in one or more unspecified locations for each user, collectively called the system mailbox for that user. When mailx is invoked in Receive Mode, the system mailbox shall be the default place to find new mail. As messages are read, they shall be marked to be moved to a secondary file for storage, unless specific action is taken. This secondary file is called the mbox and is normally located in the directory referred to by the HOME environment variable (see MBOX in the ENVIRONMENT VARIABLES section for a description of this file). Messages shall remain in this file until explicitly removed. When the -f option is used to read mail messages from secondary files, messages shall be retained in those files unless specifically removed. All three of these locations\u2014system mailbox, mbox, and secondary file\u2014are referred to in this section as simply ``mailboxes'', unless more specific identification is required. The mailx utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported. (Only the -s subject option shall be required on all systems. The other options are required only on systems supporting the User Portability Utilities option.) -e Test for the presence of mail in the system mailbox. The mailx utility shall write nothing and exit with a successful return code if there is mail to read. -f Read messages from the file named by the file operand instead of the system mailbox. (See also folder.) If no file operand is specified, read messages from mbox instead of the system mailbox. -F Record the message in a file named after the first recipient. The name is the login-name portion of the address found first on the To: line in the mail header. Overrides the record variable, if set (see Internal Variables in mailx). -H Write a header summary only. -i Ignore interrupts. (See also ignore.) -n Do not initialize from the system default start-up file. See the EXTENDED DESCRIPTION section. -N Do not write an initial header summary. -s subject Set the Subject header field to subject. All characters in the subject string shall appear in the delivered message. The results are unspecified if subject is longer than {LINE_MAX} - 10 bytes or contains a <newline>. -u user Read the system mailbox of the login name user. This shall only be successful if the invoking user has appropriate privileges to read the system mailbox of that user. "
  },
  {
    "command": "dot",
    "description": " The shell shall execute commands from the file in the current environment. If file does not contain a <slash>, the shell shall use the search path specified by PATH to find the directory containing file. Unlike normal command search, however, the file searched for by the dot utility need not be executable. If no readable file is found, a non-interactive shell shall abort; an interactive shell shall write a diagnostic message to standard error, but this condition shall not be considered a syntax error. None. "
  },
  {
    "command": "gcc",
    "description": " When you invoke GCC, it normally does preprocessing, compilation, assembly and linking. The \"overall options\" allow you to stop this process at an intermediate stage. For example, the -c option says not to run the linker. Then the output consists of object files output by the assembler. Other options are passed on to one or more stages of processing. Some options control the preprocessor and others the compiler itself. Yet other options control the assembler and linker; most of these are not documented here, since you rarely need to use any of them. Most of the command-line options that you can use with GCC are useful for C programs; when an option is only useful with another language (usually C++), the explanation says so explicitly. If the description for a particular option does not mention a source language, you can use that option with all supported languages. The usual way to run GCC is to run the executable called gcc, or machine-gcc when cross-compiling, or machine-gcc-version to run a specific version of GCC. When you compile C++ programs, you should invoke GCC as g++ instead. The gcc program accepts options and file names as operands. Many options have multi-letter names; therefore multiple single-letter options may not be grouped: -dv is very different from -d -v. You can mix options and other arguments. For the most part, the order you use doesn't matter. Order does matter when you use several options of the same kind; for example, if you specify -L more than once, the directories are searched in the order specified. Also, the placement of the -l option is significant. Many options have long names starting with -f or with -W---for example, -fmove-loop-invariants, -Wformat and so on. Most of these have both positive and negative forms; the negative form of -ffoo is -fno-foo. This manual documents only one of these two forms, whichever one is not the default. Some options take one or more arguments typically separated either by a space or by the equals sign (=) from the option name. Unless documented otherwise, an argument can be either numeric or a string. Numeric arguments must typically be small unsigned decimal or hexadecimal integers. Hexadecimal arguments must begin with the 0x prefix. Arguments to options that specify a size threshold of some sort may be arbitrarily large decimal or hexadecimal integers followed by a byte size suffix designating a multiple of bytes such as \"kB\" and \"KiB\" for kilobyte and kibibyte, respectively, \"MB\" and \"MiB\" for megabyte and mebibyte, \"GB\" and \"GiB\" for gigabyte and gigibyte, and so on. Such arguments are designated by byte-size in the following text. Refer to the NIST, IEC, and other relevant national and international standards for the full listing and explanation of the binary and decimal byte size prefixes. Option Summary Here is a summary of all the options, grouped by type. Explanations are in the following sections. Overall Options -c -S -E -o file -x language -v -"
  },
  {
    "command": "whoami",
    "description": " Print the user name associated with the current effective user ID. Same as id -un. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "gitk",
    "description": " Displays changes in a repository or a selected set of commits. This includes visualizing the commit graph, showing information related to each commit, and the files in the trees of each revision. To control which revisions to show, gitk supports most options applicable to the git rev-list command. It also supports a few options applicable to the git diff-* commands to control how the changes each commit introduces are shown. Finally, it supports some gitk-specific options. gitk generally only understands options with arguments in the sticked form (see gitcli(7)) due to limitations in the command-line parser. rev-list options and arguments This manual page describes only the most frequently used options. See git-rev-list(1) for a complete list. --all Show all refs (branches, tags, etc.). --branches[=<pattern>], --tags[=<pattern>], --remotes[=<pattern>] Pretend as if all the branches (tags, remote branches, resp.) are listed on the command line as <commit>. If <pattern> is given, limit refs to ones matching given shell glob. If pattern lacks ?, *, or [, /* at the end is implied. --since=<date> Show commits more recent than a specific date. --until=<date> Show commits older than a specific date. --date-order Sort commits by date when possible. --merge After an attempt to merge stops with conflicts, show the commits on the history between two branches (i.e. the HEAD and the MERGE_HEAD) that modify the conflicted files and do not exist on all the heads being merged. --left-right Mark which side of a symmetric difference a commit is reachable from. Commits from the left side are prefixed with a < symbol and those from the right with a > symbol. --full-history When filtering history with <path>..., does not prune some history. (See \"History simplification\" in git-log(1) for a more detailed explanation.) --simplify-merges Additional option to --full-history to remove some needless merges from the resulting history, as there are no selected commits contributing to this merge. (See \"History simplification\" in git-log(1) for a more detailed explanation.) --ancestry-path When given a range of commits to display (e.g. commit1..commit2 or commit2 ^commit1), only display commits that exist directly on the ancestry chain between the commit1 and commit2, i.e. commits that are both descendants of commit1, and ancestors of commit2. (See \"History simplification\" in git-log(1) for a more detailed explanation.) -L<start>,<end>:<file>, -L:<funcname>:<file> Trace the evolution of the line range given by <start>,<end>, or by the function name regex <funcname>, within the <file>. You may not give any pathspec limiters. This is currently limited to a walk starting from a single revision, i.e., you may only give zero or one positive revision arguments, and <start> and <end> (or <funcname>) must exist in the starting revision. You can specify this option more than once. Implies --patch. Patch output can be suppressed using --no-patch, but other diff formats (namely --raw, --numstat, --shortstat, --dirstat, --summary, --name-only, --name-status, --check) are not currently implemented. <start> and <end> can take one of these forms: \u2022 number If <start> or <end> is a number, it specifies an absolute line number (lines count from 1). \u2022 /regex/ This form will use the first line matching the given POSIX regex. If <start> is a regex, it will search from the end of the previous -L range, if any, otherwise from the start of file. If <start> is ^/regex/, it will search from the start of file. If <end> is a regex, it will search starting at the line given by <start>. \u2022 +offset or -offset This is only valid for <end> and will specify a number of lines before or after the line given by <start>. If :<funcname> is given in place of <start> and <end>, it is a regular expression that denotes the range from the first funcname line that matches <funcname>, up to the next funcname line. :<funcname> searches from the end of the previous -L range, if any, otherwise from the start of file. ^:<funcname> searches from the start of file. The function names are determined in the same way as git diff works out patch hunk headers (see Defining a custom hunk-header in gitattributes(5)). <revision range> Limit the revisions to show. This can be either a single revision meaning show from the given revision and back, or it can be a range in the form \"<from>..<to>\" to show all revisions between <from> and back to <to>. Note, more advanced revision selection can be applied. For a more complete list of ways to spell object names, see gitrevisions(7). <path>... Limit commits to the ones touching files in the given paths. Note, to avoid ambiguity with respect to revision names use \"--\" to separate the paths from any preceding options. gitk-specific options --argscmd=<command> Command to be run each time gitk has to determine the revision range to show. The command is expected to print on its standard output a list of additional revisions to be shown, one per line. Use this instead of explicitly specifying a <revision range> if the set of commits to show may vary between refreshes. --select-commit=<ref> Select the specified commit after loading the graph. Default behavior is equivalent to specifying --select-commit=HEAD. "
  },
  {
    "command": "realpath",
    "description": " Print the resolved absolute file name; all but the last component must exist -e, --canonicalize-existing all components of the path must exist -m, --canonicalize-missing no path components need exist or be a directory -L, --logical resolve '..' components before symlinks -P, --physical resolve symlinks as encountered (default) -q, --quiet suppress most error messages --relative-to=DIR print the resolved path relative to DIR --relative-base=DIR print absolute paths unless paths below DIR -s, --strip, --no-symlinks don't expand symlinks -z, --zero end each output line with NUL, not newline --help display this help and exit --version output version information and exit "
  },
  {
    "command": "csplit",
    "description": " Output pieces of FILE separated by PATTERN(s) to files 'xx00', 'xx01', ..., and output byte counts of each piece to standard output. Read standard input if FILE is - Mandatory arguments to long options are mandatory for short options too. -b, --suffix-format=FORMAT use sprintf FORMAT instead of %02d -f, --prefix=PREFIX use PREFIX instead of 'xx' -k, --keep-files do not remove output files on errors --suppress-matched suppress the lines matching PATTERN -n, --digits=DIGITS use specified number of digits instead of 2 -s, --quiet, --silent do not print counts of output file sizes -z, --elide-empty-files suppress empty output files --help display this help and exit --version output version information and exit Each PATTERN may be: INTEGER copy up to but not including specified line number /REGEXP/[OFFSET] copy up to but not including a matching line %REGEXP%[OFFSET] skip to, but not including a matching line {INTEGER} repeat the previous pattern specified number of times {*} repeat the previous pattern as many times as possible A line OFFSET is an integer optionally preceded by '+' or '-' "
  },
  {
    "command": "ps",
    "description": " The ps utility shall write information about processes, subject to having appropriate privileges to obtain information about those processes. By default, ps shall select all processes with the same effective user ID as the current user and the same controlling terminal as the invoker. The ps utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -a Write information for all processes associated with terminals. Implementations may omit session leaders from this list. -A Write information for all processes. -d Write information for all processes, except session leaders. -e Write information for all processes. (Equivalent to -A.) -f Generate a full listing. (See the STDOUT section for the contents of a full listing.) -g grouplist Write information for processes whose session leaders are given in grouplist. The application shall ensure that the grouplist is a single argument in the form of a <blank> or <comma>-separated list. -G grouplist Write information for processes whose real group ID numbers are given in grouplist. The application shall ensure that the grouplist is a single argument in the form of a <blank> or <comma>-separated list. -l Generate a long listing. (See STDOUT for the contents of a long listing.) -n namelist Specify the name of an alternative system namelist file in place of the default. The name of the default file and the format of a namelist file are unspecified. -o format Write information according to the format specification given in format. This is fully described in the STDOUT section. Multiple -o options can be specified; the format specification shall be interpreted as the <space>-separated concatenation of all the format option-arguments. -p proclist Write information for processes whose process ID numbers are given in proclist. The application shall ensure that the proclist is a single argument in the form of a <blank> or <comma>-separated list. -t termlist Write information for processes associated with terminals given in termlist. The application shall ensure that the termlist is a single argument in the form of a <blank> or <comma>-separated list. Terminal identifiers shall be given in an implementation-defined format. On XSI-conformant systems, they shall be given in one of two forms: the device's filename (for example, tty04) or, if the device's filename starts with tty, just the identifier following the characters tty (for example, \"04\"). -u userlist Write information for processes whose user ID numbers or login names are given in userlist. The application shall ensure that the userlist is a single argument in the form of a <blank> or <comma>-separated list. In the listing, the numerical user ID shall be written unless the -f option is used, in which case the login name shall be written. -U userlist Write information for processes whose real user ID numbers or login names are given in userlist. The application shall ensure that the userlist is a single argument in the form of a <blank> or <comma>-separated list. With the exception of -f, -l, -n namelist, and -o format, all of the options shown are used to select processes. If any are specified, the default list shall be ignored and ps shall select the processes represented by the inclusive OR of all the selection-criteria options. "
  },
  {
    "command": "journalctl",
    "description": " journalctl is used to print the log entries stored in the journal by systemd-journald.service(8) and systemd-journal-remote.service(8). If called without parameters, it will show the contents of the journal accessible to the calling user, starting with the oldest entry collected. If one or more match arguments are passed, the output is filtered accordingly. A match is in the format \"FIELD=VALUE\", e.g. \"_SYSTEMD_UNIT=httpd.service\", referring to the components of a structured journal entry. See systemd.journal-fields(7) for a list of well-known fields. If multiple matches are specified matching different fields, the log entries are filtered by both, i.e. the resulting output will show only entries matching all the specified matches of this kind. If two matches apply to the same field, then they are automatically matched as alternatives, i.e. the resulting output will show entries matching any of the specified matches for the same field. Finally, the character \"+\" may appear as a separate word between other terms on the command line. This causes all matches before and after to be combined in a disjunction (i.e. logical OR). It is also possible to filter the entries by specifying an absolute file path as an argument. The file path may be a file or a symbolic link and the file must exist at the time of the query. If a file path refers to an executable binary, an \"_EXE=\" match for the canonicalized binary path is added to the query. If a file path refers to an executable script, a \"_COMM=\" match for the script name is added to the query. If a file path refers to a device node, \"_KERNEL_DEVICE=\" matches for the kernel name of the device and for each of its ancestor devices is added to the query. Symbolic links are dereferenced, kernel names are synthesized, and parent devices are identified from the environment at the time of the query. In general, a device node is the best proxy for an actual device, as log entries do not usually contain fields that identify an actual device. For the resulting log entries to be correct for the actual device, the relevant parts of the environment at the time the entry was logged, in particular the actual device corresponding to the device node, must have been the same as those at the time of the query. Because device nodes generally change their corresponding devices across reboots, specifying a device node path causes the resulting entries to be restricted to those from the current boot. Additional constraints may be added using options --boot, --unit=, etc., to further limit what entries will be shown (logical AND). Output is interleaved from all accessible journal files, whether they are rotated or currently being written, and regardless of whether they belong to the system itself or are accessible user journals. The --header option can be used to identify which files are being shown. The set of journal files which will be used can be modified using the --user, --system, --directory, and --file options, see below. All users are granted access to their private per-user journals. However, by default, only root and users who are members of a few special groups are granted access to the system journal and the journals of other users. Members of the groups \"systemd-journal\", \"adm\", and \"wheel\" can read all journal files. Note that the two latter groups traditionally have additional privileges specified by the distribution. Members of the \"wheel\" group can often perform administrative tasks. The output is paged through less by default, and long lines are \"truncated\" to screen width. The hidden part can be viewed by using the left-arrow and right-arrow keys. Paging can be disabled; see the --no-pager option and the \"Environment\" section below. When outputting to a tty, lines are colored according to priority: lines of level ERROR and higher are colored red; lines of level NOTICE and higher are highlighted; lines of level DEBUG are colored lighter grey; other lines are displayed normally. To write entries to the journal, a few methods may be used. In general, output from systemd units is automatically connected to the journal, see systemd-journald.service(8). In addition, systemd-cat(1) may be used to send messages to the journal directly. "
  },
  {
    "command": "head",
    "description": " The head utility shall copy its input files to the standard output, ending the output for each file at a designated point. Copying shall end at the point in each input file indicated by the -n number option. The option-argument number shall be counted in units of lines. The head utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -n number The first number lines of each input file shall be copied to standard output. The application shall ensure that the number option-argument is a positive decimal integer. When a file contains less than number lines, it shall be copied to standard output in its entirety. This shall not be an error. If no options are specified, head shall act as if -n 10 had been specified. "
  },
  {
    "command": "basename",
    "description": " Print NAME with any leading directory components removed. If specified, also remove a trailing SUFFIX. Mandatory arguments to long options are mandatory for short options too. -a, --multiple support multiple arguments and treat each as a NAME -s, --suffix=SUFFIX remove a trailing SUFFIX; implies -a -z, --zero end each output line with NUL, not newline --help display this help and exit --version output version information and exit "
  },
  {
    "command": "git-maintenance",
    "description": " Run tasks to optimize Git repository data, speeding up other Git commands and reducing storage requirements for the repository. Git commands that add repository data, such as git add or git fetch, are optimized for a responsive user experience. These commands do not take time to optimize the Git data, since such optimizations scale with the full size of the repository while these user commands each perform a relatively small action. The git maintenance command provides flexibility for how to optimize the Git repository. --auto When combined with the run subcommand, run maintenance tasks only if certain thresholds are met. For example, the gc task runs when the number of loose objects exceeds the number stored in the gc.auto config setting, or when the number of pack-files exceeds the gc.autoPackLimit config setting. Not compatible with the --schedule option. --schedule When combined with the run subcommand, run maintenance tasks only if certain time conditions are met, as specified by the maintenance.<task>.schedule config value for each <task>. This config value specifies a number of seconds since the last time that task ran, according to the maintenance.<task>.lastRun config value. The tasks that are tested are those provided by the --task=<task> option(s) or those with maintenance.<task>.enabled set to true. --quiet Do not report progress or other information over stderr. --task=<task> If this option is specified one or more times, then only run the specified tasks in the specified order. If no --task=<task> arguments are specified, then only the tasks with maintenance.<task>.enabled configured as true are considered. See the TASKS section for the list of accepted <task> values. --scheduler=auto|crontab|systemd-timer|launchctl|schtasks When combined with the start subcommand, specify the scheduler for running the hourly, daily and weekly executions of git maintenance run. Possible values for <scheduler> are auto, crontab (POSIX), systemd-timer (Linux), launchctl (macOS), and schtasks (Windows). When auto is specified, the appropriate platform-specific scheduler is used; on Linux, systemd-timer is used if available, otherwise crontab. Default is auto. "
  },
  {
    "command": "git-diff-files",
    "description": " Compares the files in the working tree and the index. When paths are specified, compares only those named paths. Otherwise all entries in the index are compared. The output format is the same as for git diff-index and git diff-tree. -p, -u, --patch Generate patch (see section titled \"Generating patch text with -p\"). -s, --no-patch Suppress all output from the diff machinery. Useful for commands like git show that show the patch by default to squelch their output, or to cancel the effect of options like --patch, --stat earlier on the command line in an alias. -U<n>, --unified=<n> Generate diffs with <n> lines of context instead of the usual three. Implies --patch. --output=<file> Output to a specific file instead of stdout. --output-indicator-new=<char>, --output-indicator-old=<char>, --output-indicator-context=<char> Specify the character used to indicate new, old or context lines in the generated patch. Normally they are +, - and ' ' respectively. --raw Generate the diff in raw format. This is the default. --patch-with-raw Synonym for -p --raw. --indent-heuristic Enable the heuristic that shifts diff hunk boundaries to make patches easier to read. This is the default. --no-indent-heuristic Disable the indent heuristic. --minimal Spend extra time to make sure the smallest possible diff is produced. --patience Generate a diff using the \"patience diff\" algorithm. --histogram Generate a diff using the \"histogram diff\" algorithm. --anchored=<text> Generate a diff using the \"anchored diff\" algorithm. This option may be specified more than once. If a line exists in both the source and destination, exists only once, and starts with this text, this algorithm attempts to prevent it from appearing as a deletion or addition in the output. It uses the \"patience diff\" algorithm internally. --diff-algorithm={patience|minimal|histogram|myers} Choose a diff algorithm. The variants are as follows: default, myers The basic greedy diff algorithm. Currently, this is the default. minimal Spend extra time to make sure the smallest possible diff is produced. patience Use \"patience diff\" algorithm when generating patches. histogram This algorithm extends the patience algorithm to \"support low-occurrence common elements\". For instance, if you configured the diff.algorithm variable to a non-default value and want to use the default one, then you have to use --diff-algorithm=default option. --stat[=<width>[,<name-width>[,<count>]]] Generate a diffstat. By default, as much space as necessary will be used for the filename part, and the rest for the graph part. Maximum width defaults to terminal width, or 80 columns if not connected to a terminal, and can be overridden by <width>. The width of the filename part can be limited by giving another width <name-width> after a comma. The width of the graph part can be limited by using --stat-graph-width=<width> (affects all commands generating a stat graph) or by setting diff.statGraphWidth=<width> (does not affect git format-patch). By giving a third parameter <count>, you can limit the output to the first <count> lines, followed by ... if there are more. These parameters can also be set individually with --stat-width=<width>, --stat-name-width=<name-width> and --stat-count=<count>. --compact-summary Output a condensed summary of extended header information such as file creations or deletions (\"new\" or \"gone\", optionally \"+l\" if it\u2019s a symlink) and mode changes (\"+x\" or \"-x\" for adding or removing executable bit respectively) in diffstat. The information is put between the filename part and the graph part. Implies --stat. --numstat Similar to --stat, but shows number of added and deleted lines in decimal notation and pathname without abbreviation, to make it more machine friendly. For binary files, outputs two - instead of saying 0 0. --shortstat Output only the last line of the --stat format containing total number of modified files, as well as number of added and deleted lines. -X[<param1,param2,...>], --dirstat[=<param1,param2,...>] Output the distribution of relative amount of changes for each sub-directory. The behavior of --dirstat can be customized by passing it a comma separated list of parameters. The defaults are controlled by the diff.dirstat configuration variable (see git-config(1)). The following parameters are available: changes Compute the dirstat numbers by counting the lines that have been removed from the source, or added to the destination. This ignores the amount of pure code movements within a file. In other words, rearranging lines in a file is not counted as much as other changes. This is the default behavior when no parameter is given. lines Compute the dirstat numbers by doing the regular line-based diff analysis, and summing the removed/added line counts. (For binary files, count 64-byte chunks instead, since binary files have no natural concept of lines). This is a more expensive --dirstat behavior than the changes behavior, but it does count rearranged lines within a file as much as other changes. The resulting output is consistent with what you get from the other --*stat options. files Compute the dirstat numbers by counting the number of files changed. Each changed file counts equally in the dirstat analysis. This is the computationally cheapest --dirstat behavior, since it does not have to look at the file contents at all. cumulative Count changes in a child directory for the parent directory as well. Note that when using cumulative, the sum of the percentages reported may exceed 100%. The default (non-cumulative) behavior can be specified with the noncumulative parameter. <limit> An integer parameter specifies a cut-off percent (3% by default). Directories contributing less than this percentage of the changes are not shown in the output. Example: The following will count changed files, while ignoring directories with less than 10% of the total amount of changed files, and accumulating child directory counts in the parent directories: --dirstat=files,10,cumulative. --cumulative Synonym for --dirstat=cumulative --dirstat-by-file[=<param1,param2>...] Synonym for --dirstat=files,param1,param2... --summary Output a condensed summary of extended header information such as creations, renames and mode changes. --patch-with-stat Synonym for -p --stat. -z When --raw, --numstat, --name-only or --name-status has been given, do not munge pathnames and use NULs as output field terminators. Without this option, pathnames with \"unusual\" characters are quoted as explained for the configuration variable core.quotePath (see git-config(1)). --name-only Show only names of changed files. The file names are often encoded in UTF-8. For more information see the discussion about encoding in the git-log(1) manual page. --name-status Show only names and status of changed files. See the description of the --diff-filter option on what the status letters mean. Just like --name-only the file names are often encoded in UTF-8. --submodule[=<format>] Specify how differences in submodules are shown. When specifying --submodule=short the short format is used. This format just shows the names of the commits at the beginning and end of the range. When --submodule or --submodule=log is specified, the log format is used. This format lists the commits in the range like git-submodule(1) summary does. When --submodule=diff is specified, the diff format is used. This format shows an inline diff of the changes in the submodule contents between the commit range. Defaults to diff.submodule or the short format if the config option is unset. --color[=<when>] Show colored diff. --color (i.e. without =<when>) is the same as --color=always. <when> can be one of always, never, or auto. --no-color Turn off colored diff. It is the same as --color=never. --color-moved[=<mode>] Moved lines of code are colored differently. The <mode> defaults to no if the option is not given and to zebra if the option with no mode is given. The mode must be one of: no Moved lines are not highlighted. default Is a synonym for zebra. This may change to a more sensible mode in the future. plain Any line that is added in one location and was removed in another location will be colored with color.diff.newMoved. Similarly color.diff.oldMoved will be used for removed lines that are added somewhere else in the diff. This mode picks up any moved line, but it is not very useful in a review to determine if a block of code was moved without permutation. blocks Blocks of moved text of at least 20 alphanumeric characters are detected greedily. The detected blocks are painted using either the color.diff.{old,new}Moved color. Adjacent blocks cannot be told apart. zebra Blocks of moved text are detected as in blocks mode. The blocks are painted using either the color.diff.{old,new}Moved color or color.diff.{old,new}MovedAlternative. The change between the two colors indicates that a new block was detected. dimmed-zebra Similar to zebra, but additional dimming of uninteresting parts of moved code is performed. The bordering lines of two adjacent blocks are considered interesting, the rest is uninteresting. dimmed_zebra is a deprecated synonym. --no-color-moved Turn off move detection. This can be used to override configuration settings. It is the same as --color-moved=no. --color-moved-ws=<modes> This configures how whitespace is ignored when performing the move detection for --color-moved. These modes can be given as a comma separated list: no Do not ignore whitespace when performing move detection. ignore-space-at-eol Ignore changes in whitespace at EOL. ignore-space-change Ignore changes in amount of whitespace. This ignores whitespace at line end, and considers all other sequences of one or more whitespace characters to be equivalent. ignore-all-space Ignore whitespace when comparing lines. This ignores differences even if one line has whitespace where the other line has none. allow-indentation-change Initially ignore any whitespace in the move detection, then group the moved code blocks only into a block if the change in whitespace is the same per line. This is incompatible with the other modes. --no-color-moved-ws Do not ignore whitespace when performing move detection. This can be used to override configuration settings. It is the same as --color-moved-ws=no. --word-diff[=<mode>] Show a word diff, using the <mode> to delimit changed words. By default, words are delimited by whitespace; see --word-diff-regex below. The <mode> defaults to plain, and must be one of: color Highlight changed words using only colors. Implies --color. plain Show words as [-removed-] and {+added+}. Makes no attempts to escape the delimiters if they appear in the input, so the output may be ambiguous. porcelain Use a special line-based format intended for script consumption. Added/removed/unchanged runs are printed in the usual unified diff format, starting with a +/-/` ` character at the beginning of the line and extending to the end of the line. Newlines in the input are represented by a tilde ~ on a line of its own. none Disable word diff again. Note that despite the name of the first mode, color is used to highlight the changed parts in all modes if enabled. --word-diff-regex=<regex> Use <regex> to decide what a word is, instead of considering runs of non-whitespace to be a word. Also implies --word-diff unless it was already enabled. Every non-overlapping match of the <regex> is considered a word. Anything between these matches is considered whitespace and ignored(!) for the purposes of finding differences. You may want to append |[^[:space:]] to your regular expression to make sure that it matches all non-whitespace characters. A match that contains a newline is silently truncated(!) at the newline. For example, --word-diff-regex=. will treat each character as a word and, correspondingly, show differences character by character. The regex can also be set via a diff driver or configuration option, see gitattributes(5) or git-config(1). Giving it explicitly overrides any diff driver or configuration setting. Diff drivers override configuration settings. --color-words[=<regex>] Equivalent to --word-diff=color plus (if a regex was specified) --word-diff-regex=<regex>. --no-renames Turn off rename detection, even when the configuration file gives the default to do so. --[no-]rename-empty Whether to use empty blobs as rename source. --check Warn if changes introduce conflict markers or whitespace errors. What are considered whitespace errors is controlled by core.whitespace configuration. By default, trailing whitespaces (including lines that consist solely of whitespaces) and a space character that is immediately followed by a tab character inside the initial indent of the line are considered whitespace errors. Exits with non-zero status if problems are found. Not compatible with --exit-code. --ws-error-highlight=<kind> Highlight whitespace errors in the context, old or new lines of the diff. Multiple values are separated by comma, none resets previous values, default reset the list to new and all is a shorthand for old,new,context. When this option is not given, and the configuration variable diff.wsErrorHighlight is not set, only whitespace errors in new lines are highlighted. The whitespace errors are colored with color.diff.whitespace. --full-index Instead of the first handful of characters, show the full pre- and post-image blob object names on the \"index\" line when generating patch format output. --binary In addition to --full-index, output a binary diff that can be applied with git-apply. Implies --patch. --abbrev[=<n>] Instead of showing the full 40-byte hexadecimal object name in diff-raw format output and diff-tree header lines, show the shortest prefix that is at least <n> hexdigits long that uniquely refers the object. In diff-patch output format, --full-index takes higher precedence, i.e. if --full-index is specified, full blob names will be shown regardless of --abbrev. Non default number of digits can be specified with --abbrev=<n>. -B[<n>][/<m>], --break-rewrites[=[<n>][/<m>]] Break complete rewrite changes into pairs of delete and create. This serves two purposes: It affects the way a change that amounts to a total rewrite of a file not as a series of deletion and insertion mixed together with a very few lines that happen to match textually as the context, but as a single deletion of everything old followed by a single insertion of everything new, and the number m controls this aspect of the -B option (defaults to 60%). -B/70% specifies that less than 30% of the original should remain in the result for Git to consider it a total rewrite (i.e. otherwise the resulting patch will be a series of deletion and insertion mixed together with context lines). When used with -M, a totally-rewritten file is also considered as the source of a rename (usually -M only considers a file that disappeared as the source of a rename), and the number n controls this aspect of the -B option (defaults to 50%). -B20% specifies that a change with addition and deletion compared to 20% or more of the file\u2019s size are eligible for being picked up as a possible source of a rename to another file. -M[<n>], --find-renames[=<n>] Detect renames. If n is specified, it is a threshold on the similarity index (i.e. amount of addition/deletions compared to the file\u2019s size). For example, -M90% means Git should consider a delete/add pair to be a rename if more than 90% of the file hasn\u2019t changed. Without a % sign, the number is to be read as a fraction, with a decimal point before it. I.e., -M5 becomes 0.5, and is thus the same as -M50%. Similarly, -M05 is the same as -M5%. To limit detection to exact renames, use -M100%. The default similarity index is 50%. -C[<n>], --find-copies[=<n>] Detect copies as well as renames. See also --find-copies-harder. If n is specified, it has the same meaning as for -M<n>. --find-copies-harder For performance reasons, by default, -C option finds copies only if the original file of the copy was modified in the same changeset. This flag makes the command inspect unmodified files as candidates for the source of copy. This is a very expensive operation for large projects, so use it with caution. Giving more than one -C option has the same effect. -D, --irreversible-delete Omit the preimage for deletes, i.e. print only the header but not the diff between the preimage and /dev/null. The resulting patch is not meant to be applied with patch or git apply; this is solely for people who want to just concentrate on reviewing the text after the change. In addition, the output obviously lacks enough information to apply such a patch in reverse, even manually, hence the name of the option. When used together with -B, omit also the preimage in the deletion part of a delete/create pair. -l<num> The -M and -C options involve some preliminary steps that can detect subsets of renames/copies cheaply, followed by an exhaustive fallback portion that compares all remaining unpaired destinations to all relevant sources. (For renames, only remaining unpaired sources are relevant; for copies, all original sources are relevant.) For N sources and destinations, this exhaustive check is O(N^2). This option prevents the exhaustive portion of rename/copy detection from running if the number of source/destination files involved exceeds the specified number. Defaults to diff.renameLimit. Note that a value of 0 is treated as unlimited. --diff-filter=[(A|C|D|M|R|T|U|X|B)...[*]] Select only files that are Added (A), Copied (C), Deleted (D), Modified (M), Renamed (R), have their type (i.e. regular file, symlink, submodule, ...) changed (T), are Unmerged (U), are Unknown (X), or have had their pairing Broken (B). Any combination of the filter characters (including none) can be used. When * (All-or-none) is added to the combination, all paths are selected if there is any file that matches other criteria in the comparison; if there is no file that matches other criteria, nothing is selected. Also, these upper-case letters can be downcased to exclude. E.g. --diff-filter=ad excludes added and deleted paths. Note that not all diffs can feature all types. For instance, copied and renamed entries cannot appear if detection for those types is disabled. -S<string> Look for differences that change the number of occurrences of the specified string (i.e. addition/deletion) in a file. Intended for the scripter\u2019s use. It is useful when you\u2019re looking for an exact block of code (like a struct), and want to know the history of that block since it first came into being: use the feature iteratively to feed the interesting block in the preimage back into -S, and keep going until you get the very first version of the block. Binary files are searched as well. -G<regex> Look for differences whose patch text contains added/removed lines that match <regex>. To illustrate the difference between -S<regex> --pickaxe-regex and -G<regex>, consider a commit with the following diff in the same file: + return frotz(nitfol, two->ptr, 1, 0); ... - hit = frotz(nitfol, mf2.ptr, 1, 0); While git log -G\"frotz\\(nitfol\" will show this commit, git log -S\"frotz\\(nitfol\" --pickaxe-regex will not (because the number of occurrences of that string did not change). Unless --text is supplied patches of binary files without a textconv filter will be ignored. See the pickaxe entry in gitdiffcore(7) for more information. --find-object=<object-id> Look for differences that change the number of occurrences of the specified object. Similar to -S, just the argument is different in that it doesn\u2019t search for a specific string but for a specific object id. The object can be a blob or a submodule commit. It implies the -t option in git-log to also find trees. --pickaxe-all When -S or -G finds a change, show all the changes in that changeset, not just the files that contain the change in <string>. --pickaxe-regex Treat the <string> given to -S as an extended POSIX regular expression to match. -O<orderfile> Control the order in which files appear in the output. This overrides the diff.orderFile configuration variable (see git-config(1)). To cancel diff.orderFile, use -O/dev/null. The output order is determined by the order of glob patterns in <orderfile>. All files with pathnames that match the first pattern are output first, all files with pathnames that match the second pattern (but not the first) are output next, and so on. All files with pathnames that do not match any pattern are output last, as if there was an implicit match-all pattern at the end of the file. If multiple pathnames have the same rank (they match the same pattern but no earlier patterns), their output order relative to each other is the normal order. <orderfile> is parsed as follows: \u2022 Blank lines are ignored, so they can be used as separators for readability. \u2022 Lines starting with a hash (\"#\") are ignored, so they can be used for comments. Add a backslash (\"\\\") to the beginning of the pattern if it starts with a hash. \u2022 Each other line contains a single pattern. Patterns have the same syntax and semantics as patterns used for fnmatch(3) without the FNM_PATHNAME flag, except a pathname also matches a pattern if removing any number of the final pathname components matches the pattern. For example, the pattern \"foo*bar\" matches \"fooasdfbar\" and \"foo/bar/baz/asdf\" but not \"foobarx\". --skip-to=<file>, --rotate-to=<file> Discard the files before the named <file> from the output (i.e. skip to), or move them to the end of the output (i.e. rotate to). These were invented primarily for use of the git difftool command, and may not be very useful otherwise. -R Swap two inputs; that is, show differences from index or on-disk file to tree contents. --relative[=<path>], --no-relative When run from a subdirectory of the project, it can be told to exclude changes outside the directory and show pathnames relative to it with this option. When you are not in a subdirectory (e.g. in a bare repository), you can name which subdirectory to make the output relative to by giving a <path> as an argument. --no-relative can be used to countermand both diff.relative config option and previous --relative. -a, --text Treat all files as text. --ignore-cr-at-eol Ignore carriage-return at the end of line when doing a comparison. --ignore-space-at-eol Ignore changes in whitespace at EOL. -b, --ignore-space-change Ignore changes in amount of whitespace. This ignores whitespace at line end, and considers all other sequences of one or more whitespace characters to be equivalent. -w, --ignore-all-space Ignore whitespace when comparing lines. This ignores differences even if one line has whitespace where the other line has none. --ignore-blank-lines Ignore changes whose lines are all blank. -I<regex>, --ignore-matching-lines=<regex> Ignore changes whose all lines match <regex>. This option may be specified more than once. --inter-hunk-context=<lines> Show the context between diff hunks, up to the specified number of lines, thereby fusing hunks that are close to each other. Defaults to diff.interHunkContext or 0 if the config option is unset. -W, --function-context Show whole function as context lines for each change. The function names are determined in the same way as git diff works out patch hunk headers (see Defining a custom hunk-header in gitattributes(5)). --exit-code Make the program exit with codes similar to diff(1). That is, it exits with 1 if there were differences and 0 means no differences. --quiet Disable all output of the program. Implies --exit-code. --ext-diff Allow an external diff helper to be executed. If you set an external diff driver with gitattributes(5), you need to use this option with git-log(1) and friends. --no-ext-diff Disallow external diff drivers. --textconv, --no-textconv Allow (or disallow) external text conversion filters to be run when comparing binary files. See gitattributes(5) for details. Because textconv filters are typically a one-way conversion, the resulting diff is suitable for human consumption, but cannot be applied. For this reason, textconv filters are enabled by default only for git-diff(1) and git-log(1), but not for git-format-patch(1) or diff plumbing commands. --ignore-submodules[=<when>] Ignore changes to submodules in the diff generation. <when> can be either \"none\", \"untracked\", \"dirty\" or \"all\", which is the default. Using \"none\" will consider the submodule modified when it either contains untracked or modified files or its HEAD differs from the commit recorded in the superproject and can be used to override any settings of the ignore option in git-config(1) or gitmodules(5). When \"untracked\" is used submodules are not considered dirty when they only contain untracked content (but they are still scanned for modified content). Using \"dirty\" ignores all changes to the work tree of submodules, only changes to the commits stored in the superproject are shown (this was the behavior until 1.7.0). Using \"all\" hides all changes to submodules. --src-prefix=<prefix> Show the given source prefix instead of \"a/\". --dst-prefix=<prefix> Show the given destination prefix instead of \"b/\". --no-prefix Do not show any source or destination prefix. --default-prefix Use the default source and destination prefixes (\"a/\" and \"b/\"). This is usually the default already, but may be used to override config such as diff.noprefix. --line-prefix=<prefix> Prepend an additional prefix to every line of output. --ita-invisible-in-index By default entries added by \"git add -N\" appear as an existing empty file in \"git diff\" and a new file in \"git diff --cached\". This option makes the entry appear as a new file in \"git diff\" and non-existent in \"git diff --cached\". This option could be reverted with --ita-visible-in-index. Both options are experimental and could be removed in future. For more detailed explanation on these common options, see also gitdiffcore(7). -1 --base, -2 --ours, -3 --theirs, -0 Diff against the \"base\" version, \"our branch\" or \"their branch\" respectively. With these options, diffs for merged entries are not shown. The default is to diff against our branch (-2) and the cleanly resolved paths. The option -0 can be given to omit diff output for unmerged entries and just show \"Unmerged\". -c, --cc This compares stage 2 (our branch), stage 3 (their branch) and the working tree file and outputs a combined diff, similar to the way diff-tree shows a merge commit with these flags. -q Remain silent even on nonexistent files "
  },
  {
    "command": "expr",
    "description": " --help display this help and exit --version output version information and exit Print the value of EXPRESSION to standard output. A blank line below separates increasing precedence groups. EXPRESSION may be: ARG1 | ARG2 ARG1 if it is neither null nor 0, otherwise ARG2 ARG1 & ARG2 ARG1 if neither argument is null or 0, otherwise 0 ARG1 < ARG2 ARG1 is less than ARG2 ARG1 <= ARG2 ARG1 is less than or equal to ARG2 ARG1 = ARG2 ARG1 is equal to ARG2 ARG1 != ARG2 ARG1 is unequal to ARG2 ARG1 >= ARG2 ARG1 is greater than or equal to ARG2 ARG1 > ARG2 ARG1 is greater than ARG2 ARG1 + ARG2 arithmetic sum of ARG1 and ARG2 ARG1 - ARG2 arithmetic difference of ARG1 and ARG2 ARG1 * ARG2 arithmetic product of ARG1 and ARG2 ARG1 / ARG2 arithmetic quotient of ARG1 divided by ARG2 ARG1 % ARG2 arithmetic remainder of ARG1 divided by ARG2 STRING : REGEXP anchored pattern match of REGEXP in STRING match STRING REGEXP same as STRING : REGEXP substr STRING POS LENGTH substring of STRING, POS counted from 1 index STRING CHARS index in STRING where any CHARS is found, or 0 length STRING length of STRING + TOKEN interpret TOKEN as a string, even if it is a keyword like 'match' or an operator like '/' ( EXPRESSION ) value of EXPRESSION Beware that many operators need to be escaped or quoted for shells. Comparisons are arithmetic if both ARGs are numbers, else lexicographical. Pattern matches return the string matched between \\( and \\) or null; if \\( and \\) are not used, they return the number of characters matched or 0. Exit status is 0 if EXPRESSION is neither null nor 0, 1 if EXPRESSION is null or 0, 2 if EXPRESSION is syntactically invalid, and 3 if an error occurred. "
  },
  {
    "command": "mv",
    "description": " Rename SOURCE to DEST, or move SOURCE(s) to DIRECTORY. Mandatory arguments to long options are mandatory for short options too. --backup[=CONTROL] make a backup of each existing destination file -b like --backup but does not accept an argument --debug explain how a file is copied. Implies -v -f, --force do not prompt before overwriting -i, --interactive prompt before overwrite -n, --no-clobber do not overwrite an existing file If you specify more than one of -i, -f, -n, only the final one takes effect. --no-copy do not copy if renaming fails --strip-trailing-slashes remove any trailing slashes from each SOURCE argument -S, --suffix=SUFFIX override the usual backup suffix -t, --target-directory=DIRECTORY move all SOURCE arguments into DIRECTORY -T, --no-target-directory treat DEST as a normal file --update[=UPDATE] control which existing files are updated; UPDATE={all,none,older(default)}. See below -u equivalent to --update[=older] -v, --verbose explain what is being done -Z, --context set SELinux security context of destination file to default type --help display this help and exit --version output version information and exit UPDATE controls which existing files in the destination are replaced. 'all' is the default operation when an --update option is not specified, and results in all existing files in the destination being replaced. 'none' is similar to the --no-clobber option, in that no files in the destination are replaced, but also skipped files do not induce a failure. 'older' is the default operation when --update is specified, and results in files being replaced if they're older than the corresponding source file. The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX. The version control method may be selected via the --backup option or through the VERSION_CONTROL environment variable. Here are the values: none, off never make backups (even if --backup is given) numbered, t make numbered backups existing, nil numbered if numbered backups exist, simple otherwise simple, never always make simple backups "
  },
  {
    "command": "loginctl",
    "description": " loginctl may be used to introspect and control the state of the systemd(1) login manager systemd-logind.service(8). The following options are understood: --no-ask-password Do not query the user for authentication for privileged operations. -p, --property= When showing session/user/seat properties, limit display to certain properties as specified as argument. If not specified, all set properties are shown. The argument should be a property name, such as \"Sessions\". If specified more than once, all properties with the specified names are shown. --value When showing session/user/seat properties, only print the value, and skip the property name and \"=\". -a, --all When showing session/user/seat properties, show all properties regardless of whether they are set or not. -l, --full Do not ellipsize process tree entries. --kill-whom= When used with kill-session, choose which processes to kill. Must be one of leader, or all to select whether to kill only the leader process of the session or all processes of the session. If omitted, defaults to all. -s, --signal= When used with kill-session or kill-user, choose which signal to send to selected processes. Must be one of the well known signal specifiers, such as SIGTERM, SIGINT or SIGSTOP. If omitted, defaults to SIGTERM. The special value \"help\" will list the known values and the program will exit immediately, and the special value \"list\" will list known values along with the numerical signal numbers and the program will exit immediately. -n, --lines= When used with user-status and session-status, controls the number of journal lines to show, counting from the most recent ones. Takes a positive integer argument. Defaults to 10. -o, --output= When used with user-status and session-status, controls the formatting of the journal entries that are shown. For the available choices, see journalctl(1). Defaults to \"short\". -H, --host= Execute the operation remotely. Specify a hostname, or a username and hostname separated by \"@\", to connect to. The hostname may optionally be suffixed by a port ssh is listening on, separated by \":\", and then a container name, separated by \"/\", which connects directly to a specific container on the specified host. This will use SSH to talk to the remote machine manager instance. Container names may be enumerated with machinectl -H HOST. Put IPv6 addresses in brackets. -M, --machine= Execute operation on a local container. Specify a container name to connect to, optionally prefixed by a user name to connect as and a separating \"@\" character. If the special string \".host\" is used in place of the container name, a connection to the local system is made (which is useful to connect to a specific user's user bus: \"--user --machine=lennart@.host\"). If the \"@\" syntax is not used, the connection is made as root user. If the \"@\" syntax is used either the left hand side or the right hand side may be omitted (but not both) in which case the local user name and \".host\" are implied. --no-pager Do not pipe output into a pager. --no-legend Do not print the legend, i.e. column headers and the footer with hints. -h, --help Print a short help text and exit. --version Print a short version string and exit. "
  },
  {
    "command": "cut",
    "description": " The cut utility shall cut out bytes (-b option), characters (-c option), or character-delimited fields (-f option) from each line in one or more files, concatenate them, and write them to standard output. The cut utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The application shall ensure that the option-argument list (see options -b, -c, and -f below) is a <comma>-separated list or <blank>-separated list of positive numbers and ranges. Ranges can be in three forms. The first is two positive numbers separated by a <hyphen-minus> (low-high), which represents all fields from the first number to the second number. The second is a positive number preceded by a <hyphen-minus> (-high), which represents all fields from field number 1 to that number. The third is a positive number followed by a <hyphen-minus> (low-), which represents that number to the last field, inclusive. The elements in list can be repeated, can overlap, and can be specified in any order, but the bytes, characters, or fields selected shall be written in the order of the input data. If an element appears in the selection list more than once, it shall be written exactly once. The following options shall be supported: -b list Cut based on a list of bytes. Each selected byte shall be output unless the -n option is also specified. It shall not be an error to select bytes not present in the input line. -c list Cut based on a list of characters. Each selected character shall be output. It shall not be an error to select characters not present in the input line. -d delim Set the field delimiter to the character delim. The default is the <tab>. -f list Cut based on a list of fields, assumed to be separated in the file by a delimiter character (see -d). Each selected field shall be output. Output fields shall be separated by a single occurrence of the field delimiter character. Lines with no field delimiters shall be passed through intact, unless -s is specified. It shall not be an error to select fields not present in the input line. -n Do not split characters. When specified with the -b option, each element in list of the form low-high (<hyphen-minus>-separated numbers) shall be modified as follows: * If the byte selected by low is not the first byte of a character, low shall be decremented to select the first byte of the character originally selected by low. If the byte selected by high is not the last byte of a character, high shall be decremented to select the last byte of the character prior to the character originally selected by high, or zero if there is no prior character. If the resulting range element has high equal to zero or low greater than high, the list element shall be dropped from list for that input line without causing an error. Each element in list of the form low- shall be treated as above with high set to the number of bytes in the current line, not including the terminating <newline>. Each element in list of the form -high shall be treated as above with low set to 1. Each element in list of the form num (a single number) shall be treated as above with low set to num and high set to num. -s Suppress lines with no delimiter characters, when used with the -f option. Unless specified, lines with no delimiters shall be passed through untouched. "
  },
  {
    "command": "kill",
    "description": " The default signal for kill is TERM. Use -l or -L to list available signals. Particularly useful signals include HUP, INT, KILL, STOP, CONT, and 0. Alternate signals may be specified in three ways: -9, -SIGKILL or -KILL. Negative PID values may be used to choose whole process groups; see the PGID column in ps command output. A PID of -1 is special; it indicates all processes except the kill process itself and init. <pid> [...] Send signal to every <pid> listed. -<signal> -s <signal> --signal <signal> Specify the signal to be sent. The signal can be specified by using name or number. The behavior of signals is explained in signal(7) manual page. -q, --queue value Use sigqueue(3) rather than kill(2) and the value argument is used to specify an integer to be sent with the signal. If the receiving process has installed a handler for this signal using the SA_SIGINFO flag to sigaction(2), then it can obtain this data via the si_value field of the siginfo_t structure. -l, --list [signal] List signal names. This option has optional argument, which will convert signal number to signal name, or other way round. -L, --table List signal names in a nice table. "
  },
  {
    "command": "sleep",
    "description": " Pause for NUMBER seconds. SUFFIX may be 's' for seconds (the default), 'm' for minutes, 'h' for hours or 'd' for days. NUMBER need not be an integer. Given two or more arguments, pause for the amount of time specified by the sum of their values. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "printf",
    "description": " The printf utility shall write formatted operands to the standard output. The argument operands shall be formatted under control of the format operand. None. "
  },
  {
    "command": "c99",
    "description": " The c99 utility is an interface to the standard C compilation system; it shall accept source code conforming to the ISO C standard. The system conceptually consists of a compiler and link editor. The input files referenced by pathname operands and -l option-arguments shall be compiled and linked to produce an executable file. (It is unspecified whether the linking occurs entirely within the operation of c99; some implementations may produce objects that are not fully resolved until the file is executed.) If the -c option is specified, for all pathname operands of the form file.c, the files: $(basename pathname .c).o shall be created as the result of successful compilation. If the -c option is not specified, it is unspecified whether such .o files are created or deleted for the file.c operands. If there are no options that prevent link editing (such as -c or -E), and all input files compile and link without error, the resulting executable file shall be written according to the -o outfile option (if present) or to the file a.out. The executable file shall be created as specified in Section 1.1.1.4, File Read, Write, and Creation, except that the file permission bits shall be set to: S_IRWXO | S_IRWXG | S_IRWXU and the bits specified by the umask of the process shall be cleared. The c99 utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except that: * Options can be interspersed with operands. * The order of specifying the -L and -l options, and the order of specifying -l options with respect to pathname operands is significant. * Conforming applications shall specify each option separately; that is, grouping option letters (for example, -cO) need not be recognized by all implementations. The following options shall be supported: -c Suppress the link-edit phase of the compilation, and do not remove any object files that are produced. -D name[=value] Define name as if by a C-language #define directive. If no =value is given, a value of 1 shall be used. The -D option has lower precedence than the -U option. That is, if name is used in both a -U and a -D option, name shall be undefined regardless of the order of the options. Additional implementation-defined names may be provided by the compiler. Implementations shall support at least 2048 bytes of -D definitions and 256 names. -E Copy C-language source files to standard output, executing all preprocessor directives; no compilation shall be performed. If any operand is not a text file, the effects are unspecified. -g Produce symbolic information in the object or executable files; the nature of this information is unspecified, and may be modified by implementation- defined interactions with other options. -I directory Change the algorithm for searching for headers whose names are not absolute pathnames to look in the directory named by the directory pathname before looking in the usual places. Thus, headers whose names are enclosed in double-quotes (\"\") shall be searched for first in the directory of the file with the #include line, then in directories named in -I options, and last in the usual places. For headers whose names are enclosed in angle brackets (\"<>\"), the header shall be searched for only in directories named in -I options and then in the usual places. Directories named in -I options shall be searched in the order specified. If the -I option is used to specify a directory that is one of the usual places searched by default, the results are unspecified. Implementations shall support at least ten instances of this option in a single c99 command invocation. -L directory Change the algorithm of searching for the libraries named in the -l objects to look in the directory named by the directory pathname before looking in the usual places. Directories named in -L options shall be searched in the order specified. If the -L option is used to specify a directory that is one of the usual places searched by default, the results are unspecified. Implementations shall support at least ten instances of this option in a single c99 command invocation. If a directory specified by a -L option contains files with names starting with any of the strings \"libc.\", \"libl.\", \"libpthread.\", \"libm.\", \"librt.\", \"libtrace.\", \"libxnet.\", or \"liby.\", the results are unspecified. -l library Search the library named liblibrary.a. A library shall be searched when its name is encountered, so the placement of a -l option is significant. Several standard libraries can be specified in this manner, as described in the EXTENDED DESCRIPTION section. Implementations may recognize implementation-defined suffixes other than .a as denoting libraries. -O optlevel Specify the level of code optimization. If the optlevel option-argument is the digit '0', all special code optimizations shall be disabled. If it is the digit '1', the nature of the optimization is unspecified. If the -O option is omitted, the nature of the system's default optimization is unspecified. It is unspecified whether code generated in the presence of the -O 0 option is the same as that generated when -O is omitted. Other optlevel values may be supported. -o outfile Use the pathname outfile, instead of the default a.out, for the executable file produced. If the -o option is present with -c or -E, the result is unspecified. -s Produce object or executable files, or both, from which symbolic and other information not required for proper execution using the exec family defined in the System Interfaces volume of POSIX.1\u20102017 has been removed (stripped). If both -g and -s options are present, the action taken is unspecified. -U name Remove any initial definition of name. Multiple instances of the -D, -I, -L, -l, and -U options can be specified. "
  },
  {
    "command": "runuser",
    "description": " runuser can be used to run commands with a substitute user and group ID. If the option -u is not given, runuser falls back to su-compatible semantics and a shell is executed. The difference between the commands runuser and su is that runuser does not ask for a password (because it may be executed by the root user only) and it uses a different PAM configuration. The command runuser does not have to be installed with set-user-ID permissions. If the PAM session is not required, then the recommended solution is to use the setpriv(1) command. When called without arguments, runuser defaults to running an interactive shell as root. For backward compatibility, runuser defaults to not changing the current directory and to setting only the environment variables HOME and SHELL (plus USER and LOGNAME if the target user is not root). This version of runuser uses PAM for session management. Note that runuser in all cases use PAM (pam_getenvlist()) to do the final environment modification. Command-line options such as --login and --preserve-environment affect the environment before it is modified by PAM. Since version 2.38 runuser resets process resource limits RLIMIT_NICE, RLIMIT_RTPRIO, RLIMIT_FSIZE, RLIMIT_AS and RLIMIT_NOFILE. -c, --command=command Pass command to the shell with the -c option. -f, --fast Pass -f to the shell, which may or may not be useful, depending on the shell. -g, --group=group The primary group to be used. This option is allowed for the root user only. -G, --supp-group=group Specify a supplementary group. This option is available to the root user only. The first specified supplementary group is also used as a primary group if the option --group is not specified. -, -l, --login Start the shell as a login shell with an environment similar to a real login: \u2022 clears all the environment variables except for TERM and variables specified by --whitelist-environment \u2022 initializes the environment variables HOME, SHELL, USER, LOGNAME, and PATH \u2022 changes to the target user\u2019s home directory \u2022 sets argv[0] of the shell to '-' in order to make the shell a login shell -P, --pty Create a pseudo-terminal for the session. The independent terminal provides better security as the user does not share a terminal with the original session. This can be used to avoid TIOCSTI ioctl terminal injection and other security attacks against terminal file descriptors. The entire session can also be moved to the background (e.g., runuser --pty -u username -- command &). If the pseudo-terminal is enabled, then runuser works as a proxy between the sessions (sync stdin and stdout). This feature is mostly designed for interactive sessions. If the standard input is not a terminal, but for example a pipe (e.g., echo \"date\" | runuser --pty -u user), then the ECHO flag for the pseudo-terminal is disabled to avoid messy output. -m, -p, --preserve-environment Preserve the entire environment, i.e., do not set HOME, SHELL, USER or LOGNAME. The option is ignored if the option --login is specified. -s, --shell=shell Run the specified shell instead of the default. The shell to run is selected according to the following rules, in order: \u2022 the shell specified with --shell \u2022 the shell specified in the environment variable SHELL if the --preserve-environment option is used \u2022 the shell listed in the passwd entry of the target user \u2022 /bin/sh If the target user has a restricted shell (i.e., not listed in /etc/shells), then the --shell option and the SHELL environment variables are ignored unless the calling user is root. --session-command=command Same as -c, but do not create a new session. (Discouraged.) -w, --whitelist-environment=list Don\u2019t reset the environment variables specified in the comma-separated list when clearing the environment for --login. The whitelist is ignored for the environment variables HOME, SHELL, USER, LOGNAME, and PATH. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "man",
    "description": " man is the system's manual pager. Each page argument given to man is normally the name of a program, utility or function. The manual page associated with each of these arguments is then found and displayed. A section, if provided, will direct man to look only in that section of the manual. The default action is to search in all of the available sections following a pre-defined order (see DEFAULTS), and to show only the first page found, even if page exists in several sections. The table below shows the section numbers of the manual followed by the types of pages they contain. 1 Executable programs or shell commands 2 System calls (functions provided by the kernel) 3 Library calls (functions within program libraries) 4 Special files (usually found in /dev) 5 File formats and conventions, e.g. /etc/passwd 6 Games 7 Miscellaneous (including macro packages and conventions), e.g. man(7), groff(7), man-pages(7) 8 System administration commands (usually only for root) 9 Kernel routines [Non standard] A manual page consists of several sections. Conventional section names include NAME, SYNOPSIS, CONFIGURATION, DESCRIPTION, OPTIONS, EXIT STATUS, RETURN VALUE, ERRORS, ENVIRONMENT, FILES, VERSIONS, CONFORMING TO, NOTES, BUGS, EXAMPLE, AUTHORS, and SEE ALSO. The following conventions apply to the SYNOPSIS section and can be used as a guide in other sections. bold text type exactly as shown. italic text replace with appropriate argument. [-abc] any or all arguments within [ ] are optional. -a|-b options delimited by | cannot be used together. argument ... argument is repeatable. [expression] ... entire expression within [ ] is repeatable. Exact rendering may vary depending on the output device. For instance, man will usually not be able to render italics when running in a terminal, and will typically use underlined or coloured text instead. The command or function illustration is a pattern that should match all possible invocations. In some cases it is advisable to illustrate several exclusive invocations as is shown in the SYNOPSIS section of this manual page. Non-argument options that are duplicated either on the command line, in $MANOPT, or both, are not harmful. For options that require an argument, each duplication will override the previous argument value. General options -C file, --config-file=file Use this user configuration file rather than the default of ~/.manpath. -d, --debug Print debugging information. -D, --default This option is normally issued as the very first option and resets man's behaviour to its default. Its use is to reset those options that may have been set in $MANOPT. Any options that follow -D will have their usual effect. --warnings[=warnings] Enable warnings from groff. This may be used to perform sanity checks on the source text of manual pages. warnings is a comma-separated list of warning names; if it is not supplied, the default is \"mac\". See the \u201cWarnings\u201d node in info groff for a list of available warning names. Main modes of operation -f, --whatis Equivalent to whatis. Display a short description from the manual page, if available. See whatis(1) for details. -k, --apropos Equivalent to apropos. Search the short manual page descriptions for keywords and display any matches. See apropos(1) for details. -K, --global-apropos Search for text in all manual pages. This is a brute- force search, and is likely to take some time; if you can, you should specify a section to reduce the number of pages that need to be searched. Search terms may be simple strings (the default), or regular expressions if the --regex option is used. Note that this searches the sources of the manual pages, not the rendered text, and so may include false positives due to things like comments in source files. Searching the rendered text would be much slower. -l, --local-file Activate \"local\" mode. Format and display local manual files instead of searching through the system's manual collection. Each manual page argument will be interpreted as an nroff source file in the correct format. No cat file is produced. If '-' is listed as one of the arguments, input will be taken from stdin. When this option is not used, and man fails to find the page required, before displaying the error message, it attempts to act as if this option was supplied, using the name as a filename and looking for an exact match. -w, --where, --path, --location Don't actually display the manual page, but do print the location of the source nroff file that would be formatted. If the -a option is also used, then print the locations of all source files that match the search criteria. -W, --where-cat, --location-cat Don't actually display the manual page, but do print the location of the preformatted cat file that would be displayed. If the -a option is also used, then print the locations of all preformatted cat files that match the search criteria. If -w and -W are both used, then print both source file and cat file separated by a space. If all of -w, -W, and -a are used, then do this for each possible match. -c, --catman This option is not for general use and should only be used by the catman program. -R encoding, --recode=encoding Instead of formatting the manual page in the usual way, output its source converted to the specified encoding. If you already know the encoding of the source file, you can also use manconv(1) directly. However, this option allows you to convert several manual pages to a single encoding without having to explicitly state the encoding of each, provided that they were already installed in a structure similar to a manual page hierarchy. Consider using man-recode(1) instead for converting multiple manual pages, since it has an interface designed for bulk conversion and so can be much faster. Finding manual pages -L locale, --locale=locale man will normally determine your current locale by a call to the C function setlocale(3) which interrogates various environment variables, possibly including $LC_MESSAGES and $LANG. To temporarily override the determined value, use this option to supply a locale string directly to man. Note that it will not take effect until the search for pages actually begins. Output such as the help message will always be displayed in the initially determined locale. -m system[,...], --systems=system[,...] If this system has access to other operating systems' manual pages, they can be accessed using this option. To search for a manual page from NewOS's manual page collection, use the option -m NewOS. The system specified can be a combination of comma delimited operating system names. To include a search of the native operating system's manual pages, include the system name man in the argument string. This option will override the $SYSTEM environment variable. -M path, --manpath=path Specify an alternate manpath to use. By default, man uses manpath derived code to determine the path to search. This option overrides the $MANPATH environment variable and causes option -m to be ignored. A path specified as a manpath must be the root of a manual page hierarchy structured into sections as described in the man-db manual (under \"The manual page system\"). To view manual pages outside such hierarchies, see the -l option. -S list, -s list, --sections=list The given list is a colon- or comma-separated list of sections, used to determine which manual sections to search and in what order. This option overrides the $MANSECT environment variable. (The -s spelling is for compatibility with System V.) -e sub-extension, --extension=sub-extension Some systems incorporate large packages of manual pages, such as those that accompany the Tcl package, into the main manual page hierarchy. To get around the problem of having two manual pages with the same name such as exit(3), the Tcl pages were usually all assigned to section l. As this is unfortunate, it is now possible to put the pages in the correct section, and to assign a specific \"extension\" to them, in this case, exit(3tcl). Under normal operation, man will display exit(3) in preference to exit(3tcl). To negotiate this situation and to avoid having to know which section the page you require resides in, it is now possible to give man a sub-extension string indicating which package the page must belong to. Using the above example, supplying the option -e tcl to man will restrict the search to pages having an extension of *tcl. -i, --ignore-case Ignore case when searching for manual pages. This is the default. -I, --match-case Search for manual pages case-sensitively. --regex Show all pages with any part of either their names or their descriptions matching each page argument as a regular expression, as with apropos(1). Since there is usually no reasonable way to pick a \"best\" page when searching for a regular expression, this option implies -a. --wildcard Show all pages with any part of either their names or their descriptions matching each page argument using shell-style wildcards, as with apropos(1) --wildcard. The page argument must match the entire name or description, or match on word boundaries in the description. Since there is usually no reasonable way to pick a \"best\" page when searching for a wildcard, this option implies -a. --names-only If the --regex or --wildcard option is used, match only page names, not page descriptions, as with whatis(1). Otherwise, no effect. -a, --all By default, man will exit after displaying the most suitable manual page it finds. Using this option forces man to display all the manual pages with names that match the search criteria. -u, --update This option causes man to update its database caches of installed manual pages. This is only needed in rare situations, and it is normally better to run mandb(8) instead. --no-subpages By default, man will try to interpret pairs of manual page names given on the command line as equivalent to a single manual page name containing a hyphen or an underscore. This supports the common pattern of programs that implement a number of subcommands, allowing them to provide manual pages for each that can be accessed using similar syntax as would be used to invoke the subcommands themselves. For example: $ man -aw git diff /usr/share/man/man1/git-diff.1.gz To disable this behaviour, use the --no-subpages option. $ man -aw --no-subpages git diff /usr/share/man/man1/git.1.gz /usr/share/man/man3/Git.3pm.gz /usr/share/man/man1/diff.1.gz Controlling formatted output -P pager, --pager=pager Specify which output pager to use. By default, man uses less, falling back to cat if less is not found or is not executable. This option overrides the $MANPAGER environment variable, which in turn overrides the $PAGER environment variable. It is not used in conjunction with -f or -k. The value may be a simple command name or a command with arguments, and may use shell quoting (backslashes, single quotes, or double quotes). It may not use pipes to connect multiple commands; if you need that, use a wrapper script, which may take the file to display either as an argument or on standard input. -r prompt, --prompt=prompt If a recent version of less is used as the pager, man will attempt to set its prompt and some sensible options. The default prompt looks like Manual page name(sec) line x where name denotes the manual page name, sec denotes the section it was found under and x the current line number. This is achieved by using the $LESS environment variable. Supplying -r with a string will override this default. The string may contain the text $MAN_PN which will be expanded to the name of the current manual page and its section name surrounded by \"(\" and \")\". The string used to produce the default could be expressed as \\ Manual\\ page\\ \\$MAN_PN\\ ?ltline\\ %lt?L/%L.: byte\\ %bB?s/%s..?\\ (END):?pB\\ %pB\\\\%.. (press h for help or q to quit) It is broken into three lines here for the sake of readability only. For its meaning see the less(1) manual page. The prompt string is first evaluated by the shell. All double quotes, back-quotes and backslashes in the prompt must be escaped by a preceding backslash. The prompt string may end in an escaped $ which may be followed by further options for less. By default man sets the -ix8 options. The $MANLESS environment variable described below may be used to set a default prompt string if none is supplied on the command line. -7, --ascii When viewing a pure ascii(7) manual page on a 7 bit terminal or terminal emulator, some characters may not display correctly when using the latin1(7) device description with GNU nroff. This option allows pure ascii manual pages to be displayed in ascii with the latin1 device. It will not translate any latin1 text. The following table shows the translations performed: some parts of it may only be displayed properly when using GNU nroff's latin1(7) device. Description Octal latin1 ascii \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 continuation 255 \u2010 - hyphen bullet (middle 267 \u2022 o dot) acute accent 264 \u00b4 ' multiplication 327 \u00d7 x sign If the latin1 column displays correctly, your terminal may be set up for latin1 characters and this option is not necessary. If the latin1 and ascii columns are identical, you are reading this page using this option or man did not format this page using the latin1 device description. If the latin1 column is missing or corrupt, you may need to view manual pages with this option. This option is ignored when using options -t, -H, -T, or -Z and may be useless for nroff other than GNU's. -E encoding, --encoding=encoding Generate output for a character encoding other than the default. For backward compatibility, encoding may be an nroff device such as ascii, latin1, or utf8 as well as a true character encoding such as UTF-8. --no-hyphenation, --nh Normally, nroff will automatically hyphenate text at line breaks even in words that do not contain hyphens, if it is necessary to do so to lay out words on a line without excessive spacing. This option disables automatic hyphenation, so words will only be hyphenated if they already contain hyphens. If you are writing a manual page and simply want to prevent nroff from hyphenating a word at an inappropriate point, do not use this option, but consult the nroff documentation instead; for instance, you can put \"\\%\" inside a word to indicate that it may be hyphenated at that point, or put \"\\%\" at the start of a word to prevent it from being hyphenated. --no-justification, --nj Normally, nroff will automatically justify text to both margins. This option disables full justification, leaving justified only to the left margin, sometimes called \"ragged-right\" text. If you are writing a manual page and simply want to prevent nroff from justifying certain paragraphs, do not use this option, but consult the nroff documentation instead; for instance, you can use the \".na\", \".nf\", \".fi\", and \".ad\" requests to temporarily disable adjusting and filling. -p string, --preprocessor=string Specify the sequence of preprocessors to run before nroff or troff/groff. Not all installations will have a full set of preprocessors. Some of the preprocessors and the letters used to designate them are: eqn (e), grap (g), pic (p), tbl (t), vgrind (v), refer (r). This option overrides the $MANROFFSEQ environment variable. zsoelim is always run as the very first preprocessor. -t, --troff Use groff -mandoc to format the manual page to stdout. This option is not required in conjunction with -H, -T, or -Z. -T[device], --troff-device[=device] This option is used to change groff (or possibly troff's) output to be suitable for a device other than the default. It implies -t. Examples (provided with Groff-1.17) include dvi, latin1, ps, utf8, X75 and X100. -H[browser], --html[=browser] This option will cause groff to produce HTML output, and will display that output in a web browser. The choice of browser is determined by the optional browser argument if one is provided, by the $BROWSER environment variable, or by a compile-time default if that is unset (usually lynx). This option implies -t, and will only work with GNU troff. -X[dpi], --gxditview[=dpi] This option displays the output of groff in a graphical window using the gxditview program. The dpi (dots per inch) may be 75, 75-12, 100, or 100-12, defaulting to 75; the -12 variants use a 12-point base font. This option implies -T with the X75, X75-12, X100, or X100-12 device respectively. -Z, --ditroff groff will run troff and then use an appropriate post- processor to produce output suitable for the chosen device. If groff -mandoc is groff, this option is passed to groff and will suppress the use of a post-processor. It implies -t. Getting help -?, --help Print a help message and exit. --usage Print a short usage message and exit. -V, --version Display version information. "
  },
  {
    "command": "git-cherry",
    "description": " Determine whether there are commits in <head>..<upstream> that are equivalent to those in the range <limit>..<head>. The equivalence test is based on the diff, after removing whitespace and line numbers. git-cherry therefore detects when commits have been \"copied\" by means of git-cherry-pick(1), git-am(1) or git-rebase(1). Outputs the SHA1 of every commit in <limit>..<head>, prefixed with - for commits that have an equivalent in <upstream>, and + for commits that do not. -v Show the commit subjects next to the SHA1s. <upstream> Upstream branch to search for equivalent commits. Defaults to the upstream branch of HEAD. <head> Working branch; defaults to HEAD. <limit> Do not report commits up to (and including) limit. "
  },
  {
    "command": "fold",
    "description": " The fold utility is a filter that shall fold lines from its input files, breaking the lines to have a maximum of width column positions (or bytes, if the -b option is specified). Lines shall be broken by the insertion of a <newline> such that each output line (referred to later in this section as a segment) is the maximum width possible that does not exceed the specified number of column positions (or bytes). A line shall not be broken in the middle of a character. The behavior is undefined if width is less than the number of columns any single character in the input would occupy. If the <carriage-return>, <backspace>, or <tab> characters are encountered in the input, and the -b option is not specified, they shall be treated specially: <backspace> The current count of line width shall be decremented by one, although the count never shall become negative. The fold utility shall not insert a <newline> immediately before or after any <backspace>, unless the following character has a width greater than 1 and would cause the line width to exceed width. <carriage-return> The current count of line width shall be set to zero. The fold utility shall not insert a <newline> immediately before or after any <carriage-return>. <tab> Each <tab> encountered shall advance the column position pointer to the next tab stop. Tab stops shall be at each column position n such that n modulo 8 equals 1. The fold utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -b Count width in bytes rather than column positions. -s If a segment of a line contains a <blank> within the first width column positions (or bytes), break the line after the last such <blank> meeting the width constraints. If there is no <blank> meeting the requirements, the -s option shall have no effect for that output segment of the input line. -w width Specify the maximum line length, in column positions (or bytes if -b is specified). The results are unspecified if width is not a positive decimal number. The default value shall be 80. "
  },
  {
    "command": "dirname",
    "description": " Output each NAME with its last non-slash component and trailing slashes removed; if NAME contains no /'s, output '.' (meaning the current directory). -z, --zero end each output line with NUL, not newline --help display this help and exit --version output version information and exit "
  },
  {
    "command": "tsort",
    "description": " Write totally ordered list consistent with the partial ordering in FILE. With no FILE, or when FILE is -, read standard input. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "base32",
    "description": " Base32 encode or decode FILE, or standard input, to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -d, --decode decode data -i, --ignore-garbage when decoding, ignore non-alphabet characters -w, --wrap=COLS wrap encoded lines after COLS character (default 76). Use 0 to disable line wrapping --help display this help and exit --version output version information and exit The data are encoded as described for the base32 alphabet in RFC 4648. When decoding, the input may contain newlines in addition to the bytes of the formal base32 alphabet. Use --ignore-garbage to attempt to recover from any other non-alphabet bytes in the encoded stream. "
  },
  {
    "command": "git-commit-tree",
    "description": " This is usually not what an end user wants to run directly. See git-commit(1) instead. Creates a new commit object based on the provided tree object and emits the new commit object id on stdout. The log message is read from the standard input, unless -m or -F options are given. The -m and -F options can be given any number of times, in any order. The commit log message will be composed in the order in which the options are given. A commit object may have any number of parents. With exactly one parent, it is an ordinary commit. Having more than one parent makes the commit a merge between several lines of history. Initial (root) commits have no parents. While a tree represents a particular directory state of a working directory, a commit represents that state in \"time\", and explains how to get there. Normally a commit would identify a new \"HEAD\" state, and while Git doesn\u2019t care where you save the note about that state, in practice we tend to just write the result to the file that is pointed at by .git/HEAD, so that we can always see what the last committed state was. <tree> An existing tree object. -p <parent> Each -p indicates the id of a parent commit object. -m <message> A paragraph in the commit log message. This can be given more than once and each <message> becomes its own paragraph. -F <file> Read the commit log message from the given file. Use - to read from the standard input. This can be given more than once and the content of each file becomes its own paragraph. -S[<keyid>], --gpg-sign[=<keyid>], --no-gpg-sign GPG-sign commits. The keyid argument is optional and defaults to the committer identity; if specified, it must be stuck to the option without a space. --no-gpg-sign is useful to countermand a --gpg-sign option given earlier on the command line. "
  },
  {
    "command": "reset",
    "description": " The @TPUT@ utility uses the terminfo database to make the values of terminal-dependent capabilities and information available to the shell (see sh(1)), to initialize or reset the terminal, or return the long name of the requested terminal type. The result depends upon the capability's type: string @TPUT@ writes the string to the standard output. No trailing newline is supplied. integer @TPUT@ writes the decimal value to the standard output, with a trailing newline. boolean @TPUT@ simply sets the exit code (0 for TRUE if the terminal has the capability, 1 for FALSE if it does not), and writes nothing to the standard output. Before using a value returned on the standard output, the application should test the exit code (e.g., $?, see sh(1)) to be sure it is 0. (See the EXIT CODES and DIAGNOSTICS sections.) For a complete list of capabilities and the capname associated with each, see terminfo(5). Options -S allows more than one capability per invocation of @TPUT@. The capabilities must be passed to @TPUT@ from the standard input instead of from the command line (see example). Only one capname is allowed per line. The -S option changes the meaning of the 0 and 1 boolean and string exit codes (see the EXIT CODES section). Because some capabilities may use string parameters rather than numbers, @TPUT@ uses a table and the presence of parameters in its input to decide whether to use tparm(3X), and how to interpret the parameters. -Ttype indicates the type of terminal. Normally this option is unnecessary, because the default is taken from the environment variable TERM. If -T is specified, then the shell variables LINES and COLUMNS will also be ignored. -V reports the version of ncurses which was used in this program, and exits. -x do not attempt to clear the terminal's scrollback buffer using the extended \u201cE3\u201d capability. Commands A few commands (init, reset and longname) are special; they are defined by the @TPUT@ program. The others are the names of capabilities from the terminal database (see terminfo(5) for a list). Although init and reset resemble capability names, @TPUT@ uses several capabilities to perform these special functions. capname indicates the capability from the terminal database. If the capability is a string that takes parameters, the arguments following the capability will be used as parameters for the string. Most parameters are numbers. Only a few terminal capabilities require string parameters; @TPUT@ uses a table to decide which to pass as strings. Normally @TPUT@ uses tparm(3X) to perform the substitution. If no parameters are given for the capability, @TPUT@ writes the string without performing the substitution. init If the terminal database is present and an entry for the user's terminal exists (see -Ttype, above), the following will occur: (1) first, @TPUT@ retrieves the current terminal mode settings for your terminal. It does this by successively testing \u2022 the standard error, \u2022 standard output, \u2022 standard input and \u2022 ultimately \u201c/dev/tty\u201d to obtain terminal settings. Having retrieved these settings, @TPUT@ remembers which file descriptor to use when updating settings. (2) if the window size cannot be obtained from the operating system, but the terminal description (or environment, e.g., LINES and COLUMNS variables specify this), update the operating system's notion of the window size. (3) the terminal modes will be updated: \u2022 any delays (e.g., newline) specified in the entry will be set in the tty driver, \u2022 tabs expansion will be turned on or off according to the specification in the entry, and \u2022 if tabs are not expanded, standard tabs will be set (every 8 spaces). (4) if present, the terminal's initialization strings will be output as detailed in the terminfo(5) section on Tabs and Initialization, (5) output is flushed. If an entry does not contain the information needed for any of these activities, that activity will silently be skipped. reset This is similar to init, with two differences: (1) before any other initialization, the terminal modes will be reset to a \u201csane\u201d state: \u2022 set cooked and echo modes, \u2022 turn off cbreak and raw modes, \u2022 turn on newline translation and \u2022 reset any unset special characters to their default values (2) Instead of putting out initialization strings, the terminal's reset strings will be output if present (rs1, rs2, rs3, rf). If the reset strings are not present, but initialization strings are, the initialization strings will be output. Otherwise, reset acts identically to init. longname If the terminal database is present and an entry for the user's terminal exists (see -Ttype above), then the long name of the terminal will be put out. The long name is the last name in the first line of the terminal's description in the terminfo database [see term(5)]. Aliases @TPUT@ handles the clear, init and reset commands specially: it allows for the possibility that it is invoked by a link with those names. If @TPUT@ is invoked by a link named reset, this has the same effect as @TPUT@ reset. The @TSET@(1) utility also treats a link named reset specially. Before ncurses 6.1, the two utilities were different from each other: \u2022 @TSET@ utility reset the terminal modes and special characters (not done with @TPUT@). \u2022 On the other hand, @TSET@'s repertoire of terminal capabilities for resetting the terminal was more limited, i.e., only reset_1string, reset_2string and reset_file in contrast to the tab-stops and margins which are set by this utility. \u2022 The reset program is usually an alias for @TSET@, because of this difference with resetting terminal modes and special characters. With the changes made for ncurses 6.1, the reset feature of the two programs is (mostly) the same. A few differences remain: \u2022 The @TSET@ program waits one second when resetting, in case it happens to be a hardware terminal. \u2022 The two programs write the terminal initialization strings to different streams (i.e., the standard error for @TSET@ and the standard output for @TPUT@). Note: although these programs write to different streams, redirecting their output to a file will capture only part of their actions. The changes to the terminal modes are not affected by redirecting the output. If @TPUT@ is invoked by a link named init, this has the same effect as @TPUT@ init. Again, you are less likely to use that link because another program named init has a more well- established use. Terminal Size Besides the special commands (e.g., clear), @TPUT@ treats certain terminfo capabilities specially: lines and cols. @TPUT@ calls setupterm(3X) to obtain the terminal size: \u2022 first, it gets the size from the terminal database (which generally is not provided for terminal emulators which do not have a fixed window size) \u2022 then it asks the operating system for the terminal's size (which generally works, unless connecting via a serial line which does not support NAWS: negotiations about window size). \u2022 finally, it inspects the environment variables LINES and COLUMNS which may override the terminal size. If the -T option is given @TPUT@ ignores the environment variables by calling use_tioctl(TRUE), relying upon the operating system (or finally, the terminal database). "
  },
  {
    "command": "git-init",
    "description": " This command creates an empty Git repository - basically a .git directory with subdirectories for objects, refs/heads, refs/tags, and template files. An initial branch without any commits will be created (see the --initial-branch option below for its name). If the $GIT_DIR environment variable is set then it specifies a path to use instead of ./.git for the base of the repository. If the object storage directory is specified via the $GIT_OBJECT_DIRECTORY environment variable then the sha1 directories are created underneath - otherwise the default $GIT_DIR/objects directory is used. Running git init in an existing repository is safe. It will not overwrite things that are already there. The primary reason for rerunning git init is to pick up newly added templates (or to move the repository to another place if --separate-git-dir is given). -q, --quiet Only print error and warning messages; all other output will be suppressed. --bare Create a bare repository. If GIT_DIR environment is not set, it is set to the current working directory. --object-format=<format> Specify the given object format (hash algorithm) for the repository. The valid values are sha1 and (if enabled) sha256. sha1 is the default. THIS OPTION IS EXPERIMENTAL! SHA-256 support is experimental and still in an early stage. A SHA-256 repository will in general not be able to share work with \"regular\" SHA-1 repositories. It should be assumed that, e.g., Git internal file formats in relation to SHA-256 repositories may change in backwards-incompatible ways. Only use --object-format=sha256 for testing purposes. --template=<template-directory> Specify the directory from which templates will be used. (See the \"TEMPLATE DIRECTORY\" section below.) --separate-git-dir=<git-dir> Instead of initializing the repository as a directory to either $GIT_DIR or ./.git/, create a text file there containing the path to the actual repository. This file acts as filesystem-agnostic Git symbolic link to the repository. If this is reinitialization, the repository will be moved to the specified path. -b <branch-name>, --initial-branch=<branch-name> Use the specified name for the initial branch in the newly created repository. If not specified, fall back to the default name (currently master, but this is subject to change in the future; the name can be customized via the init.defaultBranch configuration variable). --shared[=(false|true|umask|group|all|world|everybody|<perm>)] Specify that the Git repository is to be shared amongst several users. This allows users belonging to the same group to push into that repository. When specified, the config variable \"core.sharedRepository\" is set so that files and directories under $GIT_DIR are created with the requested permissions. When not specified, Git will use permissions reported by umask(2). The option can have the following values, defaulting to group if no value is given: umask (or false) Use permissions reported by umask(2). The default, when --shared is not specified. group (or true) Make the repository group-writable, (and g+sx, since the git group may be not the primary group of all users). This is used to loosen the permissions of an otherwise safe umask(2) value. Note that the umask still applies to the other permission bits (e.g. if umask is 0022, using group will not remove read privileges from other (non-group) users). See 0xxx for how to exactly specify the repository permissions. all (or world or everybody) Same as group, but make the repository readable by all users. <perm> <perm> is a 3-digit octal number prefixed with \u20180` and each file will have mode <perm>. <perm> will override users\u2019 umask(2) value (and not only loosen permissions as group and all does). 0640 will create a repository which is group-readable, but not group-writable or accessible to others. 0660 will create a repo that is readable and writable to the current user and group, but inaccessible to others (directories and executable files get their x bit from the r bit for corresponding classes of users). By default, the configuration flag receive.denyNonFastForwards is enabled in shared repositories, so that you cannot force a non fast-forwarding push into it. If you provide a directory, the command is run inside it. If this directory does not exist, it will be created. "
  },
  {
    "command": "csplit",
    "description": " Output pieces of FILE separated by PATTERN(s) to files 'xx00', 'xx01', ..., and output byte counts of each piece to standard output. Read standard input if FILE is - Mandatory arguments to long options are mandatory for short options too. -b, --suffix-format=FORMAT use sprintf FORMAT instead of %02d -f, --prefix=PREFIX use PREFIX instead of 'xx' -k, --keep-files do not remove output files on errors --suppress-matched suppress the lines matching PATTERN -n, --digits=DIGITS use specified number of digits instead of 2 -s, --quiet, --silent do not print counts of output file sizes -z, --elide-empty-files suppress empty output files --help display this help and exit --version output version information and exit Each PATTERN may be: INTEGER copy up to but not including specified line number /REGEXP/[OFFSET] copy up to but not including a matching line %REGEXP%[OFFSET] skip to, but not including a matching line {INTEGER} repeat the previous pattern specified number of times {*} repeat the previous pattern as many times as possible A line OFFSET is an integer optionally preceded by '+' or '-' "
  },
  {
    "command": "make",
    "description": " The make utility will determine automatically which pieces of a large program need to be recompiled, and issue the commands to recompile them. The manual describes the GNU implementation of make, which was written by Richard Stallman and Roland McGrath, and is currently maintained by Paul Smith. Our examples show C programs, since they are very common, but you can use make with any programming language whose compiler can be run with a shell command. In fact, make is not limited to programs. You can use it to describe any task where some files must be updated automatically from others whenever the others change. To prepare to use make, you must write a file called the makefile that describes the relationships among files in your program, and provides commands for updating each file. In a program, typically the executable file is updated from object files, which are in turn made by compiling source files. Once a suitable makefile exists, each time you change some source files, this simple shell command: make suffices to perform all necessary recompilations. The make program uses the makefile description and the last-modification times of the files to decide which of the files need to be updated. For each of those files, it issues the commands recorded in the makefile. make executes commands in the makefile to update one or more targets, where target is typically a program. If no -f option is present, make will look for the makefiles GNUmakefile, makefile, and Makefile, in that order. Normally you should call your makefile either makefile or Makefile. (We recommend Makefile because it appears prominently near the beginning of a directory listing, right near other important files such as README.) The first name checked, GNUmakefile, is not recommended for most makefiles. You should use this name if you have a makefile that is specific to GNU make, and will not be understood by other versions of make. If makefile is '-', the standard input is read. make updates a target if it depends on prerequisite files that have been modified since the target was last modified, or if the target does not exist. -b, -m These options are ignored for compatibility with other versions of make. -B, --always-make Unconditionally make all targets. -C dir, --directory=dir Change to directory dir before reading the makefiles or doing anything else. If multiple -C options are specified, each is interpreted relative to the previous one: -C / -C etc is equivalent to -C /etc. This is typically used with recursive invocations of make. -d Print debugging information in addition to normal processing. The debugging information says which files are being considered for remaking, which file-times are being compared and with what results, which files actually need to be remade, which implicit rules are considered and which are applied---everything interesting about how make decides what to do. --debug[=FLAGS] Print debugging information in addition to normal processing. If the FLAGS are omitted, then the behavior is the same as if -d was specified. FLAGS may be any or all of the following names, comma- or space-separated. Only the first character is significant: the rest may be omitted: all for all debugging output (same as using -d), basic for basic debugging, verbose for more verbose basic debugging, implicit for showing implicit rule search operations, jobs for details on invocation of commands, makefile for debugging while remaking makefiles, print shows all recipes that are run even if they are silent, and why shows the reason make decided to rebuild each target. Use none to disable all previous debugging flags. -e, --environment-overrides Give variables taken from the environment precedence over variables from makefiles. -E string, --eval string Interpret string using the eval function, before parsing any makefiles. -f file, --file=file, --makefile=FILE Use file as a makefile. -i, --ignore-errors Ignore all errors in commands executed to remake files. -I dir, --include-dir=dir Specifies a directory dir to search for included makefiles. If several -I options are used to specify several directories, the directories are searched in the order specified. Unlike the arguments to other flags of make, directories given with -I flags may come directly after the flag: -Idir is allowed, as well as -I dir. This syntax is allowed for compatibility with the C preprocessor's -I flag. -j [jobs], --jobs[=jobs] Specifies the number of jobs (commands) to run simultaneously. If there is more than one -j option, the last one is effective. If the -j option is given without an argument, make will not limit the number of jobs that can run simultaneously. --jobserver-style=style The style of jobserver to use. The style may be one of fifo, pipe, or sem (Windows only). -k, --keep-going Continue as much as possible after an error. While the target that failed, and those that depend on it, cannot be remade, the other dependencies of these targets can be processed all the same. -l [load], --load-average[=load] Specifies that no new jobs (commands) should be started if there are others jobs running and the load average is at least load (a floating-point number). With no argument, removes a previous load limit. -L, --check-symlink-times Use the latest mtime between symlinks and target. -n, --just-print, --dry-run, --recon Print the commands that would be executed, but do not execute them (except in certain circumstances). -o file, --old-file=file, --assume-old=file Do not remake the file file even if it is older than its dependencies, and do not remake anything on account of changes in file. Essentially the file is treated as very old and its rules are ignored. -O[type], --output-sync[=type] When running multiple jobs in parallel with -j, ensure the output of each job is collected together rather than interspersed with output from other jobs. If type is not specified or is target the output from the entire recipe for each target is grouped together. If type is line the output from each command line within a recipe is grouped together. If type is recurse output from an entire recursive make is grouped together. If type is none output synchronization is disabled. -p, --print-data-base Print the data base (rules and variable values) that results from reading the makefiles; then execute as usual or as otherwise specified. This also prints the version information given by the -v switch (see below). To print the data base without trying to remake any files, use make -p -f/dev/null. -q, --question ``Question mode''. Do not run any commands, or print anything; just return an exit status that is zero if the specified targets are already up to date, nonzero otherwise. -r, --no-builtin-rules Eliminate use of the built-in implicit rules. Also clear out the default list of suffixes for suffix rules. -R, --no-builtin-variables Don't define any built-in variables. -s, --silent, --quiet Silent operation; do not print the commands as they are executed. --no-silent Cancel the effect of the -s option. -S, --no-keep-going, --stop Cancel the effect of the -k option. -t, --touch Touch files (mark them up to date without really changing them) instead of running their commands. This is used to pretend that the commands were done, in order to fool future invocations of make. --trace Information about the disposition of each target is printed (why the target is being rebuilt and what commands are run to rebuild it). -v, --version Print the version of the make program plus a copyright, a list of authors and a notice that there is no warranty. -w, --print-directory Print a message containing the working directory before and after other processing. This may be useful for tracking down errors from complicated nests of recursive make commands. --no-print-directory Turn off -w, even if it was turned on implicitly. --shuffle[=MODE] Enable shuffling of goal and prerequisite ordering. MODE is one of none to disable shuffle mode, random to shuffle prerequisites in random order, reverse to consider prerequisites in reverse order, or an integer <seed> which enables random mode with a specific seed value. If MODE is omitted the default is random. -W file, --what-if=file, --new-file=file, --assume-new=file Pretend that the target file has just been modified. When used with the -n flag, this shows you what would happen if you were to modify that file. Without -n, it is almost the same as running a touch command on the given file before running make, except that the modification time is changed only in the imagination of make. --warn-undefined-variables Warn when an undefined variable is referenced. "
  },
  {
    "command": "sed",
    "description": " The sed utility is a stream editor that shall read one or more text files, make editing changes according to a script of editing commands, and write the results to standard output. The script shall be obtained from either the script operand string or a combination of the option-arguments from the -e script and -f script_file options. The sed utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except that the order of presentation of the -e and -f options is significant. The following options shall be supported: -e script Add the editing commands specified by the script option-argument to the end of the script of editing commands. -f script_file Add the editing commands in the file script_file to the end of the script of editing commands. -n Suppress the default output (in which each line, after it is examined for editing, is written to standard output). Only lines explicitly selected for output are written. If any -e or -f options are specified, the script of editing commands shall initially be empty. The commands specified by each -e or -f option shall be added to the script in the order specified. When each addition is made, if the previous addition (if any) was from a -e option, a <newline> shall be inserted before the new addition. The resulting script shall have the same properties as the script operand, described in the OPERANDS section. "
  },
  {
    "command": "dash",
    "description": " dash is the standard command interpreter for the system. The current version of dash is in the process of being changed to conform with the POSIX 1003.2 and 1003.2a specifications for the shell. This version has many features which make it appear similar in some respects to the Korn shell, but it is not a Korn shell clone (see ksh(1)). Only features designated by POSIX, plus a few Berkeley extensions, are being incorporated into this shell. This man page is not intended to be a tutorial or a complete specification of the shell. Overview The shell is a command that reads lines from either a file or the terminal, interprets them, and generally executes other commands. It is the program that is running when a user logs into the system (although a user can select a different shell with the chsh(1) command). The shell implements a language that has flow control constructs, a macro facility that provides a variety of features in addition to data storage, along with built in history and line editing capabilities. It incorporates many features to aid interactive use and has the advantage that the interpretative language is common to both interactive and non-interactive use (shell scripts). That is, commands can be typed directly to the running shell or can be put into a file and the file can be executed directly by the shell. Invocation If no args are present and if the standard input of the shell is connected to a terminal (or if the -i flag is set), and the -c option is not present, the shell is considered an interactive shell. An interactive shell generally prompts before each command and handles programming and command errors differently (as described below). When first starting, the shell inspects argument 0, and if it begins with a dash \u2018-\u2019, the shell is also considered a login shell. This is normally done automatically by the system when the user first logs in. A login shell first reads commands from the files /etc/profile and .profile if they exist. If the environment variable ENV is set on entry to an interactive shell, or is set in the .profile of a login shell, the shell next reads commands from the file named in ENV. Therefore, a user should place commands that are to be executed only at login time in the .profile file, and commands that are executed for every interactive shell inside the ENV file. To set the ENV variable to some file, place the following line in your .profile of your home directory ENV=$HOME/.shinit; export ENV substituting for \u201c.shinit\u201d any filename you wish. If command line arguments besides the options have been specified, then the shell treats the first argument as the name of a file from which to read commands (a shell script), and the remaining arguments are set as the positional parameters of the shell ($1, $2, etc). Otherwise, the shell reads commands from its standard input. Argument List Processing All of the single letter options that have a corresponding name can be used as an argument to the -o option. The set -o name is provided next to the single letter option in the description below. Specifying a dash \u201c-\u201d turns the option on, while using a plus \u201c+\u201d disables the option. The following options can be set from the command line or with the set builtin (described later). -a allexport Export all variables assigned to. -c Read commands from the command_string operand instead of from the standard input. Special parameter 0 will be set from the command_name operand and the positional parameters ($1, $2, etc.) set from the remaining argument operands. -C noclobber Don't overwrite existing files with \u201c>\u201d. -e errexit If not interactive, exit immediately if any untested command fails. The exit status of a command is considered to be explicitly tested if the command is used to control an if, elif, while, or until; or if the command is the left hand operand of an \u201c&&\u201d or \u201c||\u201d operator. -f noglob Disable pathname expansion. -n noexec If not interactive, read commands but do not execute them. This is useful for checking the syntax of shell scripts. -u nounset Write a message to standard error when attempting to expand a variable that is not set, and if the shell is not interactive, exit immediately. -v verbose The shell writes its input to standard error as it is read. Useful for debugging. -x xtrace Write each command to standard error (preceded by a \u2018+ \u2019) before it is executed. Useful for debugging. -I ignoreeof Ignore EOF's from input when interactive. -i interactive Force the shell to behave interactively. -l Make dash act as if it had been invoked as a login shell. -m monitor Turn on job control (set automatically when interactive). -s stdin Read commands from standard input (set automatically if no file arguments are present). This option has no effect when set after the shell has already started running (i.e. with set). -V vi Enable the built-in vi(1) command line editor (disables -E if it has been set). -E emacs Enable the built-in emacs(1) command line editor (disables -V if it has been set). -b notify Enable asynchronous notification of background job completion. (UNIMPLEMENTED for 4.4alpha) Lexical Structure The shell reads input in terms of lines from a file and breaks it up into words at whitespace (blanks and tabs), and at certain sequences of characters that are special to the shell called \u201coperators\u201d. There are two types of operators: control operators and redirection operators (their meaning is discussed later). Following is a list of operators: Control operators: & && ( ) ; ;; | || <newline> Redirection operators: < > >| << >> <& >& <<- <> Quoting Quoting is used to remove the special meaning of certain characters or words to the shell, such as operators, whitespace, or keywords. There are three types of quoting: matched single quotes, matched double quotes, and backslash. Backslash A backslash preserves the literal meaning of the following character, with the exception of \u27e8newline\u27e9. A backslash preceding a \u27e8newline\u27e9 is treated as a line continuation. Single Quotes Enclosing characters in single quotes preserves the literal meaning of all the characters (except single quotes, making it impossible to put single-quotes in a single-quoted string). Double Quotes Enclosing characters within double quotes preserves the literal meaning of all characters except dollarsign ($), backquote (`), and backslash (\\). The backslash inside double quotes is historically weird, and serves to quote only the following characters: $ ` \" \\ <newline>. Otherwise it remains literal. Reserved Words Reserved words are words that have special meaning to the shell and are recognized at the beginning of a line and after a control operator. The following are reserved words: ! elif fi while case else for then { } do done until if esac Their meaning is discussed later. Aliases An alias is a name and corresponding value set using the alias(1) builtin command. Whenever a reserved word may occur (see above), and after checking for reserved words, the shell checks the word to see if it matches an alias. If it does, it replaces it in the input stream with its value. For example, if there is an alias called \u201clf\u201d with the value \u201cls -F\u201d, then the input: lf foobar \u27e8return\u27e9 would become ls -F foobar \u27e8return\u27e9 Aliases provide a convenient way for naive users to create shorthands for commands without having to learn how to create functions with arguments. They can also be used to create lexically obscure code. This use is discouraged. Commands The shell interprets the words it reads according to a language, the specification of which is outside the scope of this man page (refer to the BNF in the POSIX 1003.2 document). Essentially though, a line is read and if the first word of the line (or after a control operator) is not a reserved word, then the shell has recognized a simple command. Otherwise, a complex command or some other special construct may have been recognized. Simple Commands If a simple command has been recognized, the shell performs the following actions: 1. Leading words of the form \u201cname=value\u201d are stripped off and assigned to the environment of the simple command. Redirection operators and their arguments (as described below) are stripped off and saved for processing. 2. The remaining words are expanded as described in the section called \u201cExpansions\u201d, and the first remaining word is considered the command name and the command is located. The remaining words are considered the arguments of the command. If no command name resulted, then the \u201cname=value\u201d variable assignments recognized in item 1 affect the current shell. 3. Redirections are performed as described in the next section. Redirections Redirections are used to change where a command reads its input or sends its output. In general, redirections open, close, or duplicate an existing reference to a file. The overall format used for redirection is: [n] redir-op file where redir-op is one of the redirection operators mentioned previously. Following is a list of the possible redirections. The [n] is an optional number between 0 and 9, as in \u20183\u2019 (not \u2018[3]\u2019), that refers to a file descriptor. [n]> file Redirect standard output (or n) to file. [n]>| file Same, but override the -C option. [n]>> file Append standard output (or n) to file. [n]< file Redirect standard input (or n) from file. [n1]<&n2 Copy file descriptor n2 as stdout (or fd n1). fd n2. [n]<&- Close standard input (or n). [n1]>&n2 Copy file descriptor n2 as stdin (or fd n1). fd n2. [n]>&- Close standard output (or n). [n]<> file Open file for reading and writing on standard input (or n). The following redirection is often called a \u201chere-document\u201d. [n]<< delimiter here-doc-text ... delimiter All the text on successive lines up to the delimiter is saved away and made available to the command on standard input, or file descriptor n if it is specified. If the delimiter as specified on the initial line is quoted, then the here-doc-text is treated literally, otherwise the text is subjected to parameter expansion, command substitution, and arithmetic expansion (as described in the section on \u201cExpansions\u201d). If the operator is \u201c<<-\u201d instead of \u201c<<\u201d, then leading tabs in the here-doc-text are stripped. Search and Execution There are three types of commands: shell functions, builtin commands, and normal programs \u2013 and the command is searched for (by name) in that order. They each are executed in a different way. When a shell function is executed, all of the shell positional parameters (except $0, which remains unchanged) are set to the arguments of the shell function. The variables which are explicitly placed in the environment of the command (by placing assignments to them before the function name) are made local to the function and are set to the values given. Then the command given in the function definition is executed. The positional parameters are restored to their original values when the command completes. This all occurs within the current shell. Shell builtins are executed internally to the shell, without spawning a new process. Otherwise, if the command name doesn't match a function or builtin, the command is searched for as a normal program in the file system (as described in the next section). When a normal program is executed, the shell runs the program, passing the arguments and the environment to the program. If the program is not a normal executable file (i.e., if it does not begin with the \"magic number\" whose ASCII representation is \"#!\", so execve(2) returns ENOEXEC then) the shell will interpret the program in a subshell. The child shell will reinitialize itself in this case, so that the effect will be as if a new shell had been invoked to handle the ad- hoc shell script, except that the location of hashed commands located in the parent shell will be remembered by the child. Note that previous versions of this document and the source code itself misleadingly and sporadically refer to a shell script without a magic number as a \"shell procedure\". Path Search When locating a command, the shell first looks to see if it has a shell function by that name. Then it looks for a builtin command by that name. If a builtin command is not found, one of two things happen: 1. Command names containing a slash are simply executed without performing any searches. 2. The shell searches each entry in PATH in turn for the command. The value of the PATH variable should be a series of entries separated by colons. Each entry consists of a directory name. The current directory may be indicated implicitly by an empty directory name, or explicitly by a single period. Command Exit Status Each command has an exit status that can influence the behaviour of other shell commands. The paradigm is that a command exits with zero for normal or success, and non-zero for failure, error, or a false indication. The man page for each command should indicate the various exit codes and what they mean. Additionally, the builtin commands return exit codes, as does an executed shell function. If a command consists entirely of variable assignments then the exit status of the command is that of the last command substitution if any, otherwise 0. Complex Commands Complex commands are combinations of simple commands with control operators or reserved words, together creating a larger complex command. More generally, a command is one of the following: \u2022 simple command \u2022 pipeline \u2022 list or compound-list \u2022 compound command \u2022 function definition Unless otherwise stated, the exit status of a command is that of the last simple command executed by the command. Pipelines A pipeline is a sequence of one or more commands separated by the control operator |. The standard output of all but the last command is connected to the standard input of the next command. The standard output of the last command is inherited from the shell, as usual. The format for a pipeline is: [!] command1 [| command2 ...] The standard output of command1 is connected to the standard input of command2. The standard input, standard output, or both of a command is considered to be assigned by the pipeline before any redirection specified by redirection operators that are part of the command. If the pipeline is not in the background (discussed later), the shell waits for all commands to complete. If the reserved word ! does not precede the pipeline, the exit status is the exit status of the last command specified in the pipeline. Otherwise, the exit status is the logical NOT of the exit status of the last command. That is, if the last command returns zero, the exit status is 1; if the last command returns greater than zero, the exit status is zero. Because pipeline assignment of standard input or standard output or both takes place before redirection, it can be modified by redirection. For example: $ command1 2>&1 | command2 sends both the standard output and standard error of command1 to the standard input of command2. A ; or \u27e8newline\u27e9 terminator causes the preceding AND-OR-list (described next) to be executed sequentially; a & causes asynchronous execution of the preceding AND-OR-list. Note that unlike some other shells, each process in the pipeline is a child of the invoking shell (unless it is a shell builtin, in which case it executes in the current shell \u2013 but any effect it has on the environment is wiped). Background Commands \u2013 & If a command is terminated by the control operator ampersand (&), the shell executes the command asynchronously \u2013 that is, the shell does not wait for the command to finish before executing the next command. The format for running a command in background is: command1 & [command2 & ...] If the shell is not interactive, the standard input of an asynchronous command is set to /dev/null. Lists \u2013 Generally Speaking A list is a sequence of zero or more commands separated by newlines, semicolons, or ampersands, and optionally terminated by one of these three characters. The commands in a list are executed in the order they are written. If command is followed by an ampersand, the shell starts the command and immediately proceeds onto the next command; otherwise it waits for the command to terminate before proceeding to the next one. Short-Circuit List Operators \u201c&&\u201d and \u201c||\u201d are AND-OR list operators. \u201c&&\u201d executes the first command, and then executes the second command if and only if the exit status of the first command is zero. \u201c||\u201d is similar, but executes the second command if and only if the exit status of the first command is nonzero. \u201c&&\u201d and \u201c||\u201d both have the same priority. Flow-Control Constructs \u2013 if, while, for, case The syntax of the if command is if list then list [ elif list then list ] ... [ else list ] fi The syntax of the while command is while list do list done The two lists are executed repeatedly while the exit status of the first list is zero. The until command is similar, but has the word until in place of while, which causes it to repeat until the exit status of the first list is zero. The syntax of the for command is for variable [ in [ word ... ] ] do list done The words following in are expanded, and then the list is executed repeatedly with the variable set to each word in turn. Omitting in word ... is equivalent to in \"$@\". The syntax of the break and continue command is break [ num ] continue [ num ] Break terminates the num innermost for or while loops. Continue continues with the next iteration of the innermost loop. These are implemented as builtin commands. The syntax of the case command is case word in [(]pattern) list ;; ... esac The pattern can actually be one or more patterns (see Shell Patterns described later), separated by \u201c|\u201d characters. The \u201c(\u201d character before the pattern is optional. Grouping Commands Together Commands may be grouped by writing either (list) or { list; } The first of these executes the commands in a subshell. Builtin commands grouped into a (list) will not affect the current shell. The second form does not fork another shell so is slightly more efficient. Grouping commands together this way allows you to redirect their output as though they were one program: { printf \" hello \" ; printf \" world\\n\" ; } > greeting Note that \u201c}\u201d must follow a control operator (here, \u201c;\u201d) so that it is recognized as a reserved word and not as another command argument. Functions The syntax of a function definition is name () command A function definition is an executable statement; when executed it installs a function named name and returns an exit status of zero. The command is normally a list enclosed between \u201c{\u201d and \u201c}\u201d. Variables may be declared to be local to a function by using a local command. This should appear as the first statement of a function, and the syntax is local [variable | -] ... Local is implemented as a builtin command. When a variable is made local, it inherits the initial value and exported and readonly flags from the variable with the same name in the surrounding scope, if there is one. Otherwise, the variable is initially unset. The shell uses dynamic scoping, so that if you make the variable x local to function f, which then calls function g, references to the variable x made inside g will refer to the variable x declared inside f, not to the global variable named x. The only special parameter that can be made local is \u201c-\u201d. Making \u201c-\u201d local any shell options that are changed via the set command inside the function to be restored to their original values when the function returns. The syntax of the return command is return [exitstatus] It terminates the currently executing function. Return is implemented as a builtin command. Variables and Parameters The shell maintains a set of parameters. A parameter denoted by a name is called a variable. When starting up, the shell turns all the environment variables into shell variables. New variables can be set using the form name=value Variables set by the user must have a name consisting solely of alphabetics, numerics, and underscores - the first of which must not be numeric. A parameter can also be denoted by a number or a special character as explained below. Positional Parameters A positional parameter is a parameter denoted by a number (n > 0). The shell sets these initially to the values of its command line arguments that follow the name of the shell script. The set builtin can also be used to set or reset them. Special Parameters A special parameter is a parameter denoted by one of the following special characters. The value of the parameter is listed next to its character. * Expands to the positional parameters, starting from one. When the expansion occurs within a double-quoted string it expands to a single field with the value of each parameter separated by the first character of the IFS variable, or by a \u27e8space\u27e9 if IFS is unset. @ Expands to the positional parameters, starting from one. When the expansion occurs within double-quotes, each positional parameter expands as a separate argument. If there are no positional parameters, the expansion of @ generates zero arguments, even when @ is double-quoted. What this basically means, for example, is if $1 is \u201cabc\u201d and $2 is \u201cdef ghi\u201d, then \"$@\" expands to the two arguments: \"abc\" \"def ghi\" # Expands to the number of positional parameters. ? Expands to the exit status of the most recent pipeline. - (Hyphen.) Expands to the current option flags (the single-letter option names concatenated into a string) as specified on invocation, by the set builtin command, or implicitly by the shell. $ Expands to the process ID of the invoked shell. A subshell retains the same value of $ as its parent. ! Expands to the process ID of the most recent background command executed from the current shell. For a pipeline, the process ID is that of the last command in the pipeline. 0 (Zero.) Expands to the name of the shell or shell script. Word Expansions This clause describes the various expansions that are performed on words. Not all expansions are performed on every word, as explained later. Tilde expansions, parameter expansions, command substitutions, arithmetic expansions, and quote removals that occur within a single word expand to a single field. It is only field splitting or pathname expansion that can create multiple fields from a single word. The single exception to this rule is the expansion of the special parameter @ within double-quotes, as was described above. The order of word expansion is: 1. Tilde Expansion, Parameter Expansion, Command Substitution, Arithmetic Expansion (these all occur at the same time). 2. Field Splitting is performed on fields generated by step (1) unless the IFS variable is null. 3. Pathname Expansion (unless set -f is in effect). 4. Quote Removal. The $ character is used to introduce parameter expansion, command substitution, or arithmetic evaluation. Tilde Expansion (substituting a user's home directory) A word beginning with an unquoted tilde character (~) is subjected to tilde expansion. All the characters up to a slash (/) or the end of the word are treated as a username and are replaced with the user's home directory. If the username is missing (as in ~/foobar), the tilde is replaced with the value of the HOME variable (the current user's home directory). Parameter Expansion The format for parameter expansion is as follows: ${expression} where expression consists of all characters until the matching \u201c}\u201d. Any \u201c}\u201d escaped by a backslash or within a quoted string, and characters in embedded arithmetic expansions, command substitutions, and variable expansions, are not examined in determining the matching \u201c}\u201d. The simplest form for parameter expansion is: ${parameter} The value, if any, of parameter is substituted. The parameter name or symbol can be enclosed in braces, which are optional except for positional parameters with more than one digit or when parameter is followed by a character that could be interpreted as part of the name. If a parameter expansion occurs inside double-quotes: 1. Pathname expansion is not performed on the results of the expansion. 2. Field splitting is not performed on the results of the expansion, with the exception of @. In addition, a parameter expansion can be modified by using one of the following formats. ${parameter:-word} Use Default Values. If parameter is unset or null, the expansion of word is substituted; otherwise, the value of parameter is substituted. ${parameter:=word} Assign Default Values. If parameter is unset or null, the expansion of word is assigned to parameter. In all cases, the final value of parameter is substituted. Only variables, not positional parameters or special parameters, can be assigned in this way. ${parameter:?[word]} Indicate Error if Null or Unset. If parameter is unset or null, the expansion of word (or a message indicating it is unset if word is omitted) is written to standard error and the shell exits with a nonzero exit status. Otherwise, the value of parameter is substituted. An interactive shell need not exit. ${parameter:+word} Use Alternative Value. If parameter is unset or null, null is substituted; otherwise, the expansion of word is substituted. In the parameter expansions shown previously, use of the colon in the format results in a test for a parameter that is unset or null; omission of the colon results in a test for a parameter that is only unset. ${#parameter} String Length. The length in characters of the value of parameter. The following four varieties of parameter expansion provide for substring processing. In each case, pattern matching notation (see Shell Patterns), rather than regular expression notation, is used to evaluate the patterns. If parameter is * or @, the result of the expansion is unspecified. Enclosing the full parameter expansion string in double-quotes does not cause the following four varieties of pattern characters to be quoted, whereas quoting characters within the braces has this effect. ${parameter%word} Remove Smallest Suffix Pattern. The word is expanded to produce a pattern. The parameter expansion then results in parameter, with the smallest portion of the suffix matched by the pattern deleted. ${parameter%%word} Remove Largest Suffix Pattern. The word is expanded to produce a pattern. The parameter expansion then results in parameter, with the largest portion of the suffix matched by the pattern deleted. ${parameter#word} Remove Smallest Prefix Pattern. The word is expanded to produce a pattern. The parameter expansion then results in parameter, with the smallest portion of the prefix matched by the pattern deleted. ${parameter "
  },
  {
    "command": "ex",
    "description": " The ex utility is a line-oriented text editor. There are two other modes of the editor\u2014open and visual\u2014in which screen- oriented editing is available. This is described more fully by the ex open and visual commands and in vi(1p). If an operand is '-', the results are unspecified. This section uses the term edit buffer to describe the current working text. No specific implementation is implied by this term. All editing changes are performed on the edit buffer, and no changes to it shall affect any file until an editor command writes the file. Certain terminals do not have all the capabilities necessary to support the complete ex definition, such as the full-screen editing commands (visual mode or open mode). When these commands cannot be supported on such terminals, this condition shall not produce an error message such as ``not an editor command'' or report a syntax error. The implementation may either accept the commands and produce results on the screen that are the result of an unsuccessful attempt to meet the requirements of this volume of POSIX.1\u20102017 or report an error describing the terminal- related deficiency. The ex utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for the unspecified usage of '-', and that '+' may be recognized as an option delimiter as well as '-'. The following options shall be supported: -c command Specify an initial command to be executed in the first edit buffer loaded from an existing file (see the EXTENDED DESCRIPTION section). Implementations may support more than a single -c option. In such implementations, the specified commands shall be executed in the order specified on the command line. -r Recover the named files (see the EXTENDED DESCRIPTION section). Recovery information for a file shall be saved during an editor or system crash (for example, when the editor is terminated by a signal which the editor can catch), or after the use of an ex preserve command. A crash in this context is an unexpected failure of the system or utility that requires restarting the failed system or utility. A system crash implies that any utilities running at the time also crash. In the case of an editor or system crash, the number of changes to the edit buffer (since the most recent preserve command) that will be recovered is unspecified. If no file operands are given and the -t option is not specified, all other options, the EXINIT variable, and any .exrc files shall be ignored; a list of all recoverable files available to the invoking user shall be written, and the editor shall exit normally without further action. -R Set readonly edit option. -s Prepare ex for batch use by taking the following actions: * Suppress writing prompts and informational (but not diagnostic) messages. * Ignore the value of TERM and any implementation default terminal type and assume the terminal is a type incapable of supporting open or visual modes; see the visual command and the description of vi(1p). * Suppress the use of the EXINIT environment variable and the reading of any .exrc file; see the EXTENDED DESCRIPTION section. * Suppress autoindentation, ignoring the value of the autoindent edit option. -t tagstring Edit the file containing the specified tagstring; see ctags(1p). The tags feature represented by -t tagstring and the tag command is optional. It shall be provided on any system that also provides a conforming implementation of ctags; otherwise, the use of -t produces undefined results. On any system, it shall be an error to specify more than a single -t option. -v Begin in visual mode (see vi(1p)). -w size Set the value of the window editor option to size. "
  },
  {
    "command": "time",
    "description": " The time utility shall invoke the utility named by the utility operand with arguments supplied as the argument operands and write a message to standard error that lists timing statistics for the utility. The message shall include the following information: * The elapsed (real) time between invocation of utility and its termination. * The User CPU time, equivalent to the sum of the tms_utime and tms_cutime fields returned by the times() function defined in the System Interfaces volume of POSIX.1\u20102017 for the process in which utility is executed. * The System CPU time, equivalent to the sum of the tms_stime and tms_cstime fields returned by the times() function for the process in which utility is executed. The precision of the timing shall be no less than the granularity defined for the size of the clock tick unit on the system, but the results shall be reported in terms of standard time units (for example, 0.02 seconds, 00:00:00.02, 1m33.75s, 365.21 seconds), not numbers of clock ticks. When time is used as part of a pipeline, the times reported are unspecified, except when it is the sole command within a grouping command (see Section 2.9.4.1, Grouping Commands) in that pipeline. For example, the commands on the left are unspecified; those on the right report on utilities a and c, respectively: time a | b | c { time a; } | b | c a | b | time c a | b | (time c) The time utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -p Write the timing output to standard error in the format shown in the STDERR section. "
  },
  {
    "command": "printf",
    "description": " The printf utility shall write formatted operands to the standard output. The argument operands shall be formatted under control of the format operand. None. "
  },
  {
    "command": "pwd",
    "description": " The pwd utility shall write to standard output an absolute pathname of the current working directory, which does not contain the filenames dot or dot-dot. The pwd utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported by the implementation: -L If the PWD environment variable contains an absolute pathname of the current directory and the pathname does not contain any components that are dot or dot-dot, pwd shall write this pathname to standard output, except that if the PWD environment variable is longer than {PATH_MAX} bytes including the terminating null, it is unspecified whether pwd writes this pathname to standard output or behaves as if the -P option had been specified. Otherwise, the -L option shall behave as the -P option. -P The pathname written to standard output shall not contain any components that refer to files of type symbolic link. If there are multiple pathnames that the pwd utility could write to standard output, one beginning with a single <slash> character and one or more beginning with two <slash> characters, then it shall write the pathname beginning with a single <slash> character. The pathname shall not contain any unnecessary <slash> characters after the leading one or two <slash> characters. If both -L and -P are specified, the last one shall apply. If neither -L nor -P is specified, the pwd utility shall behave as if -L had been specified. "
  },
  {
    "command": "loadkeys",
    "description": " The program loadkeys reads the file or files specified by FILENAME.... Its main purpose is to load the kernel keymap for the console. You can specify console device by the -C (or --console ) option. "
  },
  {
    "command": "env",
    "description": " Set each NAME to VALUE in the environment and run COMMAND. Mandatory arguments to long options are mandatory for short options too. -i, --ignore-environment start with an empty environment -0, --null end each output line with NUL, not newline -u, --unset=NAME remove variable from the environment -C, --chdir=DIR change working directory to DIR -S, --split-string=S process and split S into separate arguments; used to pass multiple arguments on shebang lines --block-signal[=SIG] block delivery of SIG signal(s) to COMMAND --default-signal[=SIG] reset handling of SIG signal(s) to the default --ignore-signal[=SIG] set handling of SIG signal(s) to do nothing --list-signal-handling list non default signal handling to stderr -v, --debug print verbose information for each processing step --help display this help and exit --version output version information and exit A mere - implies -i. If no COMMAND, print the resulting environment. SIG may be a signal name like 'PIPE', or a signal number like '13'. Without SIG, all known signals are included. Multiple signals can be comma-separated. An empty SIG argument is a no-op. Exit status: 125 if the env command itself fails 126 if COMMAND is found but cannot be invoked 127 if COMMAND cannot be found - the exit status of COMMAND otherwise -S/--split-string usage in scripts The -S option allows specifying multiple parameters in a script. Running a script named 1.pl containing the following first line: #!/usr/bin/env -S perl -w -T ... Will execute perl -w -T 1.pl . Without the '-S' parameter the script will likely fail with: /usr/bin/env: 'perl -w -T': No such file or directory See the full documentation for more details. --default-signal[=SIG] usage This option allows setting a signal handler to its default action, which is not possible using the traditional shell trap command. The following example ensures that seq will be terminated by SIGPIPE no matter how this signal is being handled in the process invoking the command. sh -c 'env --default-signal=PIPE seq inf | head -n1' "
  },
  {
    "command": "look",
    "description": " The look utility displays any lines in file which contain string as a prefix. As look performs a binary search, the lines in file must be sorted (where sort(1) was given the same options -d and/or -f that look is invoked with). If file is not specified, the file /usr/share/dict/words is used, only alphanumeric characters are compared and the case of alphabetic characters is ignored. -a, --alternative Use the alternative dictionary file. -d, --alphanum Use normal dictionary character set and order, i.e., only blanks and alphanumeric characters are compared. This is on by default if no file is specified. Note that blanks have been added to dictionary character set for compatibility with sort -d command since version 2.28. -f, --ignore-case Ignore the case of alphabetic characters. This is on by default if no file is specified. -t, --terminate character Specify a string termination character, i.e., only the characters in string up to and including the first occurrence of character are compared. -h, --help Display help text and exit. -V, --version Print version and exit. The look utility exits 0 if one or more lines were found and displayed, 1 if no lines were found, and >1 if an error occurred. "
  },
  {
    "command": "fgrep",
    "description": " grep searches for PATTERNS in each FILE. PATTERNS is one or more patterns separated by newline characters, and grep prints each line that matches a pattern. Typically PATTERNS should be quoted when grep is used in a shell command. A FILE of \u201c-\u201d stands for standard input. If no FILE is given, recursive searches examine the working directory, and nonrecursive searches read standard input. Generic Program Information --help Output a usage message and exit. -V, --version Output the version number of grep and exit. Pattern Syntax -E, --extended-regexp Interpret PATTERNS as extended regular expressions (EREs, see below). -F, --fixed-strings Interpret PATTERNS as fixed strings, not regular expressions. -G, --basic-regexp Interpret PATTERNS as basic regular expressions (BREs, see below). This is the default. -P, --perl-regexp Interpret PATTERNS as Perl-compatible regular expressions (PCREs). This option is experimental when combined with the -z (--null-data) option, and grep -P may warn of unimplemented features. Matching Control -e PATTERNS, --regexp=PATTERNS Use PATTERNS as the patterns. If this option is used multiple times or is combined with the -f (--file) option, search for all patterns given. This option can be used to protect a pattern beginning with \u201c-\u201d. -f FILE, --file=FILE Obtain patterns from FILE, one per line. If this option is used multiple times or is combined with the -e (--regexp) option, search for all patterns given. The empty file contains zero patterns, and therefore matches nothing. If FILE is - , read patterns from standard input. -i, --ignore-case Ignore case distinctions in patterns and input data, so that characters that differ only in case match each other. --no-ignore-case Do not ignore case distinctions in patterns and input data. This is the default. This option is useful for passing to shell scripts that already use -i, to cancel its effects because the two options override each other. -v, --invert-match Invert the sense of matching, to select non-matching lines. -w, --word-regexp Select only those lines containing matches that form whole words. The test is that the matching substring must either be at the beginning of the line, or preceded by a non-word constituent character. Similarly, it must be either at the end of the line or followed by a non-word constituent character. Word-constituent characters are letters, digits, and the underscore. This option has no effect if -x is also specified. -x, --line-regexp Select only those matches that exactly match the whole line. For a regular expression pattern, this is like parenthesizing the pattern and then surrounding it with ^ and $. General Output Control -c, --count Suppress normal output; instead print a count of matching lines for each input file. With the -v, --invert-match option (see above), count non-matching lines. --color[=WHEN], --colour[=WHEN] Surround the matched (non-empty) strings, matching lines, context lines, file names, line numbers, byte offsets, and separators (for fields and groups of context lines) with escape sequences to display them in color on the terminal. The colors are defined by the environment variable GREP_COLORS. WHEN is never, always, or auto. -L, --files-without-match Suppress normal output; instead print the name of each input file from which no output would normally have been printed. -l, --files-with-matches Suppress normal output; instead print the name of each input file from which output would normally have been printed. Scanning each input file stops upon first match. -m NUM, --max-count=NUM Stop reading a file after NUM matching lines. If NUM is zero, grep stops right away without reading input. A NUM of -1 is treated as infinity and grep does not stop; this is the default. If the input is standard input from a regular file, and NUM matching lines are output, grep ensures that the standard input is positioned to just after the last matching line before exiting, regardless of the presence of trailing context lines. This enables a calling process to resume a search. When grep stops after NUM matching lines, it outputs any trailing context lines. When the -c or --count option is also used, grep does not output a count greater than NUM. When the -v or --invert-match option is also used, grep stops after outputting NUM non-matching lines. -o, --only-matching Print only the matched (non-empty) parts of a matching line, with each such part on a separate output line. -q, --quiet, --silent Quiet; do not write anything to standard output. Exit immediately with zero status if any match is found, even if an error was detected. Also see the -s or --no-messages option. -s, --no-messages Suppress error messages about nonexistent or unreadable files. Output Line Prefix Control -b, --byte-offset Print the 0-based byte offset within the input file before each line of output. If -o (--only-matching) is specified, print the offset of the matching part itself. -H, --with-filename Print the file name for each match. This is the default when there is more than one file to search. This is a GNU extension. -h, --no-filename Suppress the prefixing of file names on output. This is the default when there is only one file (or only standard input) to search. --label=LABEL Display input actually coming from standard input as input coming from file LABEL. This can be useful for commands that transform a file's contents before searching, e.g., gzip -cd foo.gz | grep --label=foo -H 'some pattern'. See also the -H option. -n, --line-number Prefix each line of output with the 1-based line number within its input file. -T, --initial-tab Make sure that the first character of actual line content lies on a tab stop, so that the alignment of tabs looks normal. This is useful with options that prefix their output to the actual content: -H,-n, and -b. In order to improve the probability that lines from a single file will all start at the same column, this also causes the line number and byte offset (if present) to be printed in a minimum size field width. -Z, --null Output a zero byte (the ASCII NUL character) instead of the character that normally follows a file name. For example, grep -lZ outputs a zero byte after each file name instead of the usual newline. This option makes the output unambiguous, even in the presence of file names containing unusual characters like newlines. This option can be used with commands like find -print0, perl -0, sort -z, and xargs -0 to process arbitrary file names, even those that contain newline characters. Context Line Control -A NUM, --after-context=NUM Print NUM lines of trailing context after matching lines. Places a line containing a group separator (--) between contiguous groups of matches. With the -o or --only-matching option, this has no effect and a warning is given. -B NUM, --before-context=NUM Print NUM lines of leading context before matching lines. Places a line containing a group separator (--) between contiguous groups of matches. With the -o or --only-matching option, this has no effect and a warning is given. -C NUM, -NUM, --context=NUM Print NUM lines of output context. Places a line containing a group separator (--) between contiguous groups of matches. With the -o or --only-matching option, this has no effect and a warning is given. --group-separator=SEP When -A, -B, or -C are in use, print SEP instead of -- between groups of lines. --no-group-separator When -A, -B, or -C are in use, do not print a separator between groups of lines. File and Directory Selection -a, --text Process a binary file as if it were text; this is equivalent to the --binary-files=text option. --binary-files=TYPE If a file's data or metadata indicate that the file contains binary data, assume that the file is of type TYPE. Non-text bytes indicate binary data; these are either output bytes that are improperly encoded for the current locale, or null input bytes when the -z option is not given. By default, TYPE is binary, and grep suppresses output after null input binary data is discovered, and suppresses output lines that contain improperly encoded data. When some output is suppressed, grep follows any output with a message to standard error saying that a binary file matches. If TYPE is without-match, when grep discovers null input binary data it assumes that the rest of the file does not match; this is equivalent to the -I option. If TYPE is text, grep processes a binary file as if it were text; this is equivalent to the -a option. When type is binary, grep may treat non-text bytes as line terminators even without the -z option. This means choosing binary versus text can affect whether a pattern matches a file. For example, when type is binary the pattern q$ might match q immediately followed by a null byte, even though this is not matched when type is text. Conversely, when type is binary the pattern . (period) might not match a null byte. Warning: The -a option might output binary garbage, which can have nasty side effects if the output is a terminal and if the terminal driver interprets some of it as commands. On the other hand, when reading files whose text encodings are unknown, it can be helpful to use -a or to set LC_ALL='C' in the environment, in order to find more matches even if the matches are unsafe for direct display. -D ACTION, --devices=ACTION If an input file is a device, FIFO or socket, use ACTION to process it. By default, ACTION is read, which means that devices are read just as if they were ordinary files. If ACTION is skip, devices are silently skipped. -d ACTION, --directories=ACTION If an input file is a directory, use ACTION to process it. By default, ACTION is read, i.e., read directories just as if they were ordinary files. If ACTION is skip, silently skip directories. If ACTION is recurse, read all files under each directory, recursively, following symbolic links only if they are on the command line. This is equivalent to the -r option. --exclude=GLOB Skip any command-line file with a name suffix that matches the pattern GLOB, using wildcard matching; a name suffix is either the whole name, or a trailing part that starts with a non-slash character immediately after a slash (/) in the name. When searching recursively, skip any subfile whose base name matches GLOB; the base name is the part after the last slash. A pattern can use *, ?, and [...] as wildcards, and \\ to quote a wildcard or backslash character literally. --exclude-from=FILE Skip files whose base name matches any of the file-name globs read from FILE (using wildcard matching as described under --exclude). --exclude-dir=GLOB Skip any command-line directory with a name suffix that matches the pattern GLOB. When searching recursively, skip any subdirectory whose base name matches GLOB. Ignore any redundant trailing slashes in GLOB. -I Process a binary file as if it did not contain matching data; this is equivalent to the --binary-files=without-match option. --include=GLOB Search only files whose base name matches GLOB (using wildcard matching as described under --exclude). If contradictory --include and --exclude options are given, the last matching one wins. If no --include or --exclude options match, a file is included unless the first such option is --include. -r, --recursive Read all files under each directory, recursively, following symbolic links only if they are on the command line. Note that if no file operand is given, grep searches the working directory. This is equivalent to the -d recurse option. -R, --dereference-recursive Read all files under each directory, recursively. Follow all symbolic links, unlike -r. Other Options --line-buffered Use line buffering on output. This can cause a performance penalty. -U, --binary Treat the file(s) as binary. By default, under MS-DOS and MS-Windows, grep guesses whether a file is text or binary as described for the --binary-files option. If grep decides the file is a text file, it strips the CR characters from the original file contents (to make regular expressions with ^ and $ work correctly). Specifying -U overrules this guesswork, causing all files to be read and passed to the matching mechanism verbatim; if the file is a text file with CR/LF pairs at the end of each line, this will cause some regular expressions to fail. This option has no effect on platforms other than MS-DOS and MS-Windows. -z, --null-data Treat input and output data as sequences of lines, each terminated by a zero byte (the ASCII NUL character) instead of a newline. Like the -Z or --null option, this option can be used with commands like sort -z to process arbitrary file names. "
  },
  {
    "command": "df",
    "description": " This manual page documents the GNU version of df. df displays the amount of space available on the file system containing each file name argument. If no file name is given, the space available on all currently mounted file systems is shown. Space is shown in 1K blocks by default, unless the environment variable POSIXLY_CORRECT is set, in which case 512-byte blocks are used. If an argument is the absolute file name of a device node containing a mounted file system, df shows the space available on that file system rather than on the file system containing the device node. This version of df cannot show the space available on unmounted file systems, because on most kinds of systems doing so requires very nonportable intimate knowledge of file system structures. Show information about the file system on which each FILE resides, or all file systems by default. Mandatory arguments to long options are mandatory for short options too. -a, --all include pseudo, duplicate, inaccessible file systems -B, --block-size=SIZE scale sizes by SIZE before printing them; e.g., '-BM' prints sizes in units of 1,048,576 bytes; see SIZE format below -h, --human-readable print sizes in powers of 1024 (e.g., 1023M) -H, --si print sizes in powers of 1000 (e.g., 1.1G) -i, --inodes list inode information instead of block usage -k like --block-size=1K -l, --local limit listing to local file systems --no-sync do not invoke sync before getting usage info (default) --output[=FIELD_LIST] use the output format defined by FIELD_LIST, or print all fields if FIELD_LIST is omitted. -P, --portability use the POSIX output format --sync invoke sync before getting usage info --total elide all entries insignificant to available space, and produce a grand total -t, --type=TYPE limit listing to file systems of type TYPE -T, --print-type print file system type -x, --exclude-type=TYPE limit listing to file systems not of type TYPE -v (ignored) --help display this help and exit --version output version information and exit Display values are in units of the first available SIZE from --block-size, and the DF_BLOCK_SIZE, BLOCK_SIZE and BLOCKSIZE environment variables. Otherwise, units default to 1024 bytes (or 512 if POSIXLY_CORRECT is set). The SIZE argument is an integer and optional unit (example: 10K is 10*1024). Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or KB,MB,... (powers of 1000). Binary prefixes can be used, too: KiB=K, MiB=M, and so on. FIELD_LIST is a comma-separated list of columns to be included. Valid field names are: 'source', 'fstype', 'itotal', 'iused', 'iavail', 'ipcent', 'size', 'used', 'avail', 'pcent', 'file' and 'target' (see info page). "
  },
  {
    "command": "sha512sum",
    "description": " Print or check SHA512 (512-bit) checksums. With no FILE, or when FILE is -, read standard input. -b, --binary read in binary mode -c, --check read checksums from the FILEs and check them --tag create a BSD-style checksum -t, --text read in text mode (default) -z, --zero end each output line with NUL, not newline, and disable file name escaping The following five options are useful only when verifying checksums: --ignore-missing don't fail or report status for missing files --quiet don't print OK for each successfully verified file --status don't output anything, status code shows success --strict exit non-zero for improperly formatted checksum lines -w, --warn warn about improperly formatted checksum lines --help display this help and exit --version output version information and exit The sums are computed as described in FIPS-180-2. When checking, the input should be a former output of this program. The default mode is to print a line with: checksum, a space, a character indicating input mode ('*' for binary, ' ' for text or where binary is insignificant), and name for each FILE. Note: There is no difference between binary mode and text mode on GNU systems. "
  },
  {
    "command": "dpkg-deb",
    "description": " dpkg-deb packs, unpacks and provides information about Debian archives. Use dpkg to install and remove packages from your system. You can also invoke dpkg-deb by calling dpkg with whatever options you want to pass to dpkg-deb. dpkg will spot that you wanted dpkg-deb and run it for you. For most commands taking an input archive argument, the archive can be read from standard input if the archive name is given as a single minus character (\u00ab-\u00bb); otherwise lack of support will be documented in their respective command description. --showformat=format This option is used to specify the format of the output --show will produce. The format is a string that will be output for each package listed. The string may reference any status field using the \u201c${field- name}\u201d form, a list of the valid fields can be easily produced using -I on the same package. A complete explanation of the formatting options (including escape sequences and field tabbing) can be found in the explanation of the --showformat option in dpkg-query(1). The default for this field is \u201c${Package}\\t${Version}\\n\u201d. -zcompress-level Specify which compression level to use on the compressor backend, when building a package (default is 9 for gzip, 6 for xz, 3 for zstd). The accepted values are compressor specific. For gzip, from 0-9 with 0 being mapped to compressor none. For xz from 0-9. For zstd from 0-22, with levels from 20 to 22 enabling its ultra mode. Before dpkg 1.16.2 level 0 was equivalent to compressor none for all compressors. -Scompress-strategy Specify which compression strategy to use on the compressor backend, when building a package (since dpkg 1.16.2). Allowed values are none (since dpkg 1.16.4), filtered, huffman, rle and fixed for gzip (since dpkg 1.17.0) and extreme for xz. -Zcompress-type Specify which compression type to use when building a package. Allowed values are gzip, xz (since dpkg 1.15.6), zstd (since dpkg 1.21.18) and none (default is xz). --[no-]uniform-compression Specify that the same compression parameters should be used for all archive members (i.e. control.tar and data.tar; since dpkg 1.17.6). Otherwise only the data.tar member will use those parameters. The only supported compression types allowed to be uniformly used are none, gzip, xz and zstd. The --no-uniform-compression option disables uniform compression (since dpkg 1.19.0). Uniform compression is the default (since dpkg 1.19.0). --threads-max=threads Sets the maximum number of threads allowed for compressors that support multi-threaded operations (since dpkg 1.21.9). --root-owner-group Set the owner and group for each entry in the filesystem tree data to root with id 0 (since dpkg 1.19.0). Note: This option can be useful for rootless builds (see rootless-builds.txt), but should not be used when the entries have an owner or group that is not root. Support for these will be added later in the form of a meta manifest. --deb-format=format Set the archive format version used when building (since dpkg 1.17.0). Allowed values are 2.0 for the new format, and 0.939000 for the old one (default is 2.0). The old archive format is less easily parsed by non-Debian tools and is now obsolete; its only use is when building packages to be parsed by versions of dpkg older than 0.93.76 (September 1995), which was released as i386 a.out only. --nocheck Inhibits dpkg-deb --build's usual checks on the proposed contents of an archive. You can build any archive you want, no matter how broken, this way. -v, --verbose Enables verbose output (since dpkg 1.16.1). This currently only affects --extract making it behave like --vextract. -D, --debug Enables debugging output. This is not very interesting. "
  },
  {
    "command": "updatedb",
    "description": " This manual page documents the GNU version of updatedb, which updates file name databases used by GNU locate. The file name databases contain lists of files that were in particular directory trees when the databases were last updated. The file name of the default database is determined when locate and updatedb are configured and installed. The frequency with which the databases are updated and the directories for which they contain entries depend on how often updatedb is run, and with which arguments. In networked environments, it often makes sense to build a database at the root of each filesystem, containing the entries for that filesystem. updatedb is then run for each filesystem on the fileserver where that filesystem is on a local disk, to prevent thrashing the network. Users can select which databases locate searches using an environment variable or command line option; see locate(1). Databases cannot be concatenated together. The LOCATGE02 database format was introduced in GNU findutils version 4.0 in order to allow machines with different byte orderings to share the databases. GNU locate can read both the old and LOCATE02 database formats, though support for the old pre-4.0 database format will be removed shortly. --findoptions='-option1 -option2...' Global options to pass on to find. The environment variable FINDOPTIONS also sets this value. Default is none. --localpaths='path1 path2...' Non-network directories to put in the database. Default is /. --netpaths='path1 path2...' Network (NFS, AFS, RFS, etc.) directories to put in the database. The environment variable NETPATHS also sets this value. Default is none. --prunepaths='path1 path2...' Directories to not put in the database, which would otherwise be. Remove any trailing slashes from the path names, otherwise updatedb won't recognise the paths you want to omit (because it uses them as regular expression patterns). The environment variable PRUNEPATHS also sets this value. Default is /tmp /usr/tmp /var/tmp /afs. --prunefs='path...' File systems to not put in the database, which would otherwise be. Note that files are pruned when a file system is reached; any file system mounted under an undesired file system will be ignored. The environment variable PRUNEFS also sets this value. Default is nfs NFS proc. --output=dbfile The database file to build. Default is system-dependent. In Debian GNU/Linux, the default is /var/cache/locate/locatedb. --localuser=user The user to search non-network directories as, using su(1). Default is to search the non-network directories as the current user. You can also use the environment variable LOCALUSER to set this user. --netuser=user The user to search network directories as, using su(1). Default is daemon. You can also use the environment variable NETUSER to set this user. --dbformat=F Create the database in format F. The default format is called LOCATE02. Alternatively the slocate format is also supported. When the slocate format is in use, the database produced is marked as having security level 1. If you want to build a system-wide slocate database, you may want to run updatedb as root. --version Print the version number of updatedb and exit. --help Print a summary of the options to updatedb and exit. "
  },
  {
    "command": "sort",
    "description": " The sort utility shall perform one of the following functions: 1. Sort lines of all the named files together and write the result to the specified output. 2. Merge lines of all the named (presorted) files together and write the result to the specified output. 3. Check that a single input file is correctly presorted. Comparisons shall be based on one or more sort keys extracted from each line of input (or, if no sort keys are specified, the entire line up to, but not including, the terminating <newline>), and shall be performed using the collating sequence of the current locale. If this collating sequence does not have a total ordering of all characters (see the Base Definitions volume of POSIX.1\u20102017, Section 7.3.2, LC_COLLATE), any lines of input that collate equally should be further compared byte-by-byte using the collating sequence for the POSIX locale. The sort utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for Guideline 9, and the -k keydef option should follow the -b, -d, -f, -i, -n, and -r options. In addition, '+' may be recognized as an option delimiter as well as '-'. The following options shall be supported: -c Check that the single input file is ordered as specified by the arguments and the collating sequence of the current locale. Output shall not be sent to standard output. The exit code shall indicate whether or not disorder was detected or an error occurred. If disorder (or, with -u, a duplicate key) is detected, a warning message shall be sent to standard error indicating where the disorder or duplicate key was found. -C Same as -c, except that a warning message shall not be sent to standard error if disorder or, with -u, a duplicate key is detected. -m Merge only; the input file shall be assumed to be already sorted. -o output Specify the name of an output file to be used instead of the standard output. This file can be the same as one of the input files. -u Unique: suppress all but one in each set of lines having equal keys. If used with the -c option, check that there are no lines with duplicate keys, in addition to checking that the input file is sorted. The following options shall override the default ordering rules. When ordering options appear independent of any key field specifications, the requested field ordering rules shall be applied globally to all sort keys. When attached to a specific key (see -k), the specified ordering options shall override all global ordering options for that key. -d Specify that only <blank> characters and alphanumeric characters, according to the current setting of LC_CTYPE, shall be significant in comparisons. The behavior is undefined for a sort key to which -i or -n also applies. -f Consider all lowercase characters that have uppercase equivalents, according to the current setting of LC_CTYPE, to be the uppercase equivalent for the purposes of comparison. -i Ignore all characters that are non-printable, according to the current setting of LC_CTYPE. The behavior is undefined for a sort key for which -n also applies. -n Restrict the sort key to an initial numeric string, consisting of optional <blank> characters, optional <hyphen-minus> character, and zero or more digits with an optional radix character and thousands separators (as defined in the current locale), which shall be sorted by arithmetic value. An empty digit string shall be treated as zero. Leading zeros and signs on zeros shall not affect ordering. -r Reverse the sense of comparisons. The treatment of field separators can be altered using the options: -b Ignore leading <blank> characters when determining the starting and ending positions of a restricted sort key. If the -b option is specified before the first -k option, it shall be applied to all -k options. Otherwise, the -b option can be attached independently to each -k field_start or field_end option-argument (see below). -t char Use char as the field separator character; char shall not be considered to be part of a field (although it can be included in a sort key). Each occurrence of char shall be significant (for example, <char><char> delimits an empty field). If -t is not specified, <blank> characters shall be used as default field separators; each maximal non-empty sequence of <blank> characters that follows a non-<blank> shall be a field separator. Sort keys can be specified using the options: -k keydef The keydef argument is a restricted sort key field definition. The format of this definition is: field_start[type][,field_end[type]] where field_start and field_end define a key field restricted to a portion of the line (see the EXTENDED DESCRIPTION section), and type is one or more modifiers from the list of characters 'b', 'd', 'f', 'i', 'n', 'r'. The 'b' modifier shall behave like the -b option, but shall apply only to the field_start or field_end to which it is attached. The other modifiers shall behave like the corresponding options, but shall apply only to the key field to which they are attached; they shall have this effect if specified with field_start, field_end, or both. If any modifier is attached to a field_start or to a field_end, no option shall apply to either. Implementations shall support at least nine occurrences of the -k option, which shall be significant in command line order. If no -k option is specified, a default sort key of the entire line shall be used. When there are multiple key fields, later keys shall be compared only after all earlier keys compare equal. Except when the -u option is specified, lines that otherwise compare equal shall be ordered as if none of the options -d, -f, -i, -n, or -k were present (but with -r still in effect, if it was specified) and with all bytes in the lines significant to the comparison. The order in which lines that still compare equal are written is unspecified. "
  },
  {
    "command": "lex",
    "description": " The lex utility shall generate C programs to be used in lexical processing of character input, and that can be used as an interface to yacc. The C programs shall be generated from lex source code and conform to the ISO C standard, without depending on any undefined, unspecified, or implementation-defined behavior, except in cases where the code is copied directly from the supplied source, or in cases that are documented by the implementation. Usually, the lex utility shall write the program it generates to the file lex.yy.c; the state of this file is unspecified if lex exits with a non-zero exit status. See the EXTENDED DESCRIPTION section for a complete description of the lex input language. The lex utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for Guideline 9. The following options shall be supported: -n Suppress the summary of statistics usually written with the -v option. If no table sizes are specified in the lex source code and the -v option is not specified, then -n is implied. -t Write the resulting program to standard output instead of lex.yy.c. -v Write a summary of lex statistics to the standard output. (See the discussion of lex table sizes in Definitions in lex.) If the -t option is specified and -n is not specified, this report shall be written to standard error. If table sizes are specified in the lex source code, and if the -n option is not specified, the -v option may be enabled. "
  },
  {
    "command": "ulimit",
    "description": " The ulimit utility shall set or report the file-size writing limit imposed on files written by the shell and its child processes (files of any size may be read). Only a process with appropriate privileges can increase the limit. The ulimit utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -f Set (or report, if no blocks operand is present), the file size limit in blocks. The -f option shall also be the default case. "
  },
  {
    "command": "chfn",
    "description": " chfn is used to change your finger information. This information is stored in the /etc/passwd file, and is displayed by the finger program. The Linux finger command will display four pieces of information that can be changed by chfn: your real name, your work room and phone, and your home phone. Any of the four pieces of information can be specified on the command line. If no information is given on the command line, chfn enters interactive mode. In interactive mode, chfn will prompt for each field. At a prompt, you can enter the new information, or just press return to leave the field unchanged. Enter the keyword \"none\" to make the field blank. chfn supports non-local entries (kerberos, LDAP, etc.) if linked with libuser, otherwise use ypchfn(1), lchfn(1) or any other implementation for non-local entries. -f, --full-name full-name Specify your real name. -o, --office office Specify your office room number. -p, --office-phone office-phone Specify your office phone number. -h, --home-phone home-phone Specify your home phone number. -u, --help Display help text and exit. -V, --version Print version and exit. The short options -V have been used since version 2.39; old versions use deprecated -v. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "nice",
    "description": " Run COMMAND with an adjusted niceness, which affects process scheduling. With no COMMAND, print the current niceness. Niceness values range from -20 (most favorable to the process) to 19 (least favorable to the process). Mandatory arguments to long options are mandatory for short options too. -n, --adjustment=N add integer N to the niceness (default 10) --help display this help and exit --version output version information and exit NOTE: your shell may have its own version of nice, which usually supersedes the version described here. Please refer to your shell's documentation for details about the options it supports. Exit status: 125 if the nice command itself fails 126 if COMMAND is found but cannot be invoked 127 if COMMAND cannot be found - the exit status of COMMAND otherwise "
  },
  {
    "command": "tail",
    "description": " The tail utility shall copy its input file to the standard output beginning at a designated place. Copying shall begin at the point in the file indicated by the -c number or -n number options. The option-argument number shall be counted in units of lines or bytes, according to the options -n and -c. Both line and byte counts start from 1. Tails relative to the end of the file may be saved in an internal buffer, and thus may be limited in length. Such a buffer, if any, shall be no smaller than {LINE_MAX}*10 bytes. The tail utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except that '+' may be recognized as an option delimiter as well as '-'. The following options shall be supported: -c number The application shall ensure that the number option- argument is a decimal integer, optionally including a sign. The sign shall affect the location in the file, measured in bytes, to begin the copying: \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502Sign \u2502 Copying Starts \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 + \u2502 Relative to the beginning of the file. \u2502 \u2502 - \u2502 Relative to the end of the file. \u2502 \u2502none \u2502 Relative to the end of the file. \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 The application shall ensure that if the sign of the number option-argument is '+', the number option- argument is a non-zero decimal integer. The origin for counting shall be 1; that is, -c +1 represents the first byte of the file, -c -1 the last. -f If the input file is a regular file or if the file operand specifies a FIFO, do not terminate after the last line of the input file has been copied, but read and copy further bytes from the input file when they become available. If no file operand is specified and standard input is a pipe or FIFO, the -f option shall be ignored. If the input file is not a FIFO, pipe, or regular file, it is unspecified whether or not the -f option shall be ignored. -n number This option shall be equivalent to -c number, except the starting location in the file shall be measured in lines instead of bytes. The origin for counting shall be 1; that is, -n +1 represents the first line of the file, -n -1 the last. If neither -c nor -n is specified, -n 10 shall be assumed. "
  },
  {
    "command": "ctags",
    "description": " The ctags utility shall be provided on systems that support the the Software Development Utilities option, and either or both of the C-Language Development Utilities option and FORTRAN Development Utilities option. On other systems, it is optional. The ctags utility shall write a tagsfile or an index of objects from C-language or FORTRAN source files specified by the pathname operands. The tagsfile shall list the locators of language- specific objects within the source files. A locator consists of a name, pathname, and either a search pattern or a line number that can be used in searching for the object definition. The objects that shall be recognized are specified in the EXTENDED DESCRIPTION section. The ctags utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -a Append to tagsfile. -f tagsfile Write the object locator lists into tagsfile instead of the default file named tags in the current directory. -x Produce a list of object names, the line number, and filename in which each is defined, as well as the text of that line, and write this to the standard output. A tagsfile shall not be created when -x is specified. "
  },
  {
    "command": "mkdir",
    "description": " The mkdir utility shall create the directories specified by the operands, in the order specified. For each dir operand, the mkdir utility shall perform actions equivalent to the mkdir() function defined in the System Interfaces volume of POSIX.1\u20102017, called with the following arguments: 1. The dir operand is used as the path argument. 2. The value of the bitwise-inclusive OR of S_IRWXU, S_IRWXG, and S_IRWXO is used as the mode argument. (If the -m option is specified, the value of the mkdir() mode argument is unspecified, but the directory shall at no time have permissions less restrictive than the -m mode option- argument.) The mkdir utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -m mode Set the file permission bits of the newly-created directory to the specified mode value. The mode option- argument shall be the same as the mode operand defined for the chmod utility. In the symbolic_mode strings, the op characters '+' and '-' shall be interpreted relative to an assumed initial mode of a=rwx; '+' shall add permissions to the default mode, '-' shall delete permissions from the default mode. -p Create any missing intermediate pathname components. For each dir operand that does not name an existing directory, before performing the actions described in the DESCRIPTION above, the mkdir utility shall create any pathname components of the path prefix of dir that do not name an existing directory by performing actions equivalent to first calling the mkdir() function with the following arguments: 1. A pathname naming the missing pathname component, ending with a trailing <slash> character, as the path argument 2. The value zero as the mode argument and then calling the chmod() function with the following arguments: 1. The same path argument as in the mkdir() call 2. The value (S_IWUSR|S_IXUSR|~filemask)&0777 as the mode argument, where filemask is the file mode creation mask of the process (see the System Interfaces volume of POSIX.1\u20102017, umask(3p)) Each dir operand that names an existing directory shall be ignored without error. "
  },
  {
    "command": "test",
    "description": " The test utility shall evaluate the expression and indicate the result of the evaluation by its exit status. An exit status of zero indicates that the expression evaluated as true and an exit status of 1 indicates that the expression evaluated as false. In the second form of the utility, where the utility name used is [ rather than test, the application shall ensure that the closing square bracket is a separate argument. The test and [ utilities may be implemented as a single linked utility which examines the basename of the zeroth command line argument to determine whether to behave as the test or [ variant. Applications using the exec() family of functions to execute these utilities shall ensure that the argument passed in arg0 or argv[0] is '[' when executing the [ utility and has a basename of \"test\" when executing the test utility. The test utility shall not recognize the \"--\" argument in the manner specified by Guideline 10 in the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. No options shall be supported. "
  },
  {
    "command": "uptime",
    "description": " Print the current time, the length of time the system has been up, the number of users on the system, and the average number of jobs in the run queue over the last 1, 5 and 15 minutes. Processes in an uninterruptible sleep state also contribute to the load average. If FILE is not specified, use /var/run/utmp. /var/log/wtmp as FILE is common. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "sha384sum",
    "description": " Print or check SHA384 (384-bit) checksums. With no FILE, or when FILE is -, read standard input. -b, --binary read in binary mode -c, --check read checksums from the FILEs and check them --tag create a BSD-style checksum -t, --text read in text mode (default) -z, --zero end each output line with NUL, not newline, and disable file name escaping The following five options are useful only when verifying checksums: --ignore-missing don't fail or report status for missing files --quiet don't print OK for each successfully verified file --status don't output anything, status code shows success --strict exit non-zero for improperly formatted checksum lines -w, --warn warn about improperly formatted checksum lines --help display this help and exit --version output version information and exit The sums are computed as described in FIPS-180-2. When checking, the input should be a former output of this program. The default mode is to print a line with: checksum, a space, a character indicating input mode ('*' for binary, ' ' for text or where binary is insignificant), and name for each FILE. Note: There is no difference between binary mode and text mode on GNU systems. "
  },
  {
    "command": "file",
    "description": " This manual page documents version 5.44 of the file command. file tests each argument in an attempt to classify it. There are three sets of tests, performed in this order: filesystem tests, magic tests, and language tests. The first test that succeeds causes the file type to be printed. The type printed will usually contain one of the words text (the file contains only printing characters and a few common control characters and is probably safe to read on an ASCII terminal), executable (the file contains the result of compiling a program in a form understandable to some UNIX kernel or another), or data meaning anything else (data is usually \u201cbinary\u201d or non-printable). Exceptions are well-known file formats (core files, tar archives) that are known to contain binary data. When modifying magic files or the program itself, make sure to preserve these keywords. Users depend on knowing that all the readable files in a directory have the word \u201ctext\u201d printed. Don't do as Berkeley did and change \u201cshell commands text\u201d to \u201cshell script\u201d. The filesystem tests are based on examining the return from a stat(2) system call. The program checks to see if the file is empty, or if it's some sort of special file. Any known file types appropriate to the system you are running on (sockets, symbolic links, or named pipes (FIFOs) on those systems that implement them) are intuited if they are defined in the system header file <sys/stat.h>. The magic tests are used to check for files with data in particular fixed formats. The canonical example of this is a binary executable (compiled program) a.out file, whose format is defined in <elf.h>, <a.out.h> and possibly <exec.h> in the standard include directory. These files have a \u201cmagic number\u201d stored in a particular place near the beginning of the file that tells the UNIX operating system that the file is a binary executable, and which of several types thereof. The concept of a \u201cmagic number\u201d has been applied by extension to data files. Any file with some invariant identifier at a small fixed offset into the file can usually be described in this way. The information identifying these files is read from the compiled magic file /usr/local/share/misc/magic.mgc, or the files in the directory /usr/local/share/misc/magic if the compiled file does not exist. In addition, if $HOME/.magic.mgc or $HOME/.magic exists, it will be used in preference to the system magic files. If a file does not match any of the entries in the magic file, it is examined to see if it seems to be a text file. ASCII, ISO-8859-x, non-ISO 8-bit extended-ASCII character sets (such as those used on Macintosh and IBM PC systems), UTF-8-encoded Unicode, UTF-16-encoded Unicode, and EBCDIC character sets can be distinguished by the different ranges and sequences of bytes that constitute printable text in each set. If a file passes any of these tests, its character set is reported. ASCII, ISO-8859-x, UTF-8, and extended-ASCII files are identified as \u201ctext\u201d because they will be mostly readable on nearly any terminal; UTF-16 and EBCDIC are only \u201ccharacter data\u201d because, while they contain text, it is text that will require translation before it can be read. In addition, file will attempt to determine other characteristics of text-type files. If the lines of a file are terminated by CR, CRLF, or NEL, instead of the Unix-standard LF, this will be reported. Files that contain embedded escape sequences or overstriking will also be identified. Once file has determined the character set used in a text-type file, it will attempt to determine in what language the file is written. The language tests look for particular strings (cf. <names.h>) that can appear anywhere in the first few blocks of a file. For example, the keyword .br indicates that the file is most likely a troff(1) input file, just as the keyword struct indicates a C program. These tests are less reliable than the previous two groups, so they are performed last. The language test routines also test for some miscellany (such as tar(1) archives, JSON files). Any file that cannot be identified as having been written in any of the character sets listed above is simply said to be \u201cdata\u201d. --apple Causes the file command to output the file type and creator code as used by older MacOS versions. The code consists of eight letters, the first describing the file type, the latter the creator. This option works properly only for file formats that have the apple-style output defined. -b, --brief Do not prepend filenames to output lines (brief mode). -C, --compile Write a magic.mgc output file that contains a pre-parsed version of the magic file or directory. -c, --checking-printout Cause a checking printout of the parsed form of the magic file. This is usually used in conjunction with the -m option to debug a new magic file before installing it. -d Prints internal debugging information to stderr. -E On filesystem errors (file not found etc), instead of handling the error as regular output as POSIX mandates and keep going, issue an error message and exit. -e, --exclude testname Exclude the test named in testname from the list of tests made to determine the file type. Valid test names are: apptype EMX application type (only on EMX). ascii Various types of text files (this test will try to guess the text encoding, irrespective of the setting of the \u2018encoding\u2019 option). encoding Different text encodings for soft magic tests. tokens Ignored for backwards compatibility. cdf Prints details of Compound Document Files. compress Checks for, and looks inside, compressed files. csv Checks Comma Separated Value files. elf Prints ELF file details, provided soft magic tests are enabled and the elf magic is found. json Examines JSON (RFC-7159) files by parsing them for compliance. soft Consults magic files. simh Examines SIMH tape files. tar Examines tar files by verifying the checksum of the 512 byte tar header. Excluding this test can provide more detailed content description by using the soft magic method. text A synonym for \u2018ascii\u2019. --exclude-quiet Like --exclude but ignore tests that file does not know about. This is intended for compatibility with older versions of file. --extension Print a slash-separated list of valid extensions for the file type found. -F, --separator separator Use the specified string as the separator between the filename and the file result returned. Defaults to \u2018:\u2019. -f, --files-from namefile Read the names of the files to be examined from namefile (one per line) before the argument list. Either namefile or at least one filename argument must be present; to test the standard input, use \u2018-\u2019 as a filename argument. Please note that namefile is unwrapped and the enclosed filenames are processed when this option is encountered and before any further options processing is done. This allows one to process multiple lists of files with different command line arguments on the same file invocation. Thus if you want to set the delimiter, you need to do it before you specify the list of files, like: \u201c-F @ -f namefile\u201d, instead of: \u201c-f namefile -F @\u201d. -h, --no-dereference This option causes symlinks not to be followed (on systems that support symbolic links). This is the default if the environment variable POSIXLY_CORRECT is not defined. -i, --mime Causes the file command to output mime type strings rather than the more traditional human readable ones. Thus it may say \u2018text/plain; charset=us-ascii\u2019 rather than \u201cASCII text\u201d. --mime-type, --mime-encoding Like -i, but print only the specified element(s). -k, --keep-going Don't stop at the first match, keep going. Subsequent matches will be have the string \u2018\\012- \u2019 prepended. (If you want a newline, see the -r option.) The magic pattern with the highest strength (see the -l option) comes first. -l, --list Shows a list of patterns and their strength sorted descending by magic(4) strength which is used for the matching (see also the -k option). -L, --dereference This option causes symlinks to be followed, as the like- named option in ls(1) (on systems that support symbolic links). This is the default if the environment variable POSIXLY_CORRECT is defined. -m, --magic-file magicfiles Specify an alternate list of files and directories containing magic. This can be a single item, or a colon- separated list. If a compiled magic file is found alongside a file or directory, it will be used instead. -N, --no-pad Don't pad filenames so that they align in the output. -n, --no-buffer Force stdout to be flushed after checking each file. This is only useful if checking a list of files. It is intended to be used by programs that want filetype output from a pipe. -p, --preserve-date On systems that support utime(3) or utimes(2), attempt to preserve the access time of files analyzed, to pretend that file never read them. -P, --parameter name=value Set various parameter limits. Name Default Explanation bytes 1M max number of bytes to read from file elf_notes 256 max ELF notes processed elf_phnum 2K max ELF program sections processed elf_shnum 32K max ELF sections processed elf_shsize 128MB max ELF section size processed encoding 65K max number of bytes to determine encoding indir 50 recursion limit for indirect magic name 50 use count limit for name/use magic regex 8K length limit for regex searches -r, --raw Don't translate unprintable characters to \\ooo. Normally file translates unprintable characters to their octal representation. -s, --special-files Normally, file only attempts to read and determine the type of argument files which stat(2) reports are ordinary files. This prevents problems, because reading special files may have peculiar consequences. Specifying the -s option causes file to also read argument files which are block or character special files. This is useful for determining the filesystem types of the data in raw disk partitions, which are block special files. This option also causes file to disregard the file size as reported by stat(2) since on some systems it reports a zero size for raw disk partitions. -S, --no-sandbox On systems where libseccomp (https://github.com/seccomp/libseccomp ) is available, the -S option disables sandboxing which is enabled by default. This option is needed for file to execute external decompressing programs, i.e. when the -z option is specified and the built-in decompressors are not available. On systems where sandboxing is not available, this option has no effect. -v, --version Print the version of the program and exit. -z, --uncompress Try to look inside compressed files. -Z, --uncompress-noreport Try to look inside compressed files, but report information about the contents only not the compression. -0, --print0 Output a null character \u2018\\0\u2019 after the end of the filename. Nice to cut(1) the output. This does not affect the separator, which is still printed. If this option is repeated more than once, then file prints just the filename followed by a NUL followed by the description (or ERROR: text) followed by a second NUL for each entry. --help Print a help message and exit. "
  },
  {
    "command": "rm",
    "description": " The rm utility shall remove the directory entry specified by each file argument. If either of the files dot or dot-dot are specified as the basename portion of an operand (that is, the final pathname component) or if an operand resolves to the root directory, rm shall write a diagnostic message to standard error and do nothing more with such operands. For each file the following steps shall be taken: 1. If the file does not exist: a. If the -f option is not specified, rm shall write a diagnostic message to standard error. b. Go on to any remaining files. 2. If file is of type directory, the following steps shall be taken: a. If neither the -R option nor the -r option is specified, rm shall write a diagnostic message to standard error, do nothing more with file, and go on to any remaining files. b. If file is an empty directory, rm may skip to step 2d. If the -f option is not specified, and either the permissions of file do not permit writing and the standard input is a terminal or the -i option is specified, rm shall write a prompt to standard error and read a line from the standard input. If the response is not affirmative, rm shall do nothing more with the current file and go on to any remaining files. c. For each entry contained in file, other than dot or dot- dot, the four steps listed here (1 to 4) shall be taken with the entry as if it were a file operand. The rm utility shall not traverse directories by following symbolic links into other parts of the hierarchy, but shall remove the links themselves. d. If the -i option is specified, rm shall write a prompt to standard error and read a line from the standard input. If the response is not affirmative, rm shall do nothing more with the current file, and go on to any remaining files. 3. If file is not of type directory, the -f option is not specified, and either the permissions of file do not permit writing and the standard input is a terminal or the -i option is specified, rm shall write a prompt to the standard error and read a line from the standard input. If the response is not affirmative, rm shall do nothing more with the current file and go on to any remaining files. 4. If the current file is a directory, rm shall perform actions equivalent to the rmdir() function defined in the System Interfaces volume of POSIX.1\u20102017 called with a pathname of the current file used as the path argument. If the current file is not a directory, rm shall perform actions equivalent to the unlink() function defined in the System Interfaces volume of POSIX.1\u20102017 called with a pathname of the current file used as the path argument. If this fails for any reason, rm shall write a diagnostic message to standard error, do nothing more with the current file, and go on to any remaining files. The rm utility shall be able to descend to arbitrary depths in a file hierarchy, and shall not fail due to path length limitations (unless an operand specified by the user exceeds system limitations). The rm utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -f Do not prompt for confirmation. Do not write diagnostic messages or modify the exit status in the case of no file operands, or in the case of operands that do not exist. Any previous occurrences of the -i option shall be ignored. -i Prompt for confirmation as described previously. Any previous occurrences of the -f option shall be ignored. -R Remove file hierarchies. See the DESCRIPTION. -r Equivalent to -R. "
  },
  {
    "command": "git-update-ref",
    "description": " Given two arguments, stores the <newvalue> in the <ref>, possibly dereferencing the symbolic refs. E.g. git update-ref HEAD <newvalue> updates the current branch head to the new object. Given three arguments, stores the <newvalue> in the <ref>, possibly dereferencing the symbolic refs, after verifying that the current value of the <ref> matches <oldvalue>. E.g. git update-ref refs/heads/master <newvalue> <oldvalue> updates the master branch head to <newvalue> only if its current value is <oldvalue>. You can specify 40 \"0\" or an empty string as <oldvalue> to make sure that the ref you are creating does not exist. It also allows a \"ref\" file to be a symbolic pointer to another ref file by starting with the four-byte header sequence of \"ref:\". More importantly, it allows the update of a ref file to follow these symbolic pointers, whether they are symlinks or these \"regular file symbolic refs\". It follows real symlinks only if they start with \"refs/\": otherwise it will just try to read them and update them as a regular file (i.e. it will allow the filesystem to follow them, but will overwrite such a symlink to somewhere else with a regular filename). If --no-deref is given, <ref> itself is overwritten, rather than the result of following the symbolic pointers. In general, using git update-ref HEAD \"$head\" should be a lot safer than doing echo \"$head\" > \"$GIT_DIR/HEAD\" both from a symlink following standpoint and an error checking standpoint. The \"refs/\" rule for symlinks means that symlinks that point to \"outside\" the tree are safe: they\u2019ll be followed for reading but not for writing (so we\u2019ll never write through a ref symlink to some other tree, if you have copied a whole archive by creating a symlink tree). With -d flag, it deletes the named <ref> after verifying it still contains <oldvalue>. With --stdin, update-ref reads instructions from standard input and performs all modifications together. Specify commands of the form: update SP <ref> SP <newvalue> [SP <oldvalue>] LF create SP <ref> SP <newvalue> LF delete SP <ref> [SP <oldvalue>] LF verify SP <ref> [SP <oldvalue>] LF option SP <opt> LF start LF prepare LF commit LF abort LF With --create-reflog, update-ref will create a reflog for each ref even if one would not ordinarily be created. Quote fields containing whitespace as if they were strings in C source code; i.e., surrounded by double-quotes and with backslash escapes. Use 40 \"0\" characters or the empty string to specify a zero value. To specify a missing value, omit the value and its preceding SP entirely. Alternatively, use -z to specify in NUL-terminated format, without quoting: update SP <ref> NUL <newvalue> NUL [<oldvalue>] NUL create SP <ref> NUL <newvalue> NUL delete SP <ref> NUL [<oldvalue>] NUL verify SP <ref> NUL [<oldvalue>] NUL option SP <opt> NUL start NUL prepare NUL commit NUL abort NUL In this format, use 40 \"0\" to specify a zero value, and use the empty string to specify a missing value. In either format, values can be specified in any form that Git recognizes as an object name. Commands in any other format or a repeated <ref> produce an error. Command meanings are: update Set <ref> to <newvalue> after verifying <oldvalue>, if given. Specify a zero <newvalue> to ensure the ref does not exist after the update and/or a zero <oldvalue> to make sure the ref does not exist before the update. create Create <ref> with <newvalue> after verifying it does not exist. The given <newvalue> may not be zero. delete Delete <ref> after verifying it exists with <oldvalue>, if given. If given, <oldvalue> may not be zero. verify Verify <ref> against <oldvalue> but do not change it. If <oldvalue> is zero or missing, the ref must not exist. option Modify behavior of the next command naming a <ref>. The only valid option is no-deref to avoid dereferencing a symbolic ref. start Start a transaction. In contrast to a non-transactional session, a transaction will automatically abort if the session ends without an explicit commit. This command may create a new empty transaction when the current one has been committed or aborted already. prepare Prepare to commit the transaction. This will create lock files for all queued reference updates. If one reference could not be locked, the transaction will be aborted. commit Commit all reference updates queued for the transaction, ending the transaction. abort Abort the transaction, releasing all locks if the transaction is in prepared state. If all <ref>s can be locked with matching <oldvalue>s simultaneously, all modifications are performed. Otherwise, no modifications are performed. Note that while each individual <ref> is updated or deleted atomically, a concurrent reader may still see a subset of the modifications. "
  },
  {
    "command": "localectl",
    "description": " localectl may be used to query and change the system locale and keyboard layout settings. It communicates with systemd-localed(8) to modify files such as /etc/locale.conf and /etc/vconsole.conf. The system locale controls the language settings of system services and of the UI before the user logs in, such as the display manager, as well as the default for users after login. The keyboard settings control the keyboard layout used on the text console and of the graphical UI before the user logs in, such as the display manager, as well as the default for users after login. Note that the changes performed using this tool might require the initrd to be rebuilt to take effect during early system boot. The initrd is not rebuilt automatically by localectl, this task has to be performed manually, usually using a tool like dracut(8). Note that systemd-firstboot(1) may be used to initialize the system locale for mounted (but not booted) system images. The following options are understood: --no-ask-password Do not query the user for authentication for privileged operations. --no-convert If set-keymap or set-x11-keymap is invoked and this option is passed, then the keymap will not be converted from the console to X11, or X11 to console, respectively. -H, --host= Execute the operation remotely. Specify a hostname, or a username and hostname separated by \"@\", to connect to. The hostname may optionally be suffixed by a port ssh is listening on, separated by \":\", and then a container name, separated by \"/\", which connects directly to a specific container on the specified host. This will use SSH to talk to the remote machine manager instance. Container names may be enumerated with machinectl -H HOST. Put IPv6 addresses in brackets. -M, --machine= Execute operation on a local container. Specify a container name to connect to, optionally prefixed by a user name to connect as and a separating \"@\" character. If the special string \".host\" is used in place of the container name, a connection to the local system is made (which is useful to connect to a specific user's user bus: \"--user --machine=lennart@.host\"). If the \"@\" syntax is not used, the connection is made as root user. If the \"@\" syntax is used either the left hand side or the right hand side may be omitted (but not both) in which case the local user name and \".host\" are implied. -h, --help Print a short help text and exit. --version Print a short version string and exit. --no-pager Do not pipe output into a pager. "
  },
  {
    "command": "cat",
    "description": " The cat utility shall read files in sequence and shall write their contents to the standard output in the same sequence. The cat utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -u Write bytes from the input file to the standard output without delay as each is read. "
  },
  {
    "command": "fc",
    "description": " The fc utility shall list, or shall edit and re-execute, commands previously entered to an interactive sh. The command history list shall reference commands by number. The first number in the list is selected arbitrarily. The relationship of a number to its command shall not change except when the user logs in and no other process is accessing the list, at which time the system may reset the numbering to start the oldest retained command at another number (usually 1). When the number reaches an implementation-defined upper limit, which shall be no smaller than the value in HISTSIZE or 32767 (whichever is greater), the shell may wrap the numbers, starting the next command with a lower number (usually 1). However, despite this optional wrapping of numbers, fc shall maintain the time-ordering sequence of the commands. For example, if four commands in sequence are given the numbers 32766, 32767, 1 (wrapped), and 2 as they are executed, command 32767 is considered the command previous to 1, even though its number is higher. When commands are edited (when the -l option is not specified), the resulting lines shall be entered at the end of the history list and then re-executed by sh. The fc command that caused the editing shall not be entered into the history list. If the editor returns a non-zero exit status, this shall suppress the entry into the history list and the command re-execution. Any command line variable assignments or redirection operators used with fc shall affect both the fc command itself as well as the command that results; for example: fc -s -- -1 2>/dev/null reinvokes the previous command, suppressing standard error for both fc and the previous command. The fc utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -e editor Use the editor named by editor to edit the commands. The editor string is a utility name, subject to search via the PATH variable (see the Base Definitions volume of POSIX.1\u20102017, Chapter 8, Environment Variables). The value in the FCEDIT variable shall be used as a default when -e is not specified. If FCEDIT is null or unset, ed shall be used as the editor. -l (The letter ell.) List the commands rather than invoking an editor on them. The commands shall be written in the sequence indicated by the first and last operands, as affected by -r, with each command preceded by the command number. -n Suppress command numbers when listing with -l. -r Reverse the order of the commands listed (with -l) or edited (with neither -l nor -s). -s Re-execute the command without invoking an editor. "
  },
  {
    "command": "sum",
    "description": " Print or check BSD (16-bit) checksums. With no FILE, or when FILE is -, read standard input. -r use BSD sum algorithm (the default), use 1K blocks -s, --sysv use System V sum algorithm, use 512 bytes blocks --help display this help and exit --version output version information and exit "
  },
  {
    "command": "sha256sum",
    "description": " Print or check SHA256 (256-bit) checksums. With no FILE, or when FILE is -, read standard input. -b, --binary read in binary mode -c, --check read checksums from the FILEs and check them --tag create a BSD-style checksum -t, --text read in text mode (default) -z, --zero end each output line with NUL, not newline, and disable file name escaping The following five options are useful only when verifying checksums: --ignore-missing don't fail or report status for missing files --quiet don't print OK for each successfully verified file --status don't output anything, status code shows success --strict exit non-zero for improperly formatted checksum lines -w, --warn warn about improperly formatted checksum lines --help display this help and exit --version output version information and exit The sums are computed as described in FIPS-180-2. When checking, the input should be a former output of this program. The default mode is to print a line with: checksum, a space, a character indicating input mode ('*' for binary, ' ' for text or where binary is insignificant), and name for each FILE. Note: There is no difference between binary mode and text mode on GNU systems. "
  },
  {
    "command": "runcon",
    "description": " Run COMMAND with completely-specified CONTEXT, or with current or transitioned security context modified by one or more of LEVEL, ROLE, TYPE, and USER. If none of -c, -t, -u, -r, or -l, is specified, the first argument is used as the complete context. Any additional arguments after COMMAND are interpreted as arguments to the command. Note that only carefully-chosen contexts are likely to successfully run. Run a program in a different SELinux security context. With neither CONTEXT nor COMMAND, print the current security context. Mandatory arguments to long options are mandatory for short options too. CONTEXT Complete security context -c, --compute compute process transition context before modifying -t, --type=TYPE type (for same role as parent) -u, --user=USER user identity -r, --role=ROLE role -l, --range=RANGE levelrange --help display this help and exit --version output version information and exit Exit status: 125 if the runcon command itself fails 126 if COMMAND is found but cannot be invoked 127 if COMMAND cannot be found - the exit status of COMMAND otherwise "
  },
  {
    "command": "curl",
    "description": " curl is a tool for transferring data from or to a server. It supports these protocols: DICT, FILE, FTP, FTPS, GOPHER, GOPHERS, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, MQTT, POP3, POP3S, RTMP, RTMPS, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET, TFTP, WS and WSS. The command is designed to work without user interaction. curl offers a busload of useful tricks like proxy support, user authentication, FTP upload, HTTP post, SSL connections, cookies, file transfer resume and more. As you will see below, the number of features will make your head spin. curl is powered by libcurl for all transfer-related features. See libcurl(3) for details. Options start with one or two dashes. Many of the options require an additional value next to them. The short \"single-dash\" form of the options, -d for example, may be used with or without a space between it and its value, although a space is a recommended separator. The long \"double- dash\" form, -d, --data for example, requires a space between it and its value. Short version options that do not need any additional values can be used immediately next to each other, like for example you can specify all the options -O, -L and -v at once as -OLv. In general, all boolean options are enabled with --option and yet again disabled with --no-option. That is, you use the same option name but prefix it with \"no-\". However, in this list we mostly only list and show the --option version of them. When -:, --next is used, it resets the parser state and you start again with a clean option state, except for the options that are \"global\". Global options will retain their values and meaning even after -:, --next. The following options are global: --fail-early, --libcurl, --parallel-immediate, -Z, --parallel, -#, --progress-bar, --rate, -S, --show-error, --stderr, --styled-output, --trace-ascii, --trace-ids, --trace-time, --trace and -v, --verbose. --abstract-unix-socket <path> (HTTP) Connect through an abstract Unix domain socket, instead of using the network. Note: netstat shows the path of an abstract socket prefixed with '@', however the <path> argument should not have this leading character. If --abstract-unix-socket is provided several times, the last set value will be used. Example: curl --abstract-unix-socket socketpath https://example.com See also --unix-socket. Added in 7.53.0. --alt-svc <file name> (HTTPS) This option enables the alt-svc parser in curl. If the file name points to an existing alt-svc cache file, that will be used. After a completed transfer, the cache will be saved to the file name again if it has been modified. Specify a \"\" file name (zero length) to avoid loading/saving and make curl just handle the cache in memory. If this option is used several times, curl will load contents from all the files but the last one will be used for saving. --alt-svc can be used several times in a command line Example: curl --alt-svc svc.txt https://example.com See also --resolve and --connect-to. Added in 7.64.1. --anyauth (HTTP) Tells curl to figure out authentication method by itself, and use the most secure one the remote site claims to support. This is done by first doing a request and checking the response-headers, thus possibly inducing an extra network round-trip. This is used instead of setting a specific authentication method, which you can do with --basic, --digest, --ntlm, and --negotiate. Using --anyauth is not recommended if you do uploads from stdin, since it may require data to be sent twice and then the client must be able to rewind. If the need should arise when uploading from stdin, the upload operation will fail. Used together with -u, --user. Providing --anyauth multiple times has no extra effect. Example: curl --anyauth --user me:pwd https://example.com See also --proxy-anyauth, --basic and --digest. -a, --append (FTP SFTP) When used in an upload, this makes curl append to the target file instead of overwriting it. If the remote file does not exist, it will be created. Note that this flag is ignored by some SFTP servers (including OpenSSH). Providing -a, --append multiple times has no extra effect. Disable it again with --no-append. Example: curl --upload-file local --append ftp://example.com/ See also -r, --range and -C, --continue-at. --aws-sigv4 <provider1[:provider2[:region[:service]]]> Use AWS V4 signature authentication in the transfer. The provider argument is a string that is used by the algorithm when creating outgoing authentication headers. The region argument is a string that points to a geographic area of a resources collection (region-code) when the region name is omitted from the endpoint. The service argument is a string that points to a function provided by a cloud (service-code) when the service name is omitted from the endpoint. If --aws-sigv4 is provided several times, the last set value will be used. Example: curl --aws-sigv4 \"aws:amz:us-east-2:es\" --user \"key:secret\" https://example.com See also --basic and -u, --user. Added in 7.75.0. --basic (HTTP) Tells curl to use HTTP Basic authentication with the remote host. This is the default and this option is usually pointless, unless you use it to override a previously set option that sets a different authentication method (such as --ntlm, --digest, or --negotiate). Used together with -u, --user. Providing --basic multiple times has no extra effect. Example: curl -u name:password --basic https://example.com See also --proxy-basic. --ca-native (TLS) Tells curl to use the CA store from the native operating system to verify the peer. By default, curl will otherwise use a CA store provided in a single file or directory, but when using this option it will interface the operating system's own vault. This option only works for curl on Windows when built to use OpenSSL. When curl on Windows is built to use Schannel, this feature is implied and curl then only uses the native CA store. Providing --ca-native multiple times has no extra effect. Disable it again with --no-ca-native. Example: curl --ca-native https://example.com See also --cacert, --capath and -k, --insecure. Added in 8.2.0. --cacert <file> (TLS) Tells curl to use the specified certificate file to verify the peer. The file may contain multiple CA certificates. The certificate(s) must be in PEM format. Normally curl is built to use a default file for this, so this option is typically used to alter that default file. curl recognizes the environment variable named 'CURL_CA_BUNDLE' if it is set, and uses the given path as a path to a CA cert bundle. This option overrides that variable. The windows version of curl will automatically look for a CA certs file named 'curl-ca-bundle.crt', either in the same directory as curl.exe, or in the Current Working Directory, or in any folder along your PATH. If curl is built against the NSS SSL library, the NSS PEM PKCS#11 module (libnsspem.so) needs to be available for this option to work properly. (iOS and macOS only) If curl is built against Secure Transport, then this option is supported for backward compatibility with other SSL engines, but it should not be set. If the option is not set, then curl will use the certificates in the system and user Keychain to verify the peer, which is the preferred method of verifying the peer's certificate chain. (Schannel only) This option is supported for Schannel in Windows 7 or later with libcurl 7.60 or later. This option is supported for backward compatibility with other SSL engines; instead it is recommended to use Windows' store of root certificates (the default for Schannel). If --cacert is provided several times, the last set value will be used. Example: curl --cacert CA-file.txt https://example.com See also --capath and -k, --insecure. --capath <dir> (TLS) Tells curl to use the specified certificate directory to verify the peer. Multiple paths can be provided by separating them with \":\" (e.g. \"path1:path2:path3\"). The certificates must be in PEM format, and if curl is built against OpenSSL, the directory must have been processed using the c_rehash utility supplied with OpenSSL. Using --capath can allow OpenSSL-powered curl to make SSL-connections much more efficiently than using --cacert if the --cacert file contains many CA certificates. If this option is set, the default capath value will be ignored. If --capath is provided several times, the last set value will be used. Example: curl --capath /local/directory https://example.com See also --cacert and -k, --insecure. --cert-status (TLS) Tells curl to verify the status of the server certificate by using the Certificate Status Request (aka. OCSP stapling) TLS extension. If this option is enabled and the server sends an invalid (e.g. expired) response, if the response suggests that the server certificate has been revoked, or no response at all is received, the verification fails. This is currently only implemented in the OpenSSL, GnuTLS and NSS backends. Providing --cert-status multiple times has no extra effect. Disable it again with --no-cert-status. Example: curl --cert-status https://example.com See also --pinnedpubkey. Added in 7.41.0. --cert-type <type> (TLS) Tells curl what type the provided client certificate is using. PEM, DER, ENG and P12 are recognized types. The default type depends on the TLS backend and is usually PEM, however for Secure Transport and Schannel it is P12. If -E, --cert is a pkcs11: URI then ENG is the default type. If --cert-type is provided several times, the last set value will be used. Example: curl --cert-type PEM --cert file https://example.com See also -E, --cert, --key and --key-type. -E, --cert <certificate[:password]> (TLS) Tells curl to use the specified client certificate file when getting a file with HTTPS, FTPS or another SSL- based protocol. The certificate must be in PKCS#12 format if using Secure Transport, or PEM format if using any other engine. If the optional password is not specified, it will be queried for on the terminal. Note that this option assumes a certificate file that is the private key and the client certificate concatenated. See -E, --cert and --key to specify them independently. In the <certificate> portion of the argument, you must escape the character \":\" as \"\\:\" so that it is not recognized as the password delimiter. Similarly, you must escape the character \"\\\" as \"\\\\\" so that it is not recognized as an escape character. If curl is built against the NSS SSL library then this option can tell curl the nickname of the certificate to use within the NSS database defined by the environment variable SSL_DIR (or by default /etc/pki/nssdb). If the NSS PEM PKCS#11 module (libnsspem.so) is available then PEM files may be loaded. If you provide a path relative to the current directory, you must prefix the path with \"./\" in order to avoid confusion with an NSS database nickname. If curl is built against OpenSSL library, and the engine pkcs11 is available, then a PKCS#11 URI (RFC 7512) can be used to specify a certificate located in a PKCS#11 device. A string beginning with \"pkcs11:\" will be interpreted as a PKCS#11 URI. If a PKCS#11 URI is provided, then the --engine option will be set as \"pkcs11\" if none was provided and the --cert-type option will be set as \"ENG\" if none was provided. (iOS and macOS only) If curl is built against Secure Transport, then the certificate string can either be the name of a certificate/private key in the system or user keychain, or the path to a PKCS#12-encoded certificate and private key. If you want to use a file from the current directory, please precede it with \"./\" prefix, in order to avoid confusion with a nickname. (Schannel only) Client certificates must be specified by a path expression to a certificate store. (Loading PFX is not supported; you can import it to a store first). You can use \"<store location>\\<store name>\\<thumbprint>\" to refer to a certificate in the system certificates store, for example, \"CurrentUser\\MY\\934a7ac6f8a5d579285a74fa61e19f23ddfe8d7a\". Thumbprint is usually a SHA-1 hex string which you can see in certificate details. Following store locations are supported: CurrentUser, LocalMachine, CurrentService, Services, CurrentUserGroupPolicy, LocalMachineGroupPolicy, LocalMachineEnterprise. If -E, --cert is provided several times, the last set value will be used. Example: curl --cert certfile --key keyfile https://example.com See also --cert-type, --key and --key-type. --ciphers <list of ciphers> (TLS) Specifies which ciphers to use in the connection. The list of ciphers must specify valid ciphers. Read up on SSL cipher list details on this URL: https://curl.se/docs/ssl-ciphers.html If --ciphers is provided several times, the last set value will be used. Example: curl --ciphers ECDHE-ECDSA-AES256-CCM8 https://example.com See also --tlsv1.3. --compressed-ssh (SCP SFTP) Enables built-in SSH compression. This is a request, not an order; the server may or may not do it. Providing --compressed-ssh multiple times has no extra effect. Disable it again with --no-compressed-ssh. Example: curl --compressed-ssh sftp://example.com/ See also --compressed. Added in 7.56.0. --compressed (HTTP) Request a compressed response using one of the algorithms curl supports, and automatically decompress the content. Response headers are not modified when saved, so if they are \"interpreted\" separately again at a later point they might appear to be saying that the content is (still) compressed; while in fact it has already been decompressed. If this option is used and the server sends an unsupported encoding, curl will report an error. This is a request, not an order; the server may or may not deliver data compressed. Providing --compressed multiple times has no extra effect. Disable it again with --no-compressed. Example: curl --compressed https://example.com See also --compressed-ssh. -K, --config <file> Specify a text file to read curl arguments from. The command line arguments found in the text file will be used as if they were provided on the command line. Options and their parameters must be specified on the same line in the file, separated by whitespace, colon, or the equals sign. Long option names can optionally be given in the config file without the initial double dashes and if so, the colon or equals characters can be used as separators. If the option is specified with one or two dashes, there can be no colon or equals character between the option and its parameter. If the parameter contains whitespace (or starts with : or =), the parameter must be enclosed within quotes. Within double quotes, the following escape sequences are available: \\\\, \\\", \\t, \\n, \\r and \\v. A backslash preceding any other letter is ignored. If the first column of a config line is a '#' character, the rest of the line will be treated as a comment. Only write one option per physical line in the config file. Specify the filename to -K, --config as '-' to make curl read the file from stdin. Note that to be able to specify a URL in the config file, you need to specify it using the --url option, and not by simply writing the URL on its own line. So, it could look similar to this: url = \"https://curl.se/docs/\" # --- Example file --- # this is a comment url = \"example.com\" output = \"curlhere.html\" user-agent = \"superagent/1.0\" # and fetch another URL too url = \"example.com/docs/manpage.html\" -O referer = \"http://nowhereatall.example.com/\" # --- End of example file --- When curl is invoked, it (unless -q, --disable is used) checks for a default config file and uses it if found, even when -K, --config is used. The default config file is checked for in the following places in this order: 1) \"$CURL_HOME/.curlrc\" 2) \"$XDG_CONFIG_HOME/curlrc\" (Added in 7.73.0) 3) \"$HOME/.curlrc\" 4) Windows: \"%USERPROFILE%\\.curlrc\" 5) Windows: \"%APPDATA%\\.curlrc\" 6) Windows: \"%USERPROFILE%\\Application Data\\.curlrc\" 7) Non-Windows: use getpwuid to find the home directory 8) On Windows, if it finds no .curlrc file in the sequence described above, it checks for one in the same dir the curl executable is placed. On Windows two filenames are checked per location: .curlrc and _curlrc, preferring the former. Older versions on Windows checked for _curlrc only. -K, --config can be used several times in a command line Example: curl --config file.txt https://example.com See also -q, --disable. --connect-timeout <fractional seconds> Maximum time in seconds that you allow curl's connection to take. This only limits the connection phase, so if curl connects within the given period it will continue - if not it will exit. Since version 7.32.0, this option accepts decimal values. The \"connection phase\" is considered complete when the DNS lookup and requested TCP, TLS or QUIC handshakes are done. The decimal value needs to provided using a dot (.) as decimal separator - not the local version even if it might be using another separator. If --connect-timeout is provided several times, the last set value will be used. Examples: curl --connect-timeout 20 https://example.com curl --connect-timeout 3.14 https://example.com See also -m, --max-time. --connect-to <HOST1:PORT1:HOST2:PORT2> For a request to the given HOST1:PORT1 pair, connect to HOST2:PORT2 instead. This option is suitable to direct requests at a specific server, e.g. at a specific cluster node in a cluster of servers. This option is only used to establish the network connection. It does NOT affect the hostname/port that is used for TLS/SSL (e.g. SNI, certificate verification) or for the application protocols. \"HOST1\" and \"PORT1\" may be the empty string, meaning \"any host/port\". \"HOST2\" and \"PORT2\" may also be the empty string, meaning \"use the request's original host/port\". A \"host\" specified to this option is compared as a string, so it needs to match the name used in request URL. It can be either numerical such as \"127.0.0.1\" or the full host name such as \"example.org\". --connect-to can be used several times in a command line Example: curl --connect-to example.com:443:example.net:8443 https://example.com See also --resolve and -H, --header. Added in 7.49.0. -C, --continue-at <offset> Continue/Resume a previous file transfer at the given offset. The given offset is the exact number of bytes that will be skipped, counting from the beginning of the source file before it is transferred to the destination. If used with uploads, the FTP server command SIZE will not be used by curl. Use \"-C -\" to tell curl to automatically find out where/how to resume the transfer. It then uses the given output/input files to figure that out. If -C, --continue-at is provided several times, the last set value will be used. Examples: curl -C - https://example.com curl -C 400 https://example.com See also -r, --range. -c, --cookie-jar <filename> (HTTP) Specify to which file you want curl to write all cookies after a completed operation. Curl writes all cookies from its in-memory cookie storage to the given file at the end of operations. If no cookies are known, no data will be written. The file will be written using the Netscape cookie file format. If you set the file name to a single dash, \"-\", the cookies will be written to stdout. This command line option will activate the cookie engine that makes curl record and use cookies. Another way to activate it is to use the -b, --cookie option. If the cookie jar cannot be created or written to, the whole curl operation will not fail or even report an error clearly. Using -v, --verbose will get a warning displayed, but that is the only visible feedback you get about this possibly lethal situation. If -c, --cookie-jar is provided several times, the last set value will be used. Examples: curl -c store-here.txt https://example.com curl -c store-here.txt -b read-these https://example.com See also -b, --cookie. -b, --cookie <data|filename> (HTTP) Pass the data to the HTTP server in the Cookie header. It is supposedly the data previously received from the server in a \"Set-Cookie:\" line. The data should be in the format \"NAME1=VALUE1; NAME2=VALUE2\". This makes curl use the cookie header with this content explicitly in all outgoing request(s). If multiple requests are done due to authentication, followed redirects or similar, they will all get this cookie passed on. If no '=' symbol is used in the argument, it is instead treated as a filename to read previously stored cookie from. This option also activates the cookie engine which will make curl record incoming cookies, which may be handy if you are using this in combination with the -L, --location option or do multiple URL transfers on the same invoke. If the file name is exactly a minus (\"-\"), curl will instead read the contents from stdin. The file format of the file to read cookies from should be plain HTTP headers (Set-Cookie style) or the Netscape/Mozilla cookie file format. The file specified with -b, --cookie is only used as input. No cookies will be written to the file. To store cookies, use the -c, --cookie-jar option. If you use the Set-Cookie file format and do not specify a domain then the cookie is not sent since the domain will never match. To address this, set a domain in Set-Cookie line (doing that will include sub-domains) or preferably: use the Netscape format. Users often want to both read cookies from a file and write updated cookies back to a file, so using both -b, --cookie and -c, --cookie-jar in the same command line is common. -b, --cookie can be used several times in a command line Examples: curl -b cookiefile https://example.com curl -b cookiefile -c cookiefile https://example.com See also -c, --cookie-jar and -j, --junk-session-cookies. --create-dirs When used in conjunction with the -o, --output option, curl will create the necessary local directory hierarchy as needed. This option creates the directories mentioned with the -o, --output option, nothing else. If the -o, --output file name uses no directory, or if the directories it mentions already exist, no directories will be created. Created dirs are made with mode 0750 on unix style file systems. To create remote directories when using FTP or SFTP, try --ftp-create-dirs. Providing --create-dirs multiple times has no extra effect. Disable it again with --no-create-dirs. Example: curl --create-dirs --output local/dir/file https://example.com See also --ftp-create-dirs and --output-dir. --create-file-mode <mode> (SFTP SCP FILE) When curl is used to create files remotely using one of the supported protocols, this option allows the user to set which 'mode' to set on the file at creation time, instead of the default 0644. This option takes an octal number as argument. If --create-file-mode is provided several times, the last set value will be used. Example: curl --create-file-mode 0777 -T localfile sftp://example.com/new See also --ftp-create-dirs. Added in 7.75.0. --crlf (FTP SMTP) Convert LF to CRLF in upload. Useful for MVS (OS/390). (SMTP added in 7.40.0) Providing --crlf multiple times has no extra effect. Disable it again with --no-crlf. Example: curl --crlf -T file ftp://example.com/ See also -B, --use-ascii. --crlfile <file> (TLS) Provide a file using PEM format with a Certificate Revocation List that may specify peer certificates that are to be considered revoked. If --crlfile is provided several times, the last set value will be used. Example: curl --crlfile rejects.txt https://example.com See also --cacert and --capath. --curves <algorithm list> (TLS) Tells curl to request specific curves to use during SSL session establishment according to RFC 8422, 5.1. Multiple algorithms can be provided by separating them with \":\" (e.g. \"X25519:P-521\"). The parameter is available identically in the \"openssl s_client/s_server\" utilities. --curves allows a OpenSSL powered curl to make SSL- connections with exactly the (EC) curve requested by the client, avoiding nontransparent client/server negotiations. If this option is set, the default curves list built into openssl will be ignored. If --curves is provided several times, the last set value will be used. Example: curl --curves X25519 https://example.com See also --ciphers. Added in 7.73.0. --data-ascii <data> (HTTP) This is just an alias for -d, --data. --data-ascii can be used several times in a command line Example: curl --data-ascii @file https://example.com See also --data-binary, --data-raw and --data-urlencode. --data-binary <data> (HTTP) This posts data exactly as specified with no extra processing whatsoever. If you start the data with the letter @, the rest should be a filename. Data is posted in a similar manner as -d, --data does, except that newlines and carriage returns are preserved and conversions are never done. Like -d, --data the default content-type sent to the server is application/x-www-form-urlencoded. If you want the data to be treated as arbitrary binary data by the server then set the content-type to octet-stream: -H \"Content-Type: application/octet-stream\". If this option is used several times, the ones following the first will append data as described in -d, --data. --data-binary can be used several times in a command line Example: curl --data-binary @filename https://example.com See also --data-ascii. --data-raw <data> (HTTP) This posts data similarly to -d, --data but without the special interpretation of the @ character. --data-raw can be used several times in a command line Examples: curl --data-raw \"hello\" https://example.com curl --data-raw \"@at@at@\" https://example.com See also -d, --data. Added in 7.43.0. --data-urlencode <data> (HTTP) This posts data, similar to the other -d, --data options with the exception that this performs URL- encoding. To be CGI-compliant, the <data> part should begin with a name followed by a separator and a content specification. The <data> part can be passed to curl using one of the following syntaxes: content This will make curl URL-encode the content and pass that on. Just be careful so that the content does not contain any = or @ symbols, as that will then make the syntax match one of the other cases below! =content This will make curl URL-encode the content and pass that on. The preceding = symbol is not included in the data. name=content This will make curl URL-encode the content part and pass that on. Note that the name part is expected to be URL-encoded already. @filename This will make curl load data from the given file (including any newlines), URL-encode that data and pass it on in the POST. name@filename This will make curl load data from the given file (including any newlines), URL-encode that data and pass it on in the POST. The name part gets an equal sign appended, resulting in name=urlencoded-file- content. Note that the name is expected to be URL- encoded already. --data-urlencode can be used several times in a command line Examples: curl --data-urlencode name=val https://example.com curl --data-urlencode =encodethis https://example.com curl --data-urlencode name@file https://example.com curl --data-urlencode @fileonly https://example.com See also -d, --data and --data-raw. -d, --data <data> (HTTP MQTT) Sends the specified data in a POST request to the HTTP server, in the same way that a browser does when a user has filled in an HTML form and presses the submit button. This will cause curl to pass the data to the server using the content-type application/x-www-form- urlencoded. Compare to -F, --form. --data-raw is almost the same but does not have a special interpretation of the @ character. To post data purely binary, you should instead use the --data-binary option. To URL-encode the value of a form field you may use --data-urlencode. If any of these options is used more than once on the same command line, the data pieces specified will be merged with a separating &-symbol. Thus, using '-d name=daniel -d skill=lousy' would generate a post chunk that looks like 'name=daniel&skill=lousy'. If you start the data with the letter @, the rest should be a file name to read the data from, or - if you want curl to read the data from stdin. Posting data from a file named 'foobar' would thus be done with -d, --data @foobar. When -d, --data is told to read from a file like that, carriage returns and newlines will be stripped out. If you do not want the @ character to have a special interpretation use --data-raw instead. The data for this option is passed on to the server exactly as provided on the command line. curl will not convert it, change it or improve it. It is up to the user to provide the data in the correct form. -d, --data can be used several times in a command line Examples: curl -d \"name=curl\" https://example.com curl -d \"name=curl\" -d \"tool=cmdline\" https://example.com curl -d @filename https://example.com See also --data-binary, --data-urlencode and --data-raw. This option is mutually exclusive to -F, --form and -I, --head and -T, --upload-file. --delegation <LEVEL> (GSS/kerberos) Set LEVEL to tell the server what it is allowed to delegate when it comes to user credentials. none Do not allow any delegation. policy Delegates if and only if the OK-AS-DELEGATE flag is set in the Kerberos service ticket, which is a matter of realm policy. always Unconditionally allow the server to delegate. If --delegation is provided several times, the last set value will be used. Example: curl --delegation \"none\" https://example.com See also -k, --insecure and --ssl. --digest (HTTP) Enables HTTP Digest authentication. This is an authentication scheme that prevents the password from being sent over the wire in clear text. Use this in combination with the normal -u, --user option to set user name and password. Providing --digest multiple times has no extra effect. Disable it again with --no-digest. Example: curl -u name:password --digest https://example.com See also -u, --user, --proxy-digest and --anyauth. This option is mutually exclusive to --basic and --ntlm and --negotiate. --disable-eprt (FTP) Tell curl to disable the use of the EPRT and LPRT commands when doing active FTP transfers. Curl will normally always first attempt to use EPRT, then LPRT before using PORT, but with this option, it will use PORT right away. EPRT and LPRT are extensions to the original FTP protocol, and may not work on all servers, but they enable more functionality in a better way than the traditional PORT command. --eprt can be used to explicitly enable EPRT again and --no-eprt is an alias for --disable-eprt. If the server is accessed using IPv6, this option will have no effect as EPRT is necessary then. Disabling EPRT only changes the active behavior. If you want to switch to passive mode you need to not use -P, --ftp-port or force it with --ftp-pasv. Providing --disable-eprt multiple times has no extra effect. Disable it again with --no-disable-eprt. Example: curl --disable-eprt ftp://example.com/ See also --disable-epsv and -P, --ftp-port. --disable-epsv (FTP) Tell curl to disable the use of the EPSV command when doing passive FTP transfers. Curl will normally always first attempt to use EPSV before PASV, but with this option, it will not try using EPSV. --epsv can be used to explicitly enable EPSV again and --no-epsv is an alias for --disable-epsv. If the server is an IPv6 host, this option will have no effect as EPSV is necessary then. Disabling EPSV only changes the passive behavior. If you want to switch to active mode you need to use -P, --ftp- port. Providing --disable-epsv multiple times has no extra effect. Disable it again with --no-disable-epsv. Example: curl --disable-epsv ftp://example.com/ See also --disable-eprt and -P, --ftp-port. -q, --disable If used as the first parameter on the command line, the curlrc config file will not be read and used. See the -K, --config for details on the default config file search path. Providing -q, --disable multiple times has no extra effect. Disable it again with --no-disable. Example: curl -q https://example.com See also -K, --config. --disallow-username-in-url (HTTP) This tells curl to exit if passed a URL containing a username. This is probably most useful when the URL is being provided at runtime or similar. Providing --disallow-username-in-url multiple times has no extra effect. Disable it again with --no-disallow- username-in-url. Example: curl --disallow-username-in-url https://example.com See also --proto. Added in 7.61.0. --dns-interface <interface> (DNS) Tell curl to send outgoing DNS requests through <interface>. This option is a counterpart to --interface (which does not affect DNS). The supplied string must be an interface name (not an address). If --dns-interface is provided several times, the last set value will be used. Example: curl --dns-interface eth0 https://example.com See also --dns-ipv4-addr and --dns-ipv6-addr. --dns- interface requires that the underlying libcurl was built to support c-ares. Added in 7.33.0. --dns-ipv4-addr <address> (DNS) Tell curl to bind to <ip-address> when making IPv4 DNS requests, so that the DNS requests originate from this address. The argument should be a single IPv4 address. If --dns-ipv4-addr is provided several times, the last set value will be used. Example: curl --dns-ipv4-addr 10.1.2.3 https://example.com See also --dns-interface and --dns-ipv6-addr. --dns- ipv4-addr requires that the underlying libcurl was built to support c-ares. Added in 7.33.0. --dns-ipv6-addr <address> (DNS) Tell curl to bind to <ip-address> when making IPv6 DNS requests, so that the DNS requests originate from this address. The argument should be a single IPv6 address. If --dns-ipv6-addr is provided several times, the last set value will be used. Example: curl --dns-ipv6-addr 2a04:4e42::561 https://example.com See also --dns-interface and --dns-ipv4-addr. --dns- ipv6-addr requires that the underlying libcurl was built to support c-ares. Added in 7.33.0. --dns-servers <addresses> Set the list of DNS servers to be used instead of the system default. The list of IP addresses should be separated with commas. Port numbers may also optionally be given as :<port-number> after each IP address. If --dns-servers is provided several times, the last set value will be used. Example: curl --dns-servers 192.168.0.1,192.168.0.2 https://example.com See also --dns-interface and --dns-ipv4-addr. --dns- servers requires that the underlying libcurl was built to support c-ares. Added in 7.33.0. --doh-cert-status Same as --cert-status but used for DoH (DNS-over-HTTPS). Providing --doh-cert-status multiple times has no extra effect. Disable it again with --no-doh-cert-status. Example: curl --doh-cert-status --doh-url https://doh.example https://example.com See also --doh-insecure. Added in 7.76.0. --doh-insecure Same as -k, --insecure but used for DoH (DNS-over-HTTPS). Providing --doh-insecure multiple times has no extra effect. Disable it again with --no-doh-insecure. Example: curl --doh-insecure --doh-url https://doh.example https://example.com See also --doh-url. Added in 7.76.0. --doh-url <URL> Specifies which DNS-over-HTTPS (DoH) server to use to resolve hostnames, instead of using the default name resolver mechanism. The URL must be HTTPS. Some SSL options that you set for your transfer will apply to DoH since the name lookups take place over SSL. However, the certificate verification settings are not inherited and can be controlled separately via --doh- insecure and --doh-cert-status. This option is unset if an empty string \"\" is used as the URL. (Added in 7.85.0) If --doh-url is provided several times, the last set value will be used. Example: curl --doh-url https://doh.example https://example.com See also --doh-insecure. Added in 7.62.0. -D, --dump-header <filename> (HTTP FTP) Write the received protocol headers to the specified file. If no headers are received, the use of this option will create an empty file. When used in FTP, the FTP server response lines are considered being \"headers\" and thus are saved there. Having multiple transfers in one set of operations (i.e. the URLs in one -:, --next clause), will append them to the same file, separated by a blank line. If -D, --dump-header is provided several times, the last set value will be used. Example: curl --dump-header store.txt https://example.com See also -o, --output. --egd-file <file> (TLS) Deprecated option. This option is ignored by curl since 7.84.0. Prior to that it only had an effect on curl if built to use old versions of OpenSSL. Specify the path name to the Entropy Gathering Daemon socket. The socket is used to seed the random engine for SSL connections. If --egd-file is provided several times, the last set value will be used. Example: curl --egd-file /random/here https://example.com See also --random-file. --engine <name> (TLS) Select the OpenSSL crypto engine to use for cipher operations. Use --engine list to print a list of build- time supported engines. Note that not all (and possibly none) of the engines may be available at runtime. If --engine is provided several times, the last set value will be used. Example: curl --engine flavor https://example.com See also --ciphers and --curves. --etag-compare <file> (HTTP) This option makes a conditional HTTP request for the specific ETag read from the given file by sending a custom If-None-Match header using the stored ETag. For correct results, make sure that the specified file contains only a single line with the desired ETag. An empty file is parsed as an empty ETag. Use the option --etag-save to first save the ETag from a response, and then use this option to compare against the saved ETag in a subsequent request. If --etag-compare is provided several times, the last set value will be used. Example: curl --etag-compare etag.txt https://example.com See also --etag-save and -z, --time-cond. Added in 7.68.0. --etag-save <file> (HTTP) This option saves an HTTP ETag to the specified file. An ETag is a caching related header, usually returned in a response. If no ETag is sent by the server, an empty file is created. If --etag-save is provided several times, the last set value will be used. Example: curl --etag-save storetag.txt https://example.com See also --etag-compare. Added in 7.68.0. --expect100-timeout <seconds> (HTTP) Maximum time in seconds that you allow curl to wait for a 100-continue response when curl emits an Expects: 100-continue header in its request. By default curl will wait one second. This option accepts decimal values! When curl stops waiting, it will continue as if the response has been received. The decimal value needs to provided using a dot (.) as decimal separator - not the local version even if it might be using another separator. If --expect100-timeout is provided several times, the last set value will be used. Example: curl --expect100-timeout 2.5 -T file https://example.com See also --connect-timeout. Added in 7.47.0. --fail-early Fail and exit on the first detected transfer error. When curl is used to do multiple transfers on the command line, it will attempt to operate on each given URL, one by one. By default, it will ignore errors if there are more URLs given and the last URL's success will determine the error code curl returns. So early failures will be \"hidden\" by subsequent successful transfers. Using this option, curl will instead return an error on the first transfer that fails, independent of the amount of URLs that are given on the command line. This way, no transfer failures go undetected by scripts and similar. This option does not imply -f, --fail, which causes transfers to fail due to the server's HTTP status code. You can combine the two options, however note -f, --fail is not global and is therefore contained by -:, --next. This option is global and does not need to be specified for each use of --next. Providing --fail-early multiple times has no extra effect. Disable it again with --no-fail-early. Example: curl --fail-early https://example.com https://two.example See also -f, --fail and --fail-with-body. Added in 7.52.0. --fail-with-body (HTTP) Return an error on server errors where the HTTP response code is 400 or greater). In normal cases when an HTTP server fails to deliver a document, it returns an HTML document stating so (which often also describes why and more). This flag will still allow curl to output and save that content but also to return error 22. This is an alternative option to -f, --fail which makes curl fail for the same circumstances but without saving the content. Providing --fail-with-body multiple times has no extra effect. Disable it again with --no-fail-with-body. Example: curl --fail-with-body https://example.com See also -f, --fail. This option is mutually exclusive to -f, --fail. Added in 7.76.0. -f, --fail (HTTP) Fail fast with no output at all on server errors. This is useful to enable scripts and users to better deal with failed attempts. In normal cases when an HTTP server fails to deliver a document, it returns an HTML document stating so (which often also describes why and more). This flag will prevent curl from outputting that and return error 22. This method is not fail-safe and there are occasions where non-successful response codes will slip through, especially when authentication is involved (response codes 401 and 407). Providing -f, --fail multiple times has no extra effect. Disable it again with --no-fail. Example: curl --fail https://example.com See also --fail-with-body. This option is mutually exclusive to --fail-with-body. --false-start (TLS) Tells curl to use false start during the TLS handshake. False start is a mode where a TLS client will start sending application data before verifying the server's Finished message, thus saving a round trip when performing a full handshake. This is currently only implemented in the NSS and Secure Transport (on iOS 7.0 or later, or OS X 10.9 or later) backends. Providing --false-start multiple times has no extra effect. Disable it again with --no-false-start. Example: curl --false-start https://example.com See also --tcp-fastopen. Added in 7.42.0. --form-escape (HTTP) Tells curl to pass on names of multipart form fields and files using backslash-escaping instead of percent-encoding. If --form-escape is provided several times, the last set value will be used. Example: curl --form-escape -F 'field\\name=curl' -F 'file=@load\"this' https://example.com See also -F, --form. Added in 7.81.0. --form-string <name=string> (HTTP SMTP IMAP) Similar to -F, --form except that the value string for the named parameter is used literally. Leading '@' and '<' characters, and the ';type=' string in the value have no special meaning. Use this in preference to -F, --form if there's any possibility that the string value may accidentally trigger the '@' or '<' features of -F, --form. --form-string can be used several times in a command line Example: curl --form-string \"data\" https://example.com See also -F, --form. -F, --form <name=content> (HTTP SMTP IMAP) For HTTP protocol family, this lets curl emulate a filled-in form in which a user has pressed the submit button. This causes curl to POST data using the Content-Type multipart/form-data according to RFC 2388. For SMTP and IMAP protocols, this is the means to compose a multipart mail message to transmit. This enables uploading of binary files etc. To force the 'content' part to be a file, prefix the file name with an @ sign. To just get the content part from a file, prefix the file name with the symbol <. The difference between @ and < is then that @ makes a file get attached in the post as a file upload, while the < makes a text field and just get the contents for that text field from a file. Tell curl to read content from stdin instead of a file by using - as filename. This goes for both @ and < constructs. When stdin is used, the contents is buffered in memory first by curl to determine its size and allow a possible resend. Defining a part's data from a named non- regular file (such as a named pipe or similar) is unfortunately not subject to buffering and will be effectively read at transmission time; since the full size is unknown before the transfer starts, such data is sent as chunks by HTTP and rejected by IMAP. Example: send an image to an HTTP server, where 'profile' is the name of the form-field to which the file portrait.jpg will be the input: curl -F profile=@portrait.jpg https://example.com/upload.cgi Example: send your name and shoe size in two text fields to the server: curl -F name=John -F shoesize=11 https://example.com/ Example: send your essay in a text field to the server. Send it as a plain text field, but get the contents for it from a local file: curl -F \"story=<hugefile.txt\" https://example.com/ You can also tell curl what Content-Type to use by using 'type=', in a manner similar to: curl -F \"web=@index.html;type=text/html\" example.com or curl -F \"name=daniel;type=text/foo\" example.com You can also explicitly change the name field of a file upload part by setting filename=, like this: curl -F \"file=@localfile;filename=nameinpost\" example.com If filename/path contains ',' or ';', it must be quoted by double-quotes like: curl -F \"file=@\\\"local,file\\\";filename=\\\"name;in;post\\\"\" example.com or curl -F 'file=@\"local,file\";filename=\"name;in;post\"' example.com Note that if a filename/path is quoted by double-quotes, any double-quote or backslash within the filename must be escaped by backslash. Quoting must also be applied to non-file data if it contains semicolons, leading/trailing spaces or leading double quotes: curl -F 'colors=\"red; green; blue\";type=text/x-myapp' example.com You can add custom headers to the field by setting headers=, like curl -F \"submit=OK;headers=\\\"X-submit-type: OK\\\"\" example.com or curl -F \"submit=OK;headers=@headerfile\" example.com The headers= keyword may appear more that once and above notes about quoting apply. When headers are read from a file, Empty lines and lines starting with '#' are comments and ignored; each header can be folded by splitting between two words and starting the continuation line with a space; embedded carriage-returns and trailing spaces are stripped. Here is an example of a header file contents: # This file contain two headers. X-header-1: this is a header # The following header is folded. X-header-2: this is another header To support sending multipart mail messages, the syntax is extended as follows: - name can be omitted: the equal sign is the first character of the argument, - if data starts with '(', this signals to start a new multipart: it can be followed by a content type specification. - a multipart can be terminated with a '=)' argument. Example: the following command sends an SMTP mime email consisting in an inline part in two alternative formats: plain text and HTML. It attaches a text file: curl -F '=(;type=multipart/alternative' \\ -F '=plain text message' \\ -F '= <body>HTML message</body>;type=text/html' \\ -F '=)' -F '=@textfile.txt' ... smtp://example.com Data can be encoded for transfer using encoder=. Available encodings are binary and 8bit that do nothing else than adding the corresponding Content-Transfer-Encoding header, 7bit that only rejects 8-bit characters with a transfer error, quoted-printable and base64 that encodes data according to the corresponding schemes, limiting lines length to 76 characters. Example: send multipart mail with a quoted-printable text message and a base64 attached file: curl -F '=text message;encoder=quoted-printable' \\ -F '=@localfile;encoder=base64' ... smtp://example.com See further examples and details in the MANUAL. -F, --form can be used several times in a command line Example: curl --form \"name=curl\" --form \"file=@loadthis\" https://example.com See also -d, --data, --form-string and --form-escape. This option is mutually exclusive to -d, --data and -I, --head and -T, --upload-file. --ftp-account <data> (FTP) When an FTP server asks for \"account data\" after user name and password has been provided, this data is sent off using the ACCT command. If --ftp-account is provided several times, the last set value will be used. Example: curl --ftp-account \"mr.robot\" ftp://example.com/ See also -u, --user. --ftp-alternative-to-user <command> (FTP) If authenticating with the USER and PASS commands fails, send this command. When connecting to Tumbleweed's Secure Transport server over FTPS using a client certificate, using \"SITE AUTH\" will tell the server to retrieve the username from the certificate. If --ftp-alternative-to-user is provided several times, the last set value will be used. Example: curl --ftp-alternative-to-user \"U53r\" ftp://example.com See also --ftp-account and -u, --user. --ftp-create-dirs (FTP SFTP) When an FTP or SFTP URL/operation uses a path that does not currently exist on the server, the standard behavior of curl is to fail. Using this option, curl will instead attempt to create missing directories. Providing --ftp-create-dirs multiple times has no extra effect. Disable it again with --no-ftp-create-dirs. Example: curl --ftp-create-dirs -T file ftp://example.com/remote/path/file See also --create-dirs. --ftp-method <method> (FTP) Control what method curl should use to reach a file on an FTP(S) server. The method argument should be one of the following alternatives: multicwd curl does a single CWD operation for each path part in the given URL. For deep hierarchies this means many commands. This is how RFC 1738 says it should be done. This is the default but the slowest behavior. nocwd curl does no CWD at all. curl will do SIZE, RETR, STOR etc and give a full path to the server for all these commands. This is the fastest behavior. singlecwd curl does one CWD with the full target directory and then operates on the file \"normally\" (like in the multicwd case). This is somewhat more standards compliant than 'nocwd' but without the full penalty of 'multicwd'. If --ftp-method is provided several times, the last set value will be used. Examples: curl --ftp-method multicwd ftp://example.com/dir1/dir2/file curl --ftp-method nocwd ftp://example.com/dir1/dir2/file curl --ftp-method singlecwd ftp://example.com/dir1/dir2/file See also -l, --list-only. --ftp-pasv (FTP) Use passive mode for the data connection. Passive is the internal default behavior, but using this option can be used to override a previous -P, --ftp-port option. Reversing an enforced passive really is not doable but you must then instead enforce the correct -P, --ftp-port again. Passive mode means that curl will try the EPSV command first and then PASV, unless --disable-epsv is used. Providing --ftp-pasv multiple times has no extra effect. Disable it again with --no-ftp-pasv. Example: curl --ftp-pasv ftp://example.com/ See also --disable-epsv. -P, --ftp-port <address> (FTP) Reverses the default initiator/listener roles when connecting with FTP. This option makes curl use active mode. curl then tells the server to connect back to the client's specified address and port, while passive mode asks the server to setup an IP address and port for it to connect to. <address> should be one of: interface e.g. \"eth0\" to specify which interface's IP address you want to use (Unix only) IP address e.g. \"192.168.10.1\" to specify the exact IP address host name e.g. \"my.host.domain\" to specify the machine - make curl pick the same IP address that is already used for the control connection Disable the use of PORT with --ftp-pasv. Disable the attempt to use the EPRT command instead of PORT by using --disable-eprt. EPRT is really PORT++. You can also append \":[start]-[end]\" to the right of the address, to tell curl what TCP port range to use. That means you specify a port range, from a lower to a higher number. A single number works as well, but do note that it increases the risk of failure since the port may not be available. If -P, --ftp-port is provided several times, the last set value will be used. Examples: curl -P - ftp:/example.com curl -P eth0 ftp:/example.com curl -P 192.168.0.2 ftp:/example.com See also --ftp-pasv and --disable-eprt. --ftp-pret (FTP) Tell curl to send a PRET command before PASV (and EPSV). Certain FTP servers, mainly drftpd, require this non-standard command for directory listings as well as up and downloads in PASV mode. Providing --ftp-pret multiple times has no extra effect. Disable it again with --no-ftp-pret. Example: curl --ftp-pret ftp://example.com/ See also -P, --ftp-port and --ftp-pasv. --ftp-skip-pasv-ip (FTP) Tell curl to not use the IP address the server suggests in its response to curl's PASV command when curl connects the data connection. Instead curl will re-use the same IP address it already uses for the control connection. Since curl 7.74.0 this option is enabled by default. This option has no effect if PORT, EPRT or EPSV is used instead of PASV. Providing --ftp-skip-pasv-ip multiple times has no extra effect. Disable it again with --no-ftp-skip-pasv-ip. Example: curl --ftp-skip-pasv-ip ftp://example.com/ See also --ftp-pasv. --ftp-ssl-ccc-mode <active/passive> (FTP) Sets the CCC mode. The passive mode will not initiate the shutdown, but instead wait for the server to do it, and will not reply to the shutdown from the server. The active mode initiates the shutdown and waits for a reply from the server. Providing --ftp-ssl-ccc-mode multiple times has no extra effect. Disable it again with --no-ftp-ssl-ccc-mode. Example: curl --ftp-ssl-ccc-mode active --ftp-ssl-ccc ftps://example.com/ See also --ftp-ssl-ccc. --ftp-ssl-ccc (FTP) Use CCC (Clear Command Channel) Shuts down the SSL/TLS layer after authenticating. The rest of the control channel communication will be unencrypted. This allows NAT routers to follow the FTP transaction. The default mode is passive. Providing --ftp-ssl-ccc multiple times has no extra effect. Disable it again with --no-ftp-ssl-ccc. Example: curl --ftp-ssl-ccc ftps://example.com/ See also --ssl and --ftp-ssl-ccc-mode. --ftp-ssl-control (FTP) Require SSL/TLS for the FTP login, clear for transfer. Allows secure authentication, but non-encrypted data transfers for efficiency. Fails the transfer if the server does not support SSL/TLS. Providing --ftp-ssl-control multiple times has no extra effect. Disable it again with --no-ftp-ssl-control. Example: curl --ftp-ssl-control ftp://example.com See also --ssl. -G, --get When used, this option will make all data specified with -d, --data, --data-binary or --data-urlencode to be used in an HTTP GET request instead of the POST request that otherwise would be used. The data will be appended to the URL with a '?' separator. If used in combination with -I, --head, the POST data will instead be appended to the URL with a HEAD request. Providing -G, --get multiple times has no extra effect. Disable it again with --no-get. Examples: curl --get https://example.com curl --get -d \"tool=curl\" -d \"age=old\" https://example.com curl --get -I -d \"tool=curl\" https://example.com See also -d, --data and -X, --request. -g, --globoff This option switches off the \"URL globbing parser\". When you set this option, you can specify URLs that contain the letters {}[] without having curl itself interpret them. Note that these letters are not normal legal URL contents but they should be encoded according to the URI standard. Providing -g, --globoff multiple times has no extra effect. Disable it again with --no-globoff. Example: curl -g \"https://example.com/{[]}}}}\" See also -K, --config and -q, --disable. --happy-eyeballs-timeout-ms <milliseconds> Happy Eyeballs is an algorithm that attempts to connect to both IPv4 and IPv6 addresses for dual-stack hosts, giving IPv6 a head-start of the specified number of milliseconds. If the IPv6 address cannot be connected to within that time, then a connection attempt is made to the IPv4 address in parallel. The first connection to be established is the one that is used. The range of suggested useful values is limited. Happy Eyeballs RFC 6555 says \"It is RECOMMENDED that connection attempts be paced 150-250 ms apart to balance human factors against network load.\" libcurl currently defaults to 200 ms. Firefox and Chrome currently default to 300 ms. If --happy-eyeballs-timeout-ms is provided several times, the last set value will be used. Example: curl --happy-eyeballs-timeout-ms 500 https://example.com See also -m, --max-time and --connect-timeout. Added in 7.59.0. --haproxy-clientip (HTTP) Sets a client IP in HAProxy PROXY protocol v1 header at the beginning of the connection. For valid requests, IPv4 addresses must be indicated as a series of exactly 4 integers in the range [0..255] inclusive written in decimal representation separated by exactly one dot between each other. Heading zeroes are not permitted in front of numbers in order to avoid any possible confusion with octal numbers. IPv6 addresses must be indicated as series of 4 hexadecimal digits (upper or lower case) delimited by colons between each other, with the acceptance of one double colon sequence to replace the largest acceptable range of consecutive zeroes. The total number of decoded bits must exactly be 128. Otherwise, any string can be accepted for the client IP and will be sent. It replaces `--haproxy-protocol` if used, it is not necessary to specify both flags. This option is primarily useful when sending test requests to verify a service is working as intended. If --haproxy-clientip is provided several times, the last set value will be used. Example: curl --haproxy-clientip $IP See also -x, --proxy. Added in 8.2.0. --haproxy-protocol (HTTP) Send a HAProxy PROXY protocol v1 header at the beginning of the connection. This is used by some load balancers and reverse proxies to indicate the client's true IP address and port. This option is primarily useful when sending test requests to a service that expects this header. Providing --haproxy-protocol multiple times has no extra effect. Disable it again with --no-haproxy-protocol. Example: curl --haproxy-protocol https://example.com See also -x, --proxy. Added in 7.60.0. -I, --head (HTTP FTP FILE) Fetch the headers only! HTTP-servers feature the command HEAD which this uses to get nothing but the header of a document. When used on an FTP or FILE file, curl displays the file size and last modification time only. Providing -I, --head multiple times has no extra effect. Disable it again with --no-head. Example: curl -I https://example.com See also -G, --get, -v, --verbose and --trace-ascii. -H, --header <header/@file> (HTTP IMAP SMTP) Extra header to include in information sent. When used within an HTTP request, it is added to the regular request headers. For an IMAP or SMTP MIME uploaded mail built with -F, --form options, it is prepended to the resulting MIME document, effectively including it at the mail global level. It does not affect raw uploaded mails (Added in 7.56.0). You may specify any number of extra headers. Note that if you should add a custom header that has the same name as one of the internal ones curl would use, your externally set header will be used instead of the internal one. This allows you to make even trickier stuff than curl would normally do. You should not replace internally set headers without knowing perfectly well what you are doing. Remove an internal header by giving a replacement without content on the right side of the colon, as in: -H \"Host:\". If you send the custom header with no-value then its header must be terminated with a semicolon, such as -H \"X-Custom- Header;\" to send \"X-Custom-Header:\". curl will make sure that each header you add/replace is sent with the proper end-of-line marker, you should thus not add that as a part of the header content: do not add newlines or carriage returns, they will only mess things up for you. This option can take an argument in @filename style, which then adds a header for each line in the input file. Using @- will make curl read the header file from stdin. Added in 7.55.0. Please note that most anti-spam utilities check the presence and value of several MIME mail headers: these are \"From:\", \"To:\", \"Date:\" and \"Subject:\" among others and should be added with this option. You need --proxy-header to send custom headers intended for an HTTP proxy. Added in 7.37.0. Passing on a \"Transfer-Encoding: chunked\" header when doing an HTTP request with a request body, will make curl send the data using chunked encoding. WARNING: headers set with this option will be set in all HTTP requests - even after redirects are followed, like when told with -L, --location. This can lead to the header being sent to other hosts than the original host, so sensitive headers should be used with caution combined with following redirects. -H, --header can be used several times in a command line Examples: curl -H \"X-First-Name: Joe\" https://example.com curl -H \"User-Agent: yes-please/2000\" https://example.com curl -H \"Host:\" https://example.com curl -H @headers.txt https://example.com See also -A, --user-agent and -e, --referer. -h, --help <category> Usage help. This lists all commands of the <category>. If no arg was provided, curl will display the most important command line arguments. If the argument \"all\" was provided, curl will display all options available. If the argument \"category\" was provided, curl will display all categories and their meanings. Example: curl --help all See also -v, --verbose. --hostpubmd5 <md5> (SFTP SCP) Pass a string containing 32 hexadecimal digits. The string should be the 128 bit MD5 checksum of the remote host's public key, curl will refuse the connection with the host unless the md5sums match. If --hostpubmd5 is provided several times, the last set value will be used. Example: curl --hostpubmd5 e5c1c49020640a5ab0f2034854c321a8 sftp://example.com/ See also --hostpubsha256. --hostpubsha256 <sha256> (SFTP SCP) Pass a string containing a Base64-encoded SHA256 hash of the remote host's public key. Curl will refuse the connection with the host unless the hashes match. This feature requires libcurl to be built with libssh2 and does not work with other SSH backends. If --hostpubsha256 is provided several times, the last set value will be used. Example: curl --hostpubsha256 NDVkMTQxMGQ1ODdmMjQ3MjczYjAyOTY5MmRkMjVmNDQ= sftp://example.com/ See also --hostpubmd5. Added in 7.80.0. --hsts <file name> (HTTPS) This option enables HSTS for the transfer. If the file name points to an existing HSTS cache file, that will be used. After a completed transfer, the cache will be saved to the file name again if it has been modified. If curl is told to use HTTP:// for a transfer involving a host name that exists in the HSTS cache, it upgrades the transfer to use HTTPS. Each HSTS cache entry has an individual life time after which the upgrade is no longer performed. Specify a \"\" file name (zero length) to avoid loading/saving and make curl just handle HSTS in memory. If this option is used several times, curl will load contents from all the files but the last one will be used for saving. --hsts can be used several times in a command line Example: curl --hsts cache.txt https://example.com See also --proto. Added in 7.74.0. --http0.9 (HTTP) Tells curl to be fine with HTTP version 0.9 response. HTTP/0.9 is a completely headerless response and therefore you can also connect with this to non-HTTP servers and still get a response since curl will simply transparently downgrade - if allowed. Since curl 7.66.0, HTTP/0.9 is disabled by default. Providing --http0.9 multiple times has no extra effect. Disable it again with --no-http0.9. Example: curl --http0.9 https://example.com See also --http1.1, --http2 and --http3. Added in 7.64.0. -0, --http1.0 (HTTP) Tells curl to use HTTP version 1.0 instead of using its internally preferred HTTP version. Providing -0, --http1.0 multiple times has no extra effect. Example: curl --http1.0 https://example.com See also --http0.9 and --http1.1. This option is mutually exclusive to --http1.1 and --http2 and --http2-prior- knowledge and --http3. --http1.1 (HTTP) Tells curl to use HTTP version 1.1. Providing --http1.1 multiple times has no extra effect. Example: curl --http1.1 https://example.com See also -0, --http1.0 and --http0.9. This option is mutually exclusive to -0, --http1.0 and --http2 and --http2-prior-knowledge and --http3. Added in 7.33.0. --http2-prior-knowledge (HTTP) Tells curl to issue its non-TLS HTTP requests using HTTP/2 without HTTP/1.1 Upgrade. It requires prior knowledge that the server supports HTTP/2 straight away. HTTPS requests will still do HTTP/2 the standard way with negotiated protocol version in the TLS handshake. Providing --http2-prior-knowledge multiple times has no extra effect. Disable it again with --no-http2-prior- knowledge. Example: curl --http2-prior-knowledge https://example.com See also --http2 and --http3. --http2-prior-knowledge requires that the underlying libcurl was built to support HTTP/2. This option is mutually exclusive to --http1.1 and -0, --http1.0 and --http2 and --http3. Added in 7.49.0. --http2 (HTTP) Tells curl to use HTTP version 2. For HTTPS, this means curl will attempt to negotiate HTTP/2 in the TLS handshake. curl does this by default. For HTTP, this means curl will attempt to upgrade the request to HTTP/2 using the Upgrade: request header. When curl uses HTTP/2 over HTTPS, it does not itself insist on TLS 1.2 or higher even though that is required by the specification. A user can add this version requirement with --tlsv1.2. Providing --http2 multiple times has no extra effect. Example: curl --http2 https://example.com See also --http1.1, --http3 and --no-alpn. --http2 requires that the underlying libcurl was built to support HTTP/2. This option is mutually exclusive to --http1.1 and -0, --http1.0 and --http2-prior-knowledge and --http3. Added in 7.33.0. --http3-only (HTTP) **WARNING**: this option is experimental. Do not use in production. Instructs curl to use HTTP/3 to the host in the URL, with no fallback to earlier HTTP versions. HTTP/3 can only be used for HTTPS and not for HTTP URLs. For HTTP, this option will trigger an error. This option allows a user to avoid using the Alt-Svc method of upgrading to HTTP/3 when you know that the target speaks HTTP/3 on the given host and port. This option will make curl fail if a QUIC connection cannot be established, it will not attempt any other HTTP version on its own. Use --http3 for similar functionality with a fallback. Providing --http3-only multiple times has no extra effect. Example: curl --http3-only https://example.com See also --http1.1, --http2 and --http3. --http3-only requires that the underlying libcurl was built to support HTTP/3. This option is mutually exclusive to --http1.1 and -0, --http1.0 and --http2 and --http2-prior-knowledge and --http3. Added in 7.88.0. --http3 (HTTP) **WARNING**: this option is experimental. Do not use in production. Tells curl to try HTTP/3 to the host in the URL, but fallback to earlier HTTP versions if the HTTP/3 connection establishment fails. HTTP/3 is only available for HTTPS and not for HTTP URLs. This option allows a user to avoid using the Alt-Svc method of upgrading to HTTP/3 when you know that the target speaks HTTP/3 on the given host and port. When asked to use HTTP/3, curl will issue a separate attempt to use older HTTP versions with a slight delay, so if the HTTP/3 transfer fails or is very slow, curl will still try to proceed with an older HTTP version. Use --http3-only for similar functionality without a fallback. Providing --http3 multiple times has no extra effect. Example: curl --http3 https://example.com See also --http1.1 and --http2. --http3 requires that the underlying libcurl was built to support HTTP/3. This option is mutually exclusive to --http1.1 and -0, --http1.0 and --http2 and --http2-prior-knowledge and --http3-only. Added in 7.66.0. --ignore-content-length (FTP HTTP) For HTTP, Ignore the Content-Length header. This is particularly useful for servers running Apache 1.x, which will report incorrect Content-Length for files larger than 2 gigabytes. For FTP (since 7.46.0), skip the RETR command to figure out the size before downloading a file. This option does not work for HTTP if libcurl was built to use hyper. Providing --ignore-content-length multiple times has no extra effect. Disable it again with --no-ignore-content- length. Example: curl --ignore-content-length https://example.com See also --ftp-skip-pasv-ip. -i, --include Include the HTTP response headers in the output. The HTTP response headers can include things like server name, cookies, date of the document, HTTP version and more... To view the request headers, consider the -v, --verbose option. Providing -i, --include multiple times has no extra effect. Disable it again with --no-include. Example: curl -i https://example.com See also -v, --verbose. -k, --insecure (TLS SFTP SCP) By default, every secure connection curl makes is verified to be secure before the transfer takes place. This option makes curl skip the verification step and proceed without checking. When this option is not used for protocols using TLS, curl verifies the server's TLS certificate before it continues: that the certificate contains the right name which matches the host name used in the URL and that the certificate has been signed by a CA certificate present in the cert store. See this online resource for further details: https://curl.se/docs/sslcerts.html For SFTP and SCP, this option makes curl skip the known_hosts verification. known_hosts is a file normally stored in the user's home directory in the \".ssh\" subdirectory, which contains host names and their public keys. WARNING: using this option makes the transfer insecure. When curl uses secure protocols it trusts responses and allows for example HSTS and Alt-Svc information to be stored and used subsequently. Using -k, --insecure can make curl trust and use such information from malicious servers. Providing -k, --insecure multiple times has no extra effect. Disable it again with --no-insecure. Example: curl --insecure https://example.com See also --proxy-insecure, --cacert and --capath. --interface <name> Perform an operation using a specified interface. You can enter interface name, IP address or host name. An example could look like: curl --interface eth0:1 https://www.example.com/ On Linux it can be used to specify a VRF, but the binary needs to either have CAP_NET_RAW or to be run as root. More information about Linux VRF: https://www.kernel.org/doc/Documentation/networking/vrf.txt If --interface is provided several times, the last set value will be used. Example: curl --interface eth0 https://example.com See also --dns-interface. -4, --ipv4 This option tells curl to use IPv4 addresses only when resolving host names, and not for example try IPv6. Providing -4, --ipv4 multiple times has no extra effect. Example: curl --ipv4 https://example.com See also --http1.1 and --http2. This option is mutually exclusive to -6, --ipv6. -6, --ipv6 This option tells curl to use IPv6 addresses only when resolving host names, and not for example try IPv4. Providing -6, --ipv6 multiple times has no extra effect. Example: curl --ipv6 https://example.com See also --http1.1 and --http2. This option is mutually exclusive to -4, --ipv4. --json <data> (HTTP) Sends the specified JSON data in a POST request to the HTTP server. --json works as a shortcut for passing on these three options: --data [arg] --header \"Content-Type: application/json\" --header \"Accept: application/json\" There is no verification that the passed in data is actual JSON or that the syntax is correct. If you start the data with the letter @, the rest should be a file name to read the data from, or a single dash (-) if you want curl to read the data from stdin. Posting data from a file named 'foobar' would thus be done with --json @foobar and to instead read the data from stdin, use --json @-. If this option is used more than once on the same command line, the additional data pieces will be concatenated to the previous before sending. The headers this option sets can be overridden with -H, --header as usual. --json can be used several times in a command line Examples: curl --json '{ \"drink\": \"coffe\" }' https://example.com curl --json '{ \"drink\":' --json ' \"coffe\" }' https://example.com curl --json @prepared https://example.com curl --json @- https://example.com < json.txt See also --data-binary and --data-raw. This option is mutually exclusive to -F, --form and -I, --head and -T, --upload-file. Added in 7.82.0. -j, --junk-session-cookies (HTTP) When curl is told to read cookies from a given file, this option will make it discard all \"session cookies\". This will basically have the same effect as if a new session is started. Typical browsers always discard session cookies when they are closed down. Providing -j, --junk-session-cookies multiple times has no extra effect. Disable it again with --no-junk-session- cookies. Example: curl --junk-session-cookies -b cookies.txt https://example.com See also -b, --cookie and -c, --cookie-jar. --keepalive-time <seconds> This option sets the time a connection needs to remain idle before sending keepalive probes and the time between individual keepalive probes. It is currently effective on operating systems offering the TCP_KEEPIDLE and TCP_KEEPINTVL socket options (meaning Linux, recent AIX, HP-UX and more). Keepalives are used by the TCP stack to detect broken networks on idle connections. The number of missed keepalive probes before declaring the connection down is OS dependent and is commonly 9 or 10. This option has no effect if --no-keepalive is used. If unspecified, the option defaults to 60 seconds. If --keepalive-time is provided several times, the last set value will be used. Example: curl --keepalive-time 20 https://example.com See also --no-keepalive and -m, --max-time. --key-type <type> (TLS) Private key file type. Specify which type your --key provided private key is. DER, PEM, and ENG are supported. If not specified, PEM is assumed. If --key-type is provided several times, the last set value will be used. Example: curl --key-type DER --key here https://example.com See also --key. --key <key> (TLS SSH) Private key file name. Allows you to provide your private key in this separate file. For SSH, if not specified, curl tries the following candidates in order: '~/.ssh/id_rsa', '~/.ssh/id_dsa', './id_rsa', './id_dsa'. If curl is built against OpenSSL library, and the engine pkcs11 is available, then a PKCS#11 URI (RFC 7512) can be used to specify a private key located in a PKCS#11 device. A string beginning with \"pkcs11:\" will be interpreted as a PKCS#11 URI. If a PKCS#11 URI is provided, then the --engine option will be set as \"pkcs11\" if none was provided and the --key-type option will be set as \"ENG\" if none was provided. If curl is built against Secure Transport or Schannel then this option is ignored for TLS protocols (HTTPS, etc). Those backends expect the private key to be already present in the keychain or PKCS#12 file containing the certificate. If --key is provided several times, the last set value will be used. Example: curl --cert certificate --key here https://example.com See also --key-type and -E, --cert. --krb <level> (FTP) Enable Kerberos authentication and use. The level must be entered and should be one of 'clear', 'safe', 'confidential', or 'private'. Should you use a level that is not one of these, 'private' will instead be used. If --krb is provided several times, the last set value will be used. Example: curl --krb clear ftp://example.com/ See also --delegation and --ssl. --krb requires that the underlying libcurl was built to support Kerberos. --libcurl <file> Append this option to any ordinary curl command line, and you will get libcurl-using C source code written to the file that does the equivalent of what your command-line operation does! This option is global and does not need to be specified for each use of --next. If --libcurl is provided several times, the last set value will be used. Example: curl --libcurl client.c https://example.com See also -v, --verbose. --limit-rate <speed> Specify the maximum transfer rate you want curl to use - for both downloads and uploads. This feature is useful if you have a limited pipe and you would like your transfer not to use your entire bandwidth. To make it slower than it otherwise would be. The given speed is measured in bytes/second, unless a suffix is appended. Appending 'k' or 'K' will count the number as kilobytes, 'm' or 'M' makes it megabytes, while 'g' or 'G' makes it gigabytes. The suffixes (k, M, G, T, P) are 1024 based. For example 1k is 1024. Examples: 200K, 3m and 1G. The rate limiting logic works on averaging the transfer speed to no more than the set threshold over a period of multiple seconds. If you also use the -Y, --speed-limit option, that option will take precedence and might cripple the rate-limiting slightly, to help keeping the speed-limit logic working. If --limit-rate is provided several times, the last set value will be used. Examples: curl --limit-rate 100K https://example.com curl --limit-rate 1000 https://example.com curl --limit-rate 10M https://example.com See also --rate, -Y, --speed-limit and -y, --speed-time. -l, --list-only (FTP POP3) (FTP) When listing an FTP directory, this switch forces a name-only view. This is especially useful if the user wants to machine-parse the contents of an FTP directory since the normal directory view does not use a standard look or format. When used like this, the option causes an NLST command to be sent to the server instead of LIST. Note: Some FTP servers list only files in their response to NLST; they do not include sub-directories and symbolic links. (POP3) When retrieving a specific email from POP3, this switch forces a LIST command to be performed instead of RETR. This is particularly useful if the user wants to see if a specific message-id exists on the server and what size it is. Note: When combined with -X, --request, this option can be used to send a UIDL command instead, so the user may use the email's unique identifier rather than its message-id to make the request. Providing -l, --list-only multiple times has no extra effect. Disable it again with --no-list-only. Example: curl --list-only ftp://example.com/dir/ See also -Q, --quote and -X, --request. --local-port <num/range> Set a preferred single number or range (FROM-TO) of local port numbers to use for the connection(s). Note that port numbers by nature are a scarce resource that will be busy at times so setting this range to something too narrow might cause unnecessary connection setup failures. If --local-port is provided several times, the last set value will be used. Example: curl --local-port 1000-3000 https://example.com See also -g, --globoff. --location-trusted (HTTP) Like -L, --location, but will allow sending the name + password to all hosts that the site may redirect to. This may or may not introduce a security breach if the site redirects you to a site to which you will send your authentication info (which is plaintext in the case of HTTP Basic authentication). Providing --location-trusted multiple times has no extra effect. Disable it again with --no-location-trusted. Example: curl --location-trusted -u user:password https://example.com See also -u, --user. -L, --location (HTTP) If the server reports that the requested page has moved to a different location (indicated with a Location: header and a 3XX response code), this option will make curl redo the request on the new place. If used together with -i, --include or -I, --head, headers from all requested pages will be shown. When authentication is used, curl only sends its credentials to the initial host. If a redirect takes curl to a different host, it will not be able to intercept the user+password. See also --location-trusted on how to change this. You can limit the amount of redirects to follow by using the --max- redirs option. When curl follows a redirect and if the request is a POST, it will send the following request with a GET if the HTTP response was 301, 302, or 303. If the response code was any other 3xx code, curl will re-send the following request using the same unmodified method. You can tell curl to not change POST requests to GET after a 30x response by using the dedicated options for that: --post301, --post302 and --post303. The method set with -X, --request overrides the method curl would otherwise select to use. Providing -L, --location multiple times has no extra effect. Disable it again with --no-location. Example: curl -L https://example.com See also --resolve and --alt-svc. --login-options <options> (IMAP LDAP POP3 SMTP) Specify the login options to use during server authentication. You can use login options to specify protocol specific options that may be used during authentication. At present only IMAP, POP3 and SMTP support login options. For more information about login options please see RFC 2384, RFC 5092 and IETF draft draft-earhart-url-smtp-00.txt Since 8.2.0, IMAP supports the login option \"AUTH=+LOGIN\". With this option, curl uses the plain (not SASL) LOGIN IMAP command even if the server advertises SASL authentication. Care should be taken in using this option, as it will send out your password in plain text. This will not work if the IMAP server disables the plain LOGIN (e.g. to prevent password snooping). If --login-options is provided several times, the last set value will be used. Example: curl --login-options 'AUTH=*' imap://example.com See also -u, --user. Added in 7.34.0. --mail-auth <address> (SMTP) Specify a single address. This will be used to specify the authentication address (identity) of a submitted message that is being relayed to another server. If --mail-auth is provided several times, the last set value will be used. Example: curl --mail-auth user@example.come -T mail smtp://example.com/ See also --mail-rcpt and --mail-from. --mail-from <address> (SMTP) Specify a single address that the given mail should get sent from. If --mail-from is provided several times, the last set value will be used. Example: curl --mail-from user@example.com -T mail smtp://example.com/ See also --mail-rcpt and --mail-auth. --mail-rcpt-allowfails (SMTP) When sending data to multiple recipients, by default curl will abort SMTP conversation if at least one of the recipients causes RCPT TO command to return an error. The default behavior can be changed by passing --mail- rcpt-allowfails command-line option which will make curl ignore errors and proceed with the remaining valid recipients. If all recipients trigger RCPT TO failures and this flag is specified, curl will still abort the SMTP conversation and return the error received from to the last RCPT TO command. Providing --mail-rcpt-allowfails multiple times has no extra effect. Disable it again with --no-mail-rcpt- allowfails. Example: curl --mail-rcpt-allowfails --mail-rcpt dest@example.com smtp://example.com See also --mail-rcpt. Added in 7.69.0. --mail-rcpt <address> (SMTP) Specify a single email address, user name or mailing list name. Repeat this option several times to send to multiple recipients. When performing an address verification (VRFY command), the recipient should be specified as the user name or user name and domain (as per Section 3.5 of RFC5321). (Added in 7.34.0) When performing a mailing list expand (EXPN command), the recipient should be specified using the mailing list name, such as \"Friends\" or \"London-Office\". (Added in 7.34.0) --mail-rcpt can be used several times in a command line Example: curl --mail-rcpt user@example.net smtp://example.com See also --mail-rcpt-allowfails. -M, --manual Manual. Display the huge help text. Example: curl --manual See also -v, --verbose, --libcurl and --trace. --max-filesize <bytes> (FTP HTTP MQTT) Specify the maximum size (in bytes) of a file to download. If the file requested is larger than this value, the transfer will not start and curl will return with exit code 63. A size modifier may be used. For example, Appending 'k' or 'K' will count the number as kilobytes, 'm' or 'M' makes it megabytes, while 'g' or 'G' makes it gigabytes. Examples: 200K, 3m and 1G. (Added in 7.58.0) NOTE: The file size is not always known prior to download, and for such files this option has no effect even if the file transfer ends up being larger than this given limit. If --max-filesize is provided several times, the last set value will be used. Example: curl --max-filesize 100K https://example.com See also --limit-rate. --max-redirs <num> (HTTP) Set maximum number of redirections to follow. When -L, --location is used, to prevent curl from following too many redirects, by default, the limit is set to 50 redirects. Set this option to -1 to make it unlimited. If --max-redirs is provided several times, the last set value will be used. Example: curl --max-redirs 3 --location https://example.com See also -L, --location. -m, --max-time <fractional seconds> Maximum time in seconds that you allow each transfer to take. This is useful for preventing your batch jobs from hanging for hours due to slow networks or links going down. Since 7.32.0, this option accepts decimal values, but the actual timeout will decrease in accuracy as the specified timeout increases in decimal precision. If you enable retrying the transfer (--retry) then the maximum time counter is reset each time the transfer is retried. You can use --retry-max-time to limit the retry time. The decimal value needs to provided using a dot (.) as decimal separator - not the local version even if it might be using another separator. If -m, --max-time is provided several times, the last set value will be used. Examples: curl --max-time 10 https://example.com curl --max-time 2.92 https://example.com See also --connect-timeout and --retry-max-time. --metalink This option was previously used to specify a metalink resource. Metalink support has been disabled in curl since 7.78.0 for security reasons. If --metalink is provided several times, the last set value will be used. Example: curl --metalink file https://example.com See also -Z, --parallel. --negotiate (HTTP) Enables Negotiate (SPNEGO) authentication. This option requires a library built with GSS-API or SSPI support. Use -V, --version to see if your curl supports GSS-API/SSPI or SPNEGO. When using this option, you must also provide a fake -u, --user option to activate the authentication code properly. Sending a '-u :' is enough as the user name and password from the -u, --user option are not actually used. If this option is used several times, only the first one is used. Providing --negotiate multiple times has no extra effect. Example: curl --negotiate -u : https://example.com See also --basic, --ntlm, --anyauth and --proxy-negotiate. --netrc-file <filename> This option is similar to -n, --netrc, except that you provide the path (absolute or relative) to the netrc file that curl should use. You can only specify one netrc file per invocation. It will abide by --netrc-optional if specified. If --netrc-file is provided several times, the last set value will be used. Example: curl --netrc-file netrc https://example.com See also -n, --netrc, -u, --user and -K, --config. This option is mutually exclusive to -n, --netrc. --netrc-optional Similar to -n, --netrc, but this option makes the .netrc usage optional and not mandatory as the -n, --netrc option does. Providing --netrc-optional multiple times has no extra effect. Disable it again with --no-netrc-optional. Example: curl --netrc-optional https://example.com See also --netrc-file. This option is mutually exclusive to -n, --netrc. -n, --netrc Makes curl scan the .netrc (_netrc on Windows) file in the user's home directory for login name and password. This is typically used for FTP on Unix. If used with HTTP, curl will enable user authentication. See netrc(5) and ftp(1) for details on the file format. Curl will not complain if that file does not have the right permissions (it should be neither world- nor group-readable). The environment variable \"HOME\" is used to find the home directory. A quick and simple example of how to setup a .netrc to allow curl to FTP to the machine host.domain.com with user name 'myself' and password 'secret' could look similar to: machine host.domain.com login myself password secret Providing -n, --netrc multiple times has no extra effect. Disable it again with --no-netrc. Example: curl --netrc https://example.com See also --netrc-file, -K, --config and -u, --user. This option is mutually exclusive to --netrc-file and --netrc- optional. -:, --next Tells curl to use a separate operation for the following URL and associated options. This allows you to send several URL requests, each with their own specific options, for example, such as different user names or custom requests for each. -:, --next will reset all local options and only global ones will have their values survive over to the operation following the -:, --next instruction. Global options include -v, --verbose, --trace, --trace-ascii and --fail- early. For example, you can do both a GET and a POST in a single command line: curl www1.example.com --next -d postthis www2.example.com -:, --next can be used several times in a command line Examples: curl https://example.com --next -d postthis www2.example.com curl -I https://example.com --next https://example.net/ See also -Z, --parallel and -K, --config. Added in 7.36.0. --no-alpn (HTTPS) Disable the ALPN TLS extension. ALPN is enabled by default if libcurl was built with an SSL library that supports ALPN. ALPN is used by a libcurl that supports HTTP/2 to negotiate HTTP/2 support with the server during https sessions. Providing --no-alpn multiple times has no extra effect. Disable it again with --alpn. Example: curl --no-alpn https://example.com See also --no-npn and --http2. --no-alpn requires that the underlying libcurl was built to support TLS. Added in 7.36.0. -N, --no-buffer Disables the buffering of the output stream. In normal work situations, curl will use a standard buffered output stream that will have the effect that it will output the data in chunks, not necessarily exactly when the data arrives. Using this option will disable that buffering. Providing -N, --no-buffer multiple times has no extra effect. Disable it again with --buffer. Example: curl --no-buffer https://example.com See also -#, --progress-bar. --no-clobber When used in conjunction with the -o, --output, -J, --remote-header-name, -O, --remote-name, or --remote-name- all options, curl avoids overwriting files that already exist. Instead, a dot and a number gets appended to the name of the file that would be created, up to filename.100 after which it will not create any file. Note that this is the negated option name documented. You can thus use --clobber to enforce the clobbering, even if -J, --remote-header-name is specified. Providing --no-clobber multiple times has no extra effect. Disable it again with --clobber. Example: curl --no-clobber --output local/dir/file https://example.com See also -o, --output and -O, --remote-name. Added in 7.83.0. --no-keepalive Disables the use of keepalive messages on the TCP connection. curl otherwise enables them by default. Note that this is the negated option name documented. You can thus use --keepalive to enforce keepalive. Providing --no-keepalive multiple times has no extra effect. Disable it again with --keepalive. Example: curl --no-keepalive https://example.com See also --keepalive-time. --no-npn (HTTPS) In curl 7.86.0 and later, curl never uses NPN. Disable the NPN TLS extension. NPN is enabled by default if libcurl was built with an SSL library that supports NPN. NPN is used by a libcurl that supports HTTP/2 to negotiate HTTP/2 support with the server during https sessions. Providing --no-npn multiple times has no extra effect. Disable it again with --npn. Example: curl --no-npn https://example.com See also --no-alpn and --http2. --no-npn requires that the underlying libcurl was built to support TLS. Added in 7.36.0. --no-progress-meter Option to switch off the progress meter output without muting or otherwise affecting warning and informational messages like -s, --silent does. Note that this is the negated option name documented. You can thus use --progress-meter to enable the progress meter again. Providing --no-progress-meter multiple times has no extra effect. Disable it again with --progress-meter. Example: curl --no-progress-meter -o store https://example.com See also -v, --verbose and -s, --silent. Added in 7.67.0. --no-sessionid (TLS) Disable curl's use of SSL session-ID caching. By default all transfers are done using the cache. Note that while nothing should ever get hurt by attempting to reuse SSL session-IDs, there seem to be broken SSL implementations in the wild that may require you to disable this in order for you to succeed. Note that this is the negated option name documented. You can thus use --sessionid to enforce session-ID caching. Providing --no-sessionid multiple times has no extra effect. Disable it again with --sessionid. Example: curl --no-sessionid https://example.com See also -k, --insecure. --noproxy <no-proxy-list> Comma-separated list of hosts for which not to use a proxy, if one is specified. The only wildcard is a single * character, which matches all hosts, and effectively disables the proxy. Each name in this list is matched as either a domain which contains the hostname, or the hostname itself. For example, local.com would match local.com, local.com:80, and www.local.com, but not www.notlocal.com. Since 7.53.0, This option overrides the environment variables that disable the proxy ('no_proxy' and 'NO_PROXY'). If there's an environment variable disabling a proxy, you can set the noproxy list to \"\" to override it. Since 7.86.0, IP addresses specified to this option can be provided using CIDR notation: an appended slash and number specifies the number of \"network bits\" out of the address to use in the comparison. For example \"192.168.0.0/16\" would match all addresses starting with \"192.168\". If --noproxy is provided several times, the last set value will be used. Example: curl --noproxy \"www.example\" https://example.com See also -x, --proxy. --ntlm-wb (HTTP) Enables NTLM much in the style --ntlm does, but hand over the authentication to the separate binary ntlmauth application that is executed when needed. Providing --ntlm-wb multiple times has no extra effect. Example: curl --ntlm-wb -u user:password https://example.com See also --ntlm and --proxy-ntlm. --ntlm (HTTP) Enables NTLM authentication. The NTLM authentication method was designed by Microsoft and is used by IIS web servers. It is a proprietary protocol, reverse-engineered by clever people and implemented in curl based on their efforts. This kind of behavior should not be endorsed, you should encourage everyone who uses NTLM to switch to a public and documented authentication method instead, such as Digest. If you want to enable NTLM for your proxy authentication, then use --proxy-ntlm. If this option is used several times, only the first one is used. Providing --ntlm multiple times has no extra effect. Example: curl --ntlm -u user:password https://example.com See also --proxy-ntlm. --ntlm requires that the underlying libcurl was built to support TLS. This option is mutually exclusive to --basic and --negotiate and --digest and --anyauth. --oauth2-bearer <token> (IMAP LDAP POP3 SMTP HTTP) Specify the Bearer Token for OAUTH 2.0 server authentication. The Bearer Token is used in conjunction with the user name which can be specified as part of the --url or -u, --user options. The Bearer Token and user name are formatted according to RFC 6750. If --oauth2-bearer is provided several times, the last set value will be used. Example: curl --oauth2-bearer \"mF_9.B5f-4.1JqM\" https://example.com See also --basic, --ntlm and --digest. Added in 7.33.0. --output-dir <dir> This option specifies the directory in which files should be stored, when -O, --remote-name or -o, --output are used. The given output directory is used for all URLs and output options on the command line, up until the first -:, --next. If the specified target directory does not exist, the operation will fail unless --create-dirs is also used. If --output-dir is provided several times, the last set value will be used. Example: curl --output-dir \"tmp\" -O https://example.com See also -O, --remote-name and -J, --remote-header-name. Added in 7.73.0. -o, --output <file> Write output to <file> instead of stdout. If you are using {} or [] to fetch multiple documents, you should quote the URL and you can use '#' followed by a number in the <file> specifier. That variable will be replaced with the current string for the URL being fetched. Like in: curl \"http://{one,two}.example.com\" -o \"file_#1.txt\" or use several variables like: curl \"http://{site,host}.host[1-5].com\" -o \"#1_#2\" You may use this option as many times as the number of URLs you have. For example, if you specify two URLs on the same command line, you can use it like this: curl -o aa example.com -o bb example.net and the order of the -o options and the URLs does not matter, just that the first -o is for the first URL and so on, so the above command line can also be written as curl example.com example.net -o aa -o bb See also the --create-dirs option to create the local directories dynamically. Specifying the output as '-' (a single dash) will force the output to be done to stdout. To suppress response bodies, you can redirect output to /dev/null: curl example.com -o /dev/null Or for Windows use nul: curl example.com -o nul -o, --output can be used several times in a command line Examples: curl -o file https://example.com curl \"http://{one,two}.example.com\" -o \"file_#1.txt\" curl \"http://{site,host}.host[1-5].com\" -o \"#1_#2\" curl -o file https://example.com -o file2 https://example.net See also -O, --remote-name, --remote-name-all and -J, --remote-header-name. --parallel-immediate When doing parallel transfers, this option will instruct curl that it should rather prefer opening up more connections in parallel at once rather than waiting to see if new transfers can be added as multiplexed streams on another connection. This option is global and does not need to be specified for each use of --next. Providing --parallel-immediate multiple times has no extra effect. Disable it again with --no-parallel-immediate. Example: curl --parallel-immediate -Z https://example.com -o file1 https://example.com -o file2 See also -Z, --parallel and --parallel-max. Added in 7.68.0. --parallel-max <num> When asked to do parallel transfers, using -Z, --parallel, this option controls the maximum amount of transfers to do simultaneously. This option is global and does not need to be specified for each use of -:, --next. The default is 50. If --parallel-max is provided several times, the last set value will be used. Example: curl --parallel-max 100 -Z https://example.com ftp://example.com/ See also -Z, --parallel. Added in 7.66.0. -Z, --parallel Makes curl perform its transfers in parallel as compared to the regular serial manner. This option is global and does not need to be specified for each use of --next. Providing -Z, --parallel multiple times has no extra effect. Disable it again with --no-parallel. Example: curl --parallel https://example.com -o file1 https://example.com -o file2 See also -:, --next and -v, --verbose. Added in 7.66.0. --pass <phrase> (SSH TLS) Passphrase for the private key. If --pass is provided several times, the last set value will be used. Example: curl --pass secret --key file https://example.com See also --key and -u, --user. --path-as-is Tell curl to not handle sequences of /../ or /./ in the given URL path. Normally curl will squash or merge them according to standards but with this option set you tell it not to do that. Providing --path-as-is multiple times has no extra effect. Disable it again with --no-path-as-is. Example: curl --path-as-is https://example.com/../../etc/passwd See also --request-target. Added in 7.42.0. --pinnedpubkey <hashes> (TLS) Tells curl to use the specified public key file (or hashes) to verify the peer. This can be a path to a file which contains a single public key in PEM or DER format, or any number of base64 encoded sha256 hashes preceded by 'sha256//' and separated by ';'. When negotiating a TLS or SSL connection, the server sends a certificate indicating its identity. A public key is extracted from this certificate and if it does not exactly match the public key provided to this option, curl will abort the connection before sending or receiving any data. PEM/DER support: 7.39.0: OpenSSL, GnuTLS and GSKit 7.43.0: NSS and wolfSSL 7.47.0: mbedtls sha256 support: 7.44.0: OpenSSL, GnuTLS, NSS and wolfSSL 7.47.0: mbedtls Other SSL backends not supported. If --pinnedpubkey is provided several times, the last set value will be used. Examples: curl --pinnedpubkey keyfile https://example.com curl --pinnedpubkey 'sha256//ce118b51897f4452dc' https://example.com See also --hostpubsha256. Added in 7.39.0. --post301 (HTTP) Tells curl to respect RFC 7231/6.4.2 and not convert POST requests into GET requests when following a 301 redirection. The non-RFC behavior is ubiquitous in web browsers, so curl does the conversion by default to maintain consistency. However, a server may require a POST to remain a POST after such a redirection. This option is meaningful only when using -L, --location. Providing --post301 multiple times has no extra effect. Disable it again with --no-post301. Example: curl --post301 --location -d \"data\" https://example.com See also --post302, --post303 and -L, --location. --post302 (HTTP) Tells curl to respect RFC 7231/6.4.3 and not convert POST requests into GET requests when following a 302 redirection. The non-RFC behavior is ubiquitous in web browsers, so curl does the conversion by default to maintain consistency. However, a server may require a POST to remain a POST after such a redirection. This option is meaningful only when using -L, --location. Providing --post302 multiple times has no extra effect. Disable it again with --no-post302. Example: curl --post302 --location -d \"data\" https://example.com See also --post301, --post303 and -L, --location. --post303 (HTTP) Tells curl to violate RFC 7231/6.4.4 and not convert POST requests into GET requests when following 303 redirections. A server may require a POST to remain a POST after a 303 redirection. This option is meaningful only when using -L, --location. Providing --post303 multiple times has no extra effect. Disable it again with --no-post303. Example: curl --post303 --location -d \"data\" https://example.com See also --post302, --post301 and -L, --location. --preproxy [protocol://]host[:port] Use the specified SOCKS proxy before connecting to an HTTP or HTTPS -x, --proxy. In such a case curl first connects to the SOCKS proxy and then connects (through SOCKS) to the HTTP or HTTPS proxy. Hence pre proxy. The pre proxy string should be specified with a protocol:// prefix to specify alternative proxy protocols. Use socks4://, socks4a://, socks5:// or socks5h:// to request the specific SOCKS version to be used. No protocol specified will make curl default to SOCKS4. If the port number is not specified in the proxy string, it is assumed to be 1080. User and password that might be provided in the proxy string are URL decoded by curl. This allows you to pass in special characters such as @ by using %40 or pass in a colon with %3a. If --preproxy is provided several times, the last set value will be used. Example: curl --preproxy socks5://proxy.example -x http://http.example https://example.com See also -x, --proxy and --socks5. Added in 7.52.0. -#, --progress-bar Make curl display transfer progress as a simple progress bar instead of the standard, more informational, meter. This progress bar draws a single line of '#' characters across the screen and shows a percentage if the transfer size is known. For transfers without a known size, there will be space ship (-=o=-) that moves back and forth but only while data is being transferred, with a set of flying hash sign symbols on top. This option is global and does not need to be specified for each use of --next. Providing -#, --progress-bar multiple times has no extra effect. Disable it again with --no-progress-bar. Example: curl -# -O https://example.com See also --styled-output. --proto-default <protocol> Tells curl to use protocol for any URL missing a scheme name. An unknown or unsupported protocol causes error CURLE_UNSUPPORTED_PROTOCOL (1). This option does not change the default proxy protocol (http). Without this option set, curl guesses protocol based on the host name, see --url for details. If --proto-default is provided several times, the last set value will be used. Example: curl --proto-default https ftp.example.com See also --proto and --proto-redir. Added in 7.45.0. --proto-redir <protocols> Tells curl to limit what protocols it may use on redirect. Protocols denied by --proto are not overridden by this option. See --proto for how protocols are represented. Example, allow only HTTP and HTTPS on redirect: curl --proto-redir -all,http,https http://example.com By default curl will only allow HTTP, HTTPS, FTP and FTPS on redirect (since 7.65.2). Specifying all or +all enables all protocols on redirects, which is not good for security. If --proto-redir is provided several times, the last set value will be used. Example: curl --proto-redir =http,https https://example.com See also --proto. --proto <protocols> Tells curl to limit what protocols it may use for transfers. Protocols are evaluated left to right, are comma separated, and are each a protocol name or 'all', optionally prefixed by zero or more modifiers. Available modifiers are: + Permit this protocol in addition to protocols already permitted (this is the default if no modifier is used). - Deny this protocol, removing it from the list of protocols already permitted. = Permit only this protocol (ignoring the list already permitted), though subject to later modification by subsequent entries in the comma separated list. For example: --proto -ftps uses the default protocols, but disables ftps --proto -all,https,+http only enables http and https --proto =http,https also only enables http and https Unknown and disabled protocols produce a warning. This allows scripts to safely rely on being able to disable potentially dangerous protocols, without relying upon support for that protocol being built into curl to avoid an error. This option can be used multiple times, in which case the effect is the same as concatenating the protocols into one instance of the option. If --proto is provided several times, the last set value will be used. Example: curl --proto =http,https,sftp https://example.com See also --proto-redir and --proto-default. --proxy-anyauth Tells curl to pick a suitable authentication method when communicating with the given HTTP proxy. This might cause an extra request/response round-trip. Providing --proxy-anyauth multiple times has no extra effect. Example: curl --proxy-anyauth --proxy-user user:passwd -x proxy https://example.com See also -x, --proxy, --proxy-basic and --proxy-digest. --proxy-basic Tells curl to use HTTP Basic authentication when communicating with the given proxy. Use --basic for enabling HTTP Basic with a remote host. Basic is the default authentication method curl uses with proxies. Providing --proxy-basic multiple times has no extra effect. Example: curl --proxy-basic --proxy-user user:passwd -x proxy https://example.com See also -x, --proxy, --proxy-anyauth and --proxy-digest. --proxy-ca-native (TLS) Tells curl to use the CA store from the native operating system to verify the HTTPS proxy. By default, curl will otherwise use a CA store provided in a single file or directory, but when using this option it will interface the operating system's own vault. This option only works for curl on Windows when built to use OpenSSL. When curl on Windows is built to use Schannel, this feature is implied and curl then only uses the native CA store. Providing --proxy-ca-native multiple times has no extra effect. Disable it again with --no-proxy-ca-native. Example: curl --ca-native https://example.com See also --cacert, --capath and -k, --insecure. Added in 8.2.0. --proxy-cacert <file> Same as --cacert but used in HTTPS proxy context. If --proxy-cacert is provided several times, the last set value will be used. Example: curl --proxy-cacert CA-file.txt -x https://proxy https://example.com See also --proxy-capath, --cacert, --capath and -x, --proxy. Added in 7.52.0. --proxy-capath <dir> Same as --capath but used in HTTPS proxy context. If --proxy-capath is provided several times, the last set value will be used. Example: curl --proxy-capath /local/directory -x https://proxy https://example.com See also --proxy-cacert, -x, --proxy and --capath. Added in 7.52.0. --proxy-cert-type <type> Same as --cert-type but used in HTTPS proxy context. If --proxy-cert-type is provided several times, the last set value will be used. Example: curl --proxy-cert-type PEM --proxy-cert file -x https://proxy https://example.com See also --proxy-cert. Added in 7.52.0. --proxy-cert <cert[:passwd]> Same as -E, --cert but used in HTTPS proxy context. If --proxy-cert is provided several times, the last set value will be used. Example: curl --proxy-cert file -x https://proxy https://example.com See also --proxy-cert-type. Added in 7.52.0. --proxy-ciphers <list> Same as --ciphers but used in HTTPS proxy context. If --proxy-ciphers is provided several times, the last set value will be used. Example: curl --proxy-ciphers ECDHE-ECDSA-AES256-CCM8 -x https://proxy https://example.com See also --ciphers, --curves and -x, --proxy. Added in 7.52.0. --proxy-crlfile <file> Same as --crlfile but used in HTTPS proxy context. If --proxy-crlfile is provided several times, the last set value will be used. Example: curl --proxy-crlfile rejects.txt -x https://proxy https://example.com See also --crlfile and -x, --proxy. Added in 7.52.0. --proxy-digest Tells curl to use HTTP Digest authentication when communicating with the given proxy. Use --digest for enabling HTTP Digest with a remote host. Providing --proxy-digest multiple times has no extra effect. Example: curl --proxy-digest --proxy-user user:passwd -x proxy https://example.com See also -x, --proxy, --proxy-anyauth and --proxy-basic. --proxy-header <header/@file> (HTTP) Extra header to include in the request when sending HTTP to a proxy. You may specify any number of extra headers. This is the equivalent option to -H, --header but is for proxy communication only like in CONNECT requests when you want a separate header sent to the proxy to what is sent to the actual remote host. curl will make sure that each header you add/replace is sent with the proper end-of-line marker, you should thus not add that as a part of the header content: do not add newlines or carriage returns, they will only mess things up for you. Headers specified with this option will not be included in requests that curl knows will not be sent to a proxy. Starting in 7.55.0, this option can take an argument in @filename style, which then adds a header for each line in the input file. Using @- will make curl read the header file from stdin. This option can be used multiple times to add/replace/remove multiple headers. --proxy-header can be used several times in a command line Examples: curl --proxy-header \"X-First-Name: Joe\" -x http://proxy https://example.com curl --proxy-header \"User-Agent: surprise\" -x http://proxy https://example.com curl --proxy-header \"Host:\" -x http://proxy https://example.com See also -x, --proxy. Added in 7.37.0. --proxy-http2 (HTTP) Tells curl to try negotiate HTTP version 2 with an HTTPS proxy. The proxy might still only offer HTTP/1 and then curl will stick to using that version. This has no effect for any other kinds of proxies. Providing --proxy-http2 multiple times has no extra effect. Disable it again with --no-proxy-http2. Example: curl --proxy-http2 -x proxy https://example.com See also -x, --proxy. --proxy-http2 requires that the underlying libcurl was built to support HTTP/2. Added in 8.1.0. --proxy-insecure Same as -k, --insecure but used in HTTPS proxy context. Providing --proxy-insecure multiple times has no extra effect. Disable it again with --no-proxy-insecure. Example: curl --proxy-insecure -x https://proxy https://example.com See also -x, --proxy and -k, --insecure. Added in 7.52.0. --proxy-key-type <type> Same as --key-type but used in HTTPS proxy context. If --proxy-key-type is provided several times, the last set value will be used. Example: curl --proxy-key-type DER --proxy-key here -x https://proxy https://example.com See also --proxy-key and -x, --proxy. Added in 7.52.0. --proxy-key <key> Same as --key but used in HTTPS proxy context. If --proxy-key is provided several times, the last set value will be used. Example: curl --proxy-key here -x https://proxy https://example.com See also --proxy-key-type and -x, --proxy. Added in 7.52.0. --proxy-negotiate Tells curl to use HTTP Negotiate (SPNEGO) authentication when communicating with the given proxy. Use --negotiate for enabling HTTP Negotiate (SPNEGO) with a remote host. Providing --proxy-negotiate multiple times has no extra effect. Example: curl --proxy-negotiate --proxy-user user:passwd -x proxy https://example.com See also --proxy-anyauth and --proxy-basic. --proxy-ntlm Tells curl to use HTTP NTLM authentication when communicating with the given proxy. Use --ntlm for enabling NTLM with a remote host. Providing --proxy-ntlm multiple times has no extra effect. Example: curl --proxy-ntlm --proxy-user user:passwd -x http://proxy https://example.com See also --proxy-negotiate and --proxy-anyauth. --proxy-pass <phrase> Same as --pass but used in HTTPS proxy context. If --proxy-pass is provided several times, the last set value will be used. Example: curl --proxy-pass secret --proxy-key here -x https://proxy https://example.com See also -x, --proxy and --proxy-key. Added in 7.52.0. --proxy-pinnedpubkey <hashes> (TLS) Tells curl to use the specified public key file (or hashes) to verify the proxy. This can be a path to a file which contains a single public key in PEM or DER format, or any number of base64 encoded sha256 hashes preceded by 'sha256//' and separated by ';'. When negotiating a TLS or SSL connection, the server sends a certificate indicating its identity. A public key is extracted from this certificate and if it does not exactly match the public key provided to this option, curl will abort the connection before sending or receiving any data. If --proxy-pinnedpubkey is provided several times, the last set value will be used. Examples: curl --proxy-pinnedpubkey keyfile https://example.com curl --proxy-pinnedpubkey 'sha256//ce118b51897f4452dc' https://example.com See also --pinnedpubkey and -x, --proxy. Added in 7.59.0. --proxy-service-name <name> This option allows you to change the service name for proxy negotiation. If --proxy-service-name is provided several times, the last set value will be used. Example: curl --proxy-service-name \"shrubbery\" -x proxy https://example.com See also --service-name and -x, --proxy. Added in 7.43.0. --proxy-ssl-allow-beast Same as --ssl-allow-beast but used in HTTPS proxy context. Providing --proxy-ssl-allow-beast multiple times has no extra effect. Disable it again with --no-proxy-ssl-allow- beast. Example: curl --proxy-ssl-allow-beast -x https://proxy https://example.com See also --ssl-allow-beast and -x, --proxy. Added in 7.52.0. --proxy-ssl-auto-client-cert Same as --ssl-auto-client-cert but used in HTTPS proxy context. Providing --proxy-ssl-auto-client-cert multiple times has no extra effect. Disable it again with --no-proxy-ssl- auto-client-cert. Example: curl --proxy-ssl-auto-client-cert -x https://proxy https://example.com See also --ssl-auto-client-cert and -x, --proxy. Added in 7.77.0. --proxy-tls13-ciphers <ciphersuite list> (TLS) Specifies which cipher suites to use in the connection to your HTTPS proxy when it negotiates TLS 1.3. The list of ciphers suites must specify valid ciphers. Read up on TLS 1.3 cipher suite details on this URL: https://curl.se/docs/ssl-ciphers.html This option is currently used only when curl is built to use OpenSSL 1.1.1 or later. If you are using a different SSL backend you can try setting TLS 1.3 cipher suites by using the --proxy-ciphers option. If --proxy-tls13-ciphers is provided several times, the last set value will be used. Example: curl --proxy-tls13-ciphers TLS_AES_128_GCM_SHA256 -x proxy https://example.com See also --tls13-ciphers and --curves. Added in 7.61.0. --proxy-tlsauthtype <type> Same as --tlsauthtype but used in HTTPS proxy context. If --proxy-tlsauthtype is provided several times, the last set value will be used. Example: curl --proxy-tlsauthtype SRP -x https://proxy https://example.com See also -x, --proxy and --proxy-tlsuser. Added in 7.52.0. --proxy-tlspassword <string> Same as --tlspassword but used in HTTPS proxy context. If --proxy-tlspassword is provided several times, the last set value will be used. Example: curl --proxy-tlspassword passwd -x https://proxy https://example.com See also -x, --proxy and --proxy-tlsuser. Added in 7.52.0. --proxy-tlsuser <name> Same as --tlsuser but used in HTTPS proxy context. If --proxy-tlsuser is provided several times, the last set value will be used. Example: curl --proxy-tlsuser smith -x https://proxy https://example.com See also -x, --proxy and --proxy-tlspassword. Added in 7.52.0. --proxy-tlsv1 Same as -1, --tlsv1 but used in HTTPS proxy context. Providing --proxy-tlsv1 multiple times has no extra effect. Example: curl --proxy-tlsv1 -x https://proxy https://example.com See also -x, --proxy. Added in 7.52.0. -U, --proxy-user <user:password> Specify the user name and password to use for proxy authentication. If you use a Windows SSPI-enabled curl binary and do either Negotiate or NTLM authentication then you can tell curl to select the user name and password from your environment by specifying a single colon with this option: \"-U :\". On systems where it works, curl will hide the given option argument from process listings. This is not enough to protect credentials from possibly getting seen by other users on the same system as they will still be visible for a moment before cleared. Such sensitive data should be retrieved from a file instead or similar and never used in clear text in a command line. If -U, --proxy-user is provided several times, the last set value will be used. Example: curl --proxy-user name:pwd -x proxy https://example.com See also --proxy-pass. -x, --proxy [protocol://]host[:port] Use the specified proxy. The proxy string can be specified with a protocol:// prefix. No protocol specified or http:// will be treated as HTTP proxy. Use socks4://, socks4a://, socks5:// or socks5h:// to request a specific SOCKS version to be used. Unix domain sockets are supported for socks proxy. Set localhost for the host part. e.g. socks5h://localhost/path/to/socket.sock HTTPS proxy support via https:// protocol prefix was added in 7.52.0 for OpenSSL, GnuTLS and NSS. Since 7.87.0, it also works for BearSSL, mbedTLS, rustls, Schannel, Secure Transport and wolfSSL. Unrecognized and unsupported proxy protocols cause an error since 7.52.0. Prior versions may ignore the protocol and use http:// instead. If the port number is not specified in the proxy string, it is assumed to be 1080. This option overrides existing environment variables that set the proxy to use. If there's an environment variable setting a proxy, you can set proxy to \"\" to override it. All operations that are performed over an HTTP proxy will transparently be converted to HTTP. It means that certain protocol specific operations might not be available. This is not the case if you can tunnel through the proxy, as one with the -p, --proxytunnel option. User and password that might be provided in the proxy string are URL decoded by curl. This allows you to pass in special characters such as @ by using %40 or pass in a colon with %3a. The proxy host can be specified the same way as the proxy environment variables, including the protocol prefix (http://) and the embedded user + password. When a proxy is used, the active FTP mode as set with -P, --ftp-port, cannot be used. If -x, --proxy is provided several times, the last set value will be used. Example: curl --proxy http://proxy.example https://example.com See also --socks5 and --proxy-basic. --proxy1.0 <host[:port]> Use the specified HTTP 1.0 proxy. If the port number is not specified, it is assumed at port 1080. The only difference between this and the HTTP proxy option -x, --proxy, is that attempts to use CONNECT through the proxy will specify an HTTP 1.0 protocol instead of the default HTTP 1.1. Providing --proxy1.0 multiple times has no extra effect. Example: curl --proxy1.0 -x http://proxy https://example.com See also -x, --proxy, --socks5 and --preproxy. -p, --proxytunnel When an HTTP proxy is used -x, --proxy, this option will make curl tunnel through the proxy. The tunnel approach is made with the HTTP proxy CONNECT request and requires that the proxy allows direct connect to the remote port number curl wants to tunnel through to. To suppress proxy CONNECT response headers when curl is set to output headers use --suppress-connect-headers. Providing -p, --proxytunnel multiple times has no extra effect. Disable it again with --no-proxytunnel. Example: curl --proxytunnel -x http://proxy https://example.com See also -x, --proxy. --pubkey <key> (SFTP SCP) Public key file name. Allows you to provide your public key in this separate file. (As of 7.39.0, curl attempts to automatically extract the public key from the private key file, so passing this option is generally not required. Note that this public key extraction requires libcurl to be linked against a copy of libssh2 1.2.8 or higher that is itself linked against OpenSSL.) If --pubkey is provided several times, the last set value will be used. Example: curl --pubkey file.pub sftp://example.com/ See also --pass. -Q, --quote <command> (FTP SFTP) Send an arbitrary command to the remote FTP or SFTP server. Quote commands are sent BEFORE the transfer takes place (just after the initial PWD command in an FTP transfer, to be exact). To make commands take place after a successful transfer, prefix them with a dash '-'. (FTP only) To make commands be sent after curl has changed the working directory, just before the file transfer command(s), prefix the command with a '+'. This is not performed when a directory listing is performed. You may specify any number of commands. By default curl will stop at first failure. To make curl continue even if the command fails, prefix the command with an asterisk (*). Otherwise, if the server returns failure for one of the commands, the entire operation will be aborted. You must send syntactically correct FTP commands as RFC 959 defines to FTP servers, or one of the commands listed below to SFTP servers. SFTP is a binary protocol. Unlike for FTP, curl interprets SFTP quote commands itself before sending them to the server. File names may be quoted shell-style to embed spaces or special characters. Following is the list of all supported SFTP quote commands: atime date file The atime command sets the last access time of the file named by the file operand. The <date expression> can be all sorts of date strings, see the curl_getdate(3) man page for date expression details. (Added in 7.73.0) chgrp group file The chgrp command sets the group ID of the file named by the file operand to the group ID specified by the group operand. The group operand is a decimal integer group ID. chmod mode file The chmod command modifies the file mode bits of the specified file. The mode operand is an octal integer mode number. chown user file The chown command sets the owner of the file named by the file operand to the user ID specified by the user operand. The user operand is a decimal integer user ID. ln source_file target_file The ln and symlink commands create a symbolic link at the target_file location pointing to the source_file location. mkdir directory_name The mkdir command creates the directory named by the directory_name operand. mtime date file The mtime command sets the last modification time of the file named by the file operand. The <date expression> can be all sorts of date strings, see the curl_getdate(3) man page for date expression details. (Added in 7.73.0) pwd The pwd command returns the absolute pathname of the current working directory. rename source target The rename command renames the file or directory named by the source operand to the destination path named by the target operand. rm file The rm command removes the file specified by the file operand. rmdir directory The rmdir command removes the directory entry specified by the directory operand, provided it is empty. symlink source_file target_file See ln. -Q, --quote can be used several times in a command line Example: curl --quote \"DELE file\" ftp://example.com/foo See also -X, --request. --random-file <file> Deprecated option. This option is ignored by curl since 7.84.0. Prior to that it only had an effect on curl if built to use old versions of OpenSSL. Specify the path name to file containing what will be considered as random data. The data may be used to seed the random engine for SSL connections. If --random-file is provided several times, the last set value will be used. Example: curl --random-file rubbish https://example.com See also --egd-file. -r, --range <range> (HTTP FTP SFTP FILE) Retrieve a byte range (i.e. a partial document) from an HTTP/1.1, FTP or SFTP server or a local FILE. Ranges can be specified in a number of ways. 0-499 specifies the first 500 bytes 500-999 specifies the second 500 bytes -500 specifies the last 500 bytes 9500- specifies the bytes from offset 9500 and forward 0-0,-1 specifies the first and last byte only(*)(HTTP) 100-199,500-599 specifies two separate 100-byte ranges(*) (HTTP) (*) = NOTE that this will cause the server to reply with a multipart response, which will be returned as-is by curl! Parsing or otherwise transforming this response is the responsibility of the caller. Only digit characters (0-9) are valid in the 'start' and 'stop' fields of the 'start-stop' range syntax. If a non- digit character is given in the range, the server's response will be unspecified, depending on the server's configuration. You should also be aware that many HTTP/1.1 servers do not have this feature enabled, so that when you attempt to get a range, you will instead get the whole document. FTP and SFTP range downloads only support the simple 'start-stop' syntax (optionally with one of the numbers omitted). FTP use depends on the extended FTP command SIZE. If -r, --range is provided several times, the last set value will be used. Example: curl --range 22-44 https://example.com See also -C, --continue-at and -a, --append. --rate <max request rate> Specify the maximum transfer frequency you allow curl to use - in number of transfer starts per time unit (sometimes called request rate). Without this option, curl will start the next transfer as fast as possible. If given several URLs and a transfer completes faster than the allowed rate, curl will wait until the next transfer is started to maintain the requested rate. This option has no effect when -Z, --parallel is used. The request rate is provided as \"N/U\" where N is an integer number and U is a time unit. Supported units are 's' (second), 'm' (minute), 'h' (hour) and 'd' /(day, as in a 24 hour unit). The default time unit, if no \"/U\" is provided, is number of transfers per hour. If curl is told to allow 10 requests per minute, it will not start the next request until 6 seconds have elapsed since the previous transfer was started. This function uses millisecond resolution. If the allowed frequency is set more than 1000 per second, it will instead run unrestricted. When retrying transfers, enabled with --retry, the separate retry delay logic is used and not this setting. This option is global and does not need to be specified for each use of --next. If --rate is provided several times, the last set value will be used. Examples: curl --rate 2/s https://example.com ... curl --rate 3/h https://example.com ... curl --rate 14/m https://example.com ... See also --limit-rate and --retry-delay. Added in 7.84.0. --raw (HTTP) When used, it disables all internal HTTP decoding of content or transfer encodings and instead makes them passed on unaltered, raw. Providing --raw multiple times has no extra effect. Disable it again with --no-raw. Example: curl --raw https://example.com See also --tr-encoding. -e, --referer <URL> (HTTP) Sends the \"Referrer Page\" information to the HTTP server. This can also be set with the -H, --header flag of course. When used with -L, --location you can append \";auto\" to the -e, --referer URL to make curl automatically set the previous URL when it follows a Location: header. The \";auto\" string can be used alone, even if you do not set an initial -e, --referer. If -e, --referer is provided several times, the last set value will be used. Examples: curl --referer \"https://fake.example\" https://example.com curl --referer \"https://fake.example;auto\" -L https://example.com curl --referer \";auto\" -L https://example.com See also -A, --user-agent and -H, --header. -J, --remote-header-name (HTTP) This option tells the -O, --remote-name option to use the server-specified Content-Disposition filename instead of extracting a filename from the URL. If the server-provided file name contains a path, that will be stripped off before the file name is used. The file is saved in the current directory, or in the directory specified with --output-dir. If the server specifies a file name and a file with that name already exists in the destination directory, it will not be overwritten and an error will occur - unless you allow it by using the --clobber option. If the server does not specify a file name then this option has no effect. There's no attempt to decode %-sequences (yet) in the provided file name, so this option may provide you with rather unexpected file names. This feature uses the name from the \"filename\" field, it does not yet support the \"filename*\" field (filenames with explicit character sets). WARNING: Exercise judicious use of this option, especially on Windows. A rogue server could send you the name of a DLL or other file that could be loaded automatically by Windows or some third party software. Providing -J, --remote-header-name multiple times has no extra effect. Disable it again with --no-remote-header- name. Example: curl -OJ https://example.com/file See also -O, --remote-name. --remote-name-all This option changes the default action for all given URLs to be dealt with as if -O, --remote-name were used for each one. So if you want to disable that for a specific URL after --remote-name-all has been used, you must use \"-o -\" or --no-remote-name. Providing --remote-name-all multiple times has no extra effect. Disable it again with --no-remote-name-all. Example: curl --remote-name-all ftp://example.com/file1 ftp://example.com/file2 See also -O, --remote-name. -O, --remote-name Write output to a local file named like the remote file we get. (Only the file part of the remote file is used, the path is cut off.) The file will be saved in the current working directory. If you want the file saved in a different directory, make sure you change the current working directory before invoking curl with this option or use --output-dir. The remote file name to use for saving is extracted from the given URL, nothing else, and if it already exists it will be overwritten. If you want the server to be able to choose the file name refer to -J, --remote-header-name which can be used in addition to this option. If the server chooses a file name and that name already exists it will not be overwritten. There is no URL decoding done on the file name. If it has %20 or other URL encoded parts of the name, they will end up as-is as file name. You may use this option as many times as the number of URLs you have. -O, --remote-name can be used several times in a command line Example: curl -O https://example.com/filename See also --remote-name-all, --output-dir and -J, --remote- header-name. -R, --remote-time When used, this will make curl attempt to figure out the timestamp of the remote file, and if that is available make the local file get that same timestamp. Providing -R, --remote-time multiple times has no extra effect. Disable it again with --no-remote-time. Example: curl --remote-time -o foo https://example.com See also -O, --remote-name and -z, --time-cond. --remove-on-error When curl returns an error when told to save output in a local file, this option removes that saved file before exiting. This prevents curl from leaving a partial file in the case of an error during transfer. If the output is not a file, this option has no effect. Providing --remove-on-error multiple times has no extra effect. Disable it again with --no-remove-on-error. Example: curl --remove-on-error -o output https://example.com See also -f, --fail. Added in 7.83.0. --request-target <path> (HTTP) Tells curl to use an alternative \"target\" (path) instead of using the path as provided in the URL. Particularly useful when wanting to issue HTTP requests without leading slash or other data that does not follow the regular URL pattern, like \"OPTIONS *\". If --request-target is provided several times, the last set value will be used. Example: curl --request-target \"*\" -X OPTIONS https://example.com See also -X, --request. Added in 7.55.0. -X, --request <method> (HTTP) Specifies a custom request method to use when communicating with the HTTP server. The specified request method will be used instead of the method otherwise used (which defaults to GET). Read the HTTP 1.1 specification for details and explanations. Common additional HTTP requests include PUT and DELETE, but related technologies like WebDAV offers PROPFIND, COPY, MOVE and more. Normally you do not need this option. All sorts of GET, HEAD, POST and PUT requests are rather invoked by using dedicated command line options. This option only changes the actual word used in the HTTP request, it does not alter the way curl behaves. So for example if you want to make a proper HEAD request, using -X HEAD will not suffice. You need to use the -I, --head option. The method string you set with -X, --request will be used for all requests, which if you for example use -L, --location may cause unintended side-effects when curl does not change request method according to the HTTP 30x response codes - and similar. (FTP) Specifies a custom FTP command to use instead of LIST when doing file lists with FTP. (POP3) Specifies a custom POP3 command to use instead of LIST or RETR. (IMAP) Specifies a custom IMAP command to use instead of LIST. (Added in 7.30.0) (SMTP) Specifies a custom SMTP command to use instead of HELP or VRFY. (Added in 7.34.0) If -X, --request is provided several times, the last set value will be used. Examples: curl -X \"DELETE\" https://example.com curl -X NLST ftp://example.com/ See also --request-target. --resolve <[+]host:port:addr[,addr]...> Provide a custom address for a specific host and port pair. Using this, you can make the curl requests(s) use a specified address and prevent the otherwise normally resolved address to be used. Consider it a sort of /etc/hosts alternative provided on the command line. The port number should be the number used for the specific protocol the host will be used for. It means you need several entries if you want to provide address for the same host but different ports. By specifying '*' as host you can tell curl to resolve any host and specific port pair to the specified address. Wildcard is resolved last so any --resolve with a specific host and port will be used first. The provided address set by this option will be used even if -4, --ipv4 or -6, --ipv6 is set to make curl use another IP version. By prefixing the host with a '+' you can make the entry time out after curl's default timeout (1 minute). Note that this will only make sense for long running parallel transfers with a lot of files. In such cases, if this option is used curl will try to resolve the host as it normally would once the timeout has expired. Support for providing the IP address within [brackets] was added in 7.57.0. Support for providing multiple IP addresses per entry was added in 7.59.0. Support for resolving with wildcard was added in 7.64.0. Support for the '+' prefix was was added in 7.75.0. This option can be used many times to add many host names to resolve. --resolve can be used several times in a command line Example: curl --resolve example.com:443:127.0.0.1 https://example.com See also --connect-to and --alt-svc. --retry-all-errors Retry on any error. This option is used together with --retry. This option is the \"sledgehammer\" of retrying. Do not use this option by default (eg in curlrc), there may be unintended consequences such as sending or receiving duplicate data. Do not use with redirected input or output. You'd be much better off handling your unique problems in shell script. Please read the example below. WARNING: For server compatibility curl attempts to retry failed flaky transfers as close as possible to how they were started, but this is not possible with redirected input or output. For example, before retrying it removes output data from a failed partial transfer that was written to an output file. However this is not true of data redirected to a | pipe or > file, which are not reset. We strongly suggest you do not parse or record output via redirect in combination with this option, since you may receive duplicate data. By default curl will not error on an HTTP response code that indicates an HTTP error, if the transfer was successful. For example, if a server replies 404 Not Found and the reply is fully received then that is not an error. When --retry is used then curl will retry on some HTTP response codes that indicate transient HTTP errors, but that does not include most 4xx response codes such as 404. If you want to retry on all response codes that indicate HTTP errors (4xx and 5xx) then combine with -f, --fail. Providing --retry-all-errors multiple times has no extra effect. Disable it again with --no-retry-all-errors. Example: curl --retry 5 --retry-all-errors https://example.com See also --retry. Added in 7.71.0. --retry-connrefused In addition to the other conditions, consider ECONNREFUSED as a transient error too for --retry. This option is used together with --retry. Providing --retry-connrefused multiple times has no extra effect. Disable it again with --no-retry-connrefused. Example: curl --retry-connrefused --retry 7 https://example.com See also --retry and --retry-all-errors. Added in 7.52.0. --retry-delay <seconds> Make curl sleep this amount of time before each retry when a transfer has failed with a transient error (it changes the default backoff time algorithm between retries). This option is only interesting if --retry is also used. Setting this delay to zero will make curl use the default backoff time. If --retry-delay is provided several times, the last set value will be used. Example: curl --retry-delay 5 --retry 7 https://example.com See also --retry. --retry-max-time <seconds> The retry timer is reset before the first transfer attempt. Retries will be done as usual (see --retry) as long as the timer has not reached this given limit. Notice that if the timer has not reached the limit, the request will be made and while performing, it may take longer than this given time period. To limit a single request's maximum time, use -m, --max-time. Set this option to zero to not timeout retries. If --retry-max-time is provided several times, the last set value will be used. Example: curl --retry-max-time 30 --retry 10 https://example.com See also --retry. --retry <num> If a transient error is returned when curl tries to perform a transfer, it will retry this number of times before giving up. Setting the number to 0 makes curl do no retries (which is the default). Transient error means either: a timeout, an FTP 4xx response code or an HTTP 408, 429, 500, 502, 503 or 504 response code. When curl is about to retry a transfer, it will first wait one second and then for all forthcoming retries it will double the waiting time until it reaches 10 minutes which then will be the delay between the rest of the retries. By using --retry-delay you disable this exponential backoff algorithm. See also --retry-max-time to limit the total time allowed for retries. Since curl 7.66.0, curl will comply with the Retry-After: response header if one was present to know when to issue the next retry. If --retry is provided several times, the last set value will be used. Example: curl --retry 7 https://example.com See also --retry-max-time. --sasl-authzid <identity> Use this authorization identity (authzid), during SASL PLAIN authentication, in addition to the authentication identity (authcid) as specified by -u, --user. If the option is not specified, the server will derive the authzid from the authcid, but if specified, and depending on the server implementation, it may be used to access another user's inbox, that the user has been granted access to, or a shared mailbox for example. If --sasl-authzid is provided several times, the last set value will be used. Example: curl --sasl-authzid zid imap://example.com/ See also --login-options. Added in 7.66.0. --sasl-ir Enable initial response in SASL authentication. Providing --sasl-ir multiple times has no extra effect. Disable it again with --no-sasl-ir. Example: curl --sasl-ir imap://example.com/ See also --sasl-authzid. Added in 7.31.0. --service-name <name> This option allows you to change the service name for SPNEGO. Examples: --negotiate --service-name sockd would use sockd/server-name. If --service-name is provided several times, the last set value will be used. Example: curl --service-name sockd/server https://example.com See also --negotiate and --proxy-service-name. Added in 7.43.0. -S, --show-error When used with -s, --silent, it makes curl show an error message if it fails. This option is global and does not need to be specified for each use of --next. Providing -S, --show-error multiple times has no extra effect. Disable it again with --no-show-error. Example: curl --show-error --silent https://example.com See also --no-progress-meter. -s, --silent Silent or quiet mode. Do not show progress meter or error messages. Makes Curl mute. It will still output the data you ask for, potentially even to the terminal/stdout unless you redirect it. Use -S, --show-error in addition to this option to disable progress meter but still show error messages. Providing -s, --silent multiple times has no extra effect. Disable it again with --no-silent. Example: curl -s https://example.com See also -v, --verbose, --stderr and --no-progress-meter. --socks4 <host[:port]> Use the specified SOCKS4 proxy. If the port number is not specified, it is assumed at port 1080. Using this socket type make curl resolve the host name and passing the address on to the proxy. To specify proxy on a unix domain socket, use localhost for host, e.g. socks4://localhost/path/to/socket.sock This option overrides any previous use of -x, --proxy, as they are mutually exclusive. This option is superfluous since you can specify a socks4 proxy with -x, --proxy using a socks4:// protocol prefix. Since 7.52.0, --preproxy can be used to specify a SOCKS proxy at the same time -x, --proxy is used with an HTTP/HTTPS proxy. In such a case curl first connects to the SOCKS proxy and then connects (through SOCKS) to the HTTP or HTTPS proxy. If --socks4 is provided several times, the last set value will be used. Example: curl --socks4 hostname:4096 https://example.com See also --socks4a, --socks5 and --socks5-hostname. --socks4a <host[:port]> Use the specified SOCKS4a proxy. If the port number is not specified, it is assumed at port 1080. This asks the proxy to resolve the host name. To specify proxy on a unix domain socket, use localhost for host, e.g. socks4a://localhost/path/to/socket.sock This option overrides any previous use of -x, --proxy, as they are mutually exclusive. This option is superfluous since you can specify a socks4a proxy with -x, --proxy using a socks4a:// protocol prefix. Since 7.52.0, --preproxy can be used to specify a SOCKS proxy at the same time -x, --proxy is used with an HTTP/HTTPS proxy. In such a case curl first connects to the SOCKS proxy and then connects (through SOCKS) to the HTTP or HTTPS proxy. If --socks4a is provided several times, the last set value will be used. Example: curl --socks4a hostname:4096 https://example.com See also --socks4, --socks5 and --socks5-hostname. --socks5-basic Tells curl to use username/password authentication when connecting to a SOCKS5 proxy. The username/password authentication is enabled by default. Use --socks5-gssapi to force GSS-API authentication to SOCKS5 proxies. Providing --socks5-basic multiple times has no extra effect. Example: curl --socks5-basic --socks5 hostname:4096 https://example.com See also --socks5. Added in 7.55.0. --socks5-gssapi-nec As part of the GSS-API negotiation a protection mode is negotiated. RFC 1961 says in section 4.3/4.4 it should be protected, but the NEC reference implementation does not. The option --socks5-gssapi-nec allows the unprotected exchange of the protection mode negotiation. Providing --socks5-gssapi-nec multiple times has no extra effect. Disable it again with --no-socks5-gssapi-nec. Example: curl --socks5-gssapi-nec --socks5 hostname:4096 https://example.com See also --socks5. --socks5-gssapi-service <name> The default service name for a socks server is rcmd/server-fqdn. This option allows you to change it. Examples: --socks5 proxy-name --socks5-gssapi-service sockd would use sockd/proxy-name --socks5 proxy-name --socks5-gssapi-service sockd/real-name would use sockd/real-name for cases where the proxy-name does not match the principal name. If --socks5-gssapi-service is provided several times, the last set value will be used. Example: curl --socks5-gssapi-service sockd --socks5 hostname:4096 https://example.com See also --socks5. --socks5-gssapi Tells curl to use GSS-API authentication when connecting to a SOCKS5 proxy. The GSS-API authentication is enabled by default (if curl is compiled with GSS-API support). Use --socks5-basic to force username/password authentication to SOCKS5 proxies. Providing --socks5-gssapi multiple times has no extra effect. Disable it again with --no-socks5-gssapi. Example: curl --socks5-gssapi --socks5 hostname:4096 https://example.com See also --socks5. Added in 7.55.0. --socks5-hostname <host[:port]> Use the specified SOCKS5 proxy (and let the proxy resolve the host name). If the port number is not specified, it is assumed at port 1080. To specify proxy on a unix domain socket, use localhost for host, e.g. socks5h://localhost/path/to/socket.sock This option overrides any previous use of -x, --proxy, as they are mutually exclusive. This option is superfluous since you can specify a socks5 hostname proxy with -x, --proxy using a socks5h:// protocol prefix. Since 7.52.0, --preproxy can be used to specify a SOCKS proxy at the same time -x, --proxy is used with an HTTP/HTTPS proxy. In such a case curl first connects to the SOCKS proxy and then connects (through SOCKS) to the HTTP or HTTPS proxy. If --socks5-hostname is provided several times, the last set value will be used. Example: curl --socks5-hostname proxy.example:7000 https://example.com See also --socks5 and --socks4a. --socks5 <host[:port]> Use the specified SOCKS5 proxy - but resolve the host name locally. If the port number is not specified, it is assumed at port 1080. To specify proxy on a unix domain socket, use localhost for host, e.g. socks5://localhost/path/to/socket.sock This option overrides any previous use of -x, --proxy, as they are mutually exclusive. This option is superfluous since you can specify a socks5 proxy with -x, --proxy using a socks5:// protocol prefix. Since 7.52.0, --preproxy can be used to specify a SOCKS proxy at the same time -x, --proxy is used with an HTTP/HTTPS proxy. In such a case curl first connects to the SOCKS proxy and then connects (through SOCKS) to the HTTP or HTTPS proxy. This option (as well as --socks4) does not work with IPV6, FTPS or LDAP. If --socks5 is provided several times, the last set value will be used. Example: curl --socks5 proxy.example:7000 https://example.com See also --socks5-hostname and --socks4a. -Y, --speed-limit <speed> If a transfer is slower than this given speed (in bytes per second) for speed-time seconds it gets aborted. speed- time is set with -y, --speed-time and is 30 if not set. If -Y, --speed-limit is provided several times, the last set value will be used. Example: curl --speed-limit 300 --speed-time 10 https://example.com See also -y, --speed-time, --limit-rate and -m, --max- time. -y, --speed-time <seconds> If a transfer runs slower than speed-limit bytes per second during a speed-time period, the transfer is aborted. If speed-time is used, the default speed-limit will be 1 unless set with -Y, --speed-limit. This option controls transfers (in both directions) but will not affect slow connects etc. If this is a concern for you, try the --connect-timeout option. If -y, --speed-time is provided several times, the last set value will be used. Example: curl --speed-limit 300 --speed-time 10 https://example.com See also -Y, --speed-limit and --limit-rate. --ssl-allow-beast This option tells curl to not work around a security flaw in the SSL3 and TLS1.0 protocols known as BEAST. If this option is not used, the SSL layer may use workarounds known to cause interoperability problems with some older SSL implementations. WARNING: this option loosens the SSL security, and by using this flag you ask for exactly that. Providing --ssl-allow-beast multiple times has no extra effect. Disable it again with --no-ssl-allow-beast. Example: curl --ssl-allow-beast https://example.com See also --proxy-ssl-allow-beast and -k, --insecure. --ssl-auto-client-cert Tell libcurl to automatically locate and use a client certificate for authentication, when requested by the server. This option is only supported for Schannel (the native Windows SSL library). Prior to 7.77.0 this was the default behavior in libcurl with Schannel. Since the server can request any certificate that supports client authentication in the OS certificate store it could be a privacy violation and unexpected. Providing --ssl-auto-client-cert multiple times has no extra effect. Disable it again with --no-ssl-auto-client- cert. Example: curl --ssl-auto-client-cert https://example.com See also --proxy-ssl-auto-client-cert. Added in 7.77.0. --ssl-no-revoke (Schannel) This option tells curl to disable certificate revocation checks. WARNING: this option loosens the SSL security, and by using this flag you ask for exactly that. Providing --ssl-no-revoke multiple times has no extra effect. Disable it again with --no-ssl-no-revoke. Example: curl --ssl-no-revoke https://example.com See also --crlfile. Added in 7.44.0. --ssl-reqd (FTP IMAP POP3 SMTP LDAP) Require SSL/TLS for the connection. Terminates the connection if the transfer cannot be upgraded to use SSL/TLS. This option is handled in LDAP since version 7.81.0. It is fully supported by the OpenLDAP backend and rejected by the generic ldap backend if explicit TLS is required. This option is unnecessary if you use a URL scheme that in itself implies immediate and implicit use of TLS, like for FTPS, IMAPS, POP3S, SMTPS and LDAPS. Such transfers will always fail if the TLS handshake does not work. This option was formerly known as --ftp-ssl-reqd. Providing --ssl-reqd multiple times has no extra effect. Disable it again with --no-ssl-reqd. Example: curl --ssl-reqd ftp://example.com See also --ssl and -k, --insecure. --ssl-revoke-best-effort (Schannel) This option tells curl to ignore certificate revocation checks when they failed due to missing/offline distribution points for the revocation check lists. Providing --ssl-revoke-best-effort multiple times has no extra effect. Disable it again with --no-ssl-revoke-best- effort. Example: curl --ssl-revoke-best-effort https://example.com See also --crlfile and -k, --insecure. Added in 7.70.0. --ssl (FTP IMAP POP3 SMTP LDAP) Warning: this is considered an insecure option. Consider using --ssl-reqd instead to be sure curl upgrades to a secure connection. Try to use SSL/TLS for the connection. Reverts to a non- secure connection if the server does not support SSL/TLS. See also --ftp-ssl-control and --ssl-reqd for different levels of encryption required. This option is handled in LDAP since version 7.81.0. It is fully supported by the OpenLDAP backend and ignored by the generic ldap backend. Please note that a server may close the connection if the negotiation does not succeed. This option was formerly known as --ftp-ssl. That option name can still be used but will be removed in a future version. Providing --ssl multiple times has no extra effect. Disable it again with --no-ssl. Example: curl --ssl pop3://example.com/ See also --ssl-reqd, -k, --insecure and --ciphers. -2, --sslv2 (SSL) This option previously asked curl to use SSLv2, but starting in curl 7.77.0 this instruction is ignored. SSLv2 is widely considered insecure (see RFC 6176). Providing -2, --sslv2 multiple times has no extra effect. Example: curl --sslv2 https://example.com See also --http1.1 and --http2. -2, --sslv2 requires that the underlying libcurl was built to support TLS. This option is mutually exclusive to -3, --sslv3 and -1, --tlsv1 and --tlsv1.1 and --tlsv1.2. -3, --sslv3 (SSL) This option previously asked curl to use SSLv3, but starting in curl 7.77.0 this instruction is ignored. SSLv3 is widely considered insecure (see RFC 7568). Providing -3, --sslv3 multiple times has no extra effect. Example: curl --sslv3 https://example.com See also --http1.1 and --http2. -3, --sslv3 requires that the underlying libcurl was built to support TLS. This option is mutually exclusive to -2, --sslv2 and -1, --tlsv1 and --tlsv1.1 and --tlsv1.2. --stderr <file> Redirect all writes to stderr to the specified file instead. If the file name is a plain '-', it is instead written to stdout. This option is global and does not need to be specified for each use of --next. If --stderr is provided several times, the last set value will be used. Example: curl --stderr output.txt https://example.com See also -v, --verbose and -s, --silent. --styled-output Enables the automatic use of bold font styles when writing HTTP headers to the terminal. Use --no-styled-output to switch them off. Styled output requires a terminal that supports bold fonts. This feature is not present on curl for Windows due to lack of this capability. This option is global and does not need to be specified for each use of --next. Providing --styled-output multiple times has no extra effect. Disable it again with --no-styled-output. Example: curl --styled-output -I https://example.com See also -I, --head and -v, --verbose. Added in 7.61.0. --suppress-connect-headers When -p, --proxytunnel is used and a CONNECT request is made do not output proxy CONNECT response headers. This option is meant to be used with -D, --dump-header or -i, --include which are used to show protocol headers in the output. It has no effect on debug options such as -v, --verbose or --trace, or any statistics. Providing --suppress-connect-headers multiple times has no extra effect. Disable it again with --no-suppress- connect-headers. Example: curl --suppress-connect-headers --include -x proxy https://example.com See also -D, --dump-header, -i, --include and -p, --proxytunnel. Added in 7.54.0. --tcp-fastopen Enable use of TCP Fast Open (RFC7413). Providing --tcp-fastopen multiple times has no extra effect. Disable it again with --no-tcp-fastopen. Example: curl --tcp-fastopen https://example.com See also --false-start. Added in 7.49.0. --tcp-nodelay Turn on the TCP_NODELAY option. See the curl_easy_setopt(3) man page for details about this option. Since 7.50.2, curl sets this option by default and you need to explicitly switch it off if you do not want it on. Providing --tcp-nodelay multiple times has no extra effect. Disable it again with --no-tcp-nodelay. Example: curl --tcp-nodelay https://example.com See also -N, --no-buffer. -t, --telnet-option <opt=val> Pass options to the telnet protocol. Supported options are: TTYPE=<term> Sets the terminal type. XDISPLOC=<X display> Sets the X display location. NEW_ENV=<var,val> Sets an environment variable. -t, --telnet-option can be used several times in a command line Example: curl -t TTYPE=vt100 telnet://example.com/ See also -K, --config. --tftp-blksize <value> (TFTP) Set TFTP BLKSIZE option (must be >512). This is the block size that curl will try to use when transferring data to or from a TFTP server. By default 512 bytes will be used. If --tftp-blksize is provided several times, the last set value will be used. Example: curl --tftp-blksize 1024 tftp://example.com/file See also --tftp-no-options. --tftp-no-options (TFTP) Tells curl not to send TFTP options requests. This option improves interop with some legacy servers that do not acknowledge or properly implement TFTP options. When this option is used --tftp-blksize is ignored. Providing --tftp-no-options multiple times has no extra effect. Disable it again with --no-tftp-no-options. Example: curl --tftp-no-options tftp://192.168.0.1/ See also --tftp-blksize. Added in 7.48.0. -z, --time-cond <time> (HTTP FTP) Request a file that has been modified later than the given time and date, or one that has been modified before that time. The <date expression> can be all sorts of date strings or if it does not match any internal ones, it is taken as a filename and tries to get the modification date (mtime) from <file> instead. See the curl_getdate(3) man pages for date expression details. Start the date expression with a dash (-) to make it request for a document that is older than the given date/time, default is a document that is newer than the specified date/time. If -z, --time-cond is provided several times, the last set value will be used. Examples: curl -z \"Wed 01 Sep 2021 12:18:00\" https://example.com curl -z \"-Wed 01 Sep 2021 12:18:00\" https://example.com curl -z file https://example.com See also --etag-compare and -R, --remote-time. --tls-max <VERSION> (SSL) VERSION defines maximum supported TLS version. The minimum acceptable version is set by tlsv1.0, tlsv1.1, tlsv1.2 or tlsv1.3. If the connection is done without TLS, this option has no effect. This includes QUIC-using (HTTP/3) transfers. default Use up to recommended TLS version. 1.0 Use up to TLSv1.0. 1.1 Use up to TLSv1.1. 1.2 Use up to TLSv1.2. 1.3 Use up to TLSv1.3. If --tls-max is provided several times, the last set value will be used. Examples: curl --tls-max 1.2 https://example.com curl --tls-max 1.3 --tlsv1.2 https://example.com See also --tlsv1.0, --tlsv1.1, --tlsv1.2 and --tlsv1.3. --tls-max requires that the underlying libcurl was built to support TLS. Added in 7.54.0. --tls13-ciphers <ciphersuite list> (TLS) Specifies which cipher suites to use in the connection if it negotiates TLS 1.3. The list of ciphers suites must specify valid ciphers. Read up on TLS 1.3 cipher suite details on this URL: https://curl.se/docs/ssl-ciphers.html This option is currently used only when curl is built to use OpenSSL 1.1.1 or later or Schannel. If you are using a different SSL backend you can try setting TLS 1.3 cipher suites by using the --ciphers option. If --tls13-ciphers is provided several times, the last set value will be used. Example: curl --tls13-ciphers TLS_AES_128_GCM_SHA256 https://example.com See also --ciphers and --curves. Added in 7.61.0. --tlsauthtype <type> Set TLS authentication type. Currently, the only supported option is \"SRP\", for TLS-SRP (RFC 5054). If --tlsuser and --tlspassword are specified but --tlsauthtype is not, then this option defaults to \"SRP\". This option works only if the underlying libcurl is built with TLS-SRP support, which requires OpenSSL or GnuTLS with TLS-SRP support. If --tlsauthtype is provided several times, the last set value will be used. Example: curl --tlsauthtype SRP https://example.com See also --tlsuser. --tlspassword <string> Set password for use with the TLS authentication method specified with --tlsauthtype. Requires that --tlsuser also be set. This option does not work with TLS 1.3. If --tlspassword is provided several times, the last set value will be used. Example: curl --tlspassword pwd --tlsuser user https://example.com See also --tlsuser. --tlsuser <name> Set username for use with the TLS authentication method specified with --tlsauthtype. Requires that --tlspassword also is set. This option does not work with TLS 1.3. If --tlsuser is provided several times, the last set value will be used. Example: curl --tlspassword pwd --tlsuser user https://example.com See also --tlspassword. --tlsv1.0 (TLS) Forces curl to use TLS version 1.0 or later when connecting to a remote TLS server. In old versions of curl this option was documented to allow _only_ TLS 1.0. That behavior was inconsistent depending on the TLS library. Use --tls-max if you want to set a maximum TLS version. Providing --tlsv1.0 multiple times has no extra effect. Example: curl --tlsv1.0 https://example.com See also --tlsv1.3. Added in 7.34.0. --tlsv1.1 (TLS) Forces curl to use TLS version 1.1 or later when connecting to a remote TLS server. In old versions of curl this option was documented to allow _only_ TLS 1.1. That behavior was inconsistent depending on the TLS library. Use --tls-max if you want to set a maximum TLS version. Providing --tlsv1.1 multiple times has no extra effect. Example: curl --tlsv1.1 https://example.com See also --tlsv1.3 and --tls-max. Added in 7.34.0. --tlsv1.2 (TLS) Forces curl to use TLS version 1.2 or later when connecting to a remote TLS server. In old versions of curl this option was documented to allow _only_ TLS 1.2. That behavior was inconsistent depending on the TLS library. Use --tls-max if you want to set a maximum TLS version. Providing --tlsv1.2 multiple times has no extra effect. Example: curl --tlsv1.2 https://example.com See also --tlsv1.3 and --tls-max. Added in 7.34.0. --tlsv1.3 (TLS) Forces curl to use TLS version 1.3 or later when connecting to a remote TLS server. If the connection is done without TLS, this option has no effect. This includes QUIC-using (HTTP/3) transfers. Note that TLS 1.3 is not supported by all TLS backends. Providing --tlsv1.3 multiple times has no extra effect. Example: curl --tlsv1.3 https://example.com See also --tlsv1.2 and --tls-max. Added in 7.52.0. -1, --tlsv1 (SSL) Tells curl to use at least TLS version 1.x when negotiating with a remote TLS server. That means TLS version 1.0 or higher Providing -1, --tlsv1 multiple times has no extra effect. Example: curl --tlsv1 https://example.com See also --http1.1 and --http2. -1, --tlsv1 requires that the underlying libcurl was built to support TLS. This option is mutually exclusive to --tlsv1.1 and --tlsv1.2 and --tlsv1.3. --tr-encoding (HTTP) Request a compressed Transfer-Encoding response using one of the algorithms curl supports, and uncompress the data while receiving it. Providing --tr-encoding multiple times has no extra effect. Disable it again with --no-tr-encoding. Example: curl --tr-encoding https://example.com See also --compressed. --trace-ascii <file> Enables a full trace dump of all incoming and outgoing data, including descriptive information, to the given output file. Use \"-\" as filename to have the output sent to stdout. This is similar to --trace, but leaves out the hex part and only shows the ASCII part of the dump. It makes smaller output that might be easier to read for untrained humans. This option is global and does not need to be specified for each use of --next. If --trace-ascii is provided several times, the last set value will be used. Example: curl --trace-ascii log.txt https://example.com See also -v, --verbose and --trace. This option is mutually exclusive to --trace and -v, --verbose. --trace-ids Prepends the transfer and connection identifiers to each trace or verbose line that curl displays. This option is global and does not need to be specified for each use of --next. Providing --trace-ids multiple times has no extra effect. Disable it again with --no-trace-ids. Example: curl --trace-ids --trace-ascii output https://example.com See also --trace and -v, --verbose. Added in 8.2.0. --trace-time Prepends a time stamp to each trace or verbose line that curl displays. This option is global and does not need to be specified for each use of --next. Providing --trace-time multiple times has no extra effect. Disable it again with --no-trace-time. Example: curl --trace-time --trace-ascii output https://example.com See also --trace and -v, --verbose. --trace <file> Enables a full trace dump of all incoming and outgoing data, including descriptive information, to the given output file. Use \"-\" as filename to have the output sent to stdout. Use \"%\" as filename to have the output sent to stderr. This option is global and does not need to be specified for each use of --next. If --trace is provided several times, the last set value will be used. Example: curl --trace log.txt https://example.com See also --trace-ascii, --trace-ids and --trace-time. This option is mutually exclusive to -v, --verbose and --trace- ascii. --unix-socket <path> (HTTP) Connect through this Unix domain socket, instead of using the network. If --unix-socket is provided several times, the last set value will be used. Example: curl --unix-socket socket-path https://example.com See also --abstract-unix-socket. Added in 7.40.0. -T, --upload-file <file> This transfers the specified local file to the remote URL. If there is no file part in the specified URL, curl will append the local file name. NOTE that you must use a trailing / on the last directory to really prove to Curl that there is no file name or curl will think that your last directory name is the remote file name to use. That will most likely cause the upload operation to fail. If this is used on an HTTP(S) server, the PUT command will be used. Use the file name \"-\" (a single dash) to use stdin instead of a given file. Alternately, the file name \".\" (a single period) may be specified instead of \"-\" to use stdin in non-blocking mode to allow reading server output while stdin is being uploaded. You can specify one -T, --upload-file for each URL on the command line. Each -T, --upload-file + URL pair specifies what to upload and to where. curl also supports \"globbing\" of the -T, --upload-file argument, meaning that you can upload multiple files to a single URL by using the same URL globbing style supported in the URL. When uploading to an SMTP server: the uploaded data is assumed to be RFC 5322 formatted. It has to feature the necessary set of headers and mail body formatted correctly by the user as curl will not transcode nor encode it further in any way. -T, --upload-file can be used several times in a command line Examples: curl -T file https://example.com curl -T \"img[1-1000].png\" ftp://ftp.example.com/ curl --upload-file \"{file1,file2}\" https://example.com See also -G, --get and -I, --head. --url-query <data> (all) This option adds a piece of data, usually a name + value pair, to the end of the URL query part. The syntax is identical to that used for --data-urlencode with one extension: If the argument starts with a '+' (plus), the rest of the string is provided as-is unencoded. The query part of a URL is the one following the question mark on the right end. --url-query can be used several times in a command line Examples: curl --url-query name=val https://example.com curl --url-query =encodethis http://example.net/foo curl --url-query name@file https://example.com curl --url-query @fileonly https://example.com curl --url-query \"+name=%20foo\" https://example.com See also --data-urlencode and -G, --get. Added in 7.87.0. --url <url> Specify a URL to fetch. This option is mostly handy when you want to specify URL(s) in a config file. If the given URL is missing a scheme name (such as \"http://\" or \"ftp://\" etc) then curl will make a guess based on the host. If the outermost sub-domain name matches DICT, FTP, IMAP, LDAP, POP3 or SMTP then that protocol will be used, otherwise HTTP will be used. Since 7.45.0 guessing can be disabled by setting a default protocol, see --proto-default for details. To control where this URL is written, use the -o, --output or the -O, --remote-name options. WARNING: On Windows, particular file:// accesses can be converted to network accesses by the operating system. Beware! --url can be used several times in a command line Example: curl --url https://example.com See also -:, --next and -K, --config. -B, --use-ascii (FTP LDAP) Enable ASCII transfer. For FTP, this can also be enforced by using a URL that ends with \";type=A\". This option causes data sent to stdout to be in text mode for win32 systems. Providing -B, --use-ascii multiple times has no extra effect. Disable it again with --no-use-ascii. Example: curl -B ftp://example.com/README See also --crlf and --data-ascii. -A, --user-agent <name> (HTTP) Specify the User-Agent string to send to the HTTP server. To encode blanks in the string, surround the string with single quote marks. This header can also be set with the -H, --header or the --proxy-header options. If you give an empty argument to -A, --user-agent (\"\"), it will remove the header completely from the request. If you prefer a blank header, you can set it to a single space (\" \"). If -A, --user-agent is provided several times, the last set value will be used. Example: curl -A \"Agent 007\" https://example.com See also -H, --header and --proxy-header. -u, --user <user:password> Specify the user name and password to use for server authentication. Overrides -n, --netrc and --netrc- optional. If you simply specify the user name, curl will prompt for a password. The user name and passwords are split up on the first colon, which makes it impossible to use a colon in the user name with this option. The password can, still. On systems where it works, curl will hide the given option argument from process listings. This is not enough to protect credentials from possibly getting seen by other users on the same system as they will still be visible for a moment before cleared. Such sensitive data should be retrieved from a file instead or similar and never used in clear text in a command line. When using Kerberos V5 with a Windows based server you should include the Windows domain name in the user name, in order for the server to successfully obtain a Kerberos Ticket. If you do not, then the initial authentication handshake may fail. When using NTLM, the user name can be specified simply as the user name, without the domain, if there is a single domain and forest in your setup for example. To specify the domain name use either Down-Level Logon Name or UPN (User Principal Name) formats. For example, EXAMPLE\\user and user@example.com respectively. If you use a Windows SSPI-enabled curl binary and perform Kerberos V5, Negotiate, NTLM or Digest authentication then you can tell curl to select the user name and password from your environment by specifying a single colon with this option: \"-u :\". If -u, --user is provided several times, the last set value will be used. Example: curl -u user:secret https://example.com See also -n, --netrc and -K, --config. -v, --verbose Makes curl verbose during the operation. Useful for debugging and seeing what's going on \"under the hood\". A line starting with '>' means \"header data\" sent by curl, '<' means \"header data\" received by curl that is hidden in normal cases, and a line starting with '*' means additional info provided by curl. If you only want HTTP headers in the output, -i, --include or -D, --dump-header might be more suitable options. If you think this option still does not give you enough details, consider using --trace or --trace-ascii instead. This option is global and does not need to be specified for each use of --next. Providing -v, --verbose multiple times has no extra effect. Disable it again with --no-verbose. Example: curl --verbose https://example.com See also -i, --include, -s, --silent, --trace and --trace- ascii. This option is mutually exclusive to --trace and --trace-ascii. -V, --version Displays information about curl and the libcurl version it uses. The first line includes the full version of curl, libcurl and other 3rd party libraries linked with the executable. The second line (starts with \"Protocols:\") shows all protocols that libcurl reports to support. The third line (starts with \"Features:\") shows specific features libcurl reports to offer. Available features include: alt-svc Support for the Alt-Svc: header is provided. AsynchDNS This curl uses asynchronous name resolves. Asynchronous name resolves can be done using either the c-ares or the threaded resolver backends. brotli Support for automatic brotli compression over HTTP(S). CharConv curl was built with support for character set conversions (like EBCDIC) Debug This curl uses a libcurl built with Debug. This enables more error-tracking and memory debugging etc. For curl-developers only! gsasl The built-in SASL authentication includes extensions to support SCRAM because libcurl was built with libgsasl. GSS-API GSS-API is supported. HSTS HSTS support is present. HTTP2 HTTP/2 support has been built-in. HTTP3 HTTP/3 support has been built-in. HTTPS-proxy This curl is built to support HTTPS proxy. IDN This curl supports IDN - international domain names. IPv6 You can use IPv6 with this. Kerberos Kerberos V5 authentication is supported. Largefile This curl supports transfers of large files, files larger than 2GB. libz Automatic decompression (via gzip, deflate) of compressed files over HTTP is supported. MultiSSL This curl supports multiple TLS backends. NTLM NTLM authentication is supported. NTLM_WB NTLM delegation to winbind helper is supported. PSL PSL is short for Public Suffix List and means that this curl has been built with knowledge about \"public suffixes\". SPNEGO SPNEGO authentication is supported. SSL SSL versions of various protocols are supported, such as HTTPS, FTPS, POP3S and so on. SSPI SSPI is supported. TLS-SRP SRP (Secure Remote Password) authentication is supported for TLS. TrackMemory Debug memory tracking is supported. Unicode Unicode support on Windows. UnixSockets Unix sockets support is provided. zstd Automatic decompression (via zstd) of compressed files over HTTP is supported. Example: curl --version See also -h, --help and -M, --manual. -w, --write-out <format> Make curl display information on stdout after a completed transfer. The format is a string that may contain plain text mixed with any number of variables. The format can be specified as a literal \"string\", or you can have curl read the format from a file with \"@filename\" and to tell curl to read the format from stdin you write \"@-\". The variables present in the output format will be substituted by the value or text that curl thinks fit, as described below. All variables are specified as %{variable_name} and to output a normal % you just write them as %%. You can output a newline by using \\n, a carriage return with \\r and a tab space with \\t. The output will be written to standard output, but this can be switched to standard error by using %{stderr}. Output HTTP headers from the most recent request by using %header{name} where name is the case insensitive name of the header (without the trailing colon). The header contents are exactly as sent over the network, with leading and trailing whitespace trimmed. Added in curl 7.84.0. NOTE: In Windows the %-symbol is a special symbol used to expand environment variables. In batch files all occurrences of % must be doubled when using this option to properly escape. If this option is used at the command prompt then the % cannot be escaped and unintended expansion is possible. The variables available are: certs Output the certificate chain with details. Supported only by the OpenSSL, GnuTLS, Schannel, NSS, GSKit and Secure Transport backends. (Added in 7.88.0) content_type The Content-Type of the requested document, if there was any. errormsg The error message. (Added in 7.75.0) exitcode The numerical exitcode of the transfer. (Added in 7.75.0) filename_effective The ultimate filename that curl writes out to. This is only meaningful if curl is told to write to a file with the -O, --remote-name or -o, --output option. It's most useful in combination with the -J, --remote-header-name option. ftp_entry_path The initial path curl ended up in when logging on to the remote FTP server. header_json A JSON object with all HTTP response headers from the recent transfer. Values are provided as arrays, since in the case of multiple headers there can be multiple values. (Added in 7.83.0) The header names provided in lowercase, listed in order of appearance over the wire. Except for duplicated headers. They are grouped on the first occurrence of that header, each value is presented in the JSON array. http_code The numerical response code that was found in the last retrieved HTTP(S) or FTP(s) transfer. http_connect The numerical code that was found in the last response (from a proxy) to a curl CONNECT request. http_version The http version that was effectively used. (Added in 7.50.0) json A JSON object with all available keys. local_ip The IP address of the local end of the most recently done connection - can be either IPv4 or IPv6. local_port The local port number of the most recently done connection. method The http method used in the most recent HTTP request. (Added in 7.72.0) num_certs Number of server certificates received in the TLS handshake. Supported only by the OpenSSL, GnuTLS, Schannel, NSS, GSKit and Secure Transport backends. (Added in 7.88.0) num_connects Number of new connects made in the recent transfer. num_headers The number of response headers in the most recent request (restarted at each redirect). Note that the status line IS NOT a header. (Added in 7.73.0) num_redirects Number of redirects that were followed in the request. onerror The rest of the output is only shown if the transfer returned a non-zero error. (Added in 7.75.0) proxy_ssl_verify_result The result of the HTTPS proxy's SSL peer certificate verification that was requested. 0 means the verification was successful. (Added in 7.52.0) redirect_url When an HTTP request was made without -L, --location to follow redirects (or when --max- redirs is met), this variable will show the actual URL a redirect would have gone to. referer The Referer: header, if there was any. (Added in 7.76.0) remote_ip The remote IP address of the most recently done connection - can be either IPv4 or IPv6. remote_port The remote port number of the most recently done connection. response_code The numerical response code that was found in the last transfer (formerly known as \"http_code\"). scheme The URL scheme (sometimes called protocol) that was effectively used. (Added in 7.52.0) size_download The total amount of bytes that were downloaded. This is the size of the body/data that was transferred, excluding headers. size_header The total amount of bytes of the downloaded headers. size_request The total amount of bytes that were sent in the HTTP request. size_upload The total amount of bytes that were uploaded. This is the size of the body/data that was transferred, excluding headers. speed_download The average download speed that curl measured for the complete download. Bytes per second. speed_upload The average upload speed that curl measured for the complete upload. Bytes per second. ssl_verify_result The result of the SSL peer certificate verification that was requested. 0 means the verification was successful. stderr From this point on, the -w, --write-out output will be written to standard error. (Added in 7.63.0) stdout From this point on, the -w, --write-out output will be written to standard output. This is the default, but can be used to switch back after switching to stderr. (Added in 7.63.0) time_appconnect The time, in seconds, it took from the start until the SSL/SSH/etc connect/handshake to the remote host was completed. time_connect The time, in seconds, it took from the start until the TCP connect to the remote host (or proxy) was completed. time_namelookup The time, in seconds, it took from the start until the name resolving was completed. time_pretransfer The time, in seconds, it took from the start until the file transfer was just about to begin. This includes all pre-transfer commands and negotiations that are specific to the particular protocol(s) involved. time_redirect The time, in seconds, it took for all redirection steps including name lookup, connect, pretransfer and transfer before the final transaction was started. time_redirect shows the complete execution time for multiple redirections. time_starttransfer The time, in seconds, it took from the start until the first byte was just about to be transferred. This includes time_pretransfer and also the time the server needed to calculate the result. time_total The total time, in seconds, that the full operation lasted. url The URL that was fetched. (Added in 7.75.0) url.scheme The scheme part of the URL that was fetched. (Added in 8.1.0) url.user The user part of the URL that was fetched. (Added in 8.1.0) url.password The password part of the URL that was fetched. (Added in 8.1.0) url.options The options part of the URL that was fetched. (Added in 8.1.0) url.host The host part of the URL that was fetched. (Added in 8.1.0) url.port The port number of the URL that was fetched. If no port number was specified, but the URL scheme is known, that scheme's default port number is shown. (Added in 8.1.0) url.path The path part of the URL that was fetched. (Added in 8.1.0) url.query The query part of the URL that was fetched. (Added in 8.1.0) url.fragment The fragment part of the URL that was fetched. (Added in 8.1.0) url.zoneid The zoneid part of the URL that was fetched. (Added in 8.1.0) urle.scheme The scheme part of the effective (last) URL that was fetched. (Added in 8.1.0) urle.user The user part of the effective (last) URL that was fetched. (Added in 8.1.0) urle.password The password part of the effective (last) URL that was fetched. (Added in 8.1.0) urle.options The options part of the effective (last) URL that was fetched. (Added in 8.1.0) urle.host The host part of the effective (last) URL that was fetched. (Added in 8.1.0) urle.port The port number of the effective (last) URL that was fetched. If no port number was specified, but the URL scheme is known, that scheme's default port number is shown. (Added in 8.1.0) urle.path The path part of the effective (last) URL that was fetched. (Added in 8.1.0) urle.query The query part of the effective (last) URL that was fetched. (Added in 8.1.0) urle.fragment The fragment part of the effective (last) URL that was fetched. (Added in 8.1.0) urle.zoneid The zoneid part of the effective (last) URL that was fetched. (Added in 8.1.0) urlnum The URL index number of this transfer, 0-indexed. De-globbed URLs share the same index number as the origin globbed URL. (Added in 7.75.0) url_effective The URL that was fetched last. This is most meaningful if you have told curl to follow location: headers. If -w, --write-out is provided several times, the last set value will be used. Example: curl -w '%{response_code}\\n' https://example.com See also -v, --verbose and -I, --head. --xattr When saving output to a file, this option tells curl to store certain file metadata in extended file attributes. Currently, the URL is stored in the xdg.origin.url attribute and, for HTTP, the content type is stored in the mime_type attribute. If the file system does not support extended attributes, a warning is issued. Providing --xattr multiple times has no extra effect. Disable it again with --no-xattr. Example: curl --xattr -o storage https://example.com See also -R, --remote-time, -w, --write-out and -v, --verbose. "
  },
  {
    "command": "git-verify-commit",
    "description": " Validates the GPG signature created by git commit -S. --raw Print the raw gpg status output to standard error instead of the normal human-readable output. -v, --verbose Print the contents of the commit object before validating it. <commit>... SHA-1 identifiers of Git commit objects. "
  },
  {
    "command": "rmdir",
    "description": " Remove the DIRECTORY(ies), if they are empty. --ignore-fail-on-non-empty ignore each failure to remove a non-empty directory -p, --parents remove DIRECTORY and its ancestors; e.g., 'rmdir -p a/b' is similar to 'rmdir a/b a' -v, --verbose output a diagnostic for every directory processed --help display this help and exit --version output version information and exit "
  },
  {
    "command": "getfacl",
    "description": " For each file, getfacl displays the file name, owner, the group, and the Access Control List (ACL). If a directory has a default ACL, getfacl also displays the default ACL. Non-directories cannot have default ACLs. If getfacl is used on a file system that does not support ACLs, getfacl displays the access permissions defined by the traditional file mode permission bits. The output format of getfacl is as follows: 1: # file: somedir/ 2: # owner: lisa 3: # group: staff 4: # flags: -s- 5: user::rwx 6: user:joe:rwx #effective:r-x 7: group::rwx #effective:r-x 8: group:cool:r-x 9: mask::r-x 10: other::r-x 11: default:user::rwx 12: default:user:joe:rwx #effective:r-x 13: default:group::r-x 14: default:mask::r-x 15: default:other::--- Lines 1--3 indicate the file name, owner, and owning group. Line 4 indicates the setuid (s), setgid (s), and sticky (t) bits: either the letter representing the bit, or else a dash (-). This line is included if any of those bits is set and left out otherwise, so it will not be shown for most files. (See CONFORMANCE TO POSIX 1003.1e DRAFT STANDARD 17 below.) Lines 5, 7 and 10 correspond to the user, group and other fields of the file mode permission bits. These three are called the base ACL entries. Lines 6 and 8 are named user and named group entries. Line 9 is the effective rights mask. This entry limits the effective rights granted to all groups and to named users. (The file owner and others permissions are not affected by the effective rights mask; all other entries are.) Lines 11--15 display the default ACL associated with this directory. Directories may have a default ACL. Regular files never have a default ACL. The default behavior for getfacl is to display both the ACL and the default ACL, and to include an effective rights comment for lines where the rights of the entry differ from the effective rights. If output is to a terminal, the effective rights comment is aligned to column 40. Otherwise, a single tab character separates the ACL entry and the effective rights comment. The ACL listings of multiple files are separated by blank lines. The output of getfacl can also be used as input to setfacl. PERMISSIONS Process with search access to a file (i.e., processes with read access to the containing directory of a file) are also granted read access to the file's ACLs. This is analogous to the permissions required for accessing the file mode. -a, --access Display the file access control list. -d, --default Display the default access control list. -c, --omit-header Do not display the comment header (the first three lines of each file's output). -e, --all-effective Print all effective rights comments, even if identical to the rights defined by the ACL entry. -E, --no-effective Do not print effective rights comments. -s, --skip-base Skip files that only have the base ACL entries (owner, group, others). -R, --recursive List the ACLs of all files and directories recursively. -L, --logical Logical walk, follow symbolic links to directories. The default behavior is to follow symbolic link arguments, and skip symbolic links encountered in subdirectories. Only effective in combination with -R. -P, --physical Physical walk, do not follow symbolic links to directories. This also skips symbolic link arguments. Only effective in combination with -R. -t, --tabular Use an alternative tabular output format. The ACL and the default ACL are displayed side by side. Permissions that are ineffective due to the ACL mask entry are displayed capitalized. The entry tag names for the ACL_USER_OBJ and ACL_GROUP_OBJ entries are also displayed in capital letters, which helps in spotting those entries. -p, --absolute-names Do not strip leading slash characters (`/'). The default behavior is to strip leading slash characters. -n, --numeric List numeric user and group IDs -v, --version Print the version of getfacl and exit. -h, --help Print help explaining the command line options. -- End of command line options. All remaining parameters are interpreted as file names, even if they start with a dash character. - If the file name parameter is a single dash character, getfacl reads a list of files from standard input. "
  },
  {
    "command": "nsenter",
    "description": " The nsenter command executes program in the namespace(s) that are specified in the command-line options (described below). If program is not given, then \"${SHELL}\" is run (default: /bin/sh). Enterable namespaces are: mount namespace Mounting and unmounting filesystems will not affect the rest of the system, except for filesystems which are explicitly marked as shared (with mount --make-shared; see /proc/self/mountinfo for the shared flag). For further details, see mount_namespaces(7) and the discussion of the CLONE_NEWNS flag in clone(2). UTS namespace Setting hostname or domainname will not affect the rest of the system. For further details, see uts_namespaces(7). IPC namespace The process will have an independent namespace for POSIX message queues as well as System V message queues, semaphore sets and shared memory segments. For further details, see ipc_namespaces(7). network namespace The process will have independent IPv4 and IPv6 stacks, IP routing tables, firewall rules, the /proc/net and /sys/class/net directory trees, sockets, etc. For further details, see network_namespaces(7). PID namespace Children will have a set of PID to process mappings separate from the nsenter process. nsenter will fork by default if changing the PID namespace, so that the new program and its children share the same PID namespace and are visible to each other. If --no-fork is used, the new program will be exec\u2019ed without forking. For further details, see pid_namespaces(7). user namespace The process will have a distinct set of UIDs, GIDs and capabilities. For further details, see user_namespaces(7). cgroup namespace The process will have a virtualized view of /proc/self/cgroup, and new cgroup mounts will be rooted at the namespace cgroup root. For further details, see cgroup_namespaces(7). time namespace The process can have a distinct view of CLOCK_MONOTONIC and/or CLOCK_BOOTTIME which can be changed using /proc/self/timens_offsets. For further details, see time_namespaces(7). Various of the options below that relate to namespaces take an optional file argument. This should be one of the /proc/[pid]/ns/* files described in namespaces(7), or the pathname of a bind mount that was created on one of those files. -a, --all Enter all namespaces of the target process by the default /proc/[pid]/ns/* namespace paths. The default paths to the target process namespaces may be overwritten by namespace specific options (e.g., --all --mount=[path]). The user namespace will be ignored if the same as the caller\u2019s current user namespace. It prevents a caller that has dropped capabilities from regaining those capabilities via a call to setns(). See setns(2) for more details. -t, --target PID Specify a target process to get contexts from. The paths to the contexts specified by pid are: /proc/pid/ns/mnt the mount namespace /proc/pid/ns/uts the UTS namespace /proc/pid/ns/ipc the IPC namespace /proc/pid/ns/net the network namespace /proc/pid/ns/pid the PID namespace /proc/pid/ns/user the user namespace /proc/pid/ns/cgroup the cgroup namespace /proc/pid/ns/time the time namespace /proc/pid/root the root directory /proc/pid/cwd the working directory respectively -m, --mount[=file] Enter the mount namespace. If no file is specified, enter the mount namespace of the target process. If file is specified, enter the mount namespace specified by file. -u, --uts[=file] Enter the UTS namespace. If no file is specified, enter the UTS namespace of the target process. If file is specified, enter the UTS namespace specified by file. -i, --ipc[=file] Enter the IPC namespace. If no file is specified, enter the IPC namespace of the target process. If file is specified, enter the IPC namespace specified by file. -n, --net[=file] Enter the network namespace. If no file is specified, enter the network namespace of the target process. If file is specified, enter the network namespace specified by file. -p, --pid[=file] Enter the PID namespace. If no file is specified, enter the PID namespace of the target process. If file is specified, enter the PID namespace specified by file. -U, --user[=file] Enter the user namespace. If no file is specified, enter the user namespace of the target process. If file is specified, enter the user namespace specified by file. See also the --setuid and --setgid options. -C, --cgroup[=file] Enter the cgroup namespace. If no file is specified, enter the cgroup namespace of the target process. If file is specified, enter the cgroup namespace specified by file. -T, --time[=file] Enter the time namespace. If no file is specified, enter the time namespace of the target process. If file is specified, enter the time namespace specified by file. -G, --setgid gid Set the group ID which will be used in the entered namespace and drop supplementary groups. nsenter always sets GID for user namespaces, the default is 0. If the argument \"follow\" is specified the GID of the target process is used. -S, --setuid uid Set the user ID which will be used in the entered namespace. nsenter always sets UID for user namespaces, the default is 0. If the argument \"follow\" is specified the UID of the target process is used. --keep-caps When the --user option is given, ensure that capabilities granted in the user namespace are preserved in the child process. --preserve-credentials Don\u2019t modify UID and GID when enter user namespace. The default is to drops supplementary groups and sets GID and UID to 0. -r, --root[=directory] Set the root directory. If no directory is specified, set the root directory to the root directory of the target process. If directory is specified, set the root directory to the specified directory. The specified directory is open before it switches to the requested namespaces. -w, --wd[=directory] Set the working directory. If no directory is specified, set the working directory to the working directory of the target process. If directory is specified, set the working directory to the specified directory. The specified directory is open before it switches to the requested namespaces, it means the specified directory works as \"tunnel\" to the current namespace. See also --wdns. -W, --wdns[=directory] Set the working directory. The directory is open after switch to the requested namespaces and after chroot(2) call. The options --wd and --wdns are mutually exclusive. -e, --env Pass environment variables from the target process to the new process being created. If this option is not provided, the environment variables will remain the same as in the current namespace.. -F, --no-fork Do not fork before exec\u2019ing the specified program. By default, when entering a PID namespace, nsenter calls fork before calling exec so that any children will also be in the newly entered PID namespace. -Z, --follow-context Set the SELinux security context used for executing a new process according to already running process specified by --target PID. (The util-linux has to be compiled with SELinux support otherwise the option is unavailable.) -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "rsync",
    "description": " Rsync is a fast and extraordinarily versatile file copying tool. It can copy locally, to/from another host over any remote shell, or to/from a remote rsync daemon. It offers a large number of options that control every aspect of its behavior and permit very flexible specification of the set of files to be copied. It is famous for its delta-transfer algorithm, which reduces the amount of data sent over the network by sending only the differences between the source files and the existing files in the destination. Rsync is widely used for backups and mirroring and as an improved copy command for everyday use. Rsync finds files that need to be transferred using a \"quick check\" algorithm (by default) that looks for files that have changed in size or in last-modified time. Any changes in the other preserved attributes (as requested by options) are made on the destination file directly when the quick check indicates that the file's data does not need to be updated. Some of the additional features of rsync are: o support for copying links, devices, owners, groups, and permissions o exclude and exclude-from options similar to GNU tar o a CVS exclude mode for ignoring the same files that CVS would ignore o can use any transparent remote shell, including ssh or rsh o does not require super-user privileges o pipelining of file transfers to minimize latency costs o support for anonymous or authenticated rsync daemons (ideal for mirroring) Rsync accepts both long (double-dash + word) and short (single- dash + letter) options. The full list of the available options are described below. If an option can be specified in more than one way, the choices are comma-separated. Some options only have a long variant, not a short. If the option takes a parameter, the parameter is only listed after the long variant, even though it must also be specified for the short. When specifying a parameter, you can either use the form --option=param, --option param, -o=param, -o param, or -oparam (the latter choices assume that your option has a short variant). The parameter may need to be quoted in some manner for it to survive the shell's command-line parsing. Also keep in mind that a leading tilde (~) in a pathname is substituted by your shell, so make sure that you separate the option name from the pathname using a space if you want the local shell to expand it. --help Print a short help page describing the options available in rsync and exit. You can also use -h for --help when it is used without any other options (since it normally means --human-readable). --version, -V Print the rsync version plus other info and exit. When repeated, the information is output is a JSON format that is still fairly readable (client side only). The output includes a list of compiled-in capabilities, a list of optimizations, the default list of checksum algorithms, the default list of compression algorithms, the default list of daemon auth digests, a link to the rsync web site, and a few other items. --verbose, -v This option increases the amount of information you are given during the transfer. By default, rsync works silently. A single -v will give you information about what files are being transferred and a brief summary at the end. Two -v options will give you information on what files are being skipped and slightly more information at the end. More than two -v options should only be used if you are debugging rsync. The end-of-run summary tells you the number of bytes sent to the remote rsync (which is the receiving side on a local copy), the number of bytes received from the remote host, and the average bytes per second of the transferred data computed over the entire length of the rsync run. The second line shows the total size (in bytes), which is the sum of all the file sizes that rsync considered transferring. It also shows a \"speedup\" value, which is a ratio of the total file size divided by the sum of the sent and received bytes (which is really just a feel-good bigger-is-better number). Note that these byte values can be made more (or less) human-readable by using the --human-readable (or --no-human-readable) options. In a modern rsync, the -v option is equivalent to the setting of groups of --info and --debug options. You can choose to use these newer options in addition to, or in place of using --verbose, as any fine-grained settings override the implied settings of -v. Both --info and --debug have a way to ask for help that tells you exactly what flags are set for each increase in verbosity. However, do keep in mind that a daemon's \"max verbosity\" setting will limit how high of a level the various individual flags can be set on the daemon side. For instance, if the max is 2, then any info and/or debug flag that is set to a higher value than what would be set by -vv will be downgraded to the -vv level in the daemon's logging. --info=FLAGS This option lets you have fine-grained control over the information output you want to see. An individual flag name may be followed by a level number, with 0 meaning to silence that output, 1 being the default output level, and higher numbers increasing the output of that flag (for those that support higher levels). Use --info=help to see all the available flag names, what they output, and what flag names are added for each increase in the verbose level. Some examples: rsync -a --info=progress2 src/ dest/ rsync -avv --info=stats2,misc1,flist0 src/ dest/ Note that --info=name's output is affected by the --out- format and --itemize-changes (-i) options. See those options for more information on what is output and when. This option was added to 3.1.0, so an older rsync on the server side might reject your attempts at fine-grained control (if one or more flags needed to be send to the server and the server was too old to understand them). See also the \"max verbosity\" caveat above when dealing with a daemon. --debug=FLAGS This option lets you have fine-grained control over the debug output you want to see. An individual flag name may be followed by a level number, with 0 meaning to silence that output, 1 being the default output level, and higher numbers increasing the output of that flag (for those that support higher levels). Use --debug=help to see all the available flag names, what they output, and what flag names are added for each increase in the verbose level. Some examples: rsync -avvv --debug=none src/ dest/ rsync -avA --del --debug=del2,acl src/ dest/ Note that some debug messages will only be output when the --stderr=all option is specified, especially those pertaining to I/O and buffer debugging. Beginning in 3.2.0, this option is no longer auto- forwarded to the server side in order to allow you to specify different debug values for each side of the transfer, as well as to specify a new debug option that is only present in one of the rsync versions. If you want to duplicate the same option on both sides, using brace expansion is an easy way to save you some typing. This works in zsh and bash: rsync -aiv {-M,}--debug=del2 src/ dest/ --stderr=errors|all|client This option controls which processes output to stderr and if info messages are also changed to stderr. The mode strings can be abbreviated, so feel free to use a single letter value. The 3 possible choices are: o errors - (the default) causes all the rsync processes to send an error directly to stderr, even if the process is on the remote side of the transfer. Info messages are sent to the client side via the protocol stream. If stderr is not available (i.e. when directly connecting with a daemon via a socket) errors fall back to being sent via the protocol stream. o all - causes all rsync messages (info and error) to get written directly to stderr from all (possible) processes. This causes stderr to become line- buffered (instead of raw) and eliminates the ability to divide up the info and error messages by file handle. For those doing debugging or using several levels of verbosity, this option can help to avoid clogging up the transfer stream (which should prevent any chance of a deadlock bug hanging things up). It also allows --debug to enable some extra I/O related messages. o client - causes all rsync messages to be sent to the client side via the protocol stream. One client process outputs all messages, with errors on stderr and info messages on stdout. This was the default in older rsync versions, but can cause error delays when a lot of transfer data is ahead of the messages. If you're pushing files to an older rsync, you may want to use --stderr=all since that idiom has been around for several releases. This option was added in rsync 3.2.3. This version also began the forwarding of a non-default setting to the remote side, though rsync uses the backward-compatible options --msgs2stderr and --no-msgs2stderr to represent the all and client settings, respectively. A newer rsync will continue to accept these older option names to maintain compatibility. --quiet, -q This option decreases the amount of information you are given during the transfer, notably suppressing information messages from the remote server. This option is useful when invoking rsync from cron. --no-motd This option affects the information that is output by the client at the start of a daemon transfer. This suppresses the message-of-the-day (MOTD) text, but it also affects the list of modules that the daemon sends in response to the \"rsync host::\" request (due to a limitation in the rsync protocol), so omit this option if you want to request the list of modules from the daemon. --ignore-times, -I Normally rsync will skip any files that are already the same size and have the same modification timestamp. This option turns off this \"quick check\" behavior, causing all files to be updated. This option can be confusing compared to --ignore-existing and --ignore-non-existing in that that they cause rsync to transfer fewer files, while this option causes rsync to transfer more files. --size-only This modifies rsync's \"quick check\" algorithm for finding files that need to be transferred, changing it from the default of transferring files with either a changed size or a changed last-modified time to just looking for files that have changed in size. This is useful when starting to use rsync after using another mirroring system which may not preserve timestamps exactly. --modify-window=NUM, -@ When comparing two timestamps, rsync treats the timestamps as being equal if they differ by no more than the modify- window value. The default is 0, which matches just integer seconds. If you specify a negative value (and the receiver is at least version 3.1.3) then nanoseconds will also be taken into account. Specifying 1 is useful for copies to/from MS Windows FAT filesystems, because FAT represents times with a 2-second resolution (allowing times to differ from the original by up to 1 second). If you want all your transfers to default to comparing nanoseconds, you can create a ~/.popt file and put these lines in it: rsync alias -a -a@-1 rsync alias -t -t@-1 With that as the default, you'd need to specify --modify- window=0 (aka -@0) to override it and ignore nanoseconds, e.g. if you're copying between ext3 and ext4, or if the receiving rsync is older than 3.1.3. --checksum, -c This changes the way rsync checks if the files have been changed and are in need of a transfer. Without this option, rsync uses a \"quick check\" that (by default) checks if each file's size and time of last modification match between the sender and receiver. This option changes this to compare a 128-bit checksum for each file that has a matching size. Generating the checksums means that both sides will expend a lot of disk I/O reading all the data in the files in the transfer, so this can slow things down significantly (and this is prior to any reading that will be done to transfer changed files) The sending side generates its checksums while it is doing the file-system scan that builds the list of the available files. The receiver generates its checksums when it is scanning for changed files, and will checksum any file that has the same size as the corresponding sender's file: files with either a changed size or a changed checksum are selected for transfer. Note that rsync always verifies that each transferred file was correctly reconstructed on the receiving side by checking a whole-file checksum that is generated as the file is transferred, but that automatic after-the-transfer verification has nothing to do with this option's before- the-transfer \"Does this file need to be updated?\" check. The checksum used is auto-negotiated between the client and the server, but can be overridden using either the --checksum-choice (--cc) option or an environment variable that is discussed in that option's section. --archive, -a This is equivalent to -rlptgoD. It is a quick way of saying you want recursion and want to preserve almost everything. Be aware that it does not include preserving ACLs (-A), xattrs (-X), atimes (-U), crtimes (-N), nor the finding and preserving of hardlinks (-H). The only exception to the above equivalence is when --files-from is specified, in which case -r is not implied. --no-OPTION You may turn off one or more implied options by prefixing the option name with \"no-\". Not all positive options have a negated opposite, but a lot do, including those that can be used to disable an implied option (e.g. --no-D, --no- perms) or have different defaults in various circumstances (e.g. --no-whole-file, --no-blocking-io, --no-dirs). Every valid negated option accepts both the short and the long option name after the \"no-\" prefix (e.g. --no-R is the same as --no-relative). As an example, if you want to use --archive (-a) but don't want --owner (-o), instead of converting -a into -rlptgD, you can specify -a --no-o (aka --archive --no-owner). The order of the options is important: if you specify --no-r -a, the -r option would end up being turned on, the opposite of -a --no-r. Note also that the side-effects of the --files-from option are NOT positional, as it affects the default state of several options and slightly changes the meaning of -a (see the --files-from option for more details). --recursive, -r This tells rsync to copy directories recursively. See also --dirs (-d) for an option that allows the scanning of a single directory. See the --inc-recursive option for a discussion of the incremental recursion for creating the list of files to transfer. --inc-recursive, --i-r This option explicitly enables on incremental recursion when scanning for files, which is enabled by default when using the --recursive option and both sides of the transfer are running rsync 3.0.0 or newer. Incremental recursion uses much less memory than non- incremental, while also beginning the transfer more quickly (since it doesn't need to scan the entire transfer hierarchy before it starts transferring files). If no recursion is enabled in the source files, this option has no effect. Some options require rsync to know the full file list, so these options disable the incremental recursion mode. These include: o --delete-before (the old default of --delete) o --delete-after o --prune-empty-dirs o --delay-updates In order to make --delete compatible with incremental recursion, rsync 3.0.0 made --delete-during the default delete mode (which was first added in 2.6.4). One side-effect of incremental recursion is that any missing sub-directories inside a recursively-scanned directory are (by default) created prior to recursing into the sub-dirs. This earlier creation point (compared to a non-incremental recursion) allows rsync to then set the modify time of the finished directory right away (without having to delay that until a bunch of recursive copying has finished). However, these early directories don't yet have their completed mode, mtime, or ownership set -- they have more restrictive rights until the subdirectory's copying actually begins. This early-creation idiom can be avoided by using the --omit-dir-times option. Incremental recursion can be disabled using the --no-inc- recursive (--no-i-r) option. --no-inc-recursive, --no-i-r Disables the new incremental recursion algorithm of the --recursive option. This makes rsync scan the full file list before it begins to transfer files. See --inc- recursive for more info. --relative, -R Use relative paths. This means that the full path names specified on the command line are sent to the server rather than just the last parts of the filenames. This is particularly useful when you want to send several different directories at the same time. For example, if you used this command: rsync -av /foo/bar/baz.c remote:/tmp/ would create a file named baz.c in /tmp/ on the remote machine. If instead you used rsync -avR /foo/bar/baz.c remote:/tmp/ then a file named /tmp/foo/bar/baz.c would be created on the remote machine, preserving its full path. These extra path elements are called \"implied directories\" (i.e. the \"foo\" and the \"foo/bar\" directories in the above example). Beginning with rsync 3.0.0, rsync always sends these implied directories as real directories in the file list, even if a path element is really a symlink on the sending side. This prevents some really unexpected behaviors when copying the full path of a file that you didn't realize had a symlink in its path. If you want to duplicate a server-side symlink, include both the symlink via its path, and referent directory via its real path. If you're dealing with an older rsync on the sending side, you may need to use the --no-implied-dirs option. It is also possible to limit the amount of path information that is sent as implied directories for each path you specify. With a modern rsync on the sending side (beginning with 2.6.7), you can insert a dot and a slash into the source path, like this: rsync -avR /foo/./bar/baz.c remote:/tmp/ That would create /tmp/bar/baz.c on the remote machine. (Note that the dot must be followed by a slash, so \"/foo/.\" would not be abbreviated.) For older rsync versions, you would need to use a chdir to limit the source path. For example, when pushing files: (cd /foo; rsync -avR bar/baz.c remote:/tmp/) (Note that the parens put the two commands into a sub- shell, so that the \"cd\" command doesn't remain in effect for future commands.) If you're pulling files from an older rsync, use this idiom (but only for a non-daemon transfer): rsync -avR --rsync-path=\"cd /foo; rsync\" \\ remote:bar/baz.c /tmp/ --no-implied-dirs This option affects the default behavior of the --relative option. When it is specified, the attributes of the implied directories from the source names are not included in the transfer. This means that the corresponding path elements on the destination system are left unchanged if they exist, and any missing implied directories are created with default attributes. This even allows these implied path elements to have big differences, such as being a symlink to a directory on the receiving side. For instance, if a command-line arg or a files-from entry told rsync to transfer the file \"path/foo/file\", the directories \"path\" and \"path/foo\" are implied when --relative is used. If \"path/foo\" is a symlink to \"bar\" on the destination system, the receiving rsync would ordinarily delete \"path/foo\", recreate it as a directory, and receive the file into the new directory. With --no- implied-dirs, the receiving rsync updates \"path/foo/file\" using the existing path elements, which means that the file ends up being created in \"path/bar\". Another way to accomplish this link preservation is to use the --keep- dirlinks option (which will also affect symlinks to directories in the rest of the transfer). When pulling files from an rsync older than 3.0.0, you may need to use this option if the sending side has a symlink in the path you request and you wish the implied directories to be transferred as normal directories. --backup, -b With this option, preexisting destination files are renamed as each file is transferred or deleted. You can control where the backup file goes and what (if any) suffix gets appended using the --backup-dir and --suffix options. If you don't specify --backup-dir: 1. the --omit-dir-times option will be forced on 2. the use of --delete (without --delete-excluded), causes rsync to add a \"protect\" filter-rule for the backup suffix to the end of all your existing filters that looks like this: -f \"P *~\". This rule prevents previously backed-up files from being deleted. Note that if you are supplying your own filter rules, you may need to manually insert your own exclude/protect rule somewhere higher up in the list so that it has a high enough priority to be effective (e.g. if your rules specify a trailing inclusion/exclusion of *, the auto- added rule would never be reached). --backup-dir=DIR This implies the --backup option, and tells rsync to store all backups in the specified directory on the receiving side. This can be used for incremental backups. You can additionally specify a backup suffix using the --suffix option (otherwise the files backed up in the specified directory will keep their original filenames). Note that if you specify a relative path, the backup directory will be relative to the destination directory, so you probably want to specify either an absolute path or a path that starts with \"../\". If an rsync daemon is the receiver, the backup dir cannot go outside the module's path hierarchy, so take extra care not to delete it or copy into it. --suffix=SUFFIX This option allows you to override the default backup suffix used with the --backup (-b) option. The default suffix is a ~ if no --backup-dir was specified, otherwise it is an empty string. --update, -u This forces rsync to skip any files which exist on the destination and have a modified time that is newer than the source file. (If an existing destination file has a modification time equal to the source file's, it will be updated if the sizes are different.) Note that this does not affect the copying of dirs, symlinks, or other special files. Also, a difference of file format between the sender and receiver is always considered to be important enough for an update, no matter what date is on the objects. In other words, if the source has a directory where the destination has a file, the transfer would occur regardless of the timestamps. This option is a TRANSFER RULE, so don't expect any exclude side effects. A caution for those that choose to combine --inplace with --update: an interrupted transfer will leave behind a partial file on the receiving side that has a very recent modified time, so re-running the transfer will probably not continue the interrupted file. As such, it is usually best to avoid combining this with --inplace unless you have implemented manual steps to handle any interrupted in-progress files. --inplace This option changes how rsync transfers a file when its data needs to be updated: instead of the default method of creating a new copy of the file and moving it into place when it is complete, rsync instead writes the updated data directly to the destination file. This has several effects: o Hard links are not broken. This means the new data will be visible through other hard links to the destination file. Moreover, attempts to copy differing source files onto a multiply-linked destination file will result in a \"tug of war\" with the destination data changing back and forth. o In-use binaries cannot be updated (either the OS will prevent this from happening, or binaries that attempt to swap-in their data will misbehave or crash). o The file's data will be in an inconsistent state during the transfer and will be left that way if the transfer is interrupted or if an update fails. o A file that rsync cannot write to cannot be updated. While a super user can update any file, a normal user needs to be granted write permission for the open of the file for writing to be successful. o The efficiency of rsync's delta-transfer algorithm may be reduced if some data in the destination file is overwritten before it can be copied to a position later in the file. This does not apply if you use --backup, since rsync is smart enough to use the backup file as the basis file for the transfer. WARNING: you should not use this option to update files that are being accessed by others, so be careful when choosing to use this for a copy. This option is useful for transferring large files with block-based changes or appended data, and also on systems that are disk bound, not network bound. It can also help keep a copy-on-write filesystem snapshot from diverging the entire contents of a file that only has minor changes. The option implies --partial (since an interrupted transfer does not delete the file), but conflicts with --partial-dir and --delay-updates. Prior to rsync 2.6.4 --inplace was also incompatible with --compare-dest and --link-dest. --append This special copy mode only works to efficiently update files that are known to be growing larger where any existing content on the receiving side is also known to be the same as the content on the sender. The use of --append can be dangerous if you aren't 100% sure that all the files in the transfer are shared, growing files. You should thus use filter rules to ensure that you weed out any files that do not fit this criteria. Rsync updates these growing file in-place without verifying any of the existing content in the file (it only verifies the content that it is appending). Rsync skips any files that exist on the receiving side that are not shorter than the associated file on the sending side (which means that new files are transferred). It also skips any files whose size on the sending side gets shorter during the send negotiations (rsync warns about a \"diminished\" file when this happens). This does not interfere with the updating of a file's non- content attributes (e.g. permissions, ownership, etc.) when the file does not need to be transferred, nor does it affect the updating of any directories or non-regular files. --append-verify This special copy mode works like --append except that all the data in the file is included in the checksum verification (making it less efficient but also potentially safer). This option can be dangerous if you aren't 100% sure that all the files in the transfer are shared, growing files. See the --append option for more details. Note: prior to rsync 3.0.0, the --append option worked like --append-verify, so if you are interacting with an older rsync (or the transfer is using a protocol prior to 30), specifying either append option will initiate an --append-verify transfer. --dirs, -d Tell the sending side to include any directories that are encountered. Unlike --recursive, a directory's contents are not copied unless the directory name specified is \".\" or ends with a trailing slash (e.g. \".\", \"dir/.\", \"dir/\", etc.). Without this option or the --recursive option, rsync will skip all directories it encounters (and output a message to that effect for each one). If you specify both --dirs and --recursive, --recursive takes precedence. The --dirs option is implied by the --files-from option or the --list-only option (including an implied --list-only usage) if --recursive wasn't specified (so that directories are seen in the listing). Specify --no-dirs (or --no-d) if you want to turn this off. There is also a backward-compatibility helper option, --old-dirs (--old-d) that tells rsync to use a hack of -r --exclude='/*/*' to get an older rsync to list a single directory without recursing. --mkpath Create all missing path components of the destination path. By default, rsync allows only the final component of the destination path to not exist, which is an attempt to help you to validate your destination path. With this option, rsync creates all the missing destination-path components, just as if mkdir -p $DEST_PATH had been run on the receiving side. When specifying a destination path, including a trailing slash ensures that the whole path is treated as directory names to be created, even when the file list has a single item. See the COPYING TO A DIFFERENT NAME section for full details on how rsync decides if a final destination-path component should be created as a directory or not. If you would like the newly-created destination dirs to match the dirs on the sending side, you should be using --relative (-R) instead of --mkpath. For instance, the following two commands result in the same destination tree, but only the second command ensures that the \"some/extra/path\" components match the dirs on the sending side: rsync -ai --mkpath host:some/extra/path/*.c some/extra/path/ rsync -aiR host:some/extra/path/*.c ./ --links, -l Add symlinks to the transferred files instead of noisily ignoring them with a \"non-regular file\" warning for each symlink encountered. You can alternately silence the warning by specifying --info=nonreg0. The default handling of symlinks is to recreate each symlink's unchanged value on the receiving side. See the SYMBOLIC LINKS section for multi-option info. --copy-links, -L The sender transforms each symlink encountered in the transfer into the referent item, following the symlink chain to the file or directory that it references. If a symlink chain is broken, an error is output and the file is dropped from the transfer. This option supersedes any other options that affect symlinks in the transfer, since there are no symlinks left in the transfer. This option does not change the handling of existing symlinks on the receiving side, unlike versions of rsync prior to 2.6.3 which had the side-effect of telling the receiving side to also follow symlinks. A modern rsync won't forward this option to a remote receiver (since only the sender needs to know about it), so this caveat should only affect someone using an rsync client older than 2.6.7 (which is when -L stopped being forwarded to the receiver). See the --keep-dirlinks (-K) if you need a symlink to a directory to be treated as a real directory on the receiving side. See the SYMBOLIC LINKS section for multi-option info. --copy-unsafe-links This tells rsync to copy the referent of symbolic links that point outside the copied tree. Absolute symlinks are also treated like ordinary files, and so are any symlinks in the source path itself when --relative is used. Note that the cut-off point is the top of the transfer, which is the part of the path that rsync isn't mentioning in the verbose output. If you copy \"/src/subdir\" to \"/dest/\" then the \"subdir\" directory is a name inside the transfer tree, not the top of the transfer (which is /src) so it is legal for created relative symlinks to refer to other names inside the /src and /dest directories. If you instead copy \"/src/subdir/\" (with a trailing slash) to \"/dest/subdir\" that would not allow symlinks to any files outside of \"subdir\". Note that safe symlinks are only copied if --links was also specified or implied. The --copy-unsafe-links option has no extra effect when combined with --copy-links. See the SYMBOLIC LINKS section for multi-option info. --safe-links This tells the receiving rsync to ignore any symbolic links in the transfer which point outside the copied tree. All absolute symlinks are also ignored. Since this ignoring is happening on the receiving side, it will still be effective even when the sending side has munged symlinks (when it is using --munge-links). It also affects deletions, since the file being present in the transfer prevents any matching file on the receiver from being deleted when the symlink is deemed to be unsafe and is skipped. This option must be combined with --links (or --archive) to have any symlinks in the transfer to conditionally ignore. Its effect is superseded by --copy-unsafe-links. Using this option in conjunction with --relative may give unexpected results. See the SYMBOLIC LINKS section for multi-option info. --munge-links This option affects just one side of the transfer and tells rsync to munge symlink values when it is receiving files or unmunge symlink values when it is sending files. The munged values make the symlinks unusable on disk but allows the original contents of the symlinks to be recovered. The server-side rsync often enables this option without the client's knowledge, such as in an rsync daemon's configuration file or by an option given to the rrsync (restricted rsync) script. When specified on the client side, specify the option normally if it is the client side that has/needs the munged symlinks, or use -M--munge-links to give the option to the server when it has/needs the munged symlinks. Note that on a local transfer, the client is the sender, so specifying the option directly unmunges symlinks while specifying it as a remote option munges symlinks. This option has no effect when sent to a daemon via --remote-option because the daemon configures whether it wants munged symlinks via its \"munge symlinks\" parameter. The symlink value is munged/unmunged once it is in the transfer, so any option that transforms symlinks into non- symlinks occurs prior to the munging/unmunging except for --safe-links, which is a choice that the receiver makes, so it bases its decision on the munged/unmunged value. This does mean that if a receiver has munging enabled, that using --safe-links will cause all symlinks to be ignored (since they are all absolute). The method that rsync uses to munge the symlinks is to prefix each one's value with the string \"/rsyncd-munged/\". This prevents the links from being used as long as the directory does not exist. When this option is enabled, rsync will refuse to run if that path is a directory or a symlink to a directory (though it only checks at startup). See also the \"munge-symlinks\" python script in the support directory of the source code for a way to munge/unmunge one or more symlinks in-place. --copy-dirlinks, -k This option causes the sending side to treat a symlink to a directory as though it were a real directory. This is useful if you don't want symlinks to non-directories to be affected, as they would be using --copy-links. Without this option, if the sending side has replaced a directory with a symlink to a directory, the receiving side will delete anything that is in the way of the new symlink, including a directory hierarchy (as long as --force or --delete is in effect). See also --keep-dirlinks for an analogous option for the receiving side. --copy-dirlinks applies to all symlinks to directories in the source. If you want to follow only a few specified symlinks, a trick you can use is to pass them as additional source args with a trailing slash, using --relative to make the paths match up right. For example: rsync -r --relative src/./ src/./follow-me/ dest/ This works because rsync calls lstat(2) on the source arg as given, and the trailing slash makes lstat(2) follow the symlink, giving rise to a directory in the file-list which overrides the symlink found during the scan of \"src/./\". See the SYMBOLIC LINKS section for multi-option info. --keep-dirlinks, -K This option causes the receiving side to treat a symlink to a directory as though it were a real directory, but only if it matches a real directory from the sender. Without this option, the receiver's symlink would be deleted and replaced with a real directory. For example, suppose you transfer a directory \"foo\" that contains a file \"file\", but \"foo\" is a symlink to directory \"bar\" on the receiver. Without --keep-dirlinks, the receiver deletes symlink \"foo\", recreates it as a directory, and receives the file into the new directory. With --keep-dirlinks, the receiver keeps the symlink and \"file\" ends up in \"bar\". One note of caution: if you use --keep-dirlinks, you must trust all the symlinks in the copy or enable the --munge- links option on the receiving side! If it is possible for an untrusted user to create their own symlink to any real directory, the user could then (on a subsequent copy) replace the symlink with a real directory and affect the content of whatever directory the symlink references. For backup copies, you are better off using something like a bind mount instead of a symlink to modify your receiving hierarchy. See also --copy-dirlinks for an analogous option for the sending side. See the SYMBOLIC LINKS section for multi-option info. --hard-links, -H This tells rsync to look for hard-linked files in the source and link together the corresponding files on the destination. Without this option, hard-linked files in the source are treated as though they were separate files. This option does NOT necessarily ensure that the pattern of hard links on the destination exactly matches that on the source. Cases in which the destination may end up with extra hard links include the following: o If the destination contains extraneous hard-links (more linking than what is present in the source file list), the copying algorithm will not break them explicitly. However, if one or more of the paths have content differences, the normal file- update process will break those extra links (unless you are using the --inplace option). o If you specify a --link-dest directory that contains hard links, the linking of the destination files against the --link-dest files can cause some paths in the destination to become linked together due to the --link-dest associations. Note that rsync can only detect hard links between files that are inside the transfer set. If rsync updates a file that has extra hard-link connections to files outside the transfer, that linkage will be broken. If you are tempted to use the --inplace option to avoid this breakage, be very careful that you know how your files are being updated so that you are certain that no unintended changes happen due to lingering hard links (and see the --inplace option for more caveats). If incremental recursion is active (see --inc-recursive), rsync may transfer a missing hard-linked file before it finds that another link for that contents exists elsewhere in the hierarchy. This does not affect the accuracy of the transfer (i.e. which files are hard-linked together), just its efficiency (i.e. copying the data for a new, early copy of a hard-linked file that could have been found later in the transfer in another member of the hard- linked set of files). One way to avoid this inefficiency is to disable incremental recursion using the --no-inc- recursive option. --perms, -p This option causes the receiving rsync to set the destination permissions to be the same as the source permissions. (See also the --chmod option for a way to modify what rsync considers to be the source permissions.) When this option is off, permissions are set as follows: o Existing files (including updated files) retain their existing permissions, though the --executability option might change just the execute permission for the file. o New files get their \"normal\" permission bits set to the source file's permissions masked with the receiving directory's default permissions (either the receiving process's umask, or the permissions specified via the destination directory's default ACL), and their special permission bits disabled except in the case where a new directory inherits a setgid bit from its parent directory. Thus, when --perms and --executability are both disabled, rsync's behavior is the same as that of other file-copy utilities, such as cp(1) and tar(1). In summary: to give destination files (both old and new) the source permissions, use --perms. To give new files the destination-default permissions (while leaving existing files unchanged), make sure that the --perms option is off and use --chmod=ugo=rwX (which ensures that all non-masked bits get enabled). If you'd care to make this latter behavior easier to type, you could define a popt alias for it, such as putting this line in the file ~/.popt (the following defines the -Z option, and includes --no-g to use the default group of the destination dir): rsync alias -Z --no-p --no-g --chmod=ugo=rwX You could then use this new option in a command such as this one: rsync -avZ src/ dest/ (Caveat: make sure that -a does not follow -Z, or it will re-enable the two --no-* options mentioned above.) The preservation of the destination's setgid bit on newly- created directories when --perms is off was added in rsync 2.6.7. Older rsync versions erroneously preserved the three special permission bits for newly-created files when --perms was off, while overriding the destination's setgid bit setting on a newly-created directory. Default ACL observance was added to the ACL patch for rsync 2.6.7, so older (or non-ACL-enabled) rsyncs use the umask even if default ACLs are present. (Keep in mind that it is the version of the receiving rsync that affects these behaviors.) --executability, -E This option causes rsync to preserve the executability (or non-executability) of regular files when --perms is not enabled. A regular file is considered to be executable if at least one 'x' is turned on in its permissions. When an existing destination file's executability differs from that of the corresponding source file, rsync modifies the destination file's permissions as follows: o To make a file non-executable, rsync turns off all its 'x' permissions. o To make a file executable, rsync turns on each 'x' permission that has a corresponding 'r' permission enabled. If --perms is enabled, this option is ignored. --acls, -A This option causes rsync to update the destination ACLs to be the same as the source ACLs. The option also implies --perms. The source and destination systems must have compatible ACL entries for this option to work properly. See the --fake-super option for a way to backup and restore ACLs that are not compatible. --xattrs, -X This option causes rsync to update the destination extended attributes to be the same as the source ones. For systems that support extended-attribute namespaces, a copy being done by a super-user copies all namespaces except system.*. A normal user only copies the user.* namespace. To be able to backup and restore non-user namespaces as a normal user, see the --fake-super option. The above name filtering can be overridden by using one or more filter options with the x modifier. When you specify an xattr-affecting filter rule, rsync requires that you do your own system/user filtering, as well as any additional filtering for what xattr names are copied and what names are allowed to be deleted. For example, to skip the system namespace, you could specify: --filter='-x system.*' To skip all namespaces except the user namespace, you could specify a negated-user match: --filter='-x! user.*' To prevent any attributes from being deleted, you could specify a receiver-only rule that excludes all names: --filter='-xr *' Note that the -X option does not copy rsync's special xattr values (e.g. those used by --fake-super) unless you repeat the option (e.g. -XX). This \"copy all xattrs\" mode cannot be used with --fake-super. --chmod=CHMOD This option tells rsync to apply one or more comma- separated \"chmod\" modes to the permission of the files in the transfer. The resulting value is treated as though it were the permissions that the sending side supplied for the file, which means that this option can seem to have no effect on existing files if --perms is not enabled. In addition to the normal parsing rules specified in the chmod(1) manpage, you can specify an item that should only apply to a directory by prefixing it with a 'D', or specify an item that should only apply to a file by prefixing it with a 'F'. For example, the following will ensure that all directories get marked set-gid, that no files are other-writable, that both are user-writable and group-writable, and that both have consistent executability across all bits: --chmod=Dg+s,ug+w,Fo-w,+X Using octal mode numbers is also allowed: --chmod=D2775,F664 It is also legal to specify multiple --chmod options, as each additional option is just appended to the list of changes to make. See the --perms and --executability options for how the resulting permission value can be applied to the files in the transfer. --owner, -o This option causes rsync to set the owner of the destination file to be the same as the source file, but only if the receiving rsync is being run as the super-user (see also the --super and --fake-super options). Without this option, the owner of new and/or transferred files are set to the invoking user on the receiving side. The preservation of ownership will associate matching names by default, but may fall back to using the ID number in some circumstances (see also the --numeric-ids option for a full discussion). --group, -g This option causes rsync to set the group of the destination file to be the same as the source file. If the receiving program is not running as the super-user (or if --no-super was specified), only groups that the invoking user on the receiving side is a member of will be preserved. Without this option, the group is set to the default group of the invoking user on the receiving side. The preservation of group information will associate matching names by default, but may fall back to using the ID number in some circumstances (see also the --numeric- ids option for a full discussion). --devices This option causes rsync to transfer character and block device files to the remote system to recreate these devices. If the receiving rsync is not being run as the super-user, rsync silently skips creating the device files (see also the --super and --fake-super options). By default, rsync generates a \"non-regular file\" warning for each device file encountered when this option is not set. You can silence the warning by specifying --info=nonreg0. --specials This option causes rsync to transfer special files, such as named sockets and fifos. If the receiving rsync is not being run as the super-user, rsync silently skips creating the special files (see also the --super and --fake-super options). By default, rsync generates a \"non-regular file\" warning for each special file encountered when this option is not set. You can silence the warning by specifying --info=nonreg0. -D The -D option is equivalent to \"--devices --specials\". --copy-devices This tells rsync to treat a device on the sending side as a regular file, allowing it to be copied to a normal destination file (or another device if --write-devices was also specified). This option is refused by default by an rsync daemon. --write-devices This tells rsync to treat a device on the receiving side as a regular file, allowing the writing of file data into a device. This option implies the --inplace option. Be careful using this, as you should know what devices are present on the receiving side of the transfer, especially when running rsync as root. This option is refused by default by an rsync daemon. --times, -t This tells rsync to transfer modification times along with the files and update them on the remote system. Note that if this option is not used, the optimization that excludes files that have not been modified cannot be effective; in other words, a missing -t (or -a) will cause the next transfer to behave as if it used --ignore-times (-I), causing all files to be updated (though rsync's delta- transfer algorithm will make the update fairly efficient if the files haven't actually changed, you're much better off using -t). A modern rsync that is using transfer protocol 30 or 31 conveys a modify time using up to 8-bytes. If rsync is forced to speak an older protocol (perhaps due to the remote rsync being older than 3.0.0) a modify time is conveyed using 4-bytes. Prior to 3.2.7, these shorter values could convey a date range of 13-Dec-1901 to 19-Jan-2038. Beginning with 3.2.7, these 4-byte values now convey a date range of 1-Jan-1970 to 7-Feb-2106. If you have files dated older than 1970, make sure your rsync executables are upgraded so that the full range of dates can be conveyed. --atimes, -U This tells rsync to set the access (use) times of the destination files to the same value as the source files. If repeated, it also sets the --open-noatime option, which can help you to make the sending and receiving systems have the same access times on the transferred files without needing to run rsync an extra time after a file is transferred. Note that some older rsync versions (prior to 3.2.0) may have been built with a pre-release --atimes patch that does not imply --open-noatime when this option is repeated. --open-noatime This tells rsync to open files with the O_NOATIME flag (on systems that support it) to avoid changing the access time of the files that are being transferred. If your OS does not support the O_NOATIME flag then rsync will silently ignore this option. Note also that some filesystems are mounted to avoid updating the atime on read access even without the O_NOATIME flag being set. --crtimes, -N, This tells rsync to set the create times (newness) of the destination files to the same value as the source files. --omit-dir-times, -O This tells rsync to omit directories when it is preserving modification, access, and create times. If NFS is sharing the directories on the receiving side, it is a good idea to use -O. This option is inferred if you use --backup without --backup-dir. This option also has the side-effect of avoiding early creation of missing sub-directories when incremental recursion is enabled, as discussed in the --inc-recursive section. --omit-link-times, -J This tells rsync to omit symlinks when it is preserving modification, access, and create times. --super This tells the receiving side to attempt super-user activities even if the receiving rsync wasn't run by the super-user. These activities include: preserving users via the --owner option, preserving all groups (not just the current user's groups) via the --group option, and copying devices via the --devices option. This is useful for systems that allow such activities without being the super-user, and also for ensuring that you will get errors if the receiving side isn't being run as the super-user. To turn off super-user activities, the super-user can use --no-super. --fake-super When this option is enabled, rsync simulates super-user activities by saving/restoring the privileged attributes via special extended attributes that are attached to each file (as needed). This includes the file's owner and group (if it is not the default), the file's device info (device & special files are created as empty text files), and any permission bits that we won't allow to be set on the real file (e.g. the real file gets u-s,g-s,o-t for safety) or that would limit the owner's access (since the real super-user can always access/change a file, the files we create can always be accessed/changed by the creating user). This option also handles ACLs (if --acls was specified) and non-user extended attributes (if --xattrs was specified). This is a good way to backup data without using a super- user, and to store ACLs from incompatible systems. The --fake-super option only affects the side where the option is used. To affect the remote side of a remote- shell connection, use the --remote-option (-M) option: rsync -av -M--fake-super /src/ host:/dest/ For a local copy, this option affects both the source and the destination. If you wish a local copy to enable this option just for the destination files, specify -M--fake- super. If you wish a local copy to enable this option just for the source files, combine --fake-super with -M--super. This option is overridden by both --super and --no-super. See also the fake super setting in the daemon's rsyncd.conf file. --sparse, -S Try to handle sparse files efficiently so they take up less space on the destination. If combined with --inplace the file created might not end up with sparse blocks with some combinations of kernel version and/or filesystem type. If --whole-file is in effect (e.g. for a local copy) then it will always work because rsync truncates the file prior to writing out the updated version. Note that versions of rsync older than 3.1.3 will reject the combination of --sparse and --inplace. --preallocate This tells the receiver to allocate each destination file to its eventual size before writing data to the file. Rsync will only use the real filesystem-level preallocation support provided by Linux's fallocate(2) system call or Cygwin's posix_fallocate(3), not the slow glibc implementation that writes a null byte into each block. Without this option, larger files may not be entirely contiguous on the filesystem, but with this option rsync will probably copy more slowly. If the destination is not an extent-supporting filesystem (such as ext4, xfs, NTFS, etc.), this option may have no positive effect at all. If combined with --sparse, the file will only have sparse blocks (as opposed to allocated sequences of null bytes) if the kernel version and filesystem type support creating holes in the allocated data. --dry-run, -n This makes rsync perform a trial run that doesn't make any changes (and produces mostly the same output as a real run). It is most commonly used in combination with the --verbose (-v) and/or --itemize-changes (-i) options to see what an rsync command is going to do before one actually runs it. The output of --itemize-changes is supposed to be exactly the same on a dry run and a subsequent real run (barring intentional trickery and system call failures); if it isn't, that's a bug. Other output should be mostly unchanged, but may differ in some areas. Notably, a dry run does not send the actual data for file transfers, so --progress has no effect, the \"bytes sent\", \"bytes received\", \"literal data\", and \"matched data\" statistics are too small, and the \"speedup\" value is equivalent to a run where no file transfers were needed. --whole-file, -W This option disables rsync's delta-transfer algorithm, which causes all transferred files to be sent whole. The transfer may be faster if this option is used when the bandwidth between the source and destination machines is higher than the bandwidth to disk (especially when the \"disk\" is actually a networked filesystem). This is the default when both the source and destination are specified as local paths, but only if no batch-writing option is in effect. --no-whole-file, --no-W Disable whole-file updating when it is enabled by default for a local transfer. This usually slows rsync down, but it can be useful if you are trying to minimize the writes to the destination file (if combined with --inplace) or for testing the checksum-based update algorithm. See also the --whole-file option. --checksum-choice=STR, --cc=STR This option overrides the checksum algorithms. If one algorithm name is specified, it is used for both the transfer checksums and (assuming --checksum is specified) the pre-transfer checksums. If two comma-separated names are supplied, the first name affects the transfer checksums, and the second name affects the pre-transfer checksums (-c). The checksum options that you may be able to use are: o auto (the default automatic choice) o xxh128 o xxh3 o xxh64 (aka xxhash) o md5 o md4 o sha1 o none Run rsync --version to see the default checksum list compiled into your version (which may differ from the list above). If \"none\" is specified for the first (or only) name, the --whole-file option is forced on and no checksum verification is performed on the transferred data. If \"none\" is specified for the second (or only) name, the --checksum option cannot be used. The \"auto\" option is the default, where rsync bases its algorithm choice on a negotiation between the client and the server as follows: When both sides of the transfer are at least 3.2.0, rsync chooses the first algorithm in the client's list of choices that is also in the server's list of choices. If no common checksum choice is found, rsync exits with an error. If the remote rsync is too old to support checksum negotiation, a value is chosen based on the protocol version (which chooses between MD5 and various flavors of MD4 based on protocol age). The default order can be customized by setting the environment variable RSYNC_CHECKSUM_LIST to a space- separated list of acceptable checksum names. If the string contains a \"&\" character, it is separated into the \"client string & server string\", otherwise the same string applies to both. If the string (or string portion) contains no non-whitespace characters, the default checksum list is used. This method does not allow you to specify the transfer checksum separately from the pre- transfer checksum, and it discards \"auto\" and all unknown checksum names. A list with only invalid names results in a failed negotiation. The use of the --checksum-choice option overrides this environment list. --one-file-system, -x This tells rsync to avoid crossing a filesystem boundary when recursing. This does not limit the user's ability to specify items to copy from multiple filesystems, just rsync's recursion through the hierarchy of each directory that the user specified, and also the analogous recursion on the receiving side during deletion. Also keep in mind that rsync treats a \"bind\" mount to the same device as being on the same filesystem. If this option is repeated, rsync omits all mount-point directories from the copy. Otherwise, it includes an empty directory at each mount-point it encounters (using the attributes of the mounted directory because those of the underlying mount-point directory are inaccessible). If rsync has been told to collapse symlinks (via --copy- links or --copy-unsafe-links), a symlink to a directory on another device is treated like a mount-point. Symlinks to non-directories are unaffected by this option. --ignore-non-existing, --existing This tells rsync to skip creating files (including directories) that do not exist yet on the destination. If this option is combined with the --ignore-existing option, no files will be updated (which can be useful if all you want to do is delete extraneous files). This option is a TRANSFER RULE, so don't expect any exclude side effects. --ignore-existing This tells rsync to skip updating files that already exist on the destination (this does not ignore existing directories, or nothing would get done). See also --ignore-non-existing. This option is a TRANSFER RULE, so don't expect any exclude side effects. This option can be useful for those doing backups using the --link-dest option when they need to continue a backup run that got interrupted. Since a --link-dest run is copied into a new directory hierarchy (when it is used properly), using [--ignore-existing will ensure that the already-handled files don't get tweaked (which avoids a change in permissions on the hard-linked files). This does mean that this option is only looking at the existing files in the destination hierarchy itself. When --info=skip2 is used rsync will output \"FILENAME exists (INFO)\" messages where the INFO indicates one of \"type change\", \"sum change\" (requires -c), \"file change\" (based on the quick check), \"attr change\", or \"uptodate\". Using --info=skip1 (which is also implied by 2 -v options) outputs the exists message without the INFO suffix. --remove-source-files This tells rsync to remove from the sending side the files (meaning non-directories) that are a part of the transfer and have been successfully duplicated on the receiving side. Note that you should only use this option on source files that are quiescent. If you are using this to move files that show up in a particular directory over to another host, make sure that the finished files get renamed into the source directory, not directly written into it, so that rsync can't possibly transfer a file that is not yet fully written. If you can't first write the files into a different directory, you should use a naming idiom that lets rsync avoid transferring files that are not yet finished (e.g. name the file \"foo.new\" when it is written, rename it to \"foo\" when it is done, and then use the option --exclude='*.new' for the rsync transfer). Starting with 3.1.0, rsync will skip the sender-side removal (and output an error) if the file's size or modify time has not stayed unchanged. Starting with 3.2.6, a local rsync copy will ensure that the sender does not remove a file the receiver just verified, such as when the user accidentally makes the source and destination directory the same path. --delete This tells rsync to delete extraneous files from the receiving side (ones that aren't on the sending side), but only for the directories that are being synchronized. You must have asked rsync to send the whole directory (e.g. \"dir\" or \"dir/\") without using a wildcard for the directory's contents (e.g. \"dir/*\") since the wildcard is expanded by the shell and rsync thus gets a request to transfer individual files, not the files' parent directory. Files that are excluded from the transfer are also excluded from being deleted unless you use the --delete-excluded option or mark the rules as only matching on the sending side (see the include/exclude modifiers in the FILTER RULES section). Prior to rsync 2.6.7, this option would have no effect unless --recursive was enabled. Beginning with 2.6.7, deletions will also occur when --dirs (-d) is enabled, but only for directories whose contents are being copied. This option can be dangerous if used incorrectly! It is a very good idea to first try a run using the --dry-run (-n) option to see what files are going to be deleted. If the sending side detects any I/O errors, then the deletion of any files at the destination will be automatically disabled. This is to prevent temporary filesystem failures (such as NFS errors) on the sending side from causing a massive deletion of files on the destination. You can override this with the --ignore- errors option. The --delete option may be combined with one of the --delete-WHEN options without conflict, as well as --delete-excluded. However, if none of the --delete-WHEN options are specified, rsync will choose the --delete- during algorithm when talking to rsync 3.0.0 or newer, or the --delete-before algorithm when talking to an older rsync. See also --delete-delay and --delete-after. --delete-before Request that the file-deletions on the receiving side be done before the transfer starts. See --delete (which is implied) for more details on file-deletion. Deleting before the transfer is helpful if the filesystem is tight for space and removing extraneous files would help to make the transfer possible. However, it does introduce a delay before the start of the transfer, and this delay might cause the transfer to timeout (if --timeout was specified). It also forces rsync to use the old, non-incremental recursion algorithm that requires rsync to scan all the files in the transfer into memory at once (see --recursive). --delete-during, --del Request that the file-deletions on the receiving side be done incrementally as the transfer happens. The per- directory delete scan is done right before each directory is checked for updates, so it behaves like a more efficient --delete-before, including doing the deletions prior to any per-directory filter files being updated. This option was first added in rsync version 2.6.4. See --delete (which is implied) for more details on file- deletion. --delete-delay Request that the file-deletions on the receiving side be computed during the transfer (like --delete-during), and then removed after the transfer completes. This is useful when combined with --delay-updates and/or --fuzzy, and is more efficient than using --delete-after (but can behave differently, since --delete-after computes the deletions in a separate pass after all updates are done). If the number of removed files overflows an internal buffer, a temporary file will be created on the receiving side to hold the names (it is removed while open, so you shouldn't see it during the transfer). If the creation of the temporary file fails, rsync will try to fall back to using --delete-after (which it cannot do if --recursive is doing an incremental scan). See --delete (which is implied) for more details on file-deletion. --delete-after Request that the file-deletions on the receiving side be done after the transfer has completed. This is useful if you are sending new per-directory merge files as a part of the transfer and you want their exclusions to take effect for the delete phase of the current transfer. It also forces rsync to use the old, non-incremental recursion algorithm that requires rsync to scan all the files in the transfer into memory at once (see --recursive). See --delete (which is implied) for more details on file- deletion. See also the --delete-delay option that might be a faster choice for those that just want the deletions to occur at the end of the transfer. --delete-excluded This option turns any unqualified exclude/include rules into server-side rules that do not affect the receiver's deletions. By default, an exclude or include has both a server-side effect (to \"hide\" and \"show\" files when building the server's file list) and a receiver-side effect (to \"protect\" and \"risk\" files when deletions are occurring). Any rule that has no modifier to specify what sides it is executed on will be instead treated as if it were a server-side rule only, avoiding any \"protect\" effects of the rules. A rule can still apply to both sides even with this option specified if the rule is given both the sender & receiver modifier letters (e.g., -f'-sr foo'). Receiver-side protect/risk rules can also be explicitly specified to limit the deletions. This saves you from having to edit a bunch of -f'- foo' rules into -f'-s foo' (aka -f'H foo') rules (not to mention the corresponding includes). See the FILTER RULES section for more information. See --delete (which is implied) for more details on deletion. --ignore-missing-args When rsync is first processing the explicitly requested source files (e.g. command-line arguments or --files-from entries), it is normally an error if the file cannot be found. This option suppresses that error, and does not try to transfer the file. This does not affect subsequent vanished-file errors if a file was initially found to be present and later is no longer there. --delete-missing-args This option takes the behavior of the (implied) --ignore- missing-args option a step farther: each missing arg will become a deletion request of the corresponding destination file on the receiving side (should it exist). If the destination file is a non-empty directory, it will only be successfully deleted if --force or --delete are in effect. Other than that, this option is independent of any other type of delete processing. The missing source files are represented by special file- list entries which display as a \"*missing\" entry in the --list-only output. --ignore-errors Tells --delete to go ahead and delete files even when there are I/O errors. --force This option tells rsync to delete a non-empty directory when it is to be replaced by a non-directory. This is only relevant if deletions are not active (see --delete for details). Note for older rsync versions: --force used to still be required when using --delete-after, and it used to be non- functional unless the --recursive option was also enabled. --max-delete=NUM This tells rsync not to delete more than NUM files or directories. If that limit is exceeded, all further deletions are skipped through the end of the transfer. At the end, rsync outputs a warning (including a count of the skipped deletions) and exits with an error code of 25 (unless some more important error condition also occurred). Beginning with version 3.0.0, you may specify --max- delete=0 to be warned about any extraneous files in the destination without removing any of them. Older clients interpreted this as \"unlimited\", so if you don't know what version the client is, you can use the less obvious --max- delete=-1 as a backward-compatible way to specify that no deletions be allowed (though really old versions didn't warn when the limit was exceeded). --max-size=SIZE This tells rsync to avoid transferring any file that is larger than the specified SIZE. A numeric value can be suffixed with a string to indicate the numeric units or left unqualified to specify bytes. Feel free to use a fractional value along with the units, such as --max- size=1.5m. This option is a TRANSFER RULE, so don't expect any exclude side effects. The first letter of a units string can be B (bytes), K (kilo), M (mega), G (giga), T (tera), or P (peta). If the string is a single char or has \"ib\" added to it (e.g. \"G\" or \"GiB\") then the units are multiples of 1024. If you use a two-letter suffix that ends with a \"B\" (e.g. \"kb\") then you get units that are multiples of 1000. The string's letters can be any mix of upper and lower-case that you want to use. Finally, if the string ends with either \"+1\" or \"-1\", it is offset by one byte in the indicated direction. The largest possible value is usually 8192P-1. Examples: --max-size=1.5mb-1 is 1499999 bytes, and --max- size=2g+1 is 2147483649 bytes. Note that rsync versions prior to 3.1.0 did not allow --max-size=0. --min-size=SIZE This tells rsync to avoid transferring any file that is smaller than the specified SIZE, which can help in not transferring small, junk files. See the --max-size option for a description of SIZE and other info. Note that rsync versions prior to 3.1.0 did not allow --min-size=0. --max-alloc=SIZE By default rsync limits an individual malloc/realloc to about 1GB in size. For most people this limit works just fine and prevents a protocol error causing rsync to request massive amounts of memory. However, if you have many millions of files in a transfer, a large amount of server memory, and you don't want to split up your transfer into multiple parts, you can increase the per- allocation limit to something larger and rsync will consume more memory. Keep in mind that this is not a limit on the total size of allocated memory. It is a sanity-check value for each individual allocation. See the --max-size option for a description of how SIZE can be specified. The default suffix if none is given is bytes. Beginning in 3.2.3, a value of 0 specifies no limit. You can set a default value using the environment variable RSYNC_MAX_ALLOC using the same SIZE values as supported by this option. If the remote rsync doesn't understand the --max-alloc option, you can override an environmental value by specifying --max-alloc=1g, which will make rsync avoid sending the option to the remote side (because \"1G\" is the default). --block-size=SIZE, -B This forces the block size used in rsync's delta-transfer algorithm to a fixed value. It is normally selected based on the size of each file being updated. See the technical report for details. Beginning in 3.2.3 the SIZE can be specified with a suffix as detailed in the --max-size option. Older versions only accepted a byte count. --rsh=COMMAND, -e This option allows you to choose an alternative remote shell program to use for communication between the local and remote copies of rsync. Typically, rsync is configured to use ssh by default, but you may prefer to use rsh on a local network. If this option is used with [user@]host::module/path, then the remote shell COMMAND will be used to run an rsync daemon on the remote host, and all data will be transmitted through that remote shell connection, rather than through a direct socket connection to a running rsync daemon on the remote host. See the USING RSYNC-DAEMON FEATURES VIA A REMOTE-SHELL CONNECTION section above. Beginning with rsync 3.2.0, the RSYNC_PORT environment variable will be set when a daemon connection is being made via a remote-shell connection. It is set to 0 if the default daemon port is being assumed, or it is set to the value of the rsync port that was specified via either the --port option or a non-empty port value in an rsync:// URL. This allows the script to discern if a non-default port is being requested, allowing for things such as an SSL or stunnel helper script to connect to a default or alternate port. Command-line arguments are permitted in COMMAND provided that COMMAND is presented to rsync as a single argument. You must use spaces (not tabs or other whitespace) to separate the command and args from each other, and you can use single- and/or double-quotes to preserve spaces in an argument (but not backslashes). Note that doubling a single-quote inside a single-quoted string gives you a single-quote; likewise for double-quotes (though you need to pay attention to which quotes your shell is parsing and which quotes rsync is parsing). Some examples: -e 'ssh -p 2234' -e 'ssh -o \"ProxyCommand nohup ssh firewall nc -w1 %h %p\"' (Note that ssh users can alternately customize site- specific connect options in their .ssh/config file.) You can also choose the remote shell program using the RSYNC_RSH environment variable, which accepts the same range of values as -e. See also the --blocking-io option which is affected by this option. --rsync-path=PROGRAM Use this to specify what program is to be run on the remote machine to start-up rsync. Often used when rsync is not in the default remote-shell's path (e.g. --rsync- path=/usr/local/bin/rsync). Note that PROGRAM is run with the help of a shell, so it can be any program, script, or command sequence you'd care to run, so long as it does not corrupt the standard-in & standard-out that rsync is using to communicate. One tricky example is to set a different default directory on the remote machine for use with the --relative option. For instance: rsync -avR --rsync-path=\"cd /a/b && rsync\" host:c/d /e/ --remote-option=OPTION, -M This option is used for more advanced situations where you want certain effects to be limited to one side of the transfer only. For instance, if you want to pass --log- file=FILE and --fake-super to the remote system, specify it like this: rsync -av -M --log-file=foo -M--fake-super src/ dest/ If you want to have an option affect only the local side of a transfer when it normally affects both sides, send its negation to the remote side. Like this: rsync -av -x -M--no-x src/ dest/ Be cautious using this, as it is possible to toggle an option that will cause rsync to have a different idea about what data to expect next over the socket, and that will make it fail in a cryptic fashion. Note that you should use a separate -M option for each remote option you want to pass. On older rsync versions, the presence of any spaces in the remote-option arg could cause it to be split into separate remote args, but this requires the use of --old-args in a modern rsync. When performing a local transfer, the \"local\" side is the sender and the \"remote\" side is the receiver. Note some versions of the popt option-parsing library have a bug in them that prevents you from using an adjacent arg with an equal in it next to a short option letter (e.g. -M--log-file=/tmp/foo). If this bug affects your version of popt, you can use the version of popt that is included with rsync. --cvs-exclude, -C This is a useful shorthand for excluding a broad range of files that you often don't want to transfer between systems. It uses a similar algorithm to CVS to determine if a file should be ignored. The exclude list is initialized to exclude the following items (these initial items are marked as perishable -- see the FILTER RULES section): RCS SCCS CVS CVS.adm RCSLOG cvslog.* tags TAGS .make.state .nse_depinfo *~ #* .#* ,* _$* *$ *.old *.bak *.BAK *.orig *.rej .del-* *.a *.olb *.o *.obj *.so *.exe *.Z *.elc *.ln core .svn/ .git/ .hg/ .bzr/ then, files listed in a $HOME/.cvsignore are added to the list and any files listed in the CVSIGNORE environment variable (all cvsignore names are delimited by whitespace). Finally, any file is ignored if it is in the same directory as a .cvsignore file and matches one of the patterns listed therein. Unlike rsync's filter/exclude files, these patterns are split on whitespace. See the cvs(1) manual for more information. If you're combining -C with your own --filter rules, you should note that these CVS excludes are appended at the end of your own rules, regardless of where the -C was placed on the command-line. This makes them a lower priority than any rules you specified explicitly. If you want to control where these CVS excludes get inserted into your filter rules, you should omit the -C as a command- line option and use a combination of --filter=:C and --filter=-C (either on your command-line or by putting the \":C\" and \"-C\" rules into a filter file with your other rules). The first option turns on the per-directory scanning for the .cvsignore file. The second option does a one-time import of the CVS excludes mentioned above. --filter=RULE, -f This option allows you to add rules to selectively exclude certain files from the list of files to be transferred. This is most useful in combination with a recursive transfer. You may use as many --filter options on the command line as you like to build up the list of files to exclude. If the filter contains whitespace, be sure to quote it so that the shell gives the rule to rsync as a single argument. The text below also mentions that you can use an underscore to replace the space that separates a rule from its arg. See the FILTER RULES section for detailed information on this option. -F The -F option is a shorthand for adding two --filter rules to your command. The first time it is used is a shorthand for this rule: --filter='dir-merge /.rsync-filter' This tells rsync to look for per-directory .rsync-filter files that have been sprinkled through the hierarchy and use their rules to filter the files in the transfer. If -F is repeated, it is a shorthand for this rule: --filter='exclude .rsync-filter' This filters out the .rsync-filter files themselves from the transfer. See the FILTER RULES section for detailed information on how these options work. --exclude=PATTERN This option is a simplified form of the --filter option that specifies an exclude rule and does not allow the full rule-parsing syntax of normal filter rules. This is equivalent to specifying -f'- PATTERN'. See the FILTER RULES section for detailed information on this option. --exclude-from=FILE This option is related to the --exclude option, but it specifies a FILE that contains exclude patterns (one per line). Blank lines in the file are ignored, as are whole- line comments that start with ';' or '#' (filename rules that contain those characters are unaffected). If a line begins with \"- \" (dash, space) or \"+ \" (plus, space), then the type of rule is being explicitly specified as an exclude or an include (respectively). Any rules without such a prefix are taken to be an exclude. If a line consists of just \"!\", then the current filter rules are cleared before adding any further rules. If FILE is '-', the list will be read from standard input. --include=PATTERN This option is a simplified form of the --filter option that specifies an include rule and does not allow the full rule-parsing syntax of normal filter rules. This is equivalent to specifying -f'+ PATTERN'. See the FILTER RULES section for detailed information on this option. --include-from=FILE This option is related to the --include option, but it specifies a FILE that contains include patterns (one per line). Blank lines in the file are ignored, as are whole- line comments that start with ';' or '#' (filename rules that contain those characters are unaffected). If a line begins with \"- \" (dash, space) or \"+ \" (plus, space), then the type of rule is being explicitly specified as an exclude or an include (respectively). Any rules without such a prefix are taken to be an include. If a line consists of just \"!\", then the current filter rules are cleared before adding any further rules. If FILE is '-', the list will be read from standard input. --files-from=FILE Using this option allows you to specify the exact list of files to transfer (as read from the specified FILE or '-' for standard input). It also tweaks the default behavior of rsync to make transferring just the specified files and directories easier: o The --relative (-R) option is implied, which preserves the path information that is specified for each item in the file (use --no-relative or --no-R if you want to turn that off). o The --dirs (-d) option is implied, which will create directories specified in the list on the destination rather than noisily skipping them (use --no-dirs or --no-d if you want to turn that off). o The --archive (-a) option's behavior does not imply --recursive (-r), so specify it explicitly, if you want it. o These side-effects change the default state of rsync, so the position of the --files-from option on the command-line has no bearing on how other options are parsed (e.g. -a works the same before or after --files-from, as does --no-R and all other options). The filenames that are read from the FILE are all relative to the source dir -- any leading slashes are removed and no \"..\" references are allowed to go higher than the source dir. For example, take this command: rsync -a --files-from=/tmp/foo /usr remote:/backup If /tmp/foo contains the string \"bin\" (or even \"/bin\"), the /usr/bin directory will be created as /backup/bin on the remote host. If it contains \"bin/\" (note the trailing slash), the immediate contents of the directory would also be sent (without needing to be explicitly mentioned in the file -- this began in version 2.6.4). In both cases, if the -r option was enabled, that dir's entire hierarchy would also be transferred (keep in mind that -r needs to be specified explicitly with --files-from, since it is not implied by -a. Also note that the effect of the (enabled by default) -r option is to duplicate only the path info that is read from the file -- it does not force the duplication of the source-spec path (/usr in this case). In addition, the --files-from file can be read from the remote host instead of the local host if you specify a \"host:\" in front of the file (the host must match one end of the transfer). As a short-cut, you can specify just a prefix of \":\" to mean \"use the remote end of the transfer\". For example: rsync -a --files-from=:/path/file-list src:/ /tmp/copy This would copy all the files specified in the /path/file- list file that was located on the remote \"src\" host. If the --iconv and --secluded-args options are specified and the --files-from filenames are being sent from one host to another, the filenames will be translated from the sending host's charset to the receiving host's charset. NOTE: sorting the list of files in the --files-from input helps rsync to be more efficient, as it will avoid re- visiting the path elements that are shared between adjacent entries. If the input is not sorted, some path elements (implied directories) may end up being scanned multiple times, and rsync will eventually unduplicate them after they get turned into file-list elements. --from0, -0 This tells rsync that the rules/filenames it reads from a file are terminated by a null ('\\0') character, not a NL, CR, or CR+LF. This affects --exclude-from, --include- from, --files-from, and any merged files specified in a --filter rule. It does not affect --cvs-exclude (since all names read from a .cvsignore file are split on whitespace). --old-args This option tells rsync to stop trying to protect the arg values on the remote side from unintended word-splitting or other misinterpretation. It also allows the client to treat an empty arg as a \".\" instead of generating an error. The default in a modern rsync is for \"shell-active\" characters (including spaces) to be backslash-escaped in the args that are sent to the remote shell. The wildcard characters *, ?, [, & ] are not escaped in filename args (allowing them to expand into multiple filenames) while being protected in option args, such as --usermap. If you have a script that wants to use old-style arg splitting in its filenames, specify this option once. If the remote shell has a problem with any backslash escapes at all, specify this option twice. You may also control this setting via the RSYNC_OLD_ARGS environment variable. If it has the value \"1\", rsync will default to a single-option setting. If it has the value \"2\" (or more), rsync will default to a repeated-option setting. If it is \"0\", you'll get the default escaping behavior. The environment is always overridden by manually specified positive or negative options (the negative is --no-old-args). Note that this option also disables the extra safety check added in 3.2.5 that ensures that a remote sender isn't including extra top-level items in the file-list that you didn't request. This side-effect is necessary because we can't know for sure what names to expect when the remote shell is interpreting the args. This option conflicts with the --secluded-args option. --secluded-args, -s This option sends all filenames and most options to the remote rsync via the protocol (not the remote shell command line) which avoids letting the remote shell modify them. Wildcards are expanded on the remote host by rsync instead of a shell. This is similar to the default backslash-escaping of args that was added in 3.2.4 (see --old-args) in that it prevents things like space splitting and unwanted special- character side-effects. However, it has the drawbacks of being incompatible with older rsync versions (prior to 3.0.0) and of being refused by restricted shells that want to be able to inspect all the option values for safety. This option is useful for those times that you need the argument's character set to be converted for the remote host, if the remote shell is incompatible with the default backslash-escpaing method, or there is some other reason that you want the majority of the options and arguments to bypass the command-line of the remote shell. If you combine this option with --iconv, the args related to the remote side will be translated from the local to the remote character-set. The translation happens before wild-cards are expanded. See also the --files-from option. You may also control this setting via the RSYNC_PROTECT_ARGS environment variable. If it has a non- zero value, this setting will be enabled by default, otherwise it will be disabled by default. Either state is overridden by a manually specified positive or negative version of this option (note that --no-s and --no- secluded-args are the negative versions). This environment variable is also superseded by a non-zero RSYNC_OLD_ARGS export. This option conflicts with the --old-args option. This option used to be called --protect-args (before 3.2.6) and that older name can still be used (though specifying it as -s is always the easiest and most compatible choice). --trust-sender This option disables two extra validation checks that a local client performs on the file list generated by a remote sender. This option should only be used if you trust the sender to not put something malicious in the file list (something that could possibly be done via a modified rsync, a modified shell, or some other similar manipulation). Normally, the rsync client (as of version 3.2.5) runs two extra validation checks when pulling files from a remote rsync: o It verifies that additional arg items didn't get added at the top of the transfer. o It verifies that none of the items in the file list are names that should have been excluded (if filter rules were specified). Note that various options can turn off one or both of these checks if the option interferes with the validation. For instance: o Using a per-directory filter file reads filter rules that only the server knows about, so the filter checking is disabled. o Using the --old-args option allows the sender to manipulate the requested args, so the arg checking is disabled. o Reading the files-from list from the server side means that the client doesn't know the arg list, so the arg checking is disabled. o Using --read-batch disables both checks since the batch file's contents will have been verified when it was created. This option may help an under-powered client server if the extra pattern matching is slowing things down on a huge transfer. It can also be used to work around a currently- unknown bug in the verification logic for a transfer from a trusted sender. When using this option it is a good idea to specify a dedicated destination directory, as discussed in the MULTI-HOST SECURITY section. --copy-as=USER[:GROUP] This option instructs rsync to use the USER and (if specified after a colon) the GROUP for the copy operations. This only works if the user that is running rsync has the ability to change users. If the group is not specified then the user's default groups are used. This option can help to reduce the risk of an rsync being run as root into or out of a directory that might have live changes happening to it and you want to make sure that root-level read or write actions of system files are not possible. While you could alternatively run all of rsync as the specified user, sometimes you need the root- level host-access credentials to be used, so this allows rsync to drop root for the copying part of the operation after the remote-shell or daemon connection is established. The option only affects one side of the transfer unless the transfer is local, in which case it affects both sides. Use the --remote-option to affect the remote side, such as -M--copy-as=joe. For a local transfer, the lsh (or lsh.sh) support file provides a local-shell helper script that can be used to allow a \"localhost:\" or \"lh:\" host-spec to be specified without needing to setup any remote shells, allowing you to specify remote options that affect the side of the transfer that is using the host- spec (and using hostname \"lh\" avoids the overriding of the remote directory to the user's home dir). For example, the following rsync writes the local files as user \"joe\": sudo rsync -aiv --copy-as=joe host1:backups/joe/ /home/joe/ This makes all files owned by user \"joe\", limits the groups to those that are available to that user, and makes it impossible for the joe user to do a timed exploit of the path to induce a change to a file that the joe user has no permissions to change. The following command does a local copy into the \"dest/\" dir as user \"joe\" (assuming you've installed support/lsh into a dir on your $PATH): sudo rsync -aive lsh -M--copy-as=joe src/ lh:dest/ --temp-dir=DIR, -T This option instructs rsync to use DIR as a scratch directory when creating temporary copies of the files transferred on the receiving side. The default behavior is to create each temporary file in the same directory as the associated destination file. Beginning with rsync 3.1.1, the temp-file names inside the specified DIR will not be prefixed with an extra dot (though they will still have a random suffix added). This option is most often used when the receiving disk partition does not have enough free space to hold a copy of the largest file in the transfer. In this case (i.e. when the scratch directory is on a different disk partition), rsync will not be able to rename each received temporary file over the top of the associated destination file, but instead must copy it into place. Rsync does this by copying the file over the top of the destination file, which means that the destination file will contain truncated data during this copy. If this were not done this way (even if the destination file were first removed, the data locally copied to a temporary file in the destination directory, and then renamed into place) it would be possible for the old file to continue taking up disk space (if someone had it open), and thus there might not be enough room to fit the new version on the disk at the same time. If you are using this option for reasons other than a shortage of disk space, you may wish to combine it with the --delay-updates option, which will ensure that all copied files get put into subdirectories in the destination hierarchy, awaiting the end of the transfer. If you don't have enough room to duplicate all the arriving files on the destination partition, another way to tell rsync that you aren't overly concerned about disk space is to use the --partial-dir option with a relative path; because this tells rsync that it is OK to stash off a copy of a single file in a subdir in the destination hierarchy, rsync will use the partial-dir as a staging area to bring over the copied file, and then rename it into place from there. (Specifying a --partial-dir with an absolute path does not have this side-effect.) --fuzzy, -y This option tells rsync that it should look for a basis file for any destination file that is missing. The current algorithm looks in the same directory as the destination file for either a file that has an identical size and modified-time, or a similarly-named file. If found, rsync uses the fuzzy basis file to try to speed up the transfer. If the option is repeated, the fuzzy scan will also be done in any matching alternate destination directories that are specified via --compare-dest, --copy-dest, or --link-dest. Note that the use of the --delete option might get rid of any potential fuzzy-match files, so either use --delete- after or specify some filename exclusions if you need to prevent this. --compare-dest=DIR This option instructs rsync to use DIR on the destination machine as an additional hierarchy to compare destination files against doing transfers (if the files are missing in the destination directory). If a file is found in DIR that is identical to the sender's file, the file will NOT be transferred to the destination directory. This is useful for creating a sparse backup of just files that have changed from an earlier backup. This option is typically used to copy into an empty (or newly created) directory. Beginning in version 2.6.4, multiple --compare-dest directories may be provided, which will cause rsync to search the list in the order specified for an exact match. If a match is found that differs only in attributes, a local copy is made and the attributes updated. If a match is not found, a basis file from one of the DIRs will be selected to try to speed up the transfer. If DIR is a relative path, it is relative to the destination directory. See also --copy-dest and --link- dest. NOTE: beginning with version 3.1.0, rsync will remove a file from a non-empty destination hierarchy if an exact match is found in one of the compare-dest hierarchies (making the end result more closely match a fresh copy). --copy-dest=DIR This option behaves like --compare-dest, but rsync will also copy unchanged files found in DIR to the destination directory using a local copy. This is useful for doing transfers to a new destination while leaving existing files intact, and then doing a flash-cutover when all files have been successfully transferred. Multiple --copy-dest directories may be provided, which will cause rsync to search the list in the order specified for an unchanged file. If a match is not found, a basis file from one of the DIRs will be selected to try to speed up the transfer. If DIR is a relative path, it is relative to the destination directory. See also --compare-dest and --link-dest. --link-dest=DIR This option behaves like --copy-dest, but unchanged files are hard linked from DIR to the destination directory. The files must be identical in all preserved attributes (e.g. permissions, possibly ownership) in order for the files to be linked together. An example: rsync -av --link-dest=$PWD/prior_dir host:src_dir/ new_dir/ If files aren't linking, double-check their attributes. Also check if some attributes are getting forced outside of rsync's control, such a mount option that squishes root to a single user, or mounts a removable drive with generic ownership (such as OS X's \"Ignore ownership on this volume\" option). Beginning in version 2.6.4, multiple --link-dest directories may be provided, which will cause rsync to search the list in the order specified for an exact match (there is a limit of 20 such directories). If a match is found that differs only in attributes, a local copy is made and the attributes updated. If a match is not found, a basis file from one of the DIRs will be selected to try to speed up the transfer. This option works best when copying into an empty destination hierarchy, as existing files may get their attributes tweaked, and that can affect alternate destination files via hard-links. Also, itemizing of changes can get a bit muddled. Note that prior to version 3.1.0, an alternate-directory exact match would never be found (nor linked into the destination) when a destination file already exists. Note that if you combine this option with --ignore-times, rsync will not link any files together because it only links identical files together as a substitute for transferring the file, never as an additional check after the file is updated. If DIR is a relative path, it is relative to the destination directory. See also --compare-dest and --copy-dest. Note that rsync versions prior to 2.6.1 had a bug that could prevent --link-dest from working properly for a non- super-user when --owner (-o) was specified (or implied). You can work-around this bug by avoiding the -o option (or using --no-o) when sending to an old rsync. --compress, -z With this option, rsync compresses the file data as it is sent to the destination machine, which reduces the amount of data being transmitted -- something that is useful over a slow connection. Rsync supports multiple compression methods and will choose one for you unless you force the choice using the --compress-choice (--zc) option. Run rsync --version to see the default compress list compiled into your version. When both sides of the transfer are at least 3.2.0, rsync chooses the first algorithm in the client's list of choices that is also in the server's list of choices. If no common compress choice is found, rsync exits with an error. If the remote rsync is too old to support checksum negotiation, its list is assumed to be \"zlib\". The default order can be customized by setting the environment variable RSYNC_COMPRESS_LIST to a space- separated list of acceptable compression names. If the string contains a \"&\" character, it is separated into the \"client string & server string\", otherwise the same string applies to both. If the string (or string portion) contains no non-whitespace characters, the default compress list is used. Any unknown compression names are discarded from the list, but a list with only invalid names results in a failed negotiation. There are some older rsync versions that were configured to reject a -z option and require the use of -zz because their compression library was not compatible with the default zlib compression method. You can usually ignore this weirdness unless the rsync server complains and tells you to specify -zz. --compress-choice=STR, --zc=STR This option can be used to override the automatic negotiation of the compression algorithm that occurs when --compress is used. The option implies --compress unless \"none\" was specified, which instead implies --no-compress. The compression options that you may be able to use are: o zstd o lz4 o zlibx o zlib o none Run rsync --version to see the default compress list compiled into your version (which may differ from the list above). Note that if you see an error about an option named --old- compress or --new-compress, this is rsync trying to send the --compress-choice=zlib or --compress-choice=zlibx option in a backward-compatible manner that more rsync versions understand. This error indicates that the older rsync version on the server will not allow you to force the compression type. Note that the \"zlibx\" compression algorithm is just the \"zlib\" algorithm with matched data excluded from the compression stream (to try to make it more compatible with an external zlib implementation). --compress-level=NUM, --zl=NUM Explicitly set the compression level to use (see --compress, -z) instead of letting it default. The --compress option is implied as long as the level chosen is not a \"don't compress\" level for the compression algorithm that is in effect (e.g. zlib compression treats level 0 as \"off\"). The level values vary depending on the checksum in effect. Because rsync will negotiate a checksum choice by default (when the remote rsync is new enough), it can be good to combine this option with a --compress-choice (--zc) option unless you're sure of the choice in effect. For example: rsync -aiv --zc=zstd --zl=22 host:src/ dest/ For zlib & zlibx compression the valid values are from 1 to 9 with 6 being the default. Specifying --zl=0 turns compression off, and specifying --zl=-1 chooses the default level of 6. For zstd compression the valid values are from -131072 to 22 with 3 being the default. Specifying 0 chooses the default of 3. For lz4 compression there are no levels, so the value is always 0. If you specify a too-large or too-small value, the number is silently limited to a valid value. This allows you to specify something like --zl=999999999 and be assured that you'll end up with the maximum compression level no matter what algorithm was chosen. If you want to know the compression level that is in effect, specify --debug=nstr to see the \"negotiated string\" results. This will report something like \"Client compress: zstd (level 3)\" (along with the checksum choice in effect). --skip-compress=LIST NOTE: no compression method currently supports per-file compression changes, so this option has no effect. Override the list of file suffixes that will be compressed as little as possible. Rsync sets the compression level on a per-file basis based on the file's suffix. If the compression algorithm has an \"off\" level, then no compression occurs for those files. Other algorithms that support changing the streaming level on-the-fly will have the level minimized to reduces the CPU usage as much as possible for a matching file. The LIST should be one or more file suffixes (without the dot) separated by slashes (/). You may specify an empty string to indicate that no files should be skipped. Simple character-class matching is supported: each must consist of a list of letters inside the square brackets (e.g. no special classes, such as \"[:alpha:]\", are supported, and '-' has no special meaning). The characters asterisk (*) and question-mark (?) have no special meaning. Here's an example that specifies 6 suffixes to skip (since 1 of the 5 rules matches 2 suffixes): --skip-compress=gz/jpg/mp[34]/7z/bz2 The default file suffixes in the skip-compress list in this version of rsync are: 3g2 3gp 7z aac ace apk avi bz2 deb dmg ear f4v flac flv gpg gz iso jar jpeg jpg lrz lz lz4 lzma lzo m1a m1v m2a m2ts m2v m4a m4b m4p m4r m4v mka mkv mov mp1 mp2 mp3 mp4 mpa mpeg mpg mpv mts odb odf odg odi odm odp ods odt oga ogg ogm ogv ogx opus otg oth otp ots ott oxt png qt rar rpm rz rzip spx squashfs sxc sxd sxg sxm sxw sz tbz tbz2 tgz tlz ts txz tzo vob war webm webp xz z zip zst This list will be replaced by your --skip-compress list in all but one situation: a copy from a daemon rsync will add your skipped suffixes to its list of non-compressing files (and its list may be configured to a different default). --numeric-ids With this option rsync will transfer numeric group and user IDs rather than using user and group names and mapping them at both ends. By default rsync will use the username and groupname to determine what ownership to give files. The special uid 0 and the special group 0 are never mapped via user/group names even if the --numeric-ids option is not specified. If a user or group has no name on the source system or it has no match on the destination system, then the numeric ID from the source system is used instead. See also the use chroot setting in the rsyncd.conf manpage for some comments on how the chroot setting affects rsync's ability to look up the names of the users and groups and what you can do about it. --usermap=STRING, --groupmap=STRING These options allow you to specify users and groups that should be mapped to other values by the receiving side. The STRING is one or more FROM:TO pairs of values separated by commas. Any matching FROM value from the sender is replaced with a TO value from the receiver. You may specify usernames or user IDs for the FROM and TO values, and the FROM value may also be a wild-card string, which will be matched against the sender's names (wild- cards do NOT match against ID numbers, though see below for why a '*' matches everything). You may instead specify a range of ID numbers via an inclusive range: LOW- HIGH. For example: --usermap=0-99:nobody,wayne:admin,*:normal --groupmap=usr:1,1:usr The first match in the list is the one that is used. You should specify all your user mappings using a single --usermap option, and/or all your group mappings using a single --groupmap option. Note that the sender's name for the 0 user and group are not transmitted to the receiver, so you should either match these values using a 0, or use the names in effect on the receiving side (typically \"root\"). All other FROM names match those in use on the sending side. All TO names match those in use on the receiving side. Any IDs that do not have a name on the sending side are treated as having an empty name for the purpose of matching. This allows them to be matched via a \"*\" or using an empty name. For instance: --usermap=:nobody --groupmap=*:nobody When the --numeric-ids option is used, the sender does not send any names, so all the IDs are treated as having an empty name. This means that you will need to specify numeric FROM values if you want to map these nameless IDs to different values. For the --usermap option to work, the receiver will need to be running as a super-user (see also the --super and --fake-super options). For the --groupmap option to work, the receiver will need to have permissions to set that group. Starting with rsync 3.2.4, the --usermap option implies the --owner (-o) option while the --groupmap option implies the --group (-g) option (since rsync needs to have those options enabled for the mapping options to work). An older rsync client may need to use -s to avoid a complaint about wildcard characters, but a modern rsync handles this automatically. --chown=USER:GROUP This option forces all files to be owned by USER with group GROUP. This is a simpler interface than using --usermap & --groupmap directly, but it is implemented using those options internally so they cannot be mixed. If either the USER or GROUP is empty, no mapping for the omitted user/group will occur. If GROUP is empty, the trailing colon may be omitted, but if USER is empty, a leading colon must be supplied. If you specify \"--chown=foo:bar\", this is exactly the same as specifying \"--usermap=*:foo --groupmap=*:bar\", only easier (and with the same implied --owner and/or --group options). An older rsync client may need to use -s to avoid a complaint about wildcard characters, but a modern rsync handles this automatically. --timeout=SECONDS This option allows you to set a maximum I/O timeout in seconds. If no data is transferred for the specified time then rsync will exit. The default is 0, which means no timeout. --contimeout=SECONDS This option allows you to set the amount of time that rsync will wait for its connection to an rsync daemon to succeed. If the timeout is reached, rsync exits with an error. --address=ADDRESS By default rsync will bind to the wildcard address when connecting to an rsync daemon. The --address option allows you to specify a specific IP address (or hostname) to bind to. See also the daemon version of the --address option. --port=PORT This specifies an alternate TCP port number to use rather than the default of 873. This is only needed if you are using the double-colon (::) syntax to connect with an rsync daemon (since the URL syntax has a way to specify the port as a part of the URL). See also the daemon version of the --port option. --sockopts=OPTIONS This option can provide endless fun for people who like to tune their systems to the utmost degree. You can set all sorts of socket options which may make transfers faster (or slower!). Read the manpage for the setsockopt() system call for details on some of the options you may be able to set. By default no special socket options are set. This only affects direct socket connections to a remote rsync daemon. See also the daemon version of the --sockopts option. --blocking-io This tells rsync to use blocking I/O when launching a remote shell transport. If the remote shell is either rsh or remsh, rsync defaults to using blocking I/O, otherwise it defaults to using non-blocking I/O. (Note that ssh prefers non-blocking I/O.) --outbuf=MODE This sets the output buffering mode. The mode can be None (aka Unbuffered), Line, or Block (aka Full). You may specify as little as a single letter for the mode, and use upper or lower case. The main use of this option is to change Full buffering to Line buffering when rsync's output is going to a file or pipe. --itemize-changes, -i Requests a simple itemized list of the changes that are being made to each file, including attribute changes. This is exactly the same as specifying --out- format='%i %n%L'. If you repeat the option, unchanged files will also be output, but only if the receiving rsync is at least version 2.6.7 (you can use -vv with older versions of rsync, but that also turns on the output of other verbose messages). The \"%i\" escape has a cryptic output that is 11 letters long. The general format is like the string YXcstpoguax, where Y is replaced by the type of update being done, X is replaced by the file-type, and the other letters represent attributes that may be output if they are being modified. The update types that replace the Y are as follows: o A < means that a file is being transferred to the remote host (sent). o A > means that a file is being transferred to the local host (received). o A c means that a local change/creation is occurring for the item (such as the creation of a directory or the changing of a symlink, etc.). o A h means that the item is a hard link to another item (requires --hard-links). o A . means that the item is not being updated (though it might have attributes that are being modified). o A * means that the rest of the itemized-output area contains a message (e.g. \"deleting\"). The file-types that replace the X are: f for a file, a d for a directory, an L for a symlink, a D for a device, and a S for a special file (e.g. named sockets and fifos). The other letters in the string indicate if some attributes of the file have changed, as follows: o \".\" - the attribute is unchanged. o \"+\" - the file is newly created. o \" \" - all the attributes are unchanged (all dots turn to spaces). o \"?\" - the change is unknown (when the remote rsync is old). o A letter indicates an attribute is being updated. The attribute that is associated with each letter is as follows: o A c means either that a regular file has a different checksum (requires --checksum) or that a symlink, device, or special file has a changed value. Note that if you are sending files to an rsync prior to 3.0.1, this change flag will be present only for checksum-differing regular files. o A s means the size of a regular file is different and will be updated by the file transfer. o A t means the modification time is different and is being updated to the sender's value (requires --times). An alternate value of T means that the modification time will be set to the transfer time, which happens when a file/symlink/device is updated without --times and when a symlink is changed and the receiver can't set its time. (Note: when using an rsync 3.0.0 client, you might see the s flag combined with t instead of the proper T flag for this time-setting failure.) o A p means the permissions are different and are being updated to the sender's value (requires --perms). o An o means the owner is different and is being updated to the sender's value (requires --owner and super-user privileges). o A g means the group is different and is being updated to the sender's value (requires --group and the authority to set the group). o o A u|n|b indicates the following information: u means the access (use) time is different and is being updated to the sender's value (requires --atimes) o n means the create time (newness) is different and is being updated to the sender's value (requires --crtimes) o b means that both the access and create times are being updated o The a means that the ACL information is being changed. o The x means that the extended attribute information is being changed. One other output is possible: when deleting files, the \"%i\" will output the string \"*deleting\" for each item that is being removed (assuming that you are talking to a recent enough rsync that it logs deletions instead of outputting them as a verbose message). --out-format=FORMAT This allows you to specify exactly what the rsync client outputs to the user on a per-update basis. The format is a text string containing embedded single-character escape sequences prefixed with a percent (%) character. A default format of \"%n%L\" is assumed if either --info=name or -v is specified (this tells you just the name of the file and, if the item is a link, where it points). For a full list of the possible escape characters, see the log format setting in the rsyncd.conf manpage. Specifying the --out-format option implies the --info=name option, which will mention each file, dir, etc. that gets updated in a significant way (a transferred file, a recreated symlink/device, or a touched directory). In addition, if the itemize-changes escape (%i) is included in the string (e.g. if the --itemize-changes option was used), the logging of names increases to mention any item that is changed in any way (as long as the receiving side is at least 2.6.4). See the --itemize-changes option for a description of the output of \"%i\". Rsync will output the out-format string prior to a file's transfer unless one of the transfer-statistic escapes is requested, in which case the logging is done at the end of the file's transfer. When this late logging is in effect and --progress is also specified, rsync will also output the name of the file being transferred prior to its progress information (followed, of course, by the out- format output). --log-file=FILE This option causes rsync to log what it is doing to a file. This is similar to the logging that a daemon does, but can be requested for the client side and/or the server side of a non-daemon transfer. If specified as a client option, transfer logging will be enabled with a default format of \"%i %n%L\". See the --log-file-format option if you wish to override this. Here's an example command that requests the remote side to log what is happening: rsync -av --remote-option=--log-file=/tmp/rlog src/ dest/ This is very useful if you need to debug why a connection is closing unexpectedly. See also the daemon version of the --log-file option. --log-file-format=FORMAT This allows you to specify exactly what per-update logging is put into the file specified by the --log-file option (which must also be specified for this option to have any effect). If you specify an empty string, updated files will not be mentioned in the log file. For a list of the possible escape characters, see the log format setting in the rsyncd.conf manpage. The default FORMAT used if --log-file is specified and this option is not is '%i %n%L'. See also the daemon version of the --log-file-format option. --stats This tells rsync to print a verbose set of statistics on the file transfer, allowing you to tell how effective rsync's delta-transfer algorithm is for your data. This option is equivalent to --info=stats2 if combined with 0 or 1 -v options, or --info=stats3 if combined with 2 or more -v options. The current statistics are as follows: o Number of files is the count of all \"files\" (in the generic sense), which includes directories, symlinks, etc. The total count will be followed by a list of counts by filetype (if the total is non- zero). For example: \"(reg: 5, dir: 3, link: 2, dev: 1, special: 1)\" lists the totals for regular files, directories, symlinks, devices, and special files. If any of value is 0, it is completely omitted from the list. o Number of created files is the count of how many \"files\" (generic sense) were created (as opposed to updated). The total count will be followed by a list of counts by filetype (if the total is non- zero). o Number of deleted files is the count of how many \"files\" (generic sense) were deleted. The total count will be followed by a list of counts by filetype (if the total is non-zero). Note that this line is only output if deletions are in effect, and only if protocol 31 is being used (the default for rsync 3.1.x). o Number of regular files transferred is the count of normal files that were updated via rsync's delta- transfer algorithm, which does not include dirs, symlinks, etc. Note that rsync 3.1.0 added the word \"regular\" into this heading. o Total file size is the total sum of all file sizes in the transfer. This does not count any size for directories or special files, but does include the size of symlinks. o Total transferred file size is the total sum of all files sizes for just the transferred files. o Literal data is how much unmatched file-update data we had to send to the receiver for it to recreate the updated files. o Matched data is how much data the receiver got locally when recreating the updated files. o File list size is how big the file-list data was when the sender sent it to the receiver. This is smaller than the in-memory size for the file list due to some compressing of duplicated data when rsync sends the list. o File list generation time is the number of seconds that the sender spent creating the file list. This requires a modern rsync on the sending side for this to be present. o File list transfer time is the number of seconds that the sender spent sending the file list to the receiver. o Total bytes sent is the count of all the bytes that rsync sent from the client side to the server side. o Total bytes received is the count of all non- message bytes that rsync received by the client side from the server side. \"Non-message\" bytes means that we don't count the bytes for a verbose message that the server sent to us, which makes the stats more consistent. --8-bit-output, -8 This tells rsync to leave all high-bit characters unescaped in the output instead of trying to test them to see if they're valid in the current locale and escaping the invalid ones. All control characters (but never tabs) are always escaped, regardless of this option's setting. The escape idiom that started in 2.6.7 is to output a literal backslash (\\) and a hash (#), followed by exactly 3 octal digits. For example, a newline would output as \"\\#012\". A literal backslash that is in a filename is not escaped unless it is followed by a hash and 3 digits (0-9). --human-readable, -h Output numbers in a more human-readable format. There are 3 possible levels: 1. output numbers with a separator between each set of 3 digits (either a comma or a period, depending on if the decimal point is represented by a period or a comma). 2. output numbers in units of 1000 (with a character suffix for larger units -- see below). 3. output numbers in units of 1024. The default is human-readable level 1. Each -h option increases the level by one. You can take the level down to 0 (to output numbers as pure digits) by specifying the --no-human-readable (--no-h) option. The unit letters that are appended in levels 2 and 3 are: K (kilo), M (mega), G (giga), T (tera), or P (peta). For example, a 1234567-byte file would output as 1.23M in level-2 (assuming that a period is your local decimal point). Backward compatibility note: versions of rsync prior to 3.1.0 do not support human-readable level 1, and they default to level 0. Thus, specifying one or two -h options will behave in a comparable manner in old and new versions as long as you didn't specify a --no-h option prior to one or more -h options. See the --list-only option for one difference. --partial By default, rsync will delete any partially transferred file if the transfer is interrupted. In some circumstances it is more desirable to keep partially transferred files. Using the --partial option tells rsync to keep the partial file which should make a subsequent transfer of the rest of the file much faster. --partial-dir=DIR This option modifies the behavior of the --partial option while also implying that it be enabled. This enhanced partial-file method puts any partially transferred files into the specified DIR instead of writing the partial file out to the destination file. On the next transfer, rsync will use a file found in this dir as data to speed up the resumption of the transfer and then delete it after it has served its purpose. Note that if --whole-file is specified (or implied), any partial-dir files that are found for a file that is being updated will simply be removed (since rsync is sending files without using rsync's delta-transfer algorithm). Rsync will create the DIR if it is missing, but just the last dir -- not the whole path. This makes it easy to use a relative path (such as \"--partial-dir=.rsync-partial\") to have rsync create the partial-directory in the destination file's directory when it is needed, and then remove it again when the partial file is deleted. Note that this directory removal is only done for a relative pathname, as it is expected that an absolute path is to a directory that is reserved for partial-dir work. If the partial-dir value is not an absolute path, rsync will add an exclude rule at the end of all your existing excludes. This will prevent the sending of any partial- dir files that may exist on the sending side, and will also prevent the untimely deletion of partial-dir items on the receiving side. An example: the above --partial-dir option would add the equivalent of this \"perishable\" exclude at the end of any other filter rules: -f '-p .rsync-partial/' If you are supplying your own exclude rules, you may need to add your own exclude/hide/protect rule for the partial- dir because: 1. the auto-added rule may be ineffective at the end of your other rules, or 2. you may wish to override rsync's exclude choice. For instance, if you want to make rsync clean-up any left- over partial-dirs that may be lying around, you should specify --delete-after and add a \"risk\" filter rule, e.g. -f 'R .rsync-partial/'. Avoid using --delete-before or --delete-during unless you don't need rsync to use any of the left-over partial-dir data during the current run. IMPORTANT: the --partial-dir should not be writable by other users or it is a security risk! E.g. AVOID \"/tmp\"! You can also set the partial-dir value the RSYNC_PARTIAL_DIR environment variable. Setting this in the environment does not force --partial to be enabled, but rather it affects where partial files go when --partial is specified. For instance, instead of using --partial-dir=.rsync-tmp along with --progress, you could set RSYNC_PARTIAL_DIR=.rsync-tmp in your environment and then use the -P option to turn on the use of the .rsync- tmp dir for partial transfers. The only times that the --partial option does not look for this environment value are: 1. when --inplace was specified (since --inplace conflicts with --partial-dir), and 2. when --delay-updates was specified (see below). When a modern rsync resumes the transfer of a file in the partial-dir, that partial file is now updated in-place instead of creating yet another tmp-file copy (so it maxes out at dest + tmp instead of dest + partial + tmp). This requires both ends of the transfer to be at least version 3.2.0. For the purposes of the daemon-config's \"refuse options\" setting, --partial-dir does not imply --partial. This is so that a refusal of the --partial option can be used to disallow the overwriting of destination files with a partial transfer, while still allowing the safer idiom provided by --partial-dir. --delay-updates This option puts the temporary file from each updated file into a holding directory until the end of the transfer, at which time all the files are renamed into place in rapid succession. This attempts to make the updating of the files a little more atomic. By default the files are placed into a directory named .~tmp~ in each file's destination directory, but if you've specified the --partial-dir option, that directory will be used instead. See the comments in the --partial-dir section for a discussion of how this .~tmp~ dir will be excluded from the transfer, and what you can do if you want rsync to cleanup old .~tmp~ dirs that might be lying around. Conflicts with --inplace and --append. This option implies --no-inc-recursive since it needs the full file list in memory in order to be able to iterate over it at the end. This option uses more memory on the receiving side (one bit per file transferred) and also requires enough free disk space on the receiving side to hold an additional copy of all the updated files. Note also that you should not use an absolute path to --partial-dir unless: 1. there is no chance of any of the files in the transfer having the same name (since all the updated files will be put into a single directory if the path is absolute), and 2. there are no mount points in the hierarchy (since the delayed updates will fail if they can't be renamed into place). See also the \"atomic-rsync\" python script in the \"support\" subdir for an update algorithm that is even more atomic (it uses --link-dest and a parallel hierarchy of files). --prune-empty-dirs, -m This option tells the receiving rsync to get rid of empty directories from the file-list, including nested directories that have no non-directory children. This is useful for avoiding the creation of a bunch of useless directories when the sending rsync is recursively scanning a hierarchy of files using include/exclude/filter rules. This option can still leave empty directories on the receiving side if you make use of TRANSFER_RULES. Because the file-list is actually being pruned, this option also affects what directories get deleted when a delete is active. However, keep in mind that excluded files and directories can prevent existing items from being deleted due to an exclude both hiding source files and protecting destination files. See the perishable filter-rule option for how to avoid this. You can prevent the pruning of certain empty directories from the file-list by using a global \"protect\" filter. For instance, this option would ensure that the directory \"emptydir\" was kept in the file-list: --filter 'protect emptydir/' Here's an example that copies all .pdf files in a hierarchy, only creating the necessary destination directories to hold the .pdf files, and ensures that any superfluous files and directories in the destination are removed (note the hide filter of non-directories being used instead of an exclude): rsync -avm --del --include='*.pdf' -f 'hide,! */' src/ dest If you didn't want to remove superfluous destination files, the more time-honored options of --include='*/' --exclude='*' would work fine in place of the hide-filter (if that is more natural to you). --progress This option tells rsync to print information showing the progress of the transfer. This gives a bored user something to watch. With a modern rsync this is the same as specifying --info=flist2,name,progress, but any user- supplied settings for those info flags takes precedence (e.g. --info=flist0 --progress). While rsync is transferring a regular file, it updates a progress line that looks like this: 782448 63% 110.64kB/s 0:00:04 In this example, the receiver has reconstructed 782448 bytes or 63% of the sender's file, which is being reconstructed at a rate of 110.64 kilobytes per second, and the transfer will finish in 4 seconds if the current rate is maintained until the end. These statistics can be misleading if rsync's delta- transfer algorithm is in use. For example, if the sender's file consists of the basis file followed by additional data, the reported rate will probably drop dramatically when the receiver gets to the literal data, and the transfer will probably take much longer to finish than the receiver estimated as it was finishing the matched part of the file. When the file transfer finishes, rsync replaces the progress line with a summary line that looks like this: 1,238,099 100% 146.38kB/s 0:00:08 (xfr#5, to-chk=169/396) In this example, the file was 1,238,099 bytes long in total, the average rate of transfer for the whole file was 146.38 kilobytes per second over the 8 seconds that it took to complete, it was the 5th transfer of a regular file during the current rsync session, and there are 169 more files for the receiver to check (to see if they are up-to-date or not) remaining out of the 396 total files in the file-list. In an incremental recursion scan, rsync won't know the total number of files in the file-list until it reaches the ends of the scan, but since it starts to transfer files during the scan, it will display a line with the text \"ir-chk\" (for incremental recursion check) instead of \"to-chk\" until the point that it knows the full size of the list, at which point it will switch to using \"to-chk\". Thus, seeing \"ir-chk\" lets you know that the total count of files in the file list is still going to increase (and each time it does, the count of files left to check will increase by the number of the files added to the list). -P The -P option is equivalent to \"--partial --progress\". Its purpose is to make it much easier to specify these two options for a long transfer that may be interrupted. There is also a --info=progress2 option that outputs statistics based on the whole transfer, rather than individual files. Use this flag without outputting a filename (e.g. avoid -v or specify --info=name0) if you want to see how the transfer is doing without scrolling the screen with a lot of names. (You don't need to specify the --progress option in order to use --info=progress2.) Finally, you can get an instant progress report by sending rsync a signal of either SIGINFO or SIGVTALRM. On BSD systems, a SIGINFO is generated by typing a Ctrl+T (Linux doesn't currently support a SIGINFO signal). When the client-side process receives one of those signals, it sets a flag to output a single progress report which is output when the current file transfer finishes (so it may take a little time if a big file is being handled when the signal arrives). A filename is output (if needed) followed by the --info=progress2 format of progress info. If you don't know which of the 3 rsync processes is the client process, it's OK to signal all of them (since the non- client processes ignore the signal). CAUTION: sending SIGVTALRM to an older rsync (pre-3.2.0) will kill it. --password-file=FILE This option allows you to provide a password for accessing an rsync daemon via a file or via standard input if FILE is -. The file should contain just the password on the first line (all other lines are ignored). Rsync will exit with an error if FILE is world readable or if a root-run rsync command finds a non-root-owned file. This option does not supply a password to a remote shell transport such as ssh; to learn how to do that, consult the remote shell's documentation. When accessing an rsync daemon using a remote shell as the transport, this option only comes into effect after the remote shell finishes its authentication (i.e. if you have also specified a password in the daemon's config file). --early-input=FILE This option allows rsync to send up to 5K of data to the \"early exec\" script on its stdin. One possible use of this data is to give the script a secret that can be used to mount an encrypted filesystem (which you should unmount in the the \"post-xfer exec\" script). The daemon must be at least version 3.2.1. --list-only This option will cause the source files to be listed instead of transferred. This option is inferred if there is a single source arg and no destination specified, so its main uses are: 1. to turn a copy command that includes a destination arg into a file-listing command, or 2. to be able to specify more than one source arg. Note: be sure to include the destination. CAUTION: keep in mind that a source arg with a wild-card is expanded by the shell into multiple args, so it is never safe to try to specify a single wild-card arg to try to infer this option. A safe example is: rsync -av --list-only foo* dest/ This option always uses an output format that looks similar to this: drwxrwxr-x 4,096 2022/09/30 12:53:11 support -rw-rw-r-- 80 2005/01/11 10:37:37 support/Makefile The only option that affects this output style is (as of 3.1.0) the --human-readable (-h) option. The default is to output sizes as byte counts with digit separators (in a 14-character-width column). Specifying at least one -h option makes the sizes output with unit suffixes. If you want old-style bytecount sizes without digit separators (and an 11-character-width column) use --no-h. Compatibility note: when requesting a remote listing of files from an rsync that is version 2.6.3 or older, you may encounter an error if you ask for a non-recursive listing. This is because a file listing implies the --dirs option w/o --recursive, and older rsyncs don't have that option. To avoid this problem, either specify the --no-dirs option (if you don't need to expand a directory's content), or turn on recursion and exclude the content of subdirectories: -r --exclude='/*/*'. --bwlimit=RATE This option allows you to specify the maximum transfer rate for the data sent over the socket, specified in units per second. The RATE value can be suffixed with a string to indicate a size multiplier, and may be a fractional value (e.g. --bwlimit=1.5m). If no suffix is specified, the value will be assumed to be in units of 1024 bytes (as if \"K\" or \"KiB\" had been appended). See the --max-size option for a description of all the available suffixes. A value of 0 specifies no limit. For backward-compatibility reasons, the rate limit will be rounded to the nearest KiB unit, so no rate smaller than 1024 bytes per second is possible. Rsync writes data over the socket in blocks, and this option both limits the size of the blocks that rsync writes, and tries to keep the average transfer rate at the requested limit. Some burstiness may be seen where rsync writes out a block of data and then sleeps to bring the average rate into compliance. Due to the internal buffering of data, the --progress option may not be an accurate reflection on how fast the data is being sent. This is because some files can show up as being rapidly sent when the data is quickly buffered, while other can show up as very slow when the flushing of the output buffer occurs. This may be fixed in a future version. See also the daemon version of the --bwlimit option. --stop-after=MINS, (--time-limit=MINS) This option tells rsync to stop copying when the specified number of minutes has elapsed. For maximal flexibility, rsync does not communicate this option to the remote rsync since it is usually enough that one side of the connection quits as specified. This allows the option's use even when only one side of the connection supports it. You can tell the remote side about the time limit using --remote-option (-M), should the need arise. The --time-limit version of this option is deprecated. --stop-at=y-m-dTh:m This option tells rsync to stop copying when the specified point in time has been reached. The date & time can be fully specified in a numeric format of year-month- dayThour:minute (e.g. 2000-12-31T23:59) in the local timezone. You may choose to separate the date numbers using slashes instead of dashes. The value can also be abbreviated in a variety of ways, such as specifying a 2-digit year and/or leaving off various values. In all cases, the value will be taken to be the next possible point in time where the supplied information matches. If the value specifies the current time or a past time, rsync exits with an error. For example, \"1-30\" specifies the next January 30th (at midnight local time), \"14:00\" specifies the next 2 P.M., \"1\" specifies the next 1st of the month at midnight, \"31\" specifies the next month where we can stop on its 31st day, and \":59\" specifies the next 59th minute after the hour. For maximal flexibility, rsync does not communicate this option to the remote rsync since it is usually enough that one side of the connection quits as specified. This allows the option's use even when only one side of the connection supports it. You can tell the remote side about the time limit using --remote-option (-M), should the need arise. Do keep in mind that the remote host may have a different default timezone than your local host. --fsync Cause the receiving side to fsync each finished file. This may slow down the transfer, but can help to provide peace of mind when updating critical files. --write-batch=FILE Record a file that can later be applied to another identical destination with --read-batch. See the \"BATCH MODE\" section for details, and also the --only-write-batch option. This option overrides the negotiated checksum & compress lists and always negotiates a choice based on old-school md5/md4/zlib choices. If you want a more modern choice, use the --checksum-choice (--cc) and/or --compress-choice (--zc) options. --only-write-batch=FILE Works like --write-batch, except that no updates are made on the destination system when creating the batch. This lets you transport the changes to the destination system via some other means and then apply the changes via --read-batch. Note that you can feel free to write the batch directly to some portable media: if this media fills to capacity before the end of the transfer, you can just apply that partial transfer to the destination and repeat the whole process to get the rest of the changes (as long as you don't mind a partially updated destination system while the multi-update cycle is happening). Also note that you only save bandwidth when pushing changes to a remote system because this allows the batched data to be diverted from the sender into the batch file without having to flow over the wire to the receiver (when pulling, the sender is remote, and thus can't write the batch). --read-batch=FILE Apply all of the changes stored in FILE, a file previously generated by --write-batch. If FILE is -, the batch data will be read from standard input. See the \"BATCH MODE\" section for details. --protocol=NUM Force an older protocol version to be used. This is useful for creating a batch file that is compatible with an older version of rsync. For instance, if rsync 2.6.4 is being used with the --write-batch option, but rsync 2.6.3 is what will be used to run the --read-batch option, you should use \"--protocol=28\" when creating the batch file to force the older protocol version to be used in the batch file (assuming you can't upgrade the rsync on the reading system). --iconv=CONVERT_SPEC Rsync can convert filenames between character sets using this option. Using a CONVERT_SPEC of \".\" tells rsync to look up the default character-set via the locale setting. Alternately, you can fully specify what conversion to do by giving a local and a remote charset separated by a comma in the order --iconv=LOCAL,REMOTE, e.g. --iconv=utf8,iso88591. This order ensures that the option will stay the same whether you're pushing or pulling files. Finally, you can specify either --no-iconv or a CONVERT_SPEC of \"-\" to turn off any conversion. The default setting of this option is site-specific, and can also be affected via the RSYNC_ICONV environment variable. For a list of what charset names your local iconv library supports, you can run \"iconv --list\". If you specify the --secluded-args (-s) option, rsync will translate the filenames you specify on the command-line that are being sent to the remote host. See also the --files-from option. Note that rsync does not do any conversion of names in filter files (including include/exclude files). It is up to you to ensure that you're specifying matching rules that can match on both sides of the transfer. For instance, you can specify extra include/exclude rules if there are filename differences on the two sides that need to be accounted for. When you pass an --iconv option to an rsync daemon that allows it, the daemon uses the charset specified in its \"charset\" configuration parameter regardless of the remote charset you actually pass. Thus, you may feel free to specify just the local charset for a daemon transfer (e.g. --iconv=utf8). --ipv4, -4 or --ipv6, -6 Tells rsync to prefer IPv4/IPv6 when creating sockets or running ssh. This affects sockets that rsync has direct control over, such as the outgoing socket when directly contacting an rsync daemon, as well as the forwarding of the -4 or -6 option to ssh when rsync can deduce that ssh is being used as the remote shell. For other remote shells you'll need to specify the \"--rsh SHELL -4\" option directly (or whatever IPv4/IPv6 hint options it uses). See also the daemon version of these options. If rsync was compiled without support for IPv6, the --ipv6 option will have no effect. The rsync --version output will contain \"no IPv6\" if is the case. --checksum-seed=NUM Set the checksum seed to the integer NUM. This 4 byte checksum seed is included in each block and MD4 file checksum calculation (the more modern MD5 file checksums don't use a seed). By default the checksum seed is generated by the server and defaults to the current time(). This option is used to set a specific checksum seed, which is useful for applications that want repeatable block checksums, or in the case where the user wants a more random checksum seed. Setting NUM to 0 causes rsync to use the default of time() for checksum seed. "
  },
  {
    "command": "unexpand",
    "description": " Convert blanks in each FILE to tabs, writing to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -a, --all convert all blanks, instead of just initial blanks --first-only convert only leading sequences of blanks (overrides -a) -t, --tabs=N have tabs N characters apart instead of 8 (enables -a) -t, --tabs=LIST use comma separated list of tab positions. The last specified position can be prefixed with '/' to specify a tab size to use after the last explicitly specified tab stop. Also a prefix of '+' can be used to align remaining tab stops relative to the last specified tab stop instead of the first column --help display this help and exit --version output version information and exit "
  },
  {
    "command": "scp",
    "description": " scp copies files between hosts on a network. scp uses the SFTP protocol over a ssh(1) connection for data transfer, and uses the same authentication and provides the same security as a login session. scp will ask for passwords or passphrases if they are needed for authentication. The source and target may be specified as a local pathname, a remote host with optional path in the form [user@]host:[path], or a URI in the form scp://[user@]host[:port][/path]. Local file names can be made explicit using absolute or relative pathnames to avoid scp treating file names containing \u2018:\u2019 as host specifiers. When copying between two remote hosts, if the URI format is used, a port cannot be specified on the target if the -R option is used. The options are as follows: -3 Copies between two remote hosts are transferred through the local host. Without this option the data is copied directly between the two remote hosts. Note that, when using the legacy SCP protocol (via the -O flag), this option selects batch mode for the second host as scp cannot ask for passwords or passphrases for both hosts. This mode is the default. -4 Forces scp to use IPv4 addresses only. -6 Forces scp to use IPv6 addresses only. -A Allows forwarding of ssh-agent(1) to the remote system. The default is not to forward an authentication agent. -B Selects batch mode (prevents asking for passwords or passphrases). -C Compression enable. Passes the -C flag to ssh(1) to enable compression. -c cipher Selects the cipher to use for encrypting the data transfer. This option is directly passed to ssh(1). -D sftp_server_path Connect directly to a local SFTP server program rather than a remote one via ssh(1). This option may be useful in debugging the client and server. -F ssh_config Specifies an alternative per-user configuration file for ssh. This option is directly passed to ssh(1). -i identity_file Selects the file from which the identity (private key) for public key authentication is read. This option is directly passed to ssh(1). -J destination Connect to the target host by first making an scp connection to the jump host described by destination and then establishing a TCP forwarding to the ultimate destination from there. Multiple jump hops may be specified separated by comma characters. This is a shortcut to specify a ProxyJump configuration directive. This option is directly passed to ssh(1). -l limit Limits the used bandwidth, specified in Kbit/s. -O Use the legacy SCP protocol for file transfers instead of the SFTP protocol. Forcing the use of the SCP protocol may be necessary for servers that do not implement SFTP, for backwards-compatibility for particular filename wildcard patterns and for expanding paths with a \u2018~\u2019 prefix for older SFTP servers. -o ssh_option Can be used to pass options to ssh in the format used in ssh_config(5). This is useful for specifying options for which there is no separate scp command-line flag. For full details of the options listed below, and their possible values, see ssh_config(5). AddressFamily BatchMode BindAddress BindInterface CanonicalDomains CanonicalizeFallbackLocal CanonicalizeHostname CanonicalizeMaxDots CanonicalizePermittedCNAMEs CASignatureAlgorithms CertificateFile CheckHostIP Ciphers Compression ConnectionAttempts ConnectTimeout ControlMaster ControlPath ControlPersist GlobalKnownHostsFile GSSAPIAuthentication GSSAPIDelegateCredentials HashKnownHosts Host HostbasedAcceptedAlgorithms HostbasedAuthentication HostKeyAlgorithms HostKeyAlias Hostname IdentitiesOnly IdentityAgent IdentityFile IPQoS KbdInteractiveAuthentication KbdInteractiveDevices KexAlgorithms KnownHostsCommand LogLevel MACs NoHostAuthenticationForLocalhost NumberOfPasswordPrompts PasswordAuthentication PKCS11Provider Port PreferredAuthentications ProxyCommand ProxyJump PubkeyAcceptedAlgorithms PubkeyAuthentication RekeyLimit RequiredRSASize SendEnv ServerAliveInterval ServerAliveCountMax SetEnv StrictHostKeyChecking TCPKeepAlive UpdateHostKeys User UserKnownHostsFile VerifyHostKeyDNS -P port Specifies the port to connect to on the remote host. Note that this option is written with a capital \u2018P\u2019, because -p is already reserved for preserving the times and mode bits of the file. -p Preserves modification times, access times, and file mode bits from the source file. -q Quiet mode: disables the progress meter as well as warning and diagnostic messages from ssh(1). -R Copies between two remote hosts are performed by connecting to the origin host and executing scp there. This requires that scp running on the origin host can authenticate to the destination host without requiring a password. -r Recursively copy entire directories. Note that scp follows symbolic links encountered in the tree traversal. -S program Name of program to use for the encrypted connection. The program must understand ssh(1) options. -T Disable strict filename checking. By default when copying files from a remote host to a local directory scp checks that the received filenames match those requested on the command-line to prevent the remote end from sending unexpected or unwanted files. Because of differences in how various operating systems and shells interpret filename wildcards, these checks may cause wanted files to be rejected. This option disables these checks at the expense of fully trusting that the server will not send unexpected filenames. -v Verbose mode. Causes scp and ssh(1) to print debugging messages about their progress. This is helpful in debugging connection, authentication, and configuration problems. -X sftp_option Specify an option that controls aspects of SFTP protocol behaviour. The valid options are: nrequests=value Controls how many concurrent SFTP read or write requests may be in progress at any point in time during a download or upload. By default 64 requests may be active concurrently. buffer=value Controls the maximum buffer size for a single SFTP read/write operation used during download or upload. By default a 32KB buffer is used. "
  },
  {
    "command": "timedatectl",
    "description": " timedatectl may be used to query and change the system clock and its settings, and enable or disable time synchronization services. Use systemd-firstboot(1) to initialize the system time zone for mounted (but not booted) system images. timedatectl may be used to show the current status of time synchronization services, for example systemd-timesyncd.service(8). The following options are understood: --no-ask-password Do not query the user for authentication for privileged operations. --adjust-system-clock If set-local-rtc is invoked and this option is passed, the system clock is synchronized from the RTC again, taking the new setting into account. Otherwise, the RTC is synchronized from the system clock. --monitor If timesync-status is invoked and this option is passed, then timedatectl monitors the status of systemd-timesyncd.service(8) and updates the outputs. Use Ctrl+C to terminate the monitoring. -a, --all When showing properties of systemd-timesyncd.service(8), show all properties regardless of whether they are set or not. -p, --property= When showing properties of systemd-timesyncd.service(8), limit display to certain properties as specified as argument. If not specified, all set properties are shown. The argument should be a property name, such as \"ServerName\". If specified more than once, all properties with the specified names are shown. --value When printing properties with show-timesync, only print the value, and skip the property name and \"=\". -H, --host= Execute the operation remotely. Specify a hostname, or a username and hostname separated by \"@\", to connect to. The hostname may optionally be suffixed by a port ssh is listening on, separated by \":\", and then a container name, separated by \"/\", which connects directly to a specific container on the specified host. This will use SSH to talk to the remote machine manager instance. Container names may be enumerated with machinectl -H HOST. Put IPv6 addresses in brackets. -M, --machine= Execute operation on a local container. Specify a container name to connect to, optionally prefixed by a user name to connect as and a separating \"@\" character. If the special string \".host\" is used in place of the container name, a connection to the local system is made (which is useful to connect to a specific user's user bus: \"--user --machine=lennart@.host\"). If the \"@\" syntax is not used, the connection is made as root user. If the \"@\" syntax is used either the left hand side or the right hand side may be omitted (but not both) in which case the local user name and \".host\" are implied. -h, --help Print a short help text and exit. --version Print a short version string and exit. --no-pager Do not pipe output into a pager. "
  },
  {
    "command": "screen",
    "description": " Screen is a full-screen window manager that multiplexes a physical terminal between several processes (typically interactive shells). Each virtual terminal provides the functions of a DEC VT100 terminal and, in addition, several control functions from the ISO 6429 (ECMA 48, ANSI X3.64) and ISO 2022 standards (e.g. insert/delete line and support for multiple character sets). There is a scrollback history buffer for each virtual terminal and a copy-and-paste mechanism that allows moving text regions between windows. When screen is called, it creates a single window with a shell in it (or the specified command) and then gets out of your way so that you can use the program as you normally would. Then, at any time, you can create new (full-screen) windows with other programs in them (including more shells), kill existing windows, view a list of windows, turn output logging on and off, copy-and- paste text between windows, view the scrollback history, switch between windows in whatever manner you wish, etc. All windows run their programs completely independent of each other. Programs continue to run when their window is currently not visible and even when the whole screen session is detached from the user's terminal. When a program terminates, screen (per default) kills the window that contained it. If this window was in the foreground, the display switches to the previous window; if none are left, screen exits. Shells usually distinguish between running as login-shell or sub-shell. Screen runs them as sub- shells, unless told otherwise (See \"shell\" .screenrc command). Everything you type is sent to the program running in the current window. The only exception to this is the one keystroke that is used to initiate a command to the window manager. By default, each command begins with a control-a (abbreviated C-a from now on), and is followed by one other keystroke. The command character and all the key bindings can be fully customized to be anything you like, though they are always two characters in length. Screen does not understand the prefix \"C-\" to mean control, although this notation is used in this manual for readability. Please use the caret notation (\"^A\" instead of \"C-a\") as arguments to e.g. the escape command or the -e option. Screen will also print out control characters in caret notation. The standard way to create a new window is to type \"C-a c\". This creates a new window running a shell and switches to that window immediately, regardless of the state of the process running in the current window. Similarly, you can create a new window with a custom command in it by first binding the command to a keystroke (in your .screenrc file or at the \"C-a :\" command line) and then using it just like the \"C-a c\" command. In addition, new windows can be created by running a command like: screen emacs prog.c from a shell prompt within a previously created window. This will not run another copy of screen, but will instead supply the command name and its arguments to the window manager (specified in the $STY environment variable) who will use it to create the new window. The above example would start the emacs editor (editing prog.c) and switch to its window. - Note that you cannot transport environment variables from the invoking shell to the application (emacs in this case), because it is forked from the parent screen process, not from the invoking shell. If \"/etc/utmp\" is writable by screen, an appropriate record will be written to this file for each window, and removed when the window is terminated. This is useful for working with \"talk\", \"script\", \"shutdown\", \"rsend\", \"sccs\" and other similar programs that use the utmp file to determine who you are. As long as screen is active on your terminal, the terminal's own record is removed from the utmp file. See also \"C-a L\". "
  },
  {
    "command": "write",
    "description": " The write utility shall read lines from the standard input and write them to the terminal of the specified user. When first invoked, it shall write the message: Message from sender-login-id (sending-terminal) [date]... to user_name. When it has successfully completed the connection, the sender's terminal shall be alerted twice to indicate that what the sender is typing is being written to the recipient's terminal. If the recipient wants to reply, this can be accomplished by typing: write sender-login-id [sending-terminal] upon receipt of the initial message. Whenever a line of input as delimited by an NL, EOF, or EOL special character (see the Base Definitions volume of POSIX.1\u20102017, Chapter 11, General Terminal Interface) is accumulated while in canonical input mode, the accumulated data shall be written on the other user's terminal. Characters shall be processed as follows: * Typing <alert> shall write the <alert> character to the recipient's terminal. * Typing the erase and kill characters shall affect the sender's terminal in the manner described by the termios interface in the Base Definitions volume of POSIX.1\u20102017, Chapter 11, General Terminal Interface. * Typing the interrupt or end-of-file characters shall cause write to write an appropriate message (\"EOT\\n\" in the POSIX locale) to the recipient's terminal and exit. * Typing characters from LC_CTYPE classifications print or space shall cause those characters to be sent to the recipient's terminal. * When and only when the stty iexten local mode is enabled, the existence and processing of additional special control characters and multi-byte or single-byte functions is implementation-defined. * Typing other non-printable characters shall cause implementation-defined sequences of printable characters to be written to the recipient's terminal. To write to a user who is logged in more than once, the terminal argument can be used to indicate which terminal to write to; otherwise, the recipient's terminal is selected in an implementation-defined manner and an informational message is written to the sender's standard output, indicating which terminal was chosen. Permission to be a recipient of a write message can be denied or granted by use of the mesg utility. However, a user's privilege may further constrain the domain of accessibility of other users' terminals. The write utility shall fail when the user lacks appropriate privileges to perform the requested action. None. "
  },
  {
    "command": "as",
    "description": " GNU as is really a family of assemblers. If you use (or have used) the GNU assembler on one architecture, you should find a fairly similar environment when you use it on another architecture. Each version has much in common with the others, including object file formats, most assembler directives (often called pseudo-ops) and assembler syntax. as is primarily intended to assemble the output of the GNU C compiler \"gcc\" for use by the linker \"ld\". Nevertheless, we've tried to make as assemble correctly everything that other assemblers for the same machine would assemble. Any exceptions are documented explicitly. This doesn't mean as always uses the same syntax as another assembler for the same architecture; for example, we know of several incompatible versions of 680x0 assembly language syntax. Each time you run as it assembles exactly one source program. The source program is made up of one or more files. (The standard input is also a file.) You give as a command line that has zero or more input file names. The input files are read (from left file name to right). A command-line argument (in any position) that has no special meaning is taken to be an input file name. If you give as no file names it attempts to read one input file from the as standard input, which is normally your terminal. You may have to type ctl-D to tell as there is no more program to assemble. Use -- if you need to explicitly name the standard input file in your command line. If the source is empty, as produces a small, empty object file. as may write warnings and error messages to the standard error file (usually your terminal). This should not happen when a compiler runs as automatically. Warnings report an assumption made so that as could keep assembling a flawed program; errors report a grave problem that stops the assembly. If you are invoking as via the GNU C compiler, you can use the -Wa option to pass arguments through to the assembler. The assembler arguments must be separated from each other (and the -Wa) by commas. For example: gcc -c -g -O -Wa,-alh,-L file.c This passes two options to the assembler: -alh (emit a listing to standard output with high-level and assembly source) and -L (retain local symbols in the symbol table). Usually you do not need to use this -Wa mechanism, since many compiler command-line options are automatically passed to the assembler by the compiler. (You can call the GNU compiler driver with the -v option to see precisely what options it passes to each compilation pass, including the assembler.) @file Read command-line options from file. The options read are inserted in place of the original @file option. If file does not exist, or cannot be read, then the option will be treated literally, and not removed. Options in file are separated by whitespace. A whitespace character may be included in an option by surrounding the entire option in either single or double quotes. Any character (including a backslash) may be included by prefixing the character to be included with a backslash. The file may itself contain additional @file options; any such options will be processed recursively. -a[cdghlmns] Turn on listings, in any of a variety of ways: -ac omit false conditionals -ad omit debugging directives -ag include general information, like as version and options passed -ah include high-level source -al include assembly -am include macro expansions -an omit forms processing -as include symbols =file set the name of the listing file You may combine these options; for example, use -aln for assembly listing without forms processing. The =file option, if used, must be the last one. By itself, -a defaults to -ahls. --alternate Begin in alternate macro mode. --compress-debug-sections Compress DWARF debug sections using zlib with SHF_COMPRESSED from the ELF ABI. The resulting object file may not be compatible with older linkers and object file utilities. Note if compression would make a given section larger then it is not compressed. --compress-debug-sections=none --compress-debug-sections=zlib --compress-debug-sections=zlib-gnu --compress-debug-sections=zlib-gabi --compress-debug-sections=zstd These options control how DWARF debug sections are compressed. --compress-debug-sections=none is equivalent to --nocompress-debug-sections. --compress-debug-sections=zlib and --compress-debug-sections=zlib-gabi are equivalent to --compress-debug-sections. --compress-debug-sections=zlib-gnu compresses DWARF debug sections using the obsoleted zlib-gnu format. The debug sections are renamed to begin with .zdebug. --compress-debug-sections=zstd compresses DWARF debug sections using zstd. Note - if compression would actually make a section larger, then it is not compressed nor renamed. --nocompress-debug-sections Do not compress DWARF debug sections. This is usually the default for all targets except the x86/x86_64, but a configure time option can be used to override this. -D Enable denugging in target specific backends, if supported. Otherwise ignored. Even if ignored, this option is accepted for script compatibility with calls to other assemblers. --debug-prefix-map old=new When assembling files in directory old, record debugging information describing them as in new instead. --defsym sym=value Define the symbol sym to be value before assembling the input file. value must be an integer constant. As in C, a leading 0x indicates a hexadecimal value, and a leading 0 indicates an octal value. The value of the symbol can be overridden inside a source file via the use of a \".set\" pseudo-op. --dump-config Displays how the assembler is configured and then exits. --elf-stt-common=no --elf-stt-common=yes These options control whether the ELF assembler should generate common symbols with the \"STT_COMMON\" type. The default can be controlled by a configure option --enable-elf-stt-common. --emulation=name If the assembler is configured to support multiple different target configurations then this option can be used to select the desired form. -f \"fast\"---skip whitespace and comment preprocessing (assume source is compiler output). -g --gen-debug Generate debugging information for each assembler source line using whichever debug format is preferred by the target. This currently means either STABS, ECOFF or DWARF2. When the debug format is DWARF then a \".debug_info\" and \".debug_line\" section is only emitted when the assembly file doesn't generate one itself. --gstabs Generate stabs debugging information for each assembler line. This may help debugging assembler code, if the debugger can handle it. --gstabs+ Generate stabs debugging information for each assembler line, with GNU extensions that probably only gdb can handle, and that could make other debuggers crash or refuse to read your program. This may help debugging assembler code. Currently the only GNU extension is the location of the current working directory at assembling time. --gdwarf-2 Generate DWARF2 debugging information for each assembler line. This may help debugging assembler code, if the debugger can handle it. Note---this option is only supported by some targets, not all of them. --gdwarf-3 This option is the same as the --gdwarf-2 option, except that it allows for the possibility of the generation of extra debug information as per version 3 of the DWARF specification. Note - enabling this option does not guarantee the generation of any extra information, the choice to do so is on a per target basis. --gdwarf-4 This option is the same as the --gdwarf-2 option, except that it allows for the possibility of the generation of extra debug information as per version 4 of the DWARF specification. Note - enabling this option does not guarantee the generation of any extra information, the choice to do so is on a per target basis. --gdwarf-5 This option is the same as the --gdwarf-2 option, except that it allows for the possibility of the generation of extra debug information as per version 5 of the DWARF specification. Note - enabling this option does not guarantee the generation of any extra information, the choice to do so is on a per target basis. --gdwarf-sections Instead of creating a .debug_line section, create a series of .debug_line.foo sections where foo is the name of the corresponding code section. For example a code section called .text.func will have its dwarf line number information placed into a section called .debug_line.text.func. If the code section is just called .text then debug line section will still be called just .debug_line without any suffix. --gdwarf-cie-version=version Control which version of DWARF Common Information Entries (CIEs) are produced. When this flag is not specificed the default is version 1, though some targets can modify this default. Other possible values for version are 3 or 4. --generate-missing-build-notes=yes --generate-missing-build-notes=no These options control whether the ELF assembler should generate GNU Build attribute notes if none are present in the input sources. The default can be controlled by the --enable-generate-build-notes configure option. --gsframe --gsframe Create .sframe section from CFI directives. --hash-size N Ignored. Supported for command line compatibility with other assemblers. --help Print a summary of the command-line options and exit. --target-help Print a summary of all target specific options and exit. -I dir Add directory dir to the search list for \".include\" directives. -J Don't warn about signed overflow. -K Issue warnings when difference tables altered for long displacements. -L --keep-locals Keep (in the symbol table) local symbols. These symbols start with system-specific local label prefixes, typically .L for ELF systems or L for traditional a.out systems. --listing-lhs-width=number Set the maximum width, in words, of the output data column for an assembler listing to number. --listing-lhs-width2=number Set the maximum width, in words, of the output data column for continuation lines in an assembler listing to number. --listing-rhs-width=number Set the maximum width of an input source line, as displayed in a listing, to number bytes. --listing-cont-lines=number Set the maximum number of lines printed in a listing for a single line of input to number + 1. --multibyte-handling=allow --multibyte-handling=warn --multibyte-handling=warn-sym-only --multibyte-handling=warn_sym_only Controls how the assembler handles multibyte characters in the input. The default (which can be restored by using the allow argument) is to allow such characters without complaint. Using the warn argument will make the assembler generate a warning message whenever any multibyte character is encountered. Using the warn-sym-only argument will only cause a warning to be generated when a symbol is defined with a name that contains multibyte characters. (References to undefined symbols will not generate a warning). --no-pad-sections Stop the assembler for padding the ends of output sections to the alignment of that section. The default is to pad the sections, but this can waste space which might be needed on targets which have tight memory constraints. -o objfile Name the object-file output from as objfile. -R Fold the data section into the text section. --reduce-memory-overheads Ignored. Supported for compatibility with tools that apss the same option to both the assembler and the linker. --sectname-subst Honor substitution sequences in section names. --size-check=error --size-check=warning Issue an error or warning for invalid ELF .size directive. --statistics Print the maximum space (in bytes) and total time (in seconds) used by assembly. --strip-local-absolute Remove local absolute symbols from the outgoing symbol table. -v -version Print the as version. --version Print the as version and exit. -W --no-warn Suppress warning messages. --fatal-warnings Treat warnings as errors. --warn Don't suppress warning messages or treat them as errors. -w Ignored. -x Ignored. -Z Generate an object file even after errors. -- | files ... Standard input, or source files to assemble. The following options are available when as is configured for the 64-bit mode of the ARM Architecture (AArch64). -EB This option specifies that the output generated by the assembler should be marked as being encoded for a big-endian processor. -EL This option specifies that the output generated by the assembler should be marked as being encoded for a little- endian processor. -mabi=abi Specify which ABI the source code uses. The recognized arguments are: \"ilp32\" and \"lp64\", which decides the generated object file in ELF32 and ELF64 format respectively. The default is \"lp64\". -mcpu=processor[+extension...] This option specifies the target processor. The assembler will issue an error message if an attempt is made to assemble an instruction which will not execute on the target processor. The following processor names are recognized: \"cortex-a34\", \"cortex-a35\", \"cortex-a53\", \"cortex-a55\", \"cortex-a57\", \"cortex-a65\", \"cortex-a65ae\", \"cortex-a72\", \"cortex-a73\", \"cortex-a75\", \"cortex-a76\", \"cortex-a76ae\", \"cortex-a77\", \"cortex-a78\", \"cortex-a78ae\", \"cortex-a78c\", \"cortex-a510\", \"cortex-a710\", \"ares\", \"exynos-m1\", \"falkor\", \"neoverse-n1\", \"neoverse-n2\", \"neoverse-e1\", \"neoverse-v1\", \"qdf24xx\", \"saphira\", \"thunderx\", \"vulcan\", \"xgene1\" \"xgene2\", \"cortex-r82\", \"cortex-x1\", and \"cortex-x2\". The special name \"all\" may be used to allow the assembler to accept instructions valid for any supported processor, including all optional extensions. In addition to the basic instruction set, the assembler can be told to accept, or restrict, various extension mnemonics that extend the processor. If some implementations of a particular processor can have an extension, then then those extensions are automatically enabled. Consequently, you will not normally have to specify any additional extensions. -march=architecture[+extension...] This option specifies the target architecture. The assembler will issue an error message if an attempt is made to assemble an instruction which will not execute on the target architecture. The following architecture names are recognized: \"armv8-a\", \"armv8.1-a\", \"armv8.2-a\", \"armv8.3-a\", \"armv8.4-a\" \"armv8.5-a\", \"armv8.6-a\", \"armv8.7-a\", \"armv8.8-a\", \"armv8-r\", \"armv9-a\", \"armv9.1-a\", \"armv9.2-a\", and \"armv9.3-a\". If both -mcpu and -march are specified, the assembler will use the setting for -mcpu. If neither are specified, the assembler will default to -mcpu=all. The architecture option can be extended with the same instruction set extension options as the -mcpu option. Unlike -mcpu, extensions are not always enabled by default, -mverbose-error This option enables verbose error messages for AArch64 gas. This option is enabled by default. -mno-verbose-error This option disables verbose error messages in AArch64 gas. The following options are available when as is configured for an Alpha processor. -mcpu This option specifies the target processor. If an attempt is made to assemble an instruction which will not execute on the target processor, the assembler may either expand the instruction as a macro or issue an error message. This option is equivalent to the \".arch\" directive. The following processor names are recognized: 21064, \"21064a\", 21066, 21068, 21164, \"21164a\", \"21164pc\", 21264, \"21264a\", \"21264b\", \"ev4\", \"ev5\", \"lca45\", \"ev5\", \"ev56\", \"pca56\", \"ev6\", \"ev67\", \"ev68\". The special name \"all\" may be used to allow the assembler to accept instructions valid for any Alpha processor. In order to support existing practice in OSF/1 with respect to \".arch\", and existing practice within MILO (the Linux ARC bootloader), the numbered processor names (e.g. 21064) enable the processor-specific PALcode instructions, while the \"electro-vlasic\" names (e.g. \"ev4\") do not. -mdebug -no-mdebug Enables or disables the generation of \".mdebug\" encapsulation for stabs directives and procedure descriptors. The default is to automatically enable \".mdebug\" when the first stabs directive is seen. -relax This option forces all relocations to be put into the object file, instead of saving space and resolving some relocations at assembly time. Note that this option does not propagate all symbol arithmetic into the object file, because not all symbol arithmetic can be represented. However, the option can still be useful in specific applications. -replace -noreplace Enables or disables the optimization of procedure calls, both at assemblage and at link time. These options are only available for VMS targets and \"-replace\" is the default. See section 1.4.1 of the OpenVMS Linker Utility Manual. -g This option is used when the compiler generates debug information. When gcc is using mips-tfile to generate debug information for ECOFF, local labels must be passed through to the object file. Otherwise this option has no effect. -Gsize A local common symbol larger than size is placed in \".bss\", while smaller symbols are placed in \".sbss\". -F -32addr These options are ignored for backward compatibility. The following options are available when as is configured for an ARC processor. -mcpu=cpu This option selects the core processor variant. -EB | -EL Select either big-endian (-EB) or little-endian (-EL) output. -mcode-density Enable Code Density extension instructions. The following options are available when as is configured for the ARM processor family. -mcpu=processor[+extension...] Specify which ARM processor variant is the target. -march=architecture[+extension...] Specify which ARM architecture variant is used by the target. -mfpu=floating-point-format Select which Floating Point architecture is the target. -mfloat-abi=abi Select which floating point ABI is in use. -mthumb Enable Thumb only instruction decoding. -mapcs-32 | -mapcs-26 | -mapcs-float | -mapcs-reentrant Select which procedure calling convention is in use. -EB | -EL Select either big-endian (-EB) or little-endian (-EL) output. -mthumb-interwork Specify that the code has been generated with interworking between Thumb and ARM code in mind. -mccs Turns on CodeComposer Studio assembly syntax compatibility mode. -k Specify that PIC code has been generated. The following options are available when as is configured for the Blackfin processor family. -mcpu=processor[-sirevision] This option specifies the target processor. The optional sirevision is not used in assembler. It's here such that GCC can easily pass down its \"-mcpu=\" option. The assembler will issue an error message if an attempt is made to assemble an instruction which will not execute on the target processor. The following processor names are recognized: \"bf504\", \"bf506\", \"bf512\", \"bf514\", \"bf516\", \"bf518\", \"bf522\", \"bf523\", \"bf524\", \"bf525\", \"bf526\", \"bf527\", \"bf531\", \"bf532\", \"bf533\", \"bf534\", \"bf535\" (not implemented yet), \"bf536\", \"bf537\", \"bf538\", \"bf539\", \"bf542\", \"bf542m\", \"bf544\", \"bf544m\", \"bf547\", \"bf547m\", \"bf548\", \"bf548m\", \"bf549\", \"bf549m\", \"bf561\", and \"bf592\". -mfdpic Assemble for the FDPIC ABI. -mno-fdpic -mnopic Disable -mfdpic. The following options are available when as is configured for the Linux kernel BPF processor family. @chapter BPF Dependent Features Options -EB This option specifies that the assembler should emit big- endian eBPF. -EL This option specifies that the assembler should emit little- endian eBPF. Note that if no endianness option is specified in the command line, the host endianness is used. See the info pages for documentation of the CRIS-specific options. The following options are available when as is configured for the C-SKY processor family. -march=archname Assemble for architecture archname. The --help option lists valid values for archname. -mcpu=cpuname Assemble for architecture cpuname. The --help option lists valid values for cpuname. -EL -mlittle-endian Generate little-endian output. -EB -mbig-endian Generate big-endian output. -fpic -pic Generate position-independent code. -mljump -mno-ljump Enable/disable transformation of the short branch instructions \"jbf\", \"jbt\", and \"jbr\" to \"jmpi\". This option is for V2 processors only. It is ignored on CK801 and CK802 targets, which do not support the \"jmpi\" instruction, and is enabled by default for other processors. -mbranch-stub -mno-branch-stub Pass through \"R_CKCORE_PCREL_IMM26BY2\" relocations for \"bsr\" instructions to the linker. This option is only available for bare-metal C-SKY V2 ELF targets, where it is enabled by default. It cannot be used in code that will be dynamically linked against shared libraries. -force2bsr -mforce2bsr -no-force2bsr -mno-force2bsr Enable/disable transformation of \"jbsr\" instructions to \"bsr\". This option is always enabled (and -mno-force2bsr is ignored) for CK801/CK802 targets. It is also always enabled when -mbranch-stub is in effect. -jsri2bsr -mjsri2bsr -no-jsri2bsr -mno-jsri2bsr Enable/disable transformation of \"jsri\" instructions to \"bsr\". This option is enabled by default. -mnolrw -mno-lrw Enable/disable transformation of \"lrw\" instructions into a \"movih\"/\"ori\" pair. -melrw -mno-elrw Enable/disable extended \"lrw\" instructions. This option is enabled by default for CK800-series processors. -mlaf -mliterals-after-func -mno-laf -mno-literals-after-func Enable/disable placement of literal pools after each function. -mlabr -mliterals-after-br -mno-labr -mnoliterals-after-br Enable/disable placement of literal pools after unconditional branches. This option is enabled by default. -mistack -mno-istack Enable/disable interrupt stack instructions. This option is enabled by default on CK801, CK802, and CK802 processors. The following options explicitly enable certain optional instructions. These features are also enabled implicitly by using \"-mcpu=\" to specify a processor that supports it. -mhard-float Enable hard float instructions. -mmp Enable multiprocessor instructions. -mcp Enable coprocessor instructions. -mcache Enable cache prefetch instruction. -msecurity Enable C-SKY security instructions. -mtrust Enable C-SKY trust instructions. -mdsp Enable DSP instructions. -medsp Enable enhanced DSP instructions. -mvdsp Enable vector DSP instructions. The following options are available when as is configured for an Epiphany processor. -mepiphany Specifies that the both 32 and 16 bit instructions are allowed. This is the default behavior. -mepiphany16 Restricts the permitted instructions to just the 16 bit set. The following options are available when as is configured for an H8/300 processor. @chapter H8/300 Dependent Features Options The Renesas H8/300 version of \"as\" has one machine-dependent option: -h-tick-hex Support H'00 style hex constants in addition to 0x00 style. -mach=name Sets the H8300 machine variant. The following machine names are recognised: \"h8300h\", \"h8300hn\", \"h8300s\", \"h8300sn\", \"h8300sx\" and \"h8300sxn\". The following options are available when as is configured for an i386 processor. --32 | --x32 | --64 Select the word size, either 32 bits or 64 bits. --32 implies Intel i386 architecture, while --x32 and --64 imply AMD x86-64 architecture with 32-bit or 64-bit word-size respectively. These options are only available with the ELF object file format, and require that the necessary BFD support has been included (on a 32-bit platform you have to add --enable-64-bit-bfd to configure enable 64-bit usage and use x86-64 as target platform). -n By default, x86 GAS replaces multiple nop instructions used for alignment within code sections with multi-byte nop instructions such as leal 0(%esi,1),%esi. This switch disables the optimization if a single byte nop (0x90) is explicitly specified as the fill byte for alignment. --divide On SVR4-derived platforms, the character / is treated as a comment character, which means that it cannot be used in expressions. The --divide option turns / into a normal character. This does not disable / at the beginning of a line starting a comment, or affect using # for starting a comment. -march=CPU[+EXTENSION...] This option specifies the target processor. The assembler will issue an error message if an attempt is made to assemble an instruction which will not execute on the target processor. The following processor names are recognized: \"i8086\", \"i186\", \"i286\", \"i386\", \"i486\", \"i586\", \"i686\", \"pentium\", \"pentiumpro\", \"pentiumii\", \"pentiumiii\", \"pentium4\", \"prescott\", \"nocona\", \"core\", \"core2\", \"corei7\", \"iamcu\", \"k6\", \"k6_2\", \"athlon\", \"opteron\", \"k8\", \"amdfam10\", \"bdver1\", \"bdver2\", \"bdver3\", \"bdver4\", \"znver1\", \"znver2\", \"znver3\", \"znver4\", \"btver1\", \"btver2\", \"generic32\" and \"generic64\". In addition to the basic instruction set, the assembler can be told to accept various extension mnemonics. For example, \"-march=i686+sse4+vmx\" extends i686 with sse4 and vmx. The following extensions are currently supported: 8087, 287, 387, 687, \"cmov\", \"fxsr\", \"mmx\", \"sse\", \"sse2\", \"sse3\", \"sse4a\", \"ssse3\", \"sse4.1\", \"sse4.2\", \"sse4\", \"avx\", \"avx2\", \"adx\", \"rdseed\", \"prfchw\", \"smap\", \"mpx\", \"sha\", \"rdpid\", \"ptwrite\", \"cet\", \"gfni\", \"vaes\", \"vpclmulqdq\", \"prefetchwt1\", \"clflushopt\", \"se1\", \"clwb\", \"movdiri\", \"movdir64b\", \"enqcmd\", \"serialize\", \"tsxldtrk\", \"kl\", \"widekl\", \"hreset\", \"avx512f\", \"avx512cd\", \"avx512er\", \"avx512pf\", \"avx512vl\", \"avx512bw\", \"avx512dq\", \"avx512ifma\", \"avx512vbmi\", \"avx512_4fmaps\", \"avx512_4vnniw\", \"avx512_vpopcntdq\", \"avx512_vbmi2\", \"avx512_vnni\", \"avx512_bitalg\", \"avx512_vp2intersect\", \"tdx\", \"avx512_bf16\", \"avx_vnni\", \"avx512_fp16\", \"prefetchi\", \"avx_ifma\", \"avx_vnni_int8\", \"cmpccxadd\", \"wrmsrns\", \"msrlist\", \"avx_ne_convert\", \"rao_int\", \"amx_int8\", \"amx_bf16\", \"amx_fp16\", \"amx_tile\", \"vmx\", \"vmfunc\", \"smx\", \"xsave\", \"xsaveopt\", \"xsavec\", \"xsaves\", \"aes\", \"pclmul\", \"fsgsbase\", \"rdrnd\", \"f16c\", \"bmi2\", \"fma\", \"movbe\", \"ept\", \"lzcnt\", \"popcnt\", \"hle\", \"rtm\", \"tsx\", \"invpcid\", \"clflush\", \"mwaitx\", \"clzero\", \"wbnoinvd\", \"pconfig\", \"waitpkg\", \"uintr\", \"cldemote\", \"rdpru\", \"mcommit\", \"sev_es\", \"lwp\", \"fma4\", \"xop\", \"cx16\", \"syscall\", \"rdtscp\", \"3dnow\", \"3dnowa\", \"sse4a\", \"sse5\", \"snp\", \"invlpgb\", \"tlbsync\", \"svme\" and \"padlock\". Note that these extension mnemonics can be prefixed with \"no\" to revoke the respective (and any dependent) functionality. When the \".arch\" directive is used with -march, the \".arch\" directive will take precedent. -mtune=CPU This option specifies a processor to optimize for. When used in conjunction with the -march option, only instructions of the processor specified by the -march option will be generated. Valid CPU values are identical to the processor list of -march=CPU. -msse2avx This option specifies that the assembler should encode SSE instructions with VEX prefix. -muse-unaligned-vector-move This option specifies that the assembler should encode aligned vector move as unaligned vector move. -msse-check=none -msse-check=warning -msse-check=error These options control if the assembler should check SSE instructions. -msse-check=none will make the assembler not to check SSE instructions, which is the default. -msse-check=warning will make the assembler issue a warning for any SSE instruction. -msse-check=error will make the assembler issue an error for any SSE instruction. -mavxscalar=128 -mavxscalar=256 These options control how the assembler should encode scalar AVX instructions. -mavxscalar=128 will encode scalar AVX instructions with 128bit vector length, which is the default. -mavxscalar=256 will encode scalar AVX instructions with 256bit vector length. WARNING: Don't use this for production code - due to CPU errata the resulting code may not work on certain models. -mvexwig=0 -mvexwig=1 These options control how the assembler should encode VEX.W-ignored (WIG) VEX instructions. -mvexwig=0 will encode WIG VEX instructions with vex.w = 0, which is the default. -mvexwig=1 will encode WIG EVEX instructions with vex.w = 1. WARNING: Don't use this for production code - due to CPU errata the resulting code may not work on certain models. -mevexlig=128 -mevexlig=256 -mevexlig=512 These options control how the assembler should encode length- ignored (LIG) EVEX instructions. -mevexlig=128 will encode LIG EVEX instructions with 128bit vector length, which is the default. -mevexlig=256 and -mevexlig=512 will encode LIG EVEX instructions with 256bit and 512bit vector length, respectively. -mevexwig=0 -mevexwig=1 These options control how the assembler should encode w-ignored (WIG) EVEX instructions. -mevexwig=0 will encode WIG EVEX instructions with evex.w = 0, which is the default. -mevexwig=1 will encode WIG EVEX instructions with evex.w = 1. -mmnemonic=att -mmnemonic=intel This option specifies instruction mnemonic for matching instructions. The \".att_mnemonic\" and \".intel_mnemonic\" directives will take precedent. -msyntax=att -msyntax=intel This option specifies instruction syntax when processing instructions. The \".att_syntax\" and \".intel_syntax\" directives will take precedent. -mnaked-reg This option specifies that registers don't require a % prefix. The \".att_syntax\" and \".intel_syntax\" directives will take precedent. -madd-bnd-prefix This option forces the assembler to add BND prefix to all branches, even if such prefix was not explicitly specified in the source code. -mno-shared On ELF target, the assembler normally optimizes out non-PLT relocations against defined non-weak global branch targets with default visibility. The -mshared option tells the assembler to generate code which may go into a shared library where all non-weak global branch targets with default visibility can be preempted. The resulting code is slightly bigger. This option only affects the handling of branch instructions. -mbig-obj On PE/COFF target this option forces the use of big object file format, which allows more than 32768 sections. -momit-lock-prefix=no -momit-lock-prefix=yes These options control how the assembler should encode lock prefix. This option is intended as a workaround for processors, that fail on lock prefix. This option can only be safely used with single-core, single-thread computers -momit-lock-prefix=yes will omit all lock prefixes. -momit-lock-prefix=no will encode lock prefix as usual, which is the default. -mfence-as-lock-add=no -mfence-as-lock-add=yes These options control how the assembler should encode lfence, mfence and sfence. -mfence-as-lock-add=yes will encode lfence, mfence and sfence as lock addl $0x0, (%rsp) in 64-bit mode and lock addl $0x0, (%esp) in 32-bit mode. -mfence-as-lock-add=no will encode lfence, mfence and sfence as usual, which is the default. -mrelax-relocations=no -mrelax-relocations=yes These options control whether the assembler should generate relax relocations, R_386_GOT32X, in 32-bit mode, or R_X86_64_GOTPCRELX and R_X86_64_REX_GOTPCRELX, in 64-bit mode. -mrelax-relocations=yes will generate relax relocations. -mrelax-relocations=no will not generate relax relocations. The default can be controlled by a configure option --enable-x86-relax-relocations. -malign-branch-boundary=NUM This option controls how the assembler should align branches with segment prefixes or NOP. NUM must be a power of 2. It should be 0 or no less than 16. Branches will be aligned within NUM byte boundary. -malign-branch-boundary=0, which is the default, doesn't align branches. -malign-branch=TYPE[+TYPE...] This option specifies types of branches to align. TYPE is combination of jcc, which aligns conditional jumps, fused, which aligns fused conditional jumps, jmp, which aligns unconditional jumps, call which aligns calls, ret, which aligns rets, indirect, which aligns indirect jumps and calls. The default is -malign-branch=jcc+fused+jmp. -malign-branch-prefix-size=NUM This option specifies the maximum number of prefixes on an instruction to align branches. NUM should be between 0 and 5. The default NUM is 5. -mbranches-within-32B-boundaries This option aligns conditional jumps, fused conditional jumps and unconditional jumps within 32 byte boundary with up to 5 segment prefixes on an instruction. It is equivalent to -malign-branch-boundary=32 -malign-branch=jcc+fused+jmp -malign-branch-prefix-size=5. The default doesn't align branches. -mlfence-after-load=no -mlfence-after-load=yes These options control whether the assembler should generate lfence after load instructions. -mlfence-after-load=yes will generate lfence. -mlfence-after-load=no will not generate lfence, which is the default. -mlfence-before-indirect-branch=none -mlfence-before-indirect-branch=all -mlfence-before-indirect-branch=register -mlfence-before-indirect-branch=memory These options control whether the assembler should generate lfence before indirect near branch instructions. -mlfence-before-indirect-branch=all will generate lfence before indirect near branch via register and issue a warning before indirect near branch via memory. It also implicitly sets -mlfence-before-ret=shl when there's no explicit -mlfence-before-ret=. -mlfence-before-indirect-branch=register will generate lfence before indirect near branch via register. -mlfence-before-indirect-branch=memory will issue a warning before indirect near branch via memory. -mlfence-before-indirect-branch=none will not generate lfence nor issue warning, which is the default. Note that lfence won't be generated before indirect near branch via register with -mlfence-after-load=yes since lfence will be generated after loading branch target register. -mlfence-before-ret=none -mlfence-before-ret=shl -mlfence-before-ret=or -mlfence-before-ret=yes -mlfence-before-ret=not These options control whether the assembler should generate lfence before ret. -mlfence-before-ret=or will generate generate or instruction with lfence. -mlfence-before-ret=shl/yes will generate shl instruction with lfence. -mlfence-before-ret=not will generate not instruction with lfence. -mlfence-before-ret=none will not generate lfence, which is the default. -mx86-used-note=no -mx86-used-note=yes These options control whether the assembler should generate GNU_PROPERTY_X86_ISA_1_USED and GNU_PROPERTY_X86_FEATURE_2_USED GNU property notes. The default can be controlled by the --enable-x86-used-note configure option. -mevexrcig=rne -mevexrcig=rd -mevexrcig=ru -mevexrcig=rz These options control how the assembler should encode SAE- only EVEX instructions. -mevexrcig=rne will encode RC bits of EVEX instruction with 00, which is the default. -mevexrcig=rd, -mevexrcig=ru and -mevexrcig=rz will encode SAE-only EVEX instructions with 01, 10 and 11 RC bits, respectively. -mamd64 -mintel64 This option specifies that the assembler should accept only AMD64 or Intel64 ISA in 64-bit mode. The default is to accept common, Intel64 only and AMD64 ISAs. -O0 | -O | -O1 | -O2 | -Os Optimize instruction encoding with smaller instruction size. -O and -O1 encode 64-bit register load instructions with 64-bit immediate as 32-bit register load instructions with 31-bit or 32-bits immediates, encode 64-bit register clearing instructions with 32-bit register clearing instructions, encode 256-bit/512-bit VEX/EVEX vector register clearing instructions with 128-bit VEX vector register clearing instructions, encode 128-bit/256-bit EVEX vector register load/store instructions with VEX vector register load/store instructions, and encode 128-bit/256-bit EVEX packed integer logical instructions with 128-bit/256-bit VEX packed integer logical. -O2 includes -O1 optimization plus encodes 256-bit/512-bit EVEX vector register clearing instructions with 128-bit EVEX vector register clearing instructions. In 64-bit mode VEX encoded instructions with commutative source operands will also have their source operands swapped if this allows using the 2-byte VEX prefix form instead of the 3-byte one. Certain forms of AND as well as OR with the same (register) operand specified twice will also be changed to TEST. -Os includes -O2 optimization plus encodes 16-bit, 32-bit and 64-bit register tests with immediate as 8-bit register test with immediate. -O0 turns off this optimization. The following options are available when as is configured for the Ubicom IP2K series. -mip2022ext Specifies that the extended IP2022 instructions are allowed. -mip2022 Restores the default behaviour, which restricts the permitted instructions to just the basic IP2022 ones. The following options are available when as is configured for the Renesas M32C and M16C processors. -m32c Assemble M32C instructions. -m16c Assemble M16C instructions (the default). -relax Enable support for link-time relaxations. -h-tick-hex Support H'00 style hex constants in addition to 0x00 style. The following options are available when as is configured for the Renesas M32R (formerly Mitsubishi M32R) series. --m32rx Specify which processor in the M32R family is the target. The default is normally the M32R, but this option changes it to the M32RX. --warn-explicit-parallel-conflicts or --Wp Produce warning messages when questionable parallel constructs are encountered. --no-warn-explicit-parallel-conflicts or --Wnp Do not produce warning messages when questionable parallel constructs are encountered. The following options are available when as is configured for the Motorola 68000 series. -l Shorten references to undefined symbols, to one word instead of two. -m68000 | -m68008 | -m68010 | -m68020 | -m68030 | -m68040 | -m68060 | -m68302 | -m68331 | -m68332 | -m68333 | -m68340 | -mcpu32 | -m5200 Specify what processor in the 68000 family is the target. The default is normally the 68020, but this can be changed at configuration time. -m68881 | -m68882 | -mno-68881 | -mno-68882 The target machine does (or does not) have a floating-point coprocessor. The default is to assume a coprocessor for 68020, 68030, and cpu32. Although the basic 68000 is not compatible with the 68881, a combination of the two can be specified, since it's possible to do emulation of the coprocessor instructions with the main processor. -m68851 | -mno-68851 The target machine does (or does not) have a memory- management unit coprocessor. The default is to assume an MMU for 68020 and up. The following options are available when as is configured for an Altera Nios II processor. -relax-section Replace identified out-of-range branches with PC-relative \"jmp\" sequences when possible. The generated code sequences are suitable for use in position-independent code, but there is a practical limit on the extended branch range because of the length of the sequences. This option is the default. -relax-all Replace branch instructions not determinable to be in range and all call instructions with \"jmp\" and \"callr\" sequences (respectively). This option generates absolute relocations against the target symbols and is not appropriate for position-independent code. -no-relax Do not replace any branches or calls. -EB Generate big-endian output. -EL Generate little-endian output. This is the default. -march=architecture This option specifies the target architecture. The assembler issues an error message if an attempt is made to assemble an instruction which will not execute on the target architecture. The following architecture names are recognized: \"r1\", \"r2\". The default is \"r1\". The following options are available when as is configured for a PRU processor. -mlink-relax Assume that LD would optimize LDI32 instructions by checking the upper 16 bits of the expression. If they are all zeros, then LD would shorten the LDI32 instruction to a single LDI. In such case \"as\" will output DIFF relocations for diff expressions. -mno-link-relax Assume that LD would not optimize LDI32 instructions. As a consequence, DIFF relocations will not be emitted. -mno-warn-regname-label Do not warn if a label name matches a register name. Usually assembler programmers will want this warning to be emitted. C compilers may want to turn this off. The following options are available when as is configured for a MIPS processor. -G num This option sets the largest size of an object that can be referenced implicitly with the \"gp\" register. It is only accepted for targets that use ECOFF format, such as a DECstation running Ultrix. The default value is 8. -EB Generate \"big endian\" format output. -EL Generate \"little endian\" format output. -mips1 -mips2 -mips3 -mips4 -mips5 -mips32 -mips32r2 -mips32r3 -mips32r5 -mips32r6 -mips64 -mips64r2 -mips64r3 -mips64r5 -mips64r6 Generate code for a particular MIPS Instruction Set Architecture level. -mips1 is an alias for -march=r3000, -mips2 is an alias for -march=r6000, -mips3 is an alias for -march=r4000 and -mips4 is an alias for -march=r8000. -mips5, -mips32, -mips32r2, -mips32r3, -mips32r5, -mips32r6, -mips64, -mips64r2, -mips64r3, -mips64r5, and -mips64r6 correspond to generic MIPS V, MIPS32, MIPS32 Release 2, MIPS32 Release 3, MIPS32 Release 5, MIPS32 Release 6, MIPS64, MIPS64 Release 2, MIPS64 Release 3, MIPS64 Release 5, and MIPS64 Release 6 ISA processors, respectively. -march=cpu Generate code for a particular MIPS CPU. -mtune=cpu Schedule and tune for a particular MIPS CPU. -mfix7000 -mno-fix7000 Cause nops to be inserted if the read of the destination register of an mfhi or mflo instruction occurs in the following two instructions. -mfix-rm7000 -mno-fix-rm7000 Cause nops to be inserted if a dmult or dmultu instruction is followed by a load instruction. -mfix-r5900 -mno-fix-r5900 Do not attempt to schedule the preceding instruction into the delay slot of a branch instruction placed at the end of a short loop of six instructions or fewer and always schedule a \"nop\" instruction there instead. The short loop bug under certain conditions causes loops to execute only once or twice, due to a hardware bug in the R5900 chip. -mdebug -no-mdebug Cause stabs-style debugging output to go into an ECOFF-style .mdebug section instead of the standard ELF .stabs sections. -mpdr -mno-pdr Control generation of \".pdr\" sections. -mgp32 -mfp32 The register sizes are normally inferred from the ISA and ABI, but these flags force a certain group of registers to be treated as 32 bits wide at all times. -mgp32 controls the size of general-purpose registers and -mfp32 controls the size of floating-point registers. -mgp64 -mfp64 The register sizes are normally inferred from the ISA and ABI, but these flags force a certain group of registers to be treated as 64 bits wide at all times. -mgp64 controls the size of general-purpose registers and -mfp64 controls the size of floating-point registers. -mfpxx The register sizes are normally inferred from the ISA and ABI, but using this flag in combination with -mabi=32 enables an ABI variant which will operate correctly with floating- point registers which are 32 or 64 bits wide. -modd-spreg -mno-odd-spreg Enable use of floating-point operations on odd-numbered single-precision registers when supported by the ISA. -mfpxx implies -mno-odd-spreg, otherwise the default is -modd-spreg. -mips16 -no-mips16 Generate code for the MIPS 16 processor. This is equivalent to putting \".module mips16\" at the start of the assembly file. -no-mips16 turns off this option. -mmips16e2 -mno-mips16e2 Enable the use of MIPS16e2 instructions in MIPS16 mode. This is equivalent to putting \".module mips16e2\" at the start of the assembly file. -mno-mips16e2 turns off this option. -mmicromips -mno-micromips Generate code for the microMIPS processor. This is equivalent to putting \".module micromips\" at the start of the assembly file. -mno-micromips turns off this option. This is equivalent to putting \".module nomicromips\" at the start of the assembly file. -msmartmips -mno-smartmips Enables the SmartMIPS extension to the MIPS32 instruction set. This is equivalent to putting \".module smartmips\" at the start of the assembly file. -mno-smartmips turns off this option. -mips3d -no-mips3d Generate code for the MIPS-3D Application Specific Extension. This tells the assembler to accept MIPS-3D instructions. -no-mips3d turns off this option. -mdmx -no-mdmx Generate code for the MDMX Application Specific Extension. This tells the assembler to accept MDMX instructions. -no-mdmx turns off this option. -mdsp -mno-dsp Generate code for the DSP Release 1 Application Specific Extension. This tells the assembler to accept DSP Release 1 instructions. -mno-dsp turns off this option. -mdspr2 -mno-dspr2 Generate code for the DSP Release 2 Application Specific Extension. This option implies -mdsp. This tells the assembler to accept DSP Release 2 instructions. -mno-dspr2 turns off this option. -mdspr3 -mno-dspr3 Generate code for the DSP Release 3 Application Specific Extension. This option implies -mdsp and -mdspr2. This tells the assembler to accept DSP Release 3 instructions. -mno-dspr3 turns off this option. -mmsa -mno-msa Generate code for the MIPS SIMD Architecture Extension. This tells the assembler to accept MSA instructions. -mno-msa turns off this option. -mxpa -mno-xpa Generate code for the MIPS eXtended Physical Address (XPA) Extension. This tells the assembler to accept XPA instructions. -mno-xpa turns off this option. -mmt -mno-mt Generate code for the MT Application Specific Extension. This tells the assembler to accept MT instructions. -mno-mt turns off this option. -mmcu -mno-mcu Generate code for the MCU Application Specific Extension. This tells the assembler to accept MCU instructions. -mno-mcu turns off this option. -mcrc -mno-crc Generate code for the MIPS cyclic redundancy check (CRC) Application Specific Extension. This tells the assembler to accept CRC instructions. -mno-crc turns off this option. -mginv -mno-ginv Generate code for the Global INValidate (GINV) Application Specific Extension. This tells the assembler to accept GINV instructions. -mno-ginv turns off this option. -mloongson-mmi -mno-loongson-mmi Generate code for the Loongson MultiMedia extensions Instructions (MMI) Application Specific Extension. This tells the assembler to accept MMI instructions. -mno-loongson-mmi turns off this option. -mloongson-cam -mno-loongson-cam Generate code for the Loongson Content Address Memory (CAM) instructions. This tells the assembler to accept Loongson CAM instructions. -mno-loongson-cam turns off this option. -mloongson-ext -mno-loongson-ext Generate code for the Loongson EXTensions (EXT) instructions. This tells the assembler to accept Loongson EXT instructions. -mno-loongson-ext turns off this option. -mloongson-ext2 -mno-loongson-ext2 Generate code for the Loongson EXTensions R2 (EXT2) instructions. This option implies -mloongson-ext. This tells the assembler to accept Loongson EXT2 instructions. -mno-loongson-ext2 turns off this option. -minsn32 -mno-insn32 Only use 32-bit instruction encodings when generating code for the microMIPS processor. This option inhibits the use of any 16-bit instructions. This is equivalent to putting \".set insn32\" at the start of the assembly file. -mno-insn32 turns off this option. This is equivalent to putting \".set noinsn32\" at the start of the assembly file. By default -mno-insn32 is selected, allowing all instructions to be used. --construct-floats --no-construct-floats The --no-construct-floats option disables the construction of double width floating point constants by loading the two halves of the value into the two single width floating point registers that make up the double width register. By default --construct-floats is selected, allowing construction of these floating point constants. --relax-branch --no-relax-branch The --relax-branch option enables the relaxation of out-of- range branches. By default --no-relax-branch is selected, causing any out-of-range branches to produce an error. -mignore-branch-isa -mno-ignore-branch-isa Ignore branch checks for invalid transitions between ISA modes. The semantics of branches does not provide for an ISA mode switch, so in most cases the ISA mode a branch has been encoded for has to be the same as the ISA mode of the branch's target label. Therefore GAS has checks implemented that verify in branch assembly that the two ISA modes match. -mignore-branch-isa disables these checks. By default -mno-ignore-branch-isa is selected, causing any invalid branch requiring a transition between ISA modes to produce an error. -mnan=encoding Select between the IEEE 754-2008 (-mnan=2008) or the legacy (-mnan=legacy) NaN encoding format. The latter is the default. --emulation=name This option was formerly used to switch between ELF and ECOFF output on targets like IRIX 5 that supported both. MIPS ECOFF support was removed in GAS 2.24, so the option now serves little purpose. It is retained for backwards compatibility. The available configuration names are: mipself, mipslelf and mipsbelf. Choosing mipself now has no effect, since the output is always ELF. mipslelf and mipsbelf select little- and big-endian output respectively, but -EL and -EB are now the preferred options instead. -nocpp as ignores this option. It is accepted for compatibility with the native tools. --trap --no-trap --break --no-break Control how to deal with multiplication overflow and division by zero. --trap or --no-break (which are synonyms) take a trap exception (and only work for Instruction Set Architecture level 2 and higher); --break or --no-trap (also synonyms, and the default) take a break exception. -n When this option is used, as will issue a warning every time it generates a nop instruction from a macro. The following options are available when as is configured for a LoongArch processor. -fpic -fPIC Generate position-independent code -fno-pic Don't generate position-independent code (default) The following options are available when as is configured for a Meta processor. \"-mcpu=metac11\" Generate code for Meta 1.1. \"-mcpu=metac12\" Generate code for Meta 1.2. \"-mcpu=metac21\" Generate code for Meta 2.1. \"-mfpu=metac21\" Allow code to use FPU hardware of Meta 2.1. See the info pages for documentation of the MMIX-specific options. The following options are available when as is configured for a NDS32 processor. \"-O1\" Optimize for performance. \"-Os\" Optimize for space. \"-EL\" Produce little endian data output. \"-EB\" Produce little endian data output. \"-mpic\" Generate PIC. \"-mno-fp-as-gp-relax\" Suppress fp-as-gp relaxation for this file. \"-mb2bb-relax\" Back-to-back branch optimization. \"-mno-all-relax\" Suppress all relaxation for this file. \"-march=<arch name>\" Assemble for architecture <arch name> which could be v3, v3j, v3m, v3f, v3s, v2, v2j, v2f, v2s. \"-mbaseline=<baseline>\" Assemble for baseline <baseline> which could be v2, v3, v3m. \"-mfpu-freg=FREG\" Specify a FPU configuration. \"0 8 SP / 4 DP registers\" \"1 16 SP / 8 DP registers\" \"2 32 SP / 16 DP registers\" \"3 32 SP / 32 DP registers\" \"-mabi=abi\" Specify a abi version <abi> could be v1, v2, v2fp, v2fpp. \"-m[no-]mac\" Enable/Disable Multiply instructions support. \"-m[no-]div\" Enable/Disable Divide instructions support. \"-m[no-]16bit-ext\" Enable/Disable 16-bit extension \"-m[no-]dx-regs\" Enable/Disable d0/d1 registers \"-m[no-]perf-ext\" Enable/Disable Performance extension \"-m[no-]perf2-ext\" Enable/Disable Performance extension 2 \"-m[no-]string-ext\" Enable/Disable String extension \"-m[no-]reduced-regs\" Enable/Disable Reduced Register configuration (GPR16) option \"-m[no-]audio-isa-ext\" Enable/Disable AUDIO ISA extension \"-m[no-]fpu-sp-ext\" Enable/Disable FPU SP extension \"-m[no-]fpu-dp-ext\" Enable/Disable FPU DP extension \"-m[no-]fpu-fma\" Enable/Disable FPU fused-multiply-add instructions \"-mall-ext\" Turn on all extensions and instructions support The following options are available when as is configured for a PowerPC processor. -a32 Generate ELF32 or XCOFF32. -a64 Generate ELF64 or XCOFF64. -K PIC Set EF_PPC_RELOCATABLE_LIB in ELF flags. -mpwrx | -mpwr2 Generate code for POWER/2 (RIOS2). -mpwr Generate code for POWER (RIOS1) -m601 Generate code for PowerPC 601. -mppc, -mppc32, -m603, -m604 Generate code for PowerPC 603/604. -m403, -m405 Generate code for PowerPC 403/405. -m440 Generate code for PowerPC 440. BookE and some 405 instructions. -m464 Generate code for PowerPC 464. -m476 Generate code for PowerPC 476. -m7400, -m7410, -m7450, -m7455 Generate code for PowerPC 7400/7410/7450/7455. -m750cl, -mgekko, -mbroadway Generate code for PowerPC 750CL/Gekko/Broadway. -m821, -m850, -m860 Generate code for PowerPC 821/850/860. -mppc64, -m620 Generate code for PowerPC 620/625/630. -me200z2, -me200z4 Generate code for e200 variants, e200z2 with LSP, e200z4 with SPE. -me300 Generate code for PowerPC e300 family. -me500, -me500x2 Generate code for Motorola e500 core complex. -me500mc Generate code for Freescale e500mc core complex. -me500mc64 Generate code for Freescale e500mc64 core complex. -me5500 Generate code for Freescale e5500 core complex. -me6500 Generate code for Freescale e6500 core complex. -mlsp Enable LSP instructions. (Disables SPE and SPE2.) -mspe Generate code for Motorola SPE instructions. (Disables LSP.) -mspe2 Generate code for Freescale SPE2 instructions. (Disables LSP.) -mtitan Generate code for AppliedMicro Titan core complex. -mppc64bridge Generate code for PowerPC 64, including bridge insns. -mbooke Generate code for 32-bit BookE. -ma2 Generate code for A2 architecture. -maltivec Generate code for processors with AltiVec instructions. -mvle Generate code for Freescale PowerPC VLE instructions. -mvsx Generate code for processors with Vector-Scalar (VSX) instructions. -mhtm Generate code for processors with Hardware Transactional Memory instructions. -mpower4, -mpwr4 Generate code for Power4 architecture. -mpower5, -mpwr5, -mpwr5x Generate code for Power5 architecture. -mpower6, -mpwr6 Generate code for Power6 architecture. -mpower7, -mpwr7 Generate code for Power7 architecture. -mpower8, -mpwr8 Generate code for Power8 architecture. -mpower9, -mpwr9 Generate code for Power9 architecture. -mpower10, -mpwr10 Generate code for Power10 architecture. -mfuture Generate code for 'future' architecture. -mcell -mcell Generate code for Cell Broadband Engine architecture. -mcom Generate code Power/PowerPC common instructions. -many Generate code for any architecture (PWR/PWRX/PPC). -mregnames Allow symbolic names for registers. -mno-regnames Do not allow symbolic names for registers. -mrelocatable Support for GCC's -mrelocatable option. -mrelocatable-lib Support for GCC's -mrelocatable-lib option. -memb Set PPC_EMB bit in ELF flags. -mlittle, -mlittle-endian, -le Generate code for a little endian machine. -mbig, -mbig-endian, -be Generate code for a big endian machine. -msolaris Generate code for Solaris. -mno-solaris Do not generate code for Solaris. -nops=count If an alignment directive inserts more than count nops, put a branch at the beginning to skip execution of the nops. The following options are available when as is configured for a RISC-V processor. -fpic -fPIC Generate position-independent code -fno-pic Don't generate position-independent code (default) -march=ISA Select the base isa, as specified by ISA. For example -march=rv32ima. If this option and the architecture attributes aren't set, then assembler will check the default configure setting --with-arch=ISA. -misa-spec=ISAspec Select the default isa spec version. If the version of ISA isn't set by -march, then assembler helps to set the version according to the default chosen spec. If this option isn't set, then assembler will check the default configure setting --with-isa-spec=ISAspec. -mpriv-spec=PRIVspec Select the privileged spec version. We can decide whether the CSR is valid or not according to the chosen spec. If this option and the privilege attributes aren't set, then assembler will check the default configure setting --with-priv-spec=PRIVspec. -mabi=ABI Selects the ABI, which is either \"ilp32\" or \"lp64\", optionally followed by \"f\", \"d\", or \"q\" to indicate single- precision, double-precision, or quad-precision floating-point calling convention, or none to indicate the soft-float calling convention. Also, \"ilp32\" can optionally be followed by \"e\" to indicate the RVE ABI, which is always soft-float. -mrelax Take advantage of linker relaxations to reduce the number of instructions required to materialize symbol addresses. (default) -mno-relax Don't do linker relaxations. -march-attr Generate the default contents for the riscv elf attribute section if the .attribute directives are not set. This section is used to record the information that a linker or runtime loader needs to check compatibility. This information includes ISA string, stack alignment requirement, unaligned memory accesses, and the major, minor and revision version of privileged specification. -mno-arch-attr Don't generate the default riscv elf attribute section if the .attribute directives are not set. -mcsr-check Enable the CSR checking for the ISA-dependent CRS and the read-only CSR. The ISA-dependent CSR are only valid when the specific ISA is set. The read-only CSR can not be written by the CSR instructions. -mno-csr-check Don't do CSR checking. -mlittle-endian Generate code for a little endian machine. -mbig-endian Generate code for a big endian machine. See the info pages for documentation of the RX-specific options. The following options are available when as is configured for the s390 processor family. -m31 -m64 Select the word size, either 31/32 bits or 64 bits. -mesa -mzarch Select the architecture mode, either the Enterprise System Architecture (esa) or the z/Architecture mode (zarch). -march=processor Specify which s390 processor variant is the target, g5 (or arch3), g6, z900 (or arch5), z990 (or arch6), z9-109, z9-ec (or arch7), z10 (or arch8), z196 (or arch9), zEC12 (or arch10), z13 (or arch11), z14 (or arch12), z15 (or arch13), or z16 (or arch14). -mregnames -mno-regnames Allow or disallow symbolic names for registers. -mwarn-areg-zero Warn whenever the operand for a base or index register has been specified but evaluates to zero. The following options are available when as is configured for a TMS320C6000 processor. -march=arch Enable (only) instructions from architecture arch. By default, all instructions are permitted. The following values of arch are accepted: \"c62x\", \"c64x\", \"c64x+\", \"c67x\", \"c67x+\", \"c674x\". -mdsbt -mno-dsbt The -mdsbt option causes the assembler to generate the \"Tag_ABI_DSBT\" attribute with a value of 1, indicating that the code is using DSBT addressing. The -mno-dsbt option, the default, causes the tag to have a value of 0, indicating that the code does not use DSBT addressing. The linker will emit a warning if objects of different type (DSBT and non-DSBT) are linked together. -mpid=no -mpid=near -mpid=far The -mpid= option causes the assembler to generate the \"Tag_ABI_PID\" attribute with a value indicating the form of data addressing used by the code. -mpid=no, the default, indicates position-dependent data addressing, -mpid=near indicates position-independent addressing with GOT accesses using near DP addressing, and -mpid=far indicates position- independent addressing with GOT accesses using far DP addressing. The linker will emit a warning if objects built with different settings of this option are linked together. -mpic -mno-pic The -mpic option causes the assembler to generate the \"Tag_ABI_PIC\" attribute with a value of 1, indicating that the code is using position-independent code addressing, The \"-mno-pic\" option, the default, causes the tag to have a value of 0, indicating position-dependent code addressing. The linker will emit a warning if objects of different type (position-dependent and position-independent) are linked together. -mbig-endian -mlittle-endian Generate code for the specified endianness. The default is little-endian. The following options are available when as is configured for a TILE-Gx processor. -m32 | -m64 Select the word size, either 32 bits or 64 bits. -EB | -EL Select the endianness, either big-endian (-EB) or little- endian (-EL). The following option is available when as is configured for a Visium processor. -mtune=arch This option specifies the target architecture. If an attempt is made to assemble an instruction that will not execute on the target architecture, the assembler will issue an error message. The following names are recognized: \"mcm24\" \"mcm\" \"gr5\" \"gr6\" The following options are available when as is configured for an Xtensa processor. --text-section-literals | --no-text-section-literals Control the treatment of literal pools. The default is --no-text-section-literals, which places literals in separate sections in the output file. This allows the literal pool to be placed in a data RAM/ROM. With --text-section-literals, the literals are interspersed in the text section in order to keep them as close as possible to their references. This may be necessary for large assembly files, where the literals would otherwise be out of range of the \"L32R\" instructions in the text section. Literals are grouped into pools following \".literal_position\" directives or preceding \"ENTRY\" instructions. These options only affect literals referenced via PC-relative \"L32R\" instructions; literals for absolute mode \"L32R\" instructions are handled separately. --auto-litpools | --no-auto-litpools Control the treatment of literal pools. The default is --no-auto-litpools, which in the absence of --text-section-literals places literals in separate sections in the output file. This allows the literal pool to be placed in a data RAM/ROM. With --auto-litpools, the literals are interspersed in the text section in order to keep them as close as possible to their references, explicit \".literal_position\" directives are not required. This may be necessary for very large functions, where single literal pool at the beginning of the function may not be reachable by \"L32R\" instructions at the end. These options only affect literals referenced via PC-relative \"L32R\" instructions; literals for absolute mode \"L32R\" instructions are handled separately. When used together with --text-section-literals, --auto-litpools takes precedence. --absolute-literals | --no-absolute-literals Indicate to the assembler whether \"L32R\" instructions use absolute or PC-relative addressing. If the processor includes the absolute addressing option, the default is to use absolute \"L32R\" relocations. Otherwise, only the PC- relative \"L32R\" relocations can be used. --target-align | --no-target-align Enable or disable automatic alignment to reduce branch penalties at some expense in code size. This optimization is enabled by default. Note that the assembler will always align instructions like \"LOOP\" that have fixed alignment requirements. --longcalls | --no-longcalls Enable or disable transformation of call instructions to allow calls across a greater range of addresses. This option should be used when call targets can potentially be out of range. It may degrade both code size and performance, but the linker can generally optimize away the unnecessary overhead when a call ends up within range. The default is --no-longcalls. --transform | --no-transform Enable or disable all assembler transformations of Xtensa instructions, including both relaxation and optimization. The default is --transform; --no-transform should only be used in the rare cases when the instructions must be exactly as specified in the assembly source. Using --no-transform causes out of range instruction operands to be errors. --rename-section oldname=newname Rename the oldname section to newname. This option can be used multiple times to rename multiple sections. --trampolines | --no-trampolines Enable or disable transformation of jump instructions to allow jumps across a greater range of addresses. This option should be used when jump targets can potentially be out of range. In the absence of such jumps this option does not affect code size or performance. The default is --trampolines. --abi-windowed | --abi-call0 Choose ABI tag written to the \".xtensa.info\" section. ABI tag indicates ABI of the assembly code. A warning is issued by the linker on an attempt to link object files with inconsistent ABI tags. Default ABI is chosen by the Xtensa core configuration. The following options are available when as is configured for an Z80 processor. @chapter Z80 Dependent Features Command-line Options -march=CPU[-EXT...][+EXT...] This option specifies the target processor. The assembler will issue an error message if an attempt is made to assemble an instruction which will not execute on the target processor. The following processor names are recognized: \"z80\", \"z180\", \"ez80\", \"gbz80\", \"z80n\", \"r800\". In addition to the basic instruction set, the assembler can be told to accept some extention mnemonics. For example, \"-march=z180+sli+infc\" extends z180 with SLI instructions and IN F,(C). The following extentions are currently supported: \"full\" (all known instructions), \"adl\" (ADL CPU mode by default, eZ80 only), \"sli\" (instruction known as SLI, SLL or SL1), \"xyhl\" (instructions with halves of index registers: IXL, IXH, IYL, IYH), \"xdcb\" (instructions like RotOp (II+d),R and BitOp n,(II+d),R), \"infc\" (instruction IN F,(C) or IN (C)), \"outc0\" (instruction OUT (C),0). Note that rather than extending a basic instruction set, the extention mnemonics starting with \"-\" revoke the respective functionality: \"-march=z80-full+xyhl\" first removes all default extentions and adds support for index registers halves only. If this option is not specified then \"-march=z80+xyhl+infc\" is assumed. -local-prefix=prefix Mark all labels with specified prefix as local. But such label can be marked global explicitly in the code. This option do not change default local label prefix \".L\", it is just adds new one. -colonless Accept colonless labels. All symbols at line begin are treated as labels. -sdcc Accept assembler code produced by SDCC. -fp-s=FORMAT Single precision floating point numbers format. Default: ieee754 (32 bit). -fp-d=FORMAT Double precision floating point numbers format. Default: ieee754 (64 bit). "
  },
  {
    "command": "systemd-cat",
    "description": " systemd-cat may be used to connect the standard input and output of a process to the journal, or as a filter tool in a shell pipeline to pass the output the previous pipeline element generates to the journal. If no parameter is passed, systemd-cat will write everything it reads from standard input (stdin) to the journal. If parameters are passed, they are executed as command line with standard output (stdout) and standard error output (stderr) connected to the journal, so that all it writes is stored in the journal. The following options are understood: -h, --help Print a short help text and exit. --version Print a short version string and exit. -t, --identifier= Specify a short string that is used to identify the logging tool. If not specified, no identification string is written to the journal. -p, --priority= Specify the default priority level for the logged messages. Pass one of \"emerg\", \"alert\", \"crit\", \"err\", \"warning\", \"notice\", \"info\", \"debug\", or a value between 0 and 7 (corresponding to the same named levels). These priority values are the same as defined by syslog(3). Defaults to \"info\". Note that this simply controls the default, individual lines may be logged with different levels if they are prefixed accordingly. For details, see --level-prefix= below. --stderr-priority= Specifies the default priority level for messages from the process's standard error output (stderr). Usage of this option is the same as the --priority= option, above, and both can be used at once. When both are used, --priority= will specify the default priority for standard output (stdout). If --stderr-priority= is not specified, messages from stderr will still be logged, with the same default priority level as stdout. Also, note that when stdout and stderr use the same default priority, the messages will be strictly ordered, because one channel is used for both. When the default priority differs, two channels are used, and so stdout messages will not be strictly ordered with respect to stderr messages - though they will tend to be approximately ordered. --level-prefix= Controls whether lines read are parsed for syslog priority level prefixes. If enabled (the default), a line prefixed with a priority prefix such as \"<5>\" is logged at priority 5 (\"notice\"), and similarly for the other priority levels. Takes a boolean argument. "
  },
  {
    "command": "git-rev-parse",
    "description": " Many Git porcelainish commands take mixture of flags (i.e. parameters that begin with a dash -) and parameters meant for the underlying git rev-list command they use internally and flags and parameters for the other commands they use downstream of git rev-list. This command is used to distinguish between them. Operation Modes Each of these options must appear first on the command line. --parseopt Use git rev-parse in option parsing mode (see PARSEOPT section below). --sq-quote Use git rev-parse in shell quoting mode (see SQ-QUOTE section below). In contrast to the --sq option below, this mode does only quoting. Nothing else is done to command input. Options for --parseopt --keep-dashdash Only meaningful in --parseopt mode. Tells the option parser to echo out the first -- met instead of skipping it. --stop-at-non-option Only meaningful in --parseopt mode. Lets the option parser stop at the first non-option argument. This can be used to parse sub-commands that take options themselves. --stuck-long Only meaningful in --parseopt mode. Output the options in their long form if available, and with their arguments stuck. Options for Filtering --revs-only Do not output flags and parameters not meant for git rev-list command. --no-revs Do not output flags and parameters meant for git rev-list command. --flags Do not output non-flag parameters. --no-flags Do not output flag parameters. Options for Output --default <arg> If there is no parameter given by the user, use <arg> instead. --prefix <arg> Behave as if git rev-parse was invoked from the <arg> subdirectory of the working tree. Any relative filenames are resolved as if they are prefixed by <arg> and will be printed in that form. This can be used to convert arguments to a command run in a subdirectory so that they can still be used after moving to the top-level of the repository. For example: prefix=$(git rev-parse --show-prefix) cd \"$(git rev-parse --show-toplevel)\" # rev-parse provides the -- needed for 'set' eval \"set $(git rev-parse --sq --prefix \"$prefix\" -- \"$@\")\" --verify Verify that exactly one parameter is provided, and that it can be turned into a raw 20-byte SHA-1 that can be used to access the object database. If so, emit it to the standard output; otherwise, error out. If you want to make sure that the output actually names an object in your object database and/or can be used as a specific type of object you require, you can add the ^{type} peeling operator to the parameter. For example, git rev-parse \"$VAR^{commit}\" will make sure $VAR names an existing object that is a commit-ish (i.e. a commit, or an annotated tag that points at a commit). To make sure that $VAR names an existing object of any type, git rev-parse \"$VAR^{object}\" can be used. Note that if you are verifying a name from an untrusted source, it is wise to use --end-of-options so that the name argument is not mistaken for another option. -q, --quiet Only meaningful in --verify mode. Do not output an error message if the first argument is not a valid object name; instead exit with non-zero status silently. SHA-1s for valid object names are printed to stdout on success. --sq Usually the output is made one line per flag and parameter. This option makes output a single line, properly quoted for consumption by shell. Useful when you expect your parameter to contain whitespaces and newlines (e.g. when using pickaxe -S with git diff-*). In contrast to the --sq-quote option, the command input is still interpreted as usual. --short[=length] Same as --verify but shortens the object name to a unique prefix with at least length characters. The minimum length is 4, the default is the effective value of the core.abbrev configuration variable (see git-config(1)). --not When showing object names, prefix them with ^ and strip ^ prefix from the object names that already have one. --abbrev-ref[=(strict|loose)] A non-ambiguous short name of the objects name. The option core.warnAmbiguousRefs is used to select the strict abbreviation mode. --symbolic Usually the object names are output in SHA-1 form (with possible ^ prefix); this option makes them output in a form as close to the original input as possible. --symbolic-full-name This is similar to --symbolic, but it omits input that are not refs (i.e. branch or tag names; or more explicitly disambiguating \"heads/master\" form, when you want to name the \"master\" branch when there is an unfortunately named tag \"master\"), and show them as full refnames (e.g. \"refs/heads/master\"). Options for Objects --all Show all refs found in refs/. --branches[=pattern], --tags[=pattern], --remotes[=pattern] Show all branches, tags, or remote-tracking branches, respectively (i.e., refs found in refs/heads, refs/tags, or refs/remotes, respectively). If a pattern is given, only refs matching the given shell glob are shown. If the pattern does not contain a globbing character (?, *, or [), it is turned into a prefix match by appending /*. --glob=pattern Show all refs matching the shell glob pattern pattern. If the pattern does not start with refs/, this is automatically prepended. If the pattern does not contain a globbing character (?, *, or [), it is turned into a prefix match by appending /*. --exclude=<glob-pattern> Do not include refs matching <glob-pattern> that the next --all, --branches, --tags, --remotes, or --glob would otherwise consider. Repetitions of this option accumulate exclusion patterns up to the next --all, --branches, --tags, --remotes, or --glob option (other options or arguments do not clear accumulated patterns). The patterns given should not begin with refs/heads, refs/tags, or refs/remotes when applied to --branches, --tags, or --remotes, respectively, and they must begin with refs/ when applied to --glob or --all. If a trailing /* is intended, it must be given explicitly. --exclude-hidden=[fetch|receive|uploadpack] Do not include refs that would be hidden by git-fetch, git-receive-pack or git-upload-pack by consulting the appropriate fetch.hideRefs, receive.hideRefs or uploadpack.hideRefs configuration along with transfer.hideRefs (see git-config(1)). This option affects the next pseudo-ref option --all or --glob and is cleared after processing them. --disambiguate=<prefix> Show every object whose name begins with the given prefix. The <prefix> must be at least 4 hexadecimal digits long to avoid listing each and every object in the repository by mistake. Options for Files --local-env-vars List the GIT_* environment variables that are local to the repository (e.g. GIT_DIR or GIT_WORK_TREE, but not GIT_EDITOR). Only the names of the variables are listed, not their value, even if they are set. --path-format=(absolute|relative) Controls the behavior of certain other options. If specified as absolute, the paths printed by those options will be absolute and canonical. If specified as relative, the paths will be relative to the current working directory if that is possible. The default is option specific. This option may be specified multiple times and affects only the arguments that follow it on the command line, either to the end of the command line or the next instance of this option. The following options are modified by --path-format: --git-dir Show $GIT_DIR if defined. Otherwise show the path to the .git directory. The path shown, when relative, is relative to the current working directory. If $GIT_DIR is not defined and the current directory is not detected to lie in a Git repository or work tree print a message to stderr and exit with nonzero status. --git-common-dir Show $GIT_COMMON_DIR if defined, else $GIT_DIR. --resolve-git-dir <path> Check if <path> is a valid repository or a gitfile that points at a valid repository, and print the location of the repository. If <path> is a gitfile then the resolved path to the real repository is printed. --git-path <path> Resolve \"$GIT_DIR/<path>\" and takes other path relocation variables such as $GIT_OBJECT_DIRECTORY, $GIT_INDEX_FILE... into account. For example, if $GIT_OBJECT_DIRECTORY is set to /foo/bar then \"git rev-parse --git-path objects/abc\" returns /foo/bar/abc. --show-toplevel Show the (by default, absolute) path of the top-level directory of the working tree. If there is no working tree, report an error. --show-superproject-working-tree Show the absolute path of the root of the superproject\u2019s working tree (if exists) that uses the current repository as its submodule. Outputs nothing if the current repository is not used as a submodule by any project. --shared-index-path Show the path to the shared index file in split index mode, or empty if not in split-index mode. The following options are unaffected by --path-format: --absolute-git-dir Like --git-dir, but its output is always the canonicalized absolute path. --is-inside-git-dir When the current working directory is below the repository directory print \"true\", otherwise \"false\". --is-inside-work-tree When the current working directory is inside the work tree of the repository print \"true\", otherwise \"false\". --is-bare-repository When the repository is bare print \"true\", otherwise \"false\". --is-shallow-repository When the repository is shallow print \"true\", otherwise \"false\". --show-cdup When the command is invoked from a subdirectory, show the path of the top-level directory relative to the current directory (typically a sequence of \"../\", or an empty string). --show-prefix When the command is invoked from a subdirectory, show the path of the current directory relative to the top-level directory. --show-object-format[=(storage|input|output)] Show the object format (hash algorithm) used for the repository for storage inside the .git directory, input, or output. For input, multiple algorithms may be printed, space-separated. If not specified, the default is \"storage\". Other Options --since=datestring, --after=datestring Parse the date string, and output the corresponding --max-age= parameter for git rev-list. --until=datestring, --before=datestring Parse the date string, and output the corresponding --min-age= parameter for git rev-list. <args>... Flags and parameters to be parsed. "
  },
  {
    "command": "patch",
    "description": " The patch utility shall read a source (patch) file containing any of four forms of difference (diff) listings produced by the diff utility (normal, copied context, unified context, or in the style of ed) and apply those differences to a file. By default, patch shall read from the standard input. The patch utility shall attempt to determine the type of the diff listing, unless overruled by a -c, -e, -n, or -u option. If the patch file contains more than one patch, patch shall attempt to apply each of them as if they came from separate patch files. (In this case, the application shall ensure that the name of the patch file is determinable for each diff listing.) The patch utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -b Save a copy of the original contents of each modified file, before the differences are applied, in a file of the same name with the suffix .orig appended to it. If the file already exists, it shall be overwritten; if multiple patches are applied to the same file, the .orig file shall be written only for the first patch. When the -o outfile option is also specified, file.orig shall not be created but, if outfile already exists, outfile.orig shall be created. -c Interpret the patch file as a copied context difference (the output of the utility diff when the -c or -C options are specified). -d dir Change the current directory to dir before processing as described in the EXTENDED DESCRIPTION section. -D define Mark changes with one of the following C preprocessor constructs: #ifdef define ... #endif #ifndef define ... #endif optionally combined with the C preprocessor construct #else. If the patched file is processed with the C preprocessor, where the macro define is defined, the output shall contain the changes from the patch file; otherwise, the output shall not contain the patches specified in the patch file. -e Interpret the patch file as an ed script, rather than a diff script. -i patchfile Read the patch information from the file named by the pathname patchfile, rather than the standard input. -l (The letter ell.) Cause any sequence of <blank> characters in the difference script to match any sequence of <blank> characters in the input file. Other characters shall be matched exactly. -n Interpret the script as a normal difference. -N Ignore patches where the differences have already been applied to the file; by default, already-applied patches shall be rejected. -o outfile Instead of modifying the files (specified by the file operand or the difference listings) directly, write a copy of the file referenced by each patch, with the appropriate differences applied, to outfile. Multiple patches for a single file shall be applied to the intermediate versions of the file created by any previous patches, and shall result in multiple, concatenated versions of the file being written to outfile. -p num For all pathnames in the patch file that indicate the names of files to be patched, delete num pathname components from the beginning of each pathname. If the pathname in the patch file is absolute, any leading <slash> characters shall be considered the first component (that is, -p 1 shall remove the leading <slash> characters). Specifying -p 0 shall cause the full pathname to be used. If -p is not specified, only the basename (the final pathname component) shall be used. -R Reverse the sense of the patch script; that is, assume that the difference script was created from the new version to the old version. The -R option cannot be used with ed scripts. The patch utility shall attempt to reverse each portion of the script before applying it. Rejected differences shall be saved in swapped format. If this option is not specified, and until a portion of the patch file is successfully applied, patch attempts to apply each portion in its reversed sense as well as in its normal sense. If the attempt is successful, the user shall be prompted to determine whether the -R option should be set. -r rejectfile Override the default reject filename. In the default case, the reject file shall have the same name as the output file, with the suffix .rej appended to it; see Patch Application. -u Interpret the patch file as a unified context difference (the output of the diff utility when the -u or -U options are specified). "
  },
  {
    "command": "size",
    "description": " The GNU size utility lists the section sizes and the total size for each of the binary files objfile on its argument list. By default, one line of output is generated for each file or each module if the file is an archive. objfile... are the files to be examined. If none are specified, the file \"a.out\" will be used instead. The command-line options have the following meanings: -A -B -G --format=compatibility Using one of these options, you can choose whether the output from GNU size resembles output from System V size (using -A, or --format=sysv), or Berkeley size (using -B, or --format=berkeley). The default is the one-line format similar to Berkeley's. Alternatively, you can choose the GNU format output (using -G, or --format=gnu), this is similar to Berkeley's output format, but sizes are counted differently. Here is an example of the Berkeley (default) format of output from size: $ size --format=Berkeley ranlib size text data bss dec hex filename 294880 81920 11592 388392 5ed28 ranlib 294880 81920 11888 388688 5ee50 size The Berkeley style output counts read only data in the \"text\" column, not in the \"data\" column, the \"dec\" and \"hex\" columns both display the sum of the \"text\", \"data\", and \"bss\" columns in decimal and hexadecimal respectively. The GNU format counts read only data in the \"data\" column, not the \"text\" column, and only displays the sum of the \"text\", \"data\", and \"bss\" columns once, in the \"total\" column. The --radix option can be used to change the number base for all columns. Here is the same data displayed with GNU conventions: $ size --format=GNU ranlib size text data bss total filename 279880 96920 11592 388392 ranlib 279880 96920 11888 388688 size This is the same data, but displayed closer to System V conventions: $ size --format=SysV ranlib size ranlib : section size addr .text 294880 8192 .data 81920 303104 .bss 11592 385024 Total 388392 size : section size addr .text 294880 8192 .data 81920 303104 .bss 11888 385024 Total 388688 --help -h -H -? Show a summary of acceptable arguments and options. -d -o -x --radix=number Using one of these options, you can control whether the size of each section is given in decimal (-d, or --radix=10); octal (-o, or --radix=8); or hexadecimal (-x, or --radix=16). In --radix=number, only the three values (8, 10, 16) are supported. The total size is always given in two radices; decimal and hexadecimal for -d or -x output, or octal and hexadecimal if you're using -o. --common Print total size of common symbols in each file. When using Berkeley or GNU format these are included in the bss size. -t --totals Show totals of all objects listed (Berkeley or GNU format mode only). --target=bfdname Specify that the object-code format for objfile is bfdname. This option may not be necessary; size can automatically recognize many formats. -v -V --version Display the version number of size. -f Ignored. This option is used by other versions of the size program, but it is not supported by the GNU Binutils version. @file Read command-line options from file. The options read are inserted in place of the original @file option. If file does not exist, or cannot be read, then the option will be treated literally, and not removed. Options in file are separated by whitespace. A whitespace character may be included in an option by surrounding the entire option in either single or double quotes. Any character (including a backslash) may be included by prefixing the character to be included with a backslash. The file may itself contain additional @file options; any such options will be processed recursively. "
  },
  {
    "command": "column",
    "description": " The column utility formats its input into multiple columns. The util support three modes: columns are filled before rows This is the default mode (required by backward compatibility). rows are filled before columns This mode is enabled by option -x, --fillrows table Determine the number of columns the input contains and create a table. This mode is enabled by option -t, --table and columns formatting is possible to modify by --table-* options. Use this mode if not sure. The output is aligned to the terminal width in interactive mode and the 80 columns in non-interactive mode (see --output-width for more details). Input is taken from file, or otherwise from standard input. Empty lines are ignored and all invalid multibyte sequences are encoded by x<hex> convention. The argument columns for --table-* options is a comma separated list of the column names as defined by --table-columns, or names defined by --table-column or it\u2019s column number in order as specified by input. It\u2019s possible to mix names and numbers. The special placeholder '0' (e.g. -R0) may be used to specify all columns and '-1' (e.g. -R -1) to specify the last visible column. It\u2019s possible to use ranges like '1-5' when addressing columns by numbers. -J, --json Use JSON output format to print the table, the option --table-columns is required and the option --table-name is recommended. -c, --output-width width Output is formatted to a width specified as number of characters. The original name of this option is --columns; this name is deprecated since v2.30. Note that input longer than width is not truncated by default. The default is a terminal width and the 80 columns in non-interactive mode. The column headers are never truncated. The placeholder \"unlimited\" (or 0) is possible to use to not restrict output width. This is recommended for example when output to the files rather than on terminal. -d, --table-noheadings Do not print header. This option allows the use of logical column names on the command line, but keeps the header hidden when printing the table. -o, --output-separator string Specify the columns delimiter for table output (default is two spaces). -s, --separator separators Specify the possible input item delimiters (default is whitespace). -t, --table Determine the number of columns the input contains and create a table. Columns are delimited with whitespace, by default, or with the characters supplied using the --output-separator option. Table output is useful for pretty-printing. -C, --table-column properties Define one column by comma separated list of column attributes. This option can be used more than once, every use defines just one column. The properties replace some of --table- options. For example --table-column name=FOO,right define one column where text is aligned to right. The option is mutually exclusive to --table-columns. The currently supported attributes are: name=string Specifies column name. trunc The column text can be truncated when necessary. The same as --table-truncate. right Right align text in the specified columns. The same as --table-right. width=number Specifies column width. The width is used as a hint only. The width is strictly followed only when strictwidth attribute is used too. strictwidth Strictly follow column width= setting. noextreme Specify columns where is possible to ignore unusually long cells. See --table-noextreme for more details. wrap Specify columns where is possible to use multi-line cell for long text when necessary. See --table-wrap. hide Don\u2019t print specified columns. See --table-hide. json=type Define column type for JSON output, Supported are string, number and boolean. -N, --table-columns names Specify the columns names by comma separated list of names. The names are used for the table header or to address column in option argument. See also --table-column. -l, --table-columns-limit number Specify maximal number of the input columns. The last column will contain all remaining line data if the limit is smaller than the number of the columns in the input data. -R, --table-right columns Right align text in the specified columns. -T, --table-truncate columns Specify columns where text can be truncated when necessary, otherwise very long table entries may be printed on multiple lines. -E, --table-noextreme columns Specify columns where is possible to ignore unusually long (longer than average) cells when calculate column width. The option has impact to the width calculation and table formatting, but the printed text is not affected. The option is used for the last visible column by default. -e, --table-header-repeat Print header line for each page. -W, --table-wrap columns Specify columns where is possible to use multi-line cell for long text when necessary. -H, --table-hide columns Don\u2019t print specified columns. The special placeholder '-' may be used to hide all unnamed columns (see --table-columns). -O, --table-order columns Specify columns order on output. -n, --table-name name Specify the table name used for JSON output. The default is \"table\". -m, --table-maxout Fill all available space on output. -L, --keep-empty-lines Preserve whitespace-only lines in the input. The default is ignore empty lines at all. This option\u2019s original name was --table-empty-lines but is now deprecated because it gives the false impression that the option only applies to table mode. -r, --tree column Specify column to use tree-like output. Note that the circular dependencies and other anomalies in child and parent relation are silently ignored. -i, --tree-id column Specify column with line ID to create child-parent relation. -p, --tree-parent column Specify column with parent ID to create child-parent relation. -x, --fillrows Fill rows before filling columns. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "seq",
    "description": " Print numbers from FIRST to LAST, in steps of INCREMENT. Mandatory arguments to long options are mandatory for short options too. -f, --format=FORMAT use printf style floating-point FORMAT -s, --separator=STRING use STRING to separate numbers (default: \\n) -w, --equal-width equalize width by padding with leading zeroes --help display this help and exit --version output version information and exit If FIRST or INCREMENT is omitted, it defaults to 1. That is, an omitted INCREMENT defaults to 1 even when LAST is smaller than FIRST. The sequence of numbers ends when the sum of the current number and INCREMENT would become greater than LAST. FIRST, INCREMENT, and LAST are interpreted as floating point values. INCREMENT is usually positive if FIRST is smaller than LAST, and INCREMENT is usually negative if FIRST is greater than LAST. INCREMENT must not be 0; none of FIRST, INCREMENT and LAST may be NaN. FORMAT must be suitable for printing one argument of type 'double'; it defaults to %.PRECf if FIRST, INCREMENT, and LAST are all fixed point decimal numbers with maximum precision PREC, and to %g otherwise. "
  },
  {
    "command": "fmt",
    "description": " Reformat each paragraph in the FILE(s), writing to standard output. The option -WIDTH is an abbreviated form of --width=DIGITS. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -c, --crown-margin preserve indentation of first two lines -p, --prefix=STRING reformat only lines beginning with STRING, reattaching the prefix to reformatted lines -s, --split-only split long lines, but do not refill -t, --tagged-paragraph indentation of first line different from second -u, --uniform-spacing one space between words, two after sentences -w, --width=WIDTH maximum line width (default of 75 columns) -g, --goal=WIDTH goal width (default of 93% of width) --help display this help and exit --version output version information and exit "
  },
  {
    "command": "groups",
    "description": " The groups command displays the current group names or ID values. If the value does not have a corresponding entry in /etc/group, the value will be displayed as the numerical group value. The optional user parameter will display the groups for the named user. "
  },
  {
    "command": "nm",
    "description": " The nm utility shall display symbolic information appearing in the object file, executable file, or object-file library named by file. If no symbolic information is available for a valid input file, the nm utility shall report that fact, but not consider it an error condition. The default base used when numeric values are written is unspecified. On XSI-conformant systems, it shall be decimal if the -P option is not specified. The nm utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -A Write the full pathname or library name of an object on each line. -e Write only external (global) and static symbol information. -f Produce full output. Write redundant symbols (.text, .data, and .bss), normally suppressed. -g Write only external (global) symbol information. -o Write numeric values in octal (equivalent to -t o). -P Write information in a portable output format, as specified in the STDOUT section. -t format Write each numeric value in the specified format. The format shall be dependent on the single character used as the format option-argument: d decimal (default if -P is not specified). o octal. x hexadecimal (default if -P is specified). -u Write only undefined symbols. -v Sort output by value instead of by symbol name. -x Write numeric values in hexadecimal (equivalent to -t x). "
  },
  {
    "command": "git-stage",
    "description": " This is a synonym for git-add(1). Please refer to the documentation of that command. "
  },
  {
    "command": "dd",
    "description": " Copy a file, converting and formatting according to the operands. bs=BYTES read and write up to BYTES bytes at a time (default: 512); overrides ibs and obs cbs=BYTES convert BYTES bytes at a time conv=CONVS convert the file as per the comma separated symbol list count=N copy only N input blocks ibs=BYTES read up to BYTES bytes at a time (default: 512) if=FILE read from FILE instead of stdin iflag=FLAGS read as per the comma separated symbol list obs=BYTES write BYTES bytes at a time (default: 512) of=FILE write to FILE instead of stdout oflag=FLAGS write as per the comma separated symbol list seek=N (or oseek=N) skip N obs-sized output blocks skip=N (or iseek=N) skip N ibs-sized input blocks status=LEVEL The LEVEL of information to print to stderr; 'none' suppresses everything but error messages, 'noxfer' suppresses the final transfer statistics, 'progress' shows periodic transfer statistics N and BYTES may be followed by the following multiplicative suffixes: c=1, w=2, b=512, kB=1000, K=1024, MB=1000*1000, M=1024*1024, xM=M, GB=1000*1000*1000, G=1024*1024*1024, and so on for T, P, E, Z, Y, R, Q. Binary prefixes can be used, too: KiB=K, MiB=M, and so on. If N ends in 'B', it counts bytes not blocks. Each CONV symbol may be: ascii from EBCDIC to ASCII ebcdic from ASCII to EBCDIC ibm from ASCII to alternate EBCDIC block pad newline-terminated records with spaces to cbs-size unblock replace trailing spaces in cbs-size records with newline lcase change upper case to lower case ucase change lower case to upper case sparse try to seek rather than write all-NUL output blocks swab swap every pair of input bytes sync pad every input block with NULs to ibs-size; when used with block or unblock, pad with spaces rather than NULs excl fail if the output file already exists nocreat do not create the output file notrunc do not truncate the output file noerror continue after read errors fdatasync physically write output file data before finishing fsync likewise, but also write metadata Each FLAG symbol may be: append append mode (makes sense only for output; conv=notrunc suggested) direct use direct I/O for data directory fail unless a directory dsync use synchronized I/O for data sync likewise, but also for metadata fullblock accumulate full blocks of input (iflag only) nonblock use non-blocking I/O noatime do not update access time nocache Request to drop cache. See also oflag=sync noctty do not assign controlling terminal from file nofollow do not follow symlinks Sending a USR1 signal to a running 'dd' process makes it print I/O statistics to standard error and then resume copying. Options are: --help display this help and exit --version output version information and exit "
  },
  {
    "command": "prlimit",
    "description": " Given a process ID and one or more resources, prlimit tries to retrieve and/or modify the limits. When command is given, prlimit will run this command with the given arguments. The limits parameter is composed of a soft and a hard value, separated by a colon (:), in order to modify the existing values. If no limits are given, prlimit will display the current values. If one of the values is not given, then the existing one will be used. To specify the unlimited or infinity limit (RLIM_INFINITY), the -1 or 'unlimited' string can be passed. Because of the nature of limits, the soft limit must be lower or equal to the high limit (also called the ceiling). To see all available resource limits, refer to the RESOURCE OPTIONS section. \u2022 soft:_hard_ Specify both limits. \u2022 soft: Specify only the soft limit. \u2022 :hard Specify only the hard limit. \u2022 value Specify both limits to the same value. "
  },
  {
    "command": "uniq",
    "description": " The uniq utility shall read an input file comparing adjacent lines, and write one copy of each input line on the output. The second and succeeding copies of repeated adjacent input lines shall not be written. The trailing <newline> of each line in the input shall be ignored when doing comparisons. Repeated lines in the input shall not be detected if they are not adjacent. The uniq utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except that '+' may be recognized as an option delimiter as well as '-'. The following options shall be supported: -c Precede each output line with a count of the number of times the line occurred in the input. -d Suppress the writing of lines that are not repeated in the input. -f fields Ignore the first fields fields on each input line when doing comparisons, where fields is a positive decimal integer. A field is the maximal string matched by the basic regular expression: [[:blank:]]*[^[:blank:]]* If the fields option-argument specifies more fields than appear on an input line, a null string shall be used for comparison. -s chars Ignore the first chars characters when doing comparisons, where chars shall be a positive decimal integer. If specified in conjunction with the -f option, the first chars characters after the first fields fields shall be ignored. If the chars option- argument specifies more characters than remain on an input line, a null string shall be used for comparison. -u Suppress the writing of lines that are repeated in the input. "
  },
  {
    "command": "git-remote",
    "description": " Manage the set of repositories (\"remotes\") whose branches you track. -v, --verbose Be a little more verbose and show remote url after name. For promisor remotes, also show which filter (blob:none etc.) are configured. NOTE: This must be placed between remote and subcommand. "
  },
  {
    "command": "systemd-path",
    "description": " systemd-path may be used to query system and user paths. The tool makes many of the paths described in file-hierarchy(7) available for querying. When invoked without arguments, a list of known paths and their current values is shown. When at least one argument is passed, the path with this name is queried and its value shown. The variables whose name begins with \"search-\" do not refer to individual paths, but instead to a list of colon-separated search paths, in their order of precedence. The following options are understood: --suffix= Printed paths are suffixed by the specified string. -h, --help Print a short help text and exit. --version Print a short version string and exit. "
  },
  {
    "command": "whatis",
    "description": " Each manual page has a short description available within it. whatis searches the manual page names and displays the manual page descriptions of any name matched. name may contain wildcards (-w) or be a regular expression (-r). Using these options, it may be necessary to quote the name or escape (\\) the special characters to stop the shell from interpreting them. index databases are used during the search, and are updated by the mandb program. Depending on your installation, this may be run by a periodic cron job, or may need to be run manually after new manual pages have been installed. To produce an old style text whatis database from the relative index database, issue the command: whatis -M manpath -w '*' | sort > manpath/whatis where manpath is a manual page hierarchy such as /usr/man. -d, --debug Print debugging information. -v, --verbose Print verbose warning messages. -r, --regex Interpret each name as a regular expression. If a name matches any part of a page name, a match will be made. This option causes whatis to be somewhat slower due to the nature of database searches. -w, --wildcard Interpret each name as a pattern containing shell style wildcards. For a match to be made, an expanded name must match the entire page name. This option causes whatis to be somewhat slower due to the nature of database searches. -l, --long Do not trim output to the terminal width. Normally, output will be truncated to the terminal width to avoid ugly results from poorly-written NAME sections. -s list, --sections=list, --section=list Search only the given manual sections. list is a colon- or comma-separated list of sections. If an entry in list is a simple section, for example \"3\", then the displayed list of descriptions will include pages in sections \"3\", \"3perl\", \"3x\", and so on; while if an entry in list has an extension, for example \"3perl\", then the list will only include pages in that exact part of the manual section. -m system[,...], --systems=system[,...] If this system has access to other operating systems' manual page names, they can be accessed using this option. To search NewOS's manual page names, use the option -m NewOS. The system specified can be a combination of comma delimited operating system names. To include a search of the native operating system's manual page names, include the system name man in the argument string. This option will override the $SYSTEM environment variable. -M path, --manpath=path Specify an alternate set of colon-delimited manual page hierarchies to search. By default, whatis uses the $MANPATH environment variable, unless it is empty or unset, in which case it will determine an appropriate manpath based on your $PATH environment variable. This option overrides the contents of $MANPATH. -L locale, --locale=locale whatis will normally determine your current locale by a call to the C function setlocale(3) which interrogates various environment variables, possibly including $LC_MESSAGES and $LANG. To temporarily override the determined value, use this option to supply a locale string directly to whatis. Note that it will not take effect until the search for pages actually begins. Output such as the help message will always be displayed in the initially determined locale. -C file, --config-file=file Use this user configuration file rather than the default of ~/.manpath. -?, --help Print a help message and exit. --usage Print a short usage message and exit. -V, --version Display version information. "
  },
  {
    "command": "git-grep",
    "description": " Look for specified patterns in the tracked files in the work tree, blobs registered in the index file, or blobs in given tree objects. Patterns are lists of one or more search expressions separated by newline characters. An empty string as search expression matches all lines. --cached Instead of searching tracked files in the working tree, search blobs registered in the index file. --no-index Search files in the current directory that is not managed by Git. --untracked In addition to searching in the tracked files in the working tree, search also in untracked files. --no-exclude-standard Also search in ignored files by not honoring the .gitignore mechanism. Only useful with --untracked. --exclude-standard Do not pay attention to ignored files specified via the .gitignore mechanism. Only useful when searching files in the current directory with --no-index. --recurse-submodules Recursively search in each submodule that is active and checked out in the repository. When used in combination with the <tree> option the prefix of all submodule output will be the name of the parent project\u2019s <tree> object. This option has no effect if --no-index is given. -a, --text Process binary files as if they were text. --textconv Honor textconv filter settings. --no-textconv Do not honor textconv filter settings. This is the default. -i, --ignore-case Ignore case differences between the patterns and the files. -I Don\u2019t match the pattern in binary files. --max-depth <depth> For each <pathspec> given on command line, descend at most <depth> levels of directories. A value of -1 means no limit. This option is ignored if <pathspec> contains active wildcards. In other words if \"a*\" matches a directory named \"a*\", \"*\" is matched literally so --max-depth is still effective. -r, --recursive Same as --max-depth=-1; this is the default. --no-recursive Same as --max-depth=0. -w, --word-regexp Match the pattern only at word boundary (either begin at the beginning of a line, or preceded by a non-word character; end at the end of a line or followed by a non-word character). -v, --invert-match Select non-matching lines. -h, -H By default, the command shows the filename for each match. -h option is used to suppress this output. -H is there for completeness and does not do anything except it overrides -h given earlier on the command line. --full-name When run from a subdirectory, the command usually outputs paths relative to the current directory. This option forces paths to be output relative to the project top directory. -E, --extended-regexp, -G, --basic-regexp Use POSIX extended/basic regexp for patterns. Default is to use basic regexp. -P, --perl-regexp Use Perl-compatible regular expressions for patterns. Support for these types of regular expressions is an optional compile-time dependency. If Git wasn\u2019t compiled with support for them providing this option will cause it to die. -F, --fixed-strings Use fixed strings for patterns (don\u2019t interpret pattern as a regex). -n, --line-number Prefix the line number to matching lines. --column Prefix the 1-indexed byte-offset of the first match from the start of the matching line. -l, --files-with-matches, --name-only, -L, --files-without-match Instead of showing every matched line, show only the names of files that contain (or do not contain) matches. For better compatibility with git diff, --name-only is a synonym for --files-with-matches. -O[<pager>], --open-files-in-pager[=<pager>] Open the matching files in the pager (not the output of grep). If the pager happens to be \"less\" or \"vi\", and the user specified only one pattern, the first file is positioned at the first match automatically. The pager argument is optional; if specified, it must be stuck to the option without a space. If pager is unspecified, the default pager will be used (see core.pager in git-config(1)). -z, --null Use \\0 as the delimiter for pathnames in the output, and print them verbatim. Without this option, pathnames with \"unusual\" characters are quoted as explained for the configuration variable core.quotePath (see git-config(1)). -o, --only-matching Print only the matched (non-empty) parts of a matching line, with each such part on a separate output line. -c, --count Instead of showing every matched line, show the number of lines that match. --color[=<when>] Show colored matches. The value must be always (the default), never, or auto. --no-color Turn off match highlighting, even when the configuration file gives the default to color output. Same as --color=never. --break Print an empty line between matches from different files. --heading Show the filename above the matches in that file instead of at the start of each shown line. -p, --show-function Show the preceding line that contains the function name of the match, unless the matching line is a function name itself. The name is determined in the same way as git diff works out patch hunk headers (see Defining a custom hunk-header in gitattributes(5)). -<num>, -C <num>, --context <num> Show <num> leading and trailing lines, and place a line containing -- between contiguous groups of matches. -A <num>, --after-context <num> Show <num> trailing lines, and place a line containing -- between contiguous groups of matches. -B <num>, --before-context <num> Show <num> leading lines, and place a line containing -- between contiguous groups of matches. -W, --function-context Show the surrounding text from the previous line containing a function name up to the one before the next function name, effectively showing the whole function in which the match was found. The function names are determined in the same way as git diff works out patch hunk headers (see Defining a custom hunk-header in gitattributes(5)). -m <num>, --max-count <num> Limit the amount of matches per file. When using the -v or --invert-match option, the search stops after the specified number of non-matches. A value of -1 will return unlimited results (the default). A value of 0 will exit immediately with a non-zero status. --threads <num> Number of grep worker threads to use. See grep.threads in CONFIGURATION for more information. -f <file> Read patterns from <file>, one per line. Passing the pattern via <file> allows for providing a search pattern containing a \\0. Not all pattern types support patterns containing \\0. Git will error out if a given pattern type can\u2019t support such a pattern. The --perl-regexp pattern type when compiled against the PCRE v2 backend has the widest support for these types of patterns. In versions of Git before 2.23.0 patterns containing \\0 would be silently considered fixed. This was never documented, there were also odd and undocumented interactions between e.g. non-ASCII patterns containing \\0 and --ignore-case. In future versions we may learn to support patterns containing \\0 for more search backends, until then we\u2019ll die when the pattern type in question doesn\u2019t support them. -e The next parameter is the pattern. This option has to be used for patterns starting with - and should be used in scripts passing user input to grep. Multiple patterns are combined by or. --and, --or, --not, ( ... ) Specify how multiple patterns are combined using Boolean expressions. --or is the default operator. --and has higher precedence than --or. -e has to be used for all patterns. --all-match When giving multiple pattern expressions combined with --or, this flag is specified to limit the match to files that have lines to match all of them. -q, --quiet Do not output matched lines; instead, exit with status 0 when there is a match and with non-zero status when there isn\u2019t. <tree>... Instead of searching tracked files in the working tree, search blobs in the given trees. -- Signals the end of options; the rest of the parameters are <pathspec> limiters. <pathspec>... If given, limit the search to paths matching at least one pattern. Both leading paths match and glob(7) patterns are supported. For more details about the <pathspec> syntax, see the pathspec entry in gitglossary(7). "
  },
  {
    "command": "touch",
    "description": " Update the access and modification times of each FILE to the current time. A FILE argument that does not exist is created empty, unless -c or -h is supplied. A FILE argument string of - is handled specially and causes touch to change the times of the file associated with standard output. Mandatory arguments to long options are mandatory for short options too. -a change only the access time -c, --no-create do not create any files -d, --date=STRING parse STRING and use it instead of current time -f (ignored) -h, --no-dereference affect each symbolic link instead of any referenced file (useful only on systems that can change the timestamps of a symlink) -m change only the modification time -r, --reference=FILE use this file's times instead of current time -t STAMP use [[CC]YY]MMDDhhmm[.ss] instead of current time --time=WORD change the specified time: WORD is access, atime, or use: equivalent to -a WORD is modify or mtime: equivalent to -m --help display this help and exit --version output version information and exit Note that the -d and -t options accept different time-date formats. "
  },
  {
    "command": "vdir",
    "description": " List information about the FILEs (the current directory by default). Sort entries alphabetically if none of -cftuvSUX nor --sort is specified. Mandatory arguments to long options are mandatory for short options too. -a, --all do not ignore entries starting with . -A, --almost-all do not list implied . and .. --author with -l, print the author of each file -b, --escape print C-style escapes for nongraphic characters --block-size=SIZE with -l, scale sizes by SIZE when printing them; e.g., '--block-size=M'; see SIZE format below -B, --ignore-backups do not list implied entries ending with ~ -c with -lt: sort by, and show, ctime (time of last change of file status information); with -l: show ctime and sort by name; otherwise: sort by ctime, newest first -C list entries by columns --color[=WHEN] color the output WHEN; more info below -d, --directory list directories themselves, not their contents -D, --dired generate output designed for Emacs' dired mode -f list all entries in directory order -F, --classify[=WHEN] append indicator (one of */=>@|) to entries WHEN --file-type likewise, except do not append '*' --format=WORD across -x, commas -m, horizontal -x, long -l, single-column -1, verbose -l, vertical -C --full-time like -l --time-style=full-iso -g like -l, but do not list owner --group-directories-first group directories before files; can be augmented with a --sort option, but any use of --sort=none (-U) disables grouping -G, --no-group in a long listing, don't print group names -h, --human-readable with -l and -s, print sizes like 1K 234M 2G etc. --si likewise, but use powers of 1000 not 1024 -H, --dereference-command-line follow symbolic links listed on the command line --dereference-command-line-symlink-to-dir follow each command line symbolic link that points to a directory --hide=PATTERN do not list implied entries matching shell PATTERN (overridden by -a or -A) --hyperlink[=WHEN] hyperlink file names WHEN --indicator-style=WORD append indicator with style WORD to entry names: none (default), slash (-p), file-type (--file-type), classify (-F) -i, --inode print the index number of each file -I, --ignore=PATTERN do not list implied entries matching shell PATTERN -k, --kibibytes default to 1024-byte blocks for file system usage; used only with -s and per directory totals -l use a long listing format -L, --dereference when showing file information for a symbolic link, show information for the file the link references rather than for the link itself -m fill width with a comma separated list of entries -n, --numeric-uid-gid like -l, but list numeric user and group IDs -N, --literal print entry names without quoting -o like -l, but do not list group information -p, --indicator-style=slash append / indicator to directories -q, --hide-control-chars print ? instead of nongraphic characters --show-control-chars show nongraphic characters as-is (the default, unless program is 'ls' and output is a terminal) -Q, --quote-name enclose entry names in double quotes --quoting-style=WORD use quoting style WORD for entry names: literal, locale, shell, shell-always, shell-escape, shell-escape-always, c, escape (overrides QUOTING_STYLE environment variable) -r, --reverse reverse order while sorting -R, --recursive list subdirectories recursively -s, --size print the allocated size of each file, in blocks -S sort by file size, largest first --sort=WORD sort by WORD instead of name: none (-U), size (-S), time (-t), version (-v), extension (-X), width --time=WORD select which timestamp used to display or sort; access time (-u): atime, access, use; metadata change time (-c): ctime, status; modified time (default): mtime, modification; birth time: birth, creation; with -l, WORD determines which time to show; with --sort=time, sort by WORD (newest first) --time-style=TIME_STYLE time/date format with -l; see TIME_STYLE below -t sort by time, newest first; see --time -T, --tabsize=COLS assume tab stops at each COLS instead of 8 -u with -lt: sort by, and show, access time; with -l: show access time and sort by name; otherwise: sort by access time, newest first -U do not sort; list entries in directory order -v natural sort of (version) numbers within text -w, --width=COLS set output width to COLS. 0 means no limit -x list entries by lines instead of by columns -X sort alphabetically by entry extension -Z, --context print any security context of each file --zero end each output line with NUL, not newline -1 list one file per line --help display this help and exit --version output version information and exit The SIZE argument is an integer and optional unit (example: 10K is 10*1024). Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or KB,MB,... (powers of 1000). Binary prefixes can be used, too: KiB=K, MiB=M, and so on. The TIME_STYLE argument can be full-iso, long-iso, iso, locale, or +FORMAT. FORMAT is interpreted like in date(1). If FORMAT is FORMAT1<newline>FORMAT2, then FORMAT1 applies to non-recent files and FORMAT2 to recent files. TIME_STYLE prefixed with 'posix-' takes effect only outside the POSIX locale. Also the TIME_STYLE environment variable sets the default style to use. The WHEN argument defaults to 'always' and can also be 'auto' or 'never'. Using color to distinguish file types is disabled both by default and with --color=never. With --color=auto, ls emits color codes only when standard output is connected to a terminal. The LS_COLORS environment variable can change the settings. Use the dircolors(1) command to set it. Exit status: 0 if OK, 1 if minor problems (e.g., cannot access subdirectory), 2 if serious trouble (e.g., cannot access command-line argument). "
  },
  {
    "command": "pmap",
    "description": " The pmap command reports the memory map of a process or processes. -x, --extended Show the extended format. -d, --device Show the device format. -q, --quiet Do not display some header or footer lines. -A, --range low,high Limit results to the given range to low and high address range. Notice that the low and high arguments are single string separated with comma. -X Show even more details than the -x option. WARNING: format changes according to /proc/PID/smaps -XX Show everything the kernel provides -p, --show-path Show full path to files in the mapping column -c, --read-rc Read the default configuration -C, --read-rc-from file Read the configuration from file -n, --create-rc Create new default configuration -N, --create-rc-to file Create new configuration to file -h, --help Display help text and exit. -V, --version Display version information and exit. "
  },
  {
    "command": "killall",
    "description": " killall sends a signal to all processes running any of the specified commands. If no signal name is specified, SIGTERM is sent. Signals can be specified either by name (e.g. -HUP or -SIGHUP) or by number (e.g. -1) or by option -s. If the command name is not regular expression (option -r) and contains a slash (/), processes executing that particular file will be selected for killing, independent of their name. killall returns a zero return code if at least one process has been killed for each listed command, or no commands were listed and at least one process matched the -u and -Z search criteria. killall returns non-zero otherwise. A killall process never kills itself (but may kill other killall processes). -e, --exact Require an exact match for very long names. If a command name is longer than 15 characters, the full name may be unavailable (i.e. it is swapped out). In this case, killall will kill everything that matches within the first 15 characters. With -e, such entries are skipped. killall prints a message for each skipped entry if -v is specified in addition to -e. -I, --ignore-case Do case insensitive process name match. -g, --process-group Kill the process group to which the process belongs. The kill signal is only sent once per group, even if multiple processes belonging to the same process group were found. -i, --interactive Interactively ask for confirmation before killing. -l, --list List all known signal names. -n, --ns Match against the PID namespace of the given PID. The default is to match against all namespaces. -o, --older-than Match only processes that are older (started before) the time specified. The time is specified as a float then a unit. The units are s,m,h,d,w,M,y for seconds, minutes, hours, days, weeks, months and years respectively. -q, --quiet Do not complain if no processes were killed. -r, --regexp Interpret process name pattern as a POSIX extended regular expression, per regex(3). -s, --signal, -SIGNAL Send this signal instead of SIGTERM. -u, --user Kill only processes the specified user owns. Command names are optional. -v, --verbose Report if the signal was successfully sent. -V, --version Display version information. -w, --wait Wait for all killed processes to die. killall checks once per second if any of the killed processes still exist and only returns if none are left. Note that killall may wait forever if the signal was ignored, had no effect, or if the process stays in zombie state. -y, --younger-than Match only processes that are younger (started after) the time specified. The time is specified as a float then a unit. The units are s,m,h,d,w,M,y for seconds, minutes, hours, days, weeks, Months and years respectively. -Z, --context Specify security context: kill only processes having security context that match with given extended regular expression pattern. Must precede other arguments on the command line. Command names are optional. "
  },
  {
    "command": "who",
    "description": " Print information about users who are currently logged in. -a, --all same as -b -d --login -p -r -t -T -u -b, --boot time of last system boot -d, --dead print dead processes -H, --heading print line of column headings -l, --login print system login processes --lookup attempt to canonicalize hostnames via DNS -m only hostname and user associated with stdin -p, --process print active processes spawned by init -q, --count all login names and number of users logged on -r, --runlevel print current runlevel -s, --short print only name, line, and time (default) -t, --time print last system clock change -T, -w, --mesg add user's message status as +, - or ? -u, --users list users logged in --message same as -T --writable same as -T --help display this help and exit --version output version information and exit If FILE is not specified, use /var/run/utmp. /var/log/wtmp as FILE is common. If ARG1 ARG2 given, -m presumed: 'am i' or 'mom likes' are usual. "
  },
  {
    "command": "mesg",
    "description": " The mesg utility is invoked by a user to control write access others have to the terminal device associated with standard error output. If write access is allowed, then programs such as talk(1) and write(1) may display messages on the terminal. Traditionally, write access is allowed by default. However, as users become more conscious of various security risks, there is a trend to remove write access by default, at least for the primary login shell. To make sure your ttys are set the way you want them to be set, mesg should be executed in your login scripts. The mesg utility silently exits with error status 2 if not executed on a terminal. In this case executing mesg is pointless. The command line option --verbose forces mesg to print a warning in this situation. This behaviour has been introduced in version 2.33. -v, --verbose Explain what is being done. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "gcov",
    "description": " gcov is a test coverage program. Use it in concert with GCC to analyze your programs to help create more efficient, faster running code and to discover untested parts of your program. You can use gcov as a profiling tool to help discover where your optimization efforts will best affect your code. You can also use gcov along with the other profiling tool, gprof, to assess which parts of your code use the greatest amount of computing time. Profiling tools help you analyze your code's performance. Using a profiler such as gcov or gprof, you can find out some basic performance statistics, such as: * how often each line of code executes * what lines of code are actually executed * how much computing time each section of code uses Once you know these things about how your code works when compiled, you can look at each module to see which modules should be optimized. gcov helps you determine where to work on optimization. Software developers also use coverage testing in concert with testsuites, to make sure software is actually good enough for a release. Testsuites can verify that a program works as expected; a coverage program tests to see how much of the program is exercised by the testsuite. Developers can then determine what kinds of test cases need to be added to the testsuites to create both better testing and a better final product. You should compile your code without optimization if you plan to use gcov because the optimization, by combining some lines of code into one function, may not give you as much information as you need to look for `hot spots' where the code is using a great deal of computer time. Likewise, because gcov accumulates statistics by line (at the lowest resolution), it works best with a programming style that places only one statement on each line. If you use complicated macros that expand to loops or to other control structures, the statistics are less helpful---they only report on the line where the macro call appears. If your complex macros behave like functions, you can replace them with inline functions to solve this problem. gcov creates a logfile called sourcefile.gcov which indicates how many times each line of a source file sourcefile.c has executed. You can use these logfiles along with gprof to aid in fine-tuning the performance of your programs. gprof gives timing information you can use along with the information you get from gcov. gcov works only on code compiled with GCC. It is not compatible with any other profiling or test coverage mechanism. -a --all-blocks Write individual execution counts for every basic block. Normally gcov outputs execution counts only for the main blocks of a line. With this option you can determine if blocks within a single line are not being executed. -b --branch-probabilities Write branch frequencies to the output file, and write branch summary info to the standard output. This option allows you to see how often each branch in your program was taken. Unconditional branches will not be shown, unless the -u option is given. -c --branch-counts Write branch frequencies as the number of branches taken, rather than the percentage of branches taken. -d --display-progress Display the progress on the standard output. -f --function-summaries Output summaries for each function in addition to the file level summary. -h --help Display help about using gcov (on the standard output), and exit without doing any further processing. -i --json-format Output gcov file in an easy-to-parse JSON intermediate format which does not require source code for generation. The JSON file is compressed with gzip compression algorithm and the files have .gcov.json.gz extension. Structure of the JSON is following: { \"current_working_directory\": <current_working_directory>, \"data_file\": <data_file>, \"format_version\": <format_version>, \"gcc_version\": <gcc_version> \"files\": [<file>] } Fields of the root element have following semantics: * current_working_directory: working directory where a compilation unit was compiled * data_file: name of the data file (GCDA) * format_version: semantic version of the format * gcc_version: version of the GCC compiler Each file has the following form: { \"file\": <file_name>, \"functions\": [<function>], \"lines\": [<line>] } Fields of the file element have following semantics: * file_name: name of the source file Each function has the following form: { \"blocks\": <blocks>, \"blocks_executed\": <blocks_executed>, \"demangled_name\": \"<demangled_name>, \"end_column\": <end_column>, \"end_line\": <end_line>, \"execution_count\": <execution_count>, \"name\": <name>, \"start_column\": <start_column> \"start_line\": <start_line> } Fields of the function element have following semantics: * blocks: number of blocks that are in the function * blocks_executed: number of executed blocks of the function * demangled_name: demangled name of the function * end_column: column in the source file where the function ends * end_line: line in the source file where the function ends * execution_count: number of executions of the function * name: name of the function * start_column: column in the source file where the function begins * start_line: line in the source file where the function begins Note that line numbers and column numbers number from 1. In the current implementation, start_line and start_column do not include any template parameters and the leading return type but that this is likely to be fixed in the future. Each line has the following form: { \"branches\": [<branch>], \"count\": <count>, \"line_number\": <line_number>, \"unexecuted_block\": <unexecuted_block> \"function_name\": <function_name>, } Branches are present only with -b option. Fields of the line element have following semantics: * count: number of executions of the line * line_number: line number * unexecuted_block: flag whether the line contains an unexecuted block (not all statements on the line are executed) * function_name: a name of a function this line belongs to (for a line with an inlined statements can be not set) Each branch has the following form: { \"count\": <count>, \"fallthrough\": <fallthrough>, \"throw\": <throw> } Fields of the branch element have following semantics: * count: number of executions of the branch * fallthrough: true when the branch is a fall through branch * throw: true when the branch is an exceptional branch -j --human-readable Write counts in human readable format (like 24.6k). -k --use-colors Use colors for lines of code that have zero coverage. We use red color for non-exceptional lines and cyan for exceptional. Same colors are used for basic blocks with -a option. -l --long-file-names Create long file names for included source files. For example, if the header file x.h contains code, and was included in the file a.c, then running gcov on the file a.c will produce an output file called a.c"
  },
  {
    "command": "ltrace",
    "description": " ltrace is a program that simply runs the specified command until it exits. It intercepts and records the dynamic library calls which are called by the executed process and the signals which are received by that process. It can also intercept and print the system calls executed by the program. Its use is very similar to strace(1). ltrace shows parameters of invoked functions and system calls. To determine what arguments each function has, it needs external declaration of function prototypes. Those are stored in files called prototype libraries--see ltrace.conf(5) for details on the syntax of these files. See the section PROTOTYPE LIBRARY DISCOVERY to learn how ltrace finds prototype libraries. -a, --align column Align return values in a specific column (default column is 5/8 of screen width). -A maxelts Maximum number of array elements to print before suppressing the rest with an ellipsis (\"...\"). This also limits number of recursive structure expansions. -b, --no-signals Disable printing of signals received by the traced process. -c Count time and calls for each library call and report a summary on program exit. -C, --demangle Decode (demangle) low-level symbol names into user-level names. Besides removing any initial underscore prefix used by the system, this makes C++ function names readable. -D, --debug mask Show debugging output of ltrace itself. mask is a number describing which debug messages should be displayed. Use the option -Dh to see what can be used, but note that currently the only reliable debugmask is 77, which shows all debug messages. -e filter A qualifying expression which modifies which library calls (i.e. calls done through PLT slots, which are typically calls from the main binary to a library, or inter-library calls) to trace. Usage examples and the syntax description appear below in sections FILTER SPECIFICATIONS and FILTER EXPRESSIONS. If more than one -e option appears on the command line, the library calls that match any of them are traced. If no -e is given, @MAIN is assumed as a default. -f Trace child processes as they are created by currently traced processes as a result of the fork(2) or clone(2) system calls. The new process is attached immediately. -F, --config pathlist Contains a colon-separated list of paths. If a path refers to a directory, that directory is considered when prototype libraries are searched (see the section PROTOTYPE LIBRARY DISCOVERY). If it refers to a file, that file is imported implicitly to all loaded prototype libraries. -h, --help Show a summary of the options to ltrace and exit. -i Print the instruction pointer at the time of the library call. -l, --library library_pattern Display only calls to functions implemented by libraries that match library_pattern. This is as if you specified one -e for every symbol implemented in a library specified by library_pattern. Multiple library patters can be specified with several instances of this option. Usage examples and the syntax description of library_pattern appear below in sections FILTER SPECIFICATIONS and FILTER EXPRESSIONS. Note that while this option selects calls that might be directed to the selected libraries, there's no actual guarantee that the call won't be directed elsewhere due to e.g. LD_PRELOAD or simply dependency ordering. If you want to make sure that symbols in given library are actually called, use -x @library_pattern instead. -L When no -e option is given, don't assume the default action of @MAIN. In practice this means that library calls will not be traced. -n, --indent nr Indent trace output by nr spaces for each level of call nesting. Using this option makes the program flow visualization easy to follow. This indents uselessly also functions that never return, such as service functions for throwing exceptions in the C++ runtime. -o, --output filename Write the trace output to the file filename rather than to stderr. -p pid Attach to the process with the process ID pid and begin tracing. This option can be used together with passing a command to execute. It is possible to attach to several processes by passing more than one option -p. -r Print a relative timestamp with each line of the trace. This records the time difference between the beginning of successive lines. -s strsize Specify the maximum string size to print (the default is 32). -S Display system calls as well as library calls -t Prefix each line of the trace with the time of day. -tt If given twice, the time printed will include the microseconds. -ttt If given thrice, the time printed will include the microseconds and the leading portion will be printed as the number of seconds since the epoch. -T Show the time spent inside each call. This records the time difference between the beginning and the end of each call. -u username Run command with the userid, groupid and supplementary groups of username. This option is only useful when running as root and enables the correct execution of setuid and/or setgid binaries. -w, --where nr Show backtrace of nr stack frames for each traced function. This option enabled only if elfutils or libunwind support was enabled at compile time. -x filter A qualifying expression which modifies which symbol table entry points to trace (those are typically calls inside a library or main binary, though PLT calls, traced by -e, land on entry points as well). Usage examples and the syntax description appear below in sections FILTER SPECIFICATIONS and FILTER EXPRESSIONS. If more than one -x option appears on the command line, the symbols that match any of them are traced. No entry points are traced if no -x is given. -V, --version Show the version number of ltrace and exit. "
  },
  {
    "command": "awk",
    "description": " The awk utility shall execute programs written in the awk programming language, which is specialized for textual data manipulation. An awk program is a sequence of patterns and corresponding actions. When input is read that matches a pattern, the action associated with that pattern is carried out. Input shall be interpreted as a sequence of records. By default, a record is a line, less its terminating <newline>, but this can be changed by using the RS built-in variable. Each record of input shall be matched in turn against each pattern in the program. For each pattern matched, the associated action shall be executed. The awk utility shall interpret each input record as a sequence of fields where, by default, a field is a string of non-<blank> non-<newline> characters. This default <blank> and <newline> field delimiter can be changed by using the FS built-in variable or the -F sepstring option. The awk utility shall denote the first field in a record $1, the second $2, and so on. The symbol $0 shall refer to the entire record; setting any other field causes the re-evaluation of $0. Assigning to $0 shall reset the values of all other fields and the NF built-in variable. The awk utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -F sepstring Define the input field separator. This option shall be equivalent to: -v FS=sepstring except that if -F sepstring and -v FS=sepstring are both used, it is unspecified whether the FS assignment resulting from -F sepstring is processed in command line order or is processed after the last -v FS=sepstring. See the description of the FS built-in variable, and how it is used, in the EXTENDED DESCRIPTION section. -f progfile Specify the pathname of the file progfile containing an awk program. A pathname of '-' shall denote the standard input. If multiple instances of this option are specified, the concatenation of the files specified as progfile in the order specified shall be the awk program. The awk program can alternatively be specified in the command line as a single argument. -v assignment The application shall ensure that the assignment argument is in the same form as an assignment operand. The specified variable assignment shall occur prior to executing the awk program, including the actions associated with BEGIN patterns (if any). Multiple occurrences of this option can be specified. "
  },
  {
    "command": "git-cherry-pick",
    "description": " Given one or more existing commits, apply the change each one introduces, recording a new commit for each. This requires your working tree to be clean (no modifications from the HEAD commit). When it is not obvious how to apply a change, the following happens: 1. The current branch and HEAD pointer stay at the last commit successfully made. 2. The CHERRY_PICK_HEAD ref is set to point at the commit that introduced the change that is difficult to apply. 3. Paths in which the change applied cleanly are updated both in the index file and in your working tree. 4. For conflicting paths, the index file records up to three versions, as described in the \"TRUE MERGE\" section of git-merge(1). The working tree files will include a description of the conflict bracketed by the usual conflict markers <<<<<<< and >>>>>>>. 5. No other modifications are made. See git-merge(1) for some hints on resolving such conflicts. <commit>... Commits to cherry-pick. For a more complete list of ways to spell commits, see gitrevisions(7). Sets of commits can be passed but no traversal is done by default, as if the --no-walk option was specified, see git-rev-list(1). Note that specifying a range will feed all <commit>... arguments to a single revision walk (see a later example that uses maint master..next). -e, --edit With this option, git cherry-pick will let you edit the commit message prior to committing. --cleanup=<mode> This option determines how the commit message will be cleaned up before being passed on to the commit machinery. See git-commit(1) for more details. In particular, if the <mode> is given a value of scissors, scissors will be appended to MERGE_MSG before being passed on in the case of a conflict. -x When recording the commit, append a line that says \"(cherry picked from commit ...)\" to the original commit message in order to indicate which commit this change was cherry-picked from. This is done only for cherry picks without conflicts. Do not use this option if you are cherry-picking from your private branch because the information is useless to the recipient. If on the other hand you are cherry-picking between two publicly visible branches (e.g. backporting a fix to a maintenance branch for an older release from a development branch), adding this information can be useful. -r It used to be that the command defaulted to do -x described above, and -r was to disable it. Now the default is not to do -x so this option is a no-op. -m <parent-number>, --mainline <parent-number> Usually you cannot cherry-pick a merge because you do not know which side of the merge should be considered the mainline. This option specifies the parent number (starting from 1) of the mainline and allows cherry-pick to replay the change relative to the specified parent. -n, --no-commit Usually the command automatically creates a sequence of commits. This flag applies the changes necessary to cherry-pick each named commit to your working tree and the index, without making any commit. In addition, when this option is used, your index does not have to match the HEAD commit. The cherry-pick is done against the beginning state of your index. This is useful when cherry-picking more than one commits' effect to your index in a row. -s, --signoff Add a Signed-off-by trailer at the end of the commit message. See the signoff option in git-commit(1) for more information. -S[<keyid>], --gpg-sign[=<keyid>], --no-gpg-sign GPG-sign commits. The keyid argument is optional and defaults to the committer identity; if specified, it must be stuck to the option without a space. --no-gpg-sign is useful to countermand both commit.gpgSign configuration variable, and earlier --gpg-sign. --ff If the current HEAD is the same as the parent of the cherry-pick\u2019ed commit, then a fast forward to this commit will be performed. --allow-empty By default, cherry-picking an empty commit will fail, indicating that an explicit invocation of git commit --allow-empty is required. This option overrides that behavior, allowing empty commits to be preserved automatically in a cherry-pick. Note that when \"--ff\" is in effect, empty commits that meet the \"fast-forward\" requirement will be kept even without this option. Note also, that use of this option only keeps commits that were initially empty (i.e. the commit recorded the same tree as its parent). Commits which are made empty due to a previous commit are dropped. To force the inclusion of those commits use --keep-redundant-commits. --allow-empty-message By default, cherry-picking a commit with an empty message will fail. This option overrides that behavior, allowing commits with empty messages to be cherry picked. --keep-redundant-commits If a commit being cherry picked duplicates a commit already in the current history, it will become empty. By default these redundant commits cause cherry-pick to stop so the user can examine the commit. This option overrides that behavior and creates an empty commit object. Implies --allow-empty. --strategy=<strategy> Use the given merge strategy. Should only be used once. See the MERGE STRATEGIES section in git-merge(1) for details. -X<option>, --strategy-option=<option> Pass the merge strategy-specific option through to the merge strategy. See git-merge(1) for details. --rerere-autoupdate, --no-rerere-autoupdate After the rerere mechanism reuses a recorded resolution on the current conflict to update the files in the working tree, allow it to also update the index with the result of resolution. --no-rerere-autoupdate is a good way to double-check what rerere did and catch potential mismerges, before committing the result to the index with a separate git add. "
  },
  {
    "command": "login",
    "description": " The login program is used to establish a new session with the system. It is normally invoked automatically by responding to the login: prompt on the user's terminal. login may be special to the shell and may not be invoked as a sub-process. When called from a shell, login should be executed as exec login which will cause the user to exit from the current shell (and thus will prevent the new logged in user to return to the session of the caller). Attempting to execute login from any shell but the login shell will produce an error message. The user is then prompted for a password, where appropriate. Echoing is disabled to prevent revealing the password. Only a small number of password failures are permitted before login exits and the communications link is severed. If password aging has been enabled for your account, you may be prompted for a new password before proceeding. You will be forced to provide your old password and the new password before continuing. Please refer to passwd(1) for more information. Your user and group ID will be set according to their values in the /etc/passwd file. The value for $HOME, $SHELL, $PATH, $LOGNAME, and $MAIL are set according to the appropriate fields in the password entry. Ulimit, umask and nice values may also be set according to entries in the GECOS field. On some installations, the environmental variable $TERM will be initialized to the terminal type on your tty line, as specified in /etc/ttytype. An initialization script for your command interpreter may also be executed. Please see the appropriate manual section for more information on this function. A subsystem login is indicated by the presence of a \"*\" as the first character of the login shell. The given home directory will be used as the root of a new file system which the user is actually logged into. The login program is NOT responsible for removing users from the utmp file. It is the responsibility of getty(8) and init(8) to clean up apparent ownership of a terminal session. If you use login from the shell prompt without exec, the user you use will continue to appear to be logged in even after you log out of the \"subsession\". -f Do not perform authentication, user is preauthenticated. Note: In that case, username is mandatory. -h Name of the remote host for this login. -p Preserve environment. -r Perform autologin protocol for rlogin. The -r, -h and -f options are only used when login is invoked by root. "
  },
  {
    "command": "git-branch",
    "description": " If --list is given, or if there are no non-option arguments, existing branches are listed; the current branch will be highlighted in green and marked with an asterisk. Any branches checked out in linked worktrees will be highlighted in cyan and marked with a plus sign. Option -r causes the remote-tracking branches to be listed, and option -a shows both local and remote branches. If a <pattern> is given, it is used as a shell wildcard to restrict the output to matching branches. If multiple patterns are given, a branch is shown if it matches any of the patterns. Note that when providing a <pattern>, you must use --list; otherwise the command may be interpreted as branch creation. With --contains, shows only the branches that contain the named commit (in other words, the branches whose tip commits are descendants of the named commit), --no-contains inverts it. With --merged, only branches merged into the named commit (i.e. the branches whose tip commits are reachable from the named commit) will be listed. With --no-merged only branches not merged into the named commit will be listed. If the <commit> argument is missing it defaults to HEAD (i.e. the tip of the current branch). The command\u2019s second form creates a new branch head named <branchname> which points to the current HEAD, or <start-point> if given. As a special case, for <start-point>, you may use \"A...B\" as a shortcut for the merge base of A and B if there is exactly one merge base. You can leave out at most one of A and B, in which case it defaults to HEAD. Note that this will create the new branch, but it will not switch the working tree to it; use \"git switch <newbranch>\" to switch to the new branch. When a local branch is started off a remote-tracking branch, Git sets up the branch (specifically the branch.<name>.remote and branch.<name>.merge configuration entries) so that git pull will appropriately merge from the remote-tracking branch. This behavior may be changed via the global branch.autoSetupMerge configuration flag. That setting can be overridden by using the --track and --no-track options, and changed later using git branch --set-upstream-to. With a -m or -M option, <oldbranch> will be renamed to <newbranch>. If <oldbranch> had a corresponding reflog, it is renamed to match <newbranch>, and a reflog entry is created to remember the branch renaming. If <newbranch> exists, -M must be used to force the rename to happen. The -c and -C options have the exact same semantics as -m and -M, except instead of the branch being renamed, it will be copied to a new name, along with its config and reflog. With a -d or -D option, <branchname> will be deleted. You may specify more than one branch for deletion. If the branch currently has a reflog then the reflog will also be deleted. Use -r together with -d to delete remote-tracking branches. Note, that it only makes sense to delete remote-tracking branches if they no longer exist in the remote repository or if git fetch was configured not to fetch them again. See also the prune subcommand of git-remote(1) for a way to clean up all obsolete remote-tracking branches. -d, --delete Delete a branch. The branch must be fully merged in its upstream branch, or in HEAD if no upstream was set with --track or --set-upstream-to. -D Shortcut for --delete --force. --create-reflog Create the branch\u2019s reflog. This activates recording of all changes made to the branch ref, enabling use of date based sha1 expressions such as \"<branchname>@{yesterday}\". Note that in non-bare repositories, reflogs are usually enabled by default by the core.logAllRefUpdates config option. The negated form --no-create-reflog only overrides an earlier --create-reflog, but currently does not negate the setting of core.logAllRefUpdates. -f, --force Reset <branchname> to <start-point>, even if <branchname> exists already. Without -f, git branch refuses to change an existing branch. In combination with -d (or --delete), allow deleting the branch irrespective of its merged status, or whether it even points to a valid commit. In combination with -m (or --move), allow renaming the branch even if the new branch name already exists, the same applies for -c (or --copy). Note that git branch -f <branchname> [<start-point>], even with -f, refuses to change an existing branch <branchname> that is checked out in another worktree linked to the same repository. -m, --move Move/rename a branch, together with its config and reflog. -M Shortcut for --move --force. -c, --copy Copy a branch, together with its config and reflog. -C Shortcut for --copy --force. --color[=<when>] Color branches to highlight current, local, and remote-tracking branches. The value must be always (the default), never, or auto. --no-color Turn off branch colors, even when the configuration file gives the default to color output. Same as --color=never. -i, --ignore-case Sorting and filtering branches are case insensitive. --omit-empty Do not print a newline after formatted refs where the format expands to the empty string. --column[=<options>], --no-column Display branch listing in columns. See configuration variable column.branch for option syntax. --column and --no-column without options are equivalent to always and never respectively. This option is only applicable in non-verbose mode. -r, --remotes List or delete (if used with -d) the remote-tracking branches. Combine with --list to match the optional pattern(s). -a, --all List both remote-tracking branches and local branches. Combine with --list to match optional pattern(s). -l, --list List branches. With optional <pattern>..., e.g. git branch --list 'maint-*', list only the branches that match the pattern(s). --show-current Print the name of the current branch. In detached HEAD state, nothing is printed. -v, -vv, --verbose When in list mode, show sha1 and commit subject line for each head, along with relationship to upstream branch (if any). If given twice, print the path of the linked worktree (if any) and the name of the upstream branch, as well (see also git remote show <remote>). Note that the current worktree\u2019s HEAD will not have its path printed (it will always be your current directory). -q, --quiet Be more quiet when creating or deleting a branch, suppressing non-error messages. --abbrev=<n> In the verbose listing that show the commit object name, show the shortest prefix that is at least <n> hexdigits long that uniquely refers the object. The default value is 7 and can be overridden by the core.abbrev config option. --no-abbrev Display the full sha1s in the output listing rather than abbreviating them. -t, --track[=(direct|inherit)] When creating a new branch, set up branch.<name>.remote and branch.<name>.merge configuration entries to set \"upstream\" tracking configuration for the new branch. This configuration will tell git to show the relationship between the two branches in git status and git branch -v. Furthermore, it directs git pull without arguments to pull from the upstream when the new branch is checked out. The exact upstream branch is chosen depending on the optional argument: -t, --track, or --track=direct means to use the start-point branch itself as the upstream; --track=inherit means to copy the upstream configuration of the start-point branch. The branch.autoSetupMerge configuration variable specifies how git switch, git checkout and git branch should behave when neither --track nor --no-track are specified: The default option, true, behaves as though --track=direct were given whenever the start-point is a remote-tracking branch. false behaves as if --no-track were given. always behaves as though --track=direct were given. inherit behaves as though --track=inherit were given. simple behaves as though --track=direct were given only when the start-point is a remote-tracking branch and the new branch has the same name as the remote branch. See git-pull(1) and git-config(1) for additional discussion on how the branch.<name>.remote and branch.<name>.merge options are used. --no-track Do not set up \"upstream\" configuration, even if the branch.autoSetupMerge configuration variable is set. --recurse-submodules THIS OPTION IS EXPERIMENTAL! Causes the current command to recurse into submodules if submodule.propagateBranches is enabled. See submodule.propagateBranches in git-config(1). Currently, only branch creation is supported. When used in branch creation, a new branch <branchname> will be created in the superproject and all of the submodules in the superproject\u2019s <start-point>. In submodules, the branch will point to the submodule commit in the superproject\u2019s <start-point> but the branch\u2019s tracking information will be set up based on the submodule\u2019s branches and remotes e.g. git branch --recurse-submodules topic origin/main will create the submodule branch \"topic\" that points to the submodule commit in the superproject\u2019s \"origin/main\", but tracks the submodule\u2019s \"origin/main\". --set-upstream As this option had confusing syntax, it is no longer supported. Please use --track or --set-upstream-to instead. -u <upstream>, --set-upstream-to=<upstream> Set up <branchname>'s tracking information so <upstream> is considered <branchname>'s upstream branch. If no <branchname> is specified, then it defaults to the current branch. --unset-upstream Remove the upstream information for <branchname>. If no branch is specified it defaults to the current branch. --edit-description Open an editor and edit the text to explain what the branch is for, to be used by various other commands (e.g. format-patch, request-pull, and merge (if enabled)). Multi-line explanations may be used. --contains [<commit>] Only list branches which contain the specified commit (HEAD if not specified). Implies --list. --no-contains [<commit>] Only list branches which don\u2019t contain the specified commit (HEAD if not specified). Implies --list. --merged [<commit>] Only list branches whose tips are reachable from the specified commit (HEAD if not specified). Implies --list. --no-merged [<commit>] Only list branches whose tips are not reachable from the specified commit (HEAD if not specified). Implies --list. <branchname> The name of the branch to create or delete. The new branch name must pass all checks defined by git-check-ref-format(1). Some of these checks may restrict the characters allowed in a branch name. <start-point> The new branch head will point to this commit. It may be given as a branch name, a commit-id, or a tag. If this option is omitted, the current HEAD will be used instead. <oldbranch> The name of an existing branch to rename. <newbranch> The new name for an existing branch. The same restrictions as for <branchname> apply. --sort=<key> Sort based on the key given. Prefix - to sort in descending order of the value. You may use the --sort=<key> option multiple times, in which case the last key becomes the primary key. The keys supported are the same as those in git for-each-ref. Sort order defaults to the value configured for the branch.sort variable if exists, or to sorting based on the full refname (including refs/... prefix). This lists detached HEAD (if present) first, then local branches and finally remote-tracking branches. See git-config(1). --points-at <object> Only list branches of the given object. --format <format> A string that interpolates %(fieldname) from a branch ref being shown and the object it points at. The format is the same as that of git-for-each-ref(1). "
  },
  {
    "command": "base64",
    "description": " Base64 encode or decode FILE, or standard input, to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -d, --decode decode data -i, --ignore-garbage when decoding, ignore non-alphabet characters -w, --wrap=COLS wrap encoded lines after COLS character (default 76). Use 0 to disable line wrapping --help display this help and exit --version output version information and exit The data are encoded as described for the base64 alphabet in RFC 4648. When decoding, the input may contain newlines in addition to the bytes of the formal base64 alphabet. Use --ignore-garbage to attempt to recover from any other non-alphabet bytes in the encoded stream. "
  },
  {
    "command": "ipcs",
    "description": " ipcs shows information on System V inter-process communication facilities. By default it shows information about all three resources: shared memory segments, message queues, and semaphore arrays. -i, --id id Show full details on just the one resource element identified by id. This option needs to be combined with one of the three resource options: -m, -q or -s. -h, --help Display help text and exit. -V, --version Print version and exit. Resource options -m, --shmems Write information about active shared memory segments. -q, --queues Write information about active message queues. -s, --semaphores Write information about active semaphore sets. -a, --all Write information about all three resources (default). Output formats Of these options only one takes effect: the last one specified. -c, --creator Show creator and owner. -l, --limits Show resource limits. -p, --pid Show PIDs of creator and last operator. -t, --time Write time information. The time of the last control operation that changed the access permissions for all facilities, the time of the last msgsnd(2) and msgrcv(2) operations on message queues, the time of the last shmat(2) and shmdt(2) operations on shared memory, and the time of the last semop(2) operation on semaphores. -u, --summary Show status summary. Representation These affect only the -l (--limits) option. -b, --bytes Print the sizes in bytes rather than in a human-readable format. By default, the unit, sizes are expressed in, is byte, and unit prefixes are in power of 2^10 (1024). Abbreviations of symbols are exhibited truncated in order to reach a better readability, by exhibiting alone the first letter of them; examples: \"1 KiB\" and \"1 MiB\" are respectively exhibited as \"1 K\" and \"1 M\", then omitting on purpose the mention \"iB\", which is part of these abbreviations. --human Print sizes in human-readable format. "
  },
  {
    "command": "type",
    "description": " The type utility shall indicate how each argument would be interpreted if used as a command name. None. "
  },
  {
    "command": "ul",
    "description": " ul reads the named files (or standard input if none are given) and translates occurrences of underscores to the sequence which indicates underlining for the terminal in use, as specified by the environment variable TERM. The terminfo database is read to determine the appropriate sequences for underlining. If the terminal is incapable of underlining but is capable of a standout mode, then that is used instead. If the terminal can overstrike, or handles underlining automatically, ul degenerates to cat(1). If the terminal cannot underline, underlining is ignored. -i, --indicated Underlining is indicated by a separate line containing appropriate dashes `-'; this is useful when you want to look at the underlining which is present in an nroff output stream on a crt-terminal. -t, -T, --terminal terminal Override the environment variable TERM with the specified terminal type. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "ldd",
    "description": " ldd prints the shared objects (shared libraries) required by each program or shared object specified on the command line. An example of its use and output is the following: $ ldd /bin/ls linux-vdso.so.1 (0x00007ffcc3563000) libselinux.so.1 => /lib64/libselinux.so.1 (0x00007f87e5459000) libcap.so.2 => /lib64/libcap.so.2 (0x00007f87e5254000) libc.so.6 => /lib64/libc.so.6 (0x00007f87e4e92000) libpcre.so.1 => /lib64/libpcre.so.1 (0x00007f87e4c22000) libdl.so.2 => /lib64/libdl.so.2 (0x00007f87e4a1e000) /lib64/ld-linux-x86-64.so.2 (0x00005574bf12e000) libattr.so.1 => /lib64/libattr.so.1 (0x00007f87e4817000) libpthread.so.0 => /lib64/libpthread.so.0 (0x00007f87e45fa000) In the usual case, ldd invokes the standard dynamic linker (see ld.so(8)) with the LD_TRACE_LOADED_OBJECTS environment variable set to 1. This causes the dynamic linker to inspect the program's dynamic dependencies, and find (according to the rules described in ld.so(8)) and load the objects that satisfy those dependencies. For each dependency, ldd displays the location of the matching object and the (hexadecimal) address at which it is loaded. (The linux-vdso and ld-linux shared dependencies are special; see vdso(7) and ld.so(8).) Security Be aware that in some circumstances (e.g., where the program specifies an ELF interpreter other than ld-linux.so), some versions of ldd may attempt to obtain the dependency information by attempting to directly execute the program, which may lead to the execution of whatever code is defined in the program's ELF interpreter, and perhaps to execution of the program itself. (Before glibc 2.27, the upstream ldd implementation did this for example, although most distributions provided a modified version that did not.) Thus, you should never employ ldd on an untrusted executable, since this may result in the execution of arbitrary code. A safer alternative when dealing with untrusted executables is: $ objdump -p /path/to/program | grep NEEDED Note, however, that this alternative shows only the direct dependencies of the executable, while ldd shows the entire dependency tree of the executable. --version Print the version number of ldd. -v, --verbose Print all information, including, for example, symbol versioning information. -u, --unused Print unused direct dependencies. (Since glibc 2.3.4.) -d, --data-relocs Perform relocations and report any missing objects (ELF only). -r, --function-relocs Perform relocations for both data objects and functions, and report any missing objects or functions (ELF only). --help Usage information. "
  },
  {
    "command": "git-gc",
    "description": " Runs a number of housekeeping tasks within the current repository, such as compressing file revisions (to reduce disk space and increase performance), removing unreachable objects which may have been created from prior invocations of git add, packing refs, pruning reflog, rerere metadata or stale working trees. May also update ancillary indexes such as the commit-graph. When common porcelain operations that create objects are run, they will check whether the repository has grown substantially since the last maintenance, and if so run git gc automatically. See gc.auto below for how to disable this behavior. Running git gc manually should only be needed when adding objects to a repository without regularly running such porcelain commands, to do a one-off repository optimization, or e.g. to clean up a suboptimal mass-import. See the \"PACKFILE OPTIMIZATION\" section in git-fast-import(1) for more details on the import case. --aggressive Usually git gc runs very quickly while providing good disk space utilization and performance. This option will cause git gc to more aggressively optimize the repository at the expense of taking much more time. The effects of this optimization are mostly persistent. See the \"AGGRESSIVE\" section below for details. --auto With this option, git gc checks whether any housekeeping is required; if not, it exits without performing any work. See the gc.auto option in the \"CONFIGURATION\" section below for how this heuristic works. Once housekeeping is triggered by exceeding the limits of configuration options such as gc.auto and gc.autoPackLimit, all other housekeeping tasks (e.g. rerere, working trees, reflog...) will be performed as well. --[no-]cruft When expiring unreachable objects, pack them separately into a cruft pack instead of storing them as loose objects. --cruft is on by default. --prune=<date> Prune loose objects older than date (default is 2 weeks ago, overridable by the config variable gc.pruneExpire). --prune=now prunes loose objects regardless of their age and increases the risk of corruption if another process is writing to the repository concurrently; see \"NOTES\" below. --prune is on by default. --no-prune Do not prune any loose objects. --quiet Suppress all progress reports. --force Force git gc to run even if there may be another git gc instance running on this repository. --keep-largest-pack All packs except the largest non-cruft pack, any packs marked with a .keep file, and any cruft pack(s) are consolidated into a single pack. When this option is used, gc.bigPackThreshold is ignored. "
  },
  {
    "command": "git-diff",
    "description": " Show changes between the working tree and the index or a tree, changes between the index and a tree, changes between two trees, changes resulting from a merge, changes between two blob objects, or changes between two files on disk. git diff [<options>] [--] [<path>...] This form is to view the changes you made relative to the index (staging area for the next commit). In other words, the differences are what you could tell Git to further add to the index but you still haven\u2019t. You can stage these changes by using git-add(1). git diff [<options>] --no-index [--] <path> <path> This form is to compare the given two paths on the filesystem. You can omit the --no-index option when running the command in a working tree controlled by Git and at least one of the paths points outside the working tree, or when running the command outside a working tree controlled by Git. This form implies --exit-code. git diff [<options>] --cached [--merge-base] [<commit>] [--] [<path>...] This form is to view the changes you staged for the next commit relative to the named <commit>. Typically you would want comparison with the latest commit, so if you do not give <commit>, it defaults to HEAD. If HEAD does not exist (e.g. unborn branches) and <commit> is not given, it shows all staged changes. --staged is a synonym of --cached. If --merge-base is given, instead of using <commit>, use the merge base of <commit> and HEAD. git diff --cached --merge-base A is equivalent to git diff --cached $(git merge-base A HEAD). git diff [<options>] [--merge-base] <commit> [--] [<path>...] This form is to view the changes you have in your working tree relative to the named <commit>. You can use HEAD to compare it with the latest commit, or a branch name to compare with the tip of a different branch. If --merge-base is given, instead of using <commit>, use the merge base of <commit> and HEAD. git diff --merge-base A is equivalent to git diff $(git merge-base A HEAD). git diff [<options>] [--merge-base] <commit> <commit> [--] [<path>...] This is to view the changes between two arbitrary <commit>. If --merge-base is given, use the merge base of the two commits for the \"before\" side. git diff --merge-base A B is equivalent to git diff $(git merge-base A B) B. git diff [<options>] <commit> <commit>... <commit> [--] [<path>...] This form is to view the results of a merge commit. The first listed <commit> must be the merge itself; the remaining two or more commits should be its parents. Convenient ways to produce the desired set of revisions are to use the suffixes ^@ and ^!. If A is a merge commit, then git diff A A^@, git diff A^! and git show A all give the same combined diff. git diff [<options>] <commit>..<commit> [--] [<path>...] This is synonymous to the earlier form (without the ..) for viewing the changes between two arbitrary <commit>. If <commit> on one side is omitted, it will have the same effect as using HEAD instead. git diff [<options>] <commit>...<commit> [--] [<path>...] This form is to view the changes on the branch containing and up to the second <commit>, starting at a common ancestor of both <commit>. git diff A...B is equivalent to git diff $(git merge-base A B) B. You can omit any one of <commit>, which has the same effect as using HEAD instead. Just in case you are doing something exotic, it should be noted that all of the <commit> in the above description, except in the --merge-base case and in the last two forms that use .. notations, can be any <tree>. A tree of interest is the one pointed to by the special ref AUTO_MERGE, which is written by the ort merge strategy upon hitting merge conflicts (see git-merge(1)). Comparing the working tree with AUTO_MERGE shows changes you\u2019ve made so far to resolve textual conflicts (see the examples below). For a more complete list of ways to spell <commit>, see \"SPECIFYING REVISIONS\" section in gitrevisions(7). However, \"diff\" is about comparing two endpoints, not ranges, and the range notations (<commit>..<commit> and <commit>...<commit>) do not mean a range as defined in the \"SPECIFYING RANGES\" section in gitrevisions(7). git diff [<options>] <blob> <blob> This form is to view the differences between the raw contents of two blob objects. -p, -u, --patch Generate patch (see section titled \"Generating patch text with -p\"). This is the default. -s, --no-patch Suppress all output from the diff machinery. Useful for commands like git show that show the patch by default to squelch their output, or to cancel the effect of options like --patch, --stat earlier on the command line in an alias. -U<n>, --unified=<n> Generate diffs with <n> lines of context instead of the usual three. Implies --patch. --output=<file> Output to a specific file instead of stdout. --output-indicator-new=<char>, --output-indicator-old=<char>, --output-indicator-context=<char> Specify the character used to indicate new, old or context lines in the generated patch. Normally they are +, - and ' ' respectively. --raw Generate the diff in raw format. --patch-with-raw Synonym for -p --raw. --indent-heuristic Enable the heuristic that shifts diff hunk boundaries to make patches easier to read. This is the default. --no-indent-heuristic Disable the indent heuristic. --minimal Spend extra time to make sure the smallest possible diff is produced. --patience Generate a diff using the \"patience diff\" algorithm. --histogram Generate a diff using the \"histogram diff\" algorithm. --anchored=<text> Generate a diff using the \"anchored diff\" algorithm. This option may be specified more than once. If a line exists in both the source and destination, exists only once, and starts with this text, this algorithm attempts to prevent it from appearing as a deletion or addition in the output. It uses the \"patience diff\" algorithm internally. --diff-algorithm={patience|minimal|histogram|myers} Choose a diff algorithm. The variants are as follows: default, myers The basic greedy diff algorithm. Currently, this is the default. minimal Spend extra time to make sure the smallest possible diff is produced. patience Use \"patience diff\" algorithm when generating patches. histogram This algorithm extends the patience algorithm to \"support low-occurrence common elements\". For instance, if you configured the diff.algorithm variable to a non-default value and want to use the default one, then you have to use --diff-algorithm=default option. --stat[=<width>[,<name-width>[,<count>]]] Generate a diffstat. By default, as much space as necessary will be used for the filename part, and the rest for the graph part. Maximum width defaults to terminal width, or 80 columns if not connected to a terminal, and can be overridden by <width>. The width of the filename part can be limited by giving another width <name-width> after a comma. The width of the graph part can be limited by using --stat-graph-width=<width> (affects all commands generating a stat graph) or by setting diff.statGraphWidth=<width> (does not affect git format-patch). By giving a third parameter <count>, you can limit the output to the first <count> lines, followed by ... if there are more. These parameters can also be set individually with --stat-width=<width>, --stat-name-width=<name-width> and --stat-count=<count>. --compact-summary Output a condensed summary of extended header information such as file creations or deletions (\"new\" or \"gone\", optionally \"+l\" if it\u2019s a symlink) and mode changes (\"+x\" or \"-x\" for adding or removing executable bit respectively) in diffstat. The information is put between the filename part and the graph part. Implies --stat. --numstat Similar to --stat, but shows number of added and deleted lines in decimal notation and pathname without abbreviation, to make it more machine friendly. For binary files, outputs two - instead of saying 0 0. --shortstat Output only the last line of the --stat format containing total number of modified files, as well as number of added and deleted lines. -X[<param1,param2,...>], --dirstat[=<param1,param2,...>] Output the distribution of relative amount of changes for each sub-directory. The behavior of --dirstat can be customized by passing it a comma separated list of parameters. The defaults are controlled by the diff.dirstat configuration variable (see git-config(1)). The following parameters are available: changes Compute the dirstat numbers by counting the lines that have been removed from the source, or added to the destination. This ignores the amount of pure code movements within a file. In other words, rearranging lines in a file is not counted as much as other changes. This is the default behavior when no parameter is given. lines Compute the dirstat numbers by doing the regular line-based diff analysis, and summing the removed/added line counts. (For binary files, count 64-byte chunks instead, since binary files have no natural concept of lines). This is a more expensive --dirstat behavior than the changes behavior, but it does count rearranged lines within a file as much as other changes. The resulting output is consistent with what you get from the other --*stat options. files Compute the dirstat numbers by counting the number of files changed. Each changed file counts equally in the dirstat analysis. This is the computationally cheapest --dirstat behavior, since it does not have to look at the file contents at all. cumulative Count changes in a child directory for the parent directory as well. Note that when using cumulative, the sum of the percentages reported may exceed 100%. The default (non-cumulative) behavior can be specified with the noncumulative parameter. <limit> An integer parameter specifies a cut-off percent (3% by default). Directories contributing less than this percentage of the changes are not shown in the output. Example: The following will count changed files, while ignoring directories with less than 10% of the total amount of changed files, and accumulating child directory counts in the parent directories: --dirstat=files,10,cumulative. --cumulative Synonym for --dirstat=cumulative --dirstat-by-file[=<param1,param2>...] Synonym for --dirstat=files,param1,param2... --summary Output a condensed summary of extended header information such as creations, renames and mode changes. --patch-with-stat Synonym for -p --stat. -z When --raw, --numstat, --name-only or --name-status has been given, do not munge pathnames and use NULs as output field terminators. Without this option, pathnames with \"unusual\" characters are quoted as explained for the configuration variable core.quotePath (see git-config(1)). --name-only Show only names of changed files. The file names are often encoded in UTF-8. For more information see the discussion about encoding in the git-log(1) manual page. --name-status Show only names and status of changed files. See the description of the --diff-filter option on what the status letters mean. Just like --name-only the file names are often encoded in UTF-8. --submodule[=<format>] Specify how differences in submodules are shown. When specifying --submodule=short the short format is used. This format just shows the names of the commits at the beginning and end of the range. When --submodule or --submodule=log is specified, the log format is used. This format lists the commits in the range like git-submodule(1) summary does. When --submodule=diff is specified, the diff format is used. This format shows an inline diff of the changes in the submodule contents between the commit range. Defaults to diff.submodule or the short format if the config option is unset. --color[=<when>] Show colored diff. --color (i.e. without =<when>) is the same as --color=always. <when> can be one of always, never, or auto. It can be changed by the color.ui and color.diff configuration settings. --no-color Turn off colored diff. This can be used to override configuration settings. It is the same as --color=never. --color-moved[=<mode>] Moved lines of code are colored differently. It can be changed by the diff.colorMoved configuration setting. The <mode> defaults to no if the option is not given and to zebra if the option with no mode is given. The mode must be one of: no Moved lines are not highlighted. default Is a synonym for zebra. This may change to a more sensible mode in the future. plain Any line that is added in one location and was removed in another location will be colored with color.diff.newMoved. Similarly color.diff.oldMoved will be used for removed lines that are added somewhere else in the diff. This mode picks up any moved line, but it is not very useful in a review to determine if a block of code was moved without permutation. blocks Blocks of moved text of at least 20 alphanumeric characters are detected greedily. The detected blocks are painted using either the color.diff.{old,new}Moved color. Adjacent blocks cannot be told apart. zebra Blocks of moved text are detected as in blocks mode. The blocks are painted using either the color.diff.{old,new}Moved color or color.diff.{old,new}MovedAlternative. The change between the two colors indicates that a new block was detected. dimmed-zebra Similar to zebra, but additional dimming of uninteresting parts of moved code is performed. The bordering lines of two adjacent blocks are considered interesting, the rest is uninteresting. dimmed_zebra is a deprecated synonym. --no-color-moved Turn off move detection. This can be used to override configuration settings. It is the same as --color-moved=no. --color-moved-ws=<modes> This configures how whitespace is ignored when performing the move detection for --color-moved. It can be set by the diff.colorMovedWS configuration setting. These modes can be given as a comma separated list: no Do not ignore whitespace when performing move detection. ignore-space-at-eol Ignore changes in whitespace at EOL. ignore-space-change Ignore changes in amount of whitespace. This ignores whitespace at line end, and considers all other sequences of one or more whitespace characters to be equivalent. ignore-all-space Ignore whitespace when comparing lines. This ignores differences even if one line has whitespace where the other line has none. allow-indentation-change Initially ignore any whitespace in the move detection, then group the moved code blocks only into a block if the change in whitespace is the same per line. This is incompatible with the other modes. --no-color-moved-ws Do not ignore whitespace when performing move detection. This can be used to override configuration settings. It is the same as --color-moved-ws=no. --word-diff[=<mode>] Show a word diff, using the <mode> to delimit changed words. By default, words are delimited by whitespace; see --word-diff-regex below. The <mode> defaults to plain, and must be one of: color Highlight changed words using only colors. Implies --color. plain Show words as [-removed-] and {+added+}. Makes no attempts to escape the delimiters if they appear in the input, so the output may be ambiguous. porcelain Use a special line-based format intended for script consumption. Added/removed/unchanged runs are printed in the usual unified diff format, starting with a +/-/` ` character at the beginning of the line and extending to the end of the line. Newlines in the input are represented by a tilde ~ on a line of its own. none Disable word diff again. Note that despite the name of the first mode, color is used to highlight the changed parts in all modes if enabled. --word-diff-regex=<regex> Use <regex> to decide what a word is, instead of considering runs of non-whitespace to be a word. Also implies --word-diff unless it was already enabled. Every non-overlapping match of the <regex> is considered a word. Anything between these matches is considered whitespace and ignored(!) for the purposes of finding differences. You may want to append |[^[:space:]] to your regular expression to make sure that it matches all non-whitespace characters. A match that contains a newline is silently truncated(!) at the newline. For example, --word-diff-regex=. will treat each character as a word and, correspondingly, show differences character by character. The regex can also be set via a diff driver or configuration option, see gitattributes(5) or git-config(1). Giving it explicitly overrides any diff driver or configuration setting. Diff drivers override configuration settings. --color-words[=<regex>] Equivalent to --word-diff=color plus (if a regex was specified) --word-diff-regex=<regex>. --no-renames Turn off rename detection, even when the configuration file gives the default to do so. --[no-]rename-empty Whether to use empty blobs as rename source. --check Warn if changes introduce conflict markers or whitespace errors. What are considered whitespace errors is controlled by core.whitespace configuration. By default, trailing whitespaces (including lines that consist solely of whitespaces) and a space character that is immediately followed by a tab character inside the initial indent of the line are considered whitespace errors. Exits with non-zero status if problems are found. Not compatible with --exit-code. --ws-error-highlight=<kind> Highlight whitespace errors in the context, old or new lines of the diff. Multiple values are separated by comma, none resets previous values, default reset the list to new and all is a shorthand for old,new,context. When this option is not given, and the configuration variable diff.wsErrorHighlight is not set, only whitespace errors in new lines are highlighted. The whitespace errors are colored with color.diff.whitespace. --full-index Instead of the first handful of characters, show the full pre- and post-image blob object names on the \"index\" line when generating patch format output. --binary In addition to --full-index, output a binary diff that can be applied with git-apply. Implies --patch. --abbrev[=<n>] Instead of showing the full 40-byte hexadecimal object name in diff-raw format output and diff-tree header lines, show the shortest prefix that is at least <n> hexdigits long that uniquely refers the object. In diff-patch output format, --full-index takes higher precedence, i.e. if --full-index is specified, full blob names will be shown regardless of --abbrev. Non default number of digits can be specified with --abbrev=<n>. -B[<n>][/<m>], --break-rewrites[=[<n>][/<m>]] Break complete rewrite changes into pairs of delete and create. This serves two purposes: It affects the way a change that amounts to a total rewrite of a file not as a series of deletion and insertion mixed together with a very few lines that happen to match textually as the context, but as a single deletion of everything old followed by a single insertion of everything new, and the number m controls this aspect of the -B option (defaults to 60%). -B/70% specifies that less than 30% of the original should remain in the result for Git to consider it a total rewrite (i.e. otherwise the resulting patch will be a series of deletion and insertion mixed together with context lines). When used with -M, a totally-rewritten file is also considered as the source of a rename (usually -M only considers a file that disappeared as the source of a rename), and the number n controls this aspect of the -B option (defaults to 50%). -B20% specifies that a change with addition and deletion compared to 20% or more of the file\u2019s size are eligible for being picked up as a possible source of a rename to another file. -M[<n>], --find-renames[=<n>] Detect renames. If n is specified, it is a threshold on the similarity index (i.e. amount of addition/deletions compared to the file\u2019s size). For example, -M90% means Git should consider a delete/add pair to be a rename if more than 90% of the file hasn\u2019t changed. Without a % sign, the number is to be read as a fraction, with a decimal point before it. I.e., -M5 becomes 0.5, and is thus the same as -M50%. Similarly, -M05 is the same as -M5%. To limit detection to exact renames, use -M100%. The default similarity index is 50%. -C[<n>], --find-copies[=<n>] Detect copies as well as renames. See also --find-copies-harder. If n is specified, it has the same meaning as for -M<n>. --find-copies-harder For performance reasons, by default, -C option finds copies only if the original file of the copy was modified in the same changeset. This flag makes the command inspect unmodified files as candidates for the source of copy. This is a very expensive operation for large projects, so use it with caution. Giving more than one -C option has the same effect. -D, --irreversible-delete Omit the preimage for deletes, i.e. print only the header but not the diff between the preimage and /dev/null. The resulting patch is not meant to be applied with patch or git apply; this is solely for people who want to just concentrate on reviewing the text after the change. In addition, the output obviously lacks enough information to apply such a patch in reverse, even manually, hence the name of the option. When used together with -B, omit also the preimage in the deletion part of a delete/create pair. -l<num> The -M and -C options involve some preliminary steps that can detect subsets of renames/copies cheaply, followed by an exhaustive fallback portion that compares all remaining unpaired destinations to all relevant sources. (For renames, only remaining unpaired sources are relevant; for copies, all original sources are relevant.) For N sources and destinations, this exhaustive check is O(N^2). This option prevents the exhaustive portion of rename/copy detection from running if the number of source/destination files involved exceeds the specified number. Defaults to diff.renameLimit. Note that a value of 0 is treated as unlimited. --diff-filter=[(A|C|D|M|R|T|U|X|B)...[*]] Select only files that are Added (A), Copied (C), Deleted (D), Modified (M), Renamed (R), have their type (i.e. regular file, symlink, submodule, ...) changed (T), are Unmerged (U), are Unknown (X), or have had their pairing Broken (B). Any combination of the filter characters (including none) can be used. When * (All-or-none) is added to the combination, all paths are selected if there is any file that matches other criteria in the comparison; if there is no file that matches other criteria, nothing is selected. Also, these upper-case letters can be downcased to exclude. E.g. --diff-filter=ad excludes added and deleted paths. Note that not all diffs can feature all types. For instance, copied and renamed entries cannot appear if detection for those types is disabled. -S<string> Look for differences that change the number of occurrences of the specified string (i.e. addition/deletion) in a file. Intended for the scripter\u2019s use. It is useful when you\u2019re looking for an exact block of code (like a struct), and want to know the history of that block since it first came into being: use the feature iteratively to feed the interesting block in the preimage back into -S, and keep going until you get the very first version of the block. Binary files are searched as well. -G<regex> Look for differences whose patch text contains added/removed lines that match <regex>. To illustrate the difference between -S<regex> --pickaxe-regex and -G<regex>, consider a commit with the following diff in the same file: + return frotz(nitfol, two->ptr, 1, 0); ... - hit = frotz(nitfol, mf2.ptr, 1, 0); While git log -G\"frotz\\(nitfol\" will show this commit, git log -S\"frotz\\(nitfol\" --pickaxe-regex will not (because the number of occurrences of that string did not change). Unless --text is supplied patches of binary files without a textconv filter will be ignored. See the pickaxe entry in gitdiffcore(7) for more information. --find-object=<object-id> Look for differences that change the number of occurrences of the specified object. Similar to -S, just the argument is different in that it doesn\u2019t search for a specific string but for a specific object id. The object can be a blob or a submodule commit. It implies the -t option in git-log to also find trees. --pickaxe-all When -S or -G finds a change, show all the changes in that changeset, not just the files that contain the change in <string>. --pickaxe-regex Treat the <string> given to -S as an extended POSIX regular expression to match. -O<orderfile> Control the order in which files appear in the output. This overrides the diff.orderFile configuration variable (see git-config(1)). To cancel diff.orderFile, use -O/dev/null. The output order is determined by the order of glob patterns in <orderfile>. All files with pathnames that match the first pattern are output first, all files with pathnames that match the second pattern (but not the first) are output next, and so on. All files with pathnames that do not match any pattern are output last, as if there was an implicit match-all pattern at the end of the file. If multiple pathnames have the same rank (they match the same pattern but no earlier patterns), their output order relative to each other is the normal order. <orderfile> is parsed as follows: \u2022 Blank lines are ignored, so they can be used as separators for readability. \u2022 Lines starting with a hash (\"#\") are ignored, so they can be used for comments. Add a backslash (\"\\\") to the beginning of the pattern if it starts with a hash. \u2022 Each other line contains a single pattern. Patterns have the same syntax and semantics as patterns used for fnmatch(3) without the FNM_PATHNAME flag, except a pathname also matches a pattern if removing any number of the final pathname components matches the pattern. For example, the pattern \"foo*bar\" matches \"fooasdfbar\" and \"foo/bar/baz/asdf\" but not \"foobarx\". --skip-to=<file>, --rotate-to=<file> Discard the files before the named <file> from the output (i.e. skip to), or move them to the end of the output (i.e. rotate to). These were invented primarily for use of the git difftool command, and may not be very useful otherwise. -R Swap two inputs; that is, show differences from index or on-disk file to tree contents. --relative[=<path>], --no-relative When run from a subdirectory of the project, it can be told to exclude changes outside the directory and show pathnames relative to it with this option. When you are not in a subdirectory (e.g. in a bare repository), you can name which subdirectory to make the output relative to by giving a <path> as an argument. --no-relative can be used to countermand both diff.relative config option and previous --relative. -a, --text Treat all files as text. --ignore-cr-at-eol Ignore carriage-return at the end of line when doing a comparison. --ignore-space-at-eol Ignore changes in whitespace at EOL. -b, --ignore-space-change Ignore changes in amount of whitespace. This ignores whitespace at line end, and considers all other sequences of one or more whitespace characters to be equivalent. -w, --ignore-all-space Ignore whitespace when comparing lines. This ignores differences even if one line has whitespace where the other line has none. --ignore-blank-lines Ignore changes whose lines are all blank. -I<regex>, --ignore-matching-lines=<regex> Ignore changes whose all lines match <regex>. This option may be specified more than once. --inter-hunk-context=<lines> Show the context between diff hunks, up to the specified number of lines, thereby fusing hunks that are close to each other. Defaults to diff.interHunkContext or 0 if the config option is unset. -W, --function-context Show whole function as context lines for each change. The function names are determined in the same way as git diff works out patch hunk headers (see Defining a custom hunk-header in gitattributes(5)). --exit-code Make the program exit with codes similar to diff(1). That is, it exits with 1 if there were differences and 0 means no differences. --quiet Disable all output of the program. Implies --exit-code. --ext-diff Allow an external diff helper to be executed. If you set an external diff driver with gitattributes(5), you need to use this option with git-log(1) and friends. --no-ext-diff Disallow external diff drivers. --textconv, --no-textconv Allow (or disallow) external text conversion filters to be run when comparing binary files. See gitattributes(5) for details. Because textconv filters are typically a one-way conversion, the resulting diff is suitable for human consumption, but cannot be applied. For this reason, textconv filters are enabled by default only for git-diff(1) and git-log(1), but not for git-format-patch(1) or diff plumbing commands. --ignore-submodules[=<when>] Ignore changes to submodules in the diff generation. <when> can be either \"none\", \"untracked\", \"dirty\" or \"all\", which is the default. Using \"none\" will consider the submodule modified when it either contains untracked or modified files or its HEAD differs from the commit recorded in the superproject and can be used to override any settings of the ignore option in git-config(1) or gitmodules(5). When \"untracked\" is used submodules are not considered dirty when they only contain untracked content (but they are still scanned for modified content). Using \"dirty\" ignores all changes to the work tree of submodules, only changes to the commits stored in the superproject are shown (this was the behavior until 1.7.0). Using \"all\" hides all changes to submodules. --src-prefix=<prefix> Show the given source prefix instead of \"a/\". --dst-prefix=<prefix> Show the given destination prefix instead of \"b/\". --no-prefix Do not show any source or destination prefix. --default-prefix Use the default source and destination prefixes (\"a/\" and \"b/\"). This is usually the default already, but may be used to override config such as diff.noprefix. --line-prefix=<prefix> Prepend an additional prefix to every line of output. --ita-invisible-in-index By default entries added by \"git add -N\" appear as an existing empty file in \"git diff\" and a new file in \"git diff --cached\". This option makes the entry appear as a new file in \"git diff\" and non-existent in \"git diff --cached\". This option could be reverted with --ita-visible-in-index. Both options are experimental and could be removed in future. For more detailed explanation on these common options, see also gitdiffcore(7). -1 --base, -2 --ours, -3 --theirs Compare the working tree with the \"base\" version (stage #1), \"our branch\" (stage #2) or \"their branch\" (stage #3). The index contains these stages only for unmerged entries i.e. while resolving conflicts. See git-read-tree(1) section \"3-Way Merge\" for detailed information. -0 Omit diff output for unmerged entries and just show \"Unmerged\". Can be used only when comparing the working tree with the index. <path>... The <paths> parameters, when given, are used to limit the diff to the named paths (you can give directory names and get diff for all files under them). "
  },
  {
    "command": "unexpand",
    "description": " Convert blanks in each FILE to tabs, writing to standard output. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -a, --all convert all blanks, instead of just initial blanks --first-only convert only leading sequences of blanks (overrides -a) -t, --tabs=N have tabs N characters apart instead of 8 (enables -a) -t, --tabs=LIST use comma separated list of tab positions. The last specified position can be prefixed with '/' to specify a tab size to use after the last explicitly specified tab stop. Also a prefix of '+' can be used to align remaining tab stops relative to the last specified tab stop instead of the first column --help display this help and exit --version output version information and exit "
  },
  {
    "command": "unlink",
    "description": " The unlink utility shall perform the function call: unlink(file); A user may need appropriate privileges to invoke the unlink utility. None. "
  },
  {
    "command": "ls",
    "description": " For each operand that names a file of a type other than directory or symbolic link to a directory, ls shall write the name of the file as well as any requested, associated information. For each operand that names a file of type directory, ls shall write the names of files contained within the directory as well as any requested, associated information. Filenames beginning with a <period> ('.') and any associated information shall not be written out unless explicitly referenced, the -A or -a option is supplied, or an implementation-defined condition causes them to be written. If one or more of the -d, -F, or -l options are specified, and neither the -H nor the -L option is specified, for each operand that names a file of type symbolic link to a directory, ls shall write the name of the file as well as any requested, associated information. If none of the -d, -F, or -l options are specified, or the -H or -L options are specified, for each operand that names a file of type symbolic link to a directory, ls shall write the names of files contained within the directory as well as any requested, associated information. In each case where the names of files contained within a directory are written, if the directory contains any symbolic links then ls shall evaluate the file information and file type to be those of the symbolic link itself, unless the -L option is specified. If no operands are specified, ls shall behave as if a single operand of dot ('.') had been specified. If more than one operand is specified, ls shall write non-directory operands first; it shall sort directory and non-directory operands separately according to the collating sequence in the current locale. Whenever ls sorts filenames or pathnames according to the collating sequence in the current locale, if this collating sequence does not have a total ordering of all characters (see the Base Definitions volume of POSIX.1\u20102017, Section 7.3.2, LC_COLLATE), then any filenames or pathnames that collate equally should be further compared byte-by-byte using the collating sequence for the POSIX locale. The ls utility shall detect infinite loops; that is, entering a previously visited directory that is an ancestor of the last file encountered. When it detects an infinite loop, ls shall write a diagnostic message to standard error and shall either recover its position in the hierarchy or terminate. The ls utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -A Write out all directory entries, including those whose names begin with a <period> ('.') but excluding the entries dot and dot-dot (if they exist). -C Write multi-text-column output with entries sorted down the columns, according to the collating sequence. The number of text columns and the column separator characters are unspecified, but should be adapted to the nature of the output device. This option disables long format output. -F Do not follow symbolic links named as operands unless the -H or -L options are specified. Write a <slash> ('/') immediately after each pathname that is a directory, an <asterisk> ('*') after each that is executable, a <vertical-line> ('|') after each that is a FIFO, and an at-sign ('@') after each that is a symbolic link. For other file types, other symbols may be written. -H Evaluate the file information and file type for symbolic links specified on the command line to be those of the file referenced by the link, and not the link itself; however, ls shall write the name of the link itself and not the file referenced by the link. -L Evaluate the file information and file type for all symbolic links (whether named on the command line or encountered in a file hierarchy) to be those of the file referenced by the link, and not the link itself; however, ls shall write the name of the link itself and not the file referenced by the link. When -L is used with -l, write the contents of symbolic links in the long format (see the STDOUT section). -R Recursively list subdirectories encountered. When a symbolic link to a directory is encountered, the directory shall not be recursively listed unless the -L option is specified. The use of -R with -d or -f produces unspecified results. -S Sort with the primary key being file size (in decreasing order) and the secondary key being filename in the collating sequence (in increasing order). -a Write out all directory entries, including those whose names begin with a <period> ('.'). -c Use time of last modification of the file status information (see the Base Definitions volume of POSIX.1\u20102017, sys_stat.h(0p)) instead of last modification of the file itself for sorting (-t) or writing (-l). -d Do not follow symbolic links named as operands unless the -H or -L options are specified. Do not treat directories differently than other types of files. The use of -d with -R or -f produces unspecified results. -f List the entries in directory operands in the order they appear in the directory. The behavior for non- directory operands is unspecified. This option shall turn on -a. When -f is specified, any occurrences of the -r, -S, and -t options shall be ignored and any occurrences of the -A, -g, -l, -n, -o, and -s options may be ignored. The use of -f with -R or -d produces unspecified results. -g Turn on the -l (ell) option, but disable writing the file's owner name or number. Disable the -C, -m, and -x options. -i For each file, write the file's file serial number (see stat() in the System Interfaces volume of POSIX.1\u20102017). -k Set the block size for the -s option and the per- directory block count written for the -l, -n, -s, -g, and -o options (see the STDOUT section) to 1024 bytes. -l (The letter ell.) Do not follow symbolic links named as operands unless the -H or -L options are specified. Write out in long format (see the STDOUT section). Disable the -C, -m, and -x options. -m Stream output format; list pathnames across the page, separated by a <comma> character followed by a <space> character. Use a <newline> character as the list terminator and after the separator sequence when there is not room on a line for the next list entry. This option disables long format output. -n Turn on the -l (ell) option, but when writing the file's owner or group, write the file's numeric UID or GID rather than the user or group name, respectively. Disable the -C, -m, and -x options. -o Turn on the -l (ell) option, but disable writing the file's group name or number. Disable the -C, -m, and -x options. -p Write a <slash> ('/') after each filename if that file is a directory. -q Force each instance of non-printable filename characters and <tab> characters to be written as the <question-mark> ('?') character. Implementations may provide this option by default if the output is to a terminal device. -r Reverse the order of the sort to get reverse collating sequence oldest first, or smallest file size first depending on the other options given. -s Indicate the total number of file system blocks consumed by each file displayed. If the -k option is also specified, the block size shall be 1024 bytes; otherwise, the block size is implementation-defined. -t Sort with the primary key being time modified (most recently modified first) and the secondary key being filename in the collating sequence. For a symbolic link, the time used as the sort key is that of the symbolic link itself, unless ls is evaluating its file information to be that of the file referenced by the link (see the -H and -L options). -u Use time of last access (see the Base Definitions volume of POSIX.1\u20102017, sys_stat.h(0p)) instead of last modification of the file for sorting (-t) or writing (-l). -x The same as -C, except that the multi-text-column output is produced with entries sorted across, rather than down, the columns. This option disables long format output. -1 (The numeric digit one.) Force output to be one entry per line. This option does not disable long format output. (Long format output is enabled by -g, -l (ell), -n, and -o; and disabled by -C, -m, and -x.) If an option that enables long format output (-g, -l (ell), -n, and -o is given with an option that disables long format output (-C, -m, and -x), this shall not be considered an error. The last of these options specified shall determine whether long format output is written. If -R, -d, or -f are specified, the results of specifying these mutually-exclusive options are specified by the descriptions of these options above. If more than one of any of the other options shown in the SYNOPSIS section in mutually-exclusive sets are given, this shall not be considered an error; the last option specified in each set shall determine the output. Note that if -t is specified, -c and -u are not only mutually- exclusive with each other, they are also mutually-exclusive with -S when determining sort order. But even if -S is specified after all occurrences of -c, -t, and -u, the last use of -c or -u determines the timestamp printed when producing long format output. "
  },
  {
    "command": "renice",
    "description": " The renice utility shall request that the nice values (see the Base Definitions volume of POSIX.1\u20102017, Section 3.244, Nice Value) of one or more running processes be changed. By default, the applicable processes are specified by their process IDs. When a process group is specified (see -g), the request shall apply to all processes in the process group. The nice value shall be bounded in an implementation-defined manner. If the requested increment would raise or lower the nice value of the executed utility beyond implementation-defined limits, then the limit whose value was exceeded shall be used. When a user is reniced, the request applies to all processes whose saved set-user-ID matches the user ID corresponding to the user. Regardless of which options are supplied or any other factor, renice shall not alter the nice values of any process unless the user requesting such a change has appropriate privileges to do so for the specified process. If the user lacks appropriate privileges to perform the requested action, the utility shall return an error status. The saved set-user-ID of the user's process shall be checked instead of its effective user ID when renice attempts to determine the user ID of the process in order to determine whether the user has appropriate privileges. The renice utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for Guideline 9. The following options shall be supported: -g Interpret the following operands as unsigned decimal integer process group IDs. -n increment Specify how the nice value of the specified process or processes is to be adjusted. The increment option- argument is a positive or negative decimal integer that shall be used to modify the nice value of the specified process or processes. Positive increment values shall cause a lower nice value. Negative increment values may require appropriate privileges and shall cause a higher nice value. -p Interpret the following operands as unsigned decimal integer process IDs. The -p option is the default if no options are specified. -u Interpret the following operands as users. If a user exists with a user name equal to the operand, then the user ID of that user is used in further processing. Otherwise, if the operand represents an unsigned decimal integer, it shall be used as the numeric user ID of the user. "
  },
  {
    "command": "groups",
    "description": " The groups command displays the current group names or ID values. If the value does not have a corresponding entry in /etc/group, the value will be displayed as the numerical group value. The optional user parameter will display the groups for the named user. "
  },
  {
    "command": "comm",
    "description": " The comm utility shall read file1 and file2, which should be ordered in the current collating sequence, and produce three text columns as output: lines only in file1, lines only in file2, and lines in both files. If the lines in both files are not ordered according to the collating sequence of the current locale, the results are unspecified. If the collating sequence of the current locale does not have a total ordering of all characters (see the Base Definitions volume of POSIX.1\u20102017, Section 7.3.2, LC_COLLATE) and any lines from the input files collate equally but are not identical, comm should treat them as different lines but may treat them as being the same. If it treats them as different, comm should expect them to be ordered according to a further byte-by-byte comparison using the collating sequence for the POSIX locale and if they are not ordered in this way, the output of comm can identify such lines as being both unique to file1 and unique to file2 instead of being in both files. The comm utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -1 Suppress the output column of lines unique to file1. -2 Suppress the output column of lines unique to file2. -3 Suppress the output column of lines duplicated in file1 and file2. "
  },
  {
    "command": "iostat",
    "description": " The iostat command is used for monitoring system input/output device loading by observing the time the devices are active in relation to their average transfer rates. The iostat command generates reports that can be used to change system configuration to better balance the input/output load between physical disks. The first report generated by the iostat command provides statistics concerning the time since the system was booted, unless the -y option is used (in this case, this first report is omitted). Each subsequent report covers the time since the previous report. All statistics are reported each time the iostat command is run. The report consists of a CPU header row followed by a row of CPU statistics. On multiprocessor systems, CPU statistics are calculated system-wide as averages among all processors. A device header row is displayed followed by a line of statistics for each device that is configured. The interval parameter specifies the amount of time in seconds between each report. The count parameter can be specified in conjunction with the interval parameter. If the count parameter is specified, the value of count determines the number of reports generated at interval seconds apart. If the interval parameter is specified without the count parameter, the iostat command generates reports continuously. -c Display the CPU utilization report. --compact Don't break the Device Utilization Report into sub-reports so that all the metrics get displayed on a single line. -d Display the device utilization report. --dec={ 0 | 1 | 2 } Specify the number of decimal places to use (0 to 2, default value is 2). -f directory +f directory Specify an alternative directory for iostat to read devices statistics. Option -f tells iostat to use only the files located in the alternative directory, whereas option +f tells it to use both the standard kernel files and the files located in the alternative directory to read device statistics. directory is a directory containing files with statistics for devices managed in userspace. It may contain: - a \"diskstats\" file whose format is compliant with that located in \"/proc\", - statistics for individual devices contained in files whose format is compliant with that of files located in \"/sys\". In particular, the following files located in directory may be used by iostat: directory/block/device/stat directory/block/device/partition/stat partition files must have an entry in directory/dev/block/ directory, e.g.: directory/dev/block/major:minor --> ../../block/device/partition -g group_name { device [...] | ALL } Display statistics for a group of devices. The iostat command reports statistics for each individual device in the list then a line of global statistics for the group displayed as group_name and made up of all the devices in the list. The ALL keyword means that all the block devices defined by the system shall be included in the group. -H This option must be used with option -g and indicates that only global statistics for the group are to be displayed, and not statistics for individual devices in the group. -h This option is equivalent to specifying --human --pretty. --human Print sizes in human readable format (e.g. 1.0k, 1.2M, etc.) The units displayed with this option supersede any other default units (e.g. kilobytes, sectors...) associated with the metrics. -j { ID | LABEL | PATH | UUID | ... } [ device [...] | ALL ] Display persistent device names. Keywords ID, LABEL, etc. specify the type of the persistent name. These keywords are not limited, only prerequisite is that directory with required persistent names is present in /dev/disk. Optionally, multiple devices can be specified in the chosen persistent name type. Because persistent device names are usually long, option --pretty is implicitly set with this option. -k Display statistics in kilobytes per second. -m Display statistics in megabytes per second. -N Display the registered device mapper names for any device mapper devices. Useful for viewing LVM2 statistics. -o JSON Display the statistics in JSON (JavaScript Object Notation) format. JSON output field order is undefined, and new fields may be added in the future. -p [ { device[,...] | ALL } ] Display statistics for block devices and all their partitions that are used by the system. If a device name is entered on the command line, then statistics for it and all its partitions are displayed. Last, the ALL keyword indicates that statistics have to be displayed for all the block devices and partitions defined by the system, including those that have never been used. If option -j is defined before this option, devices entered on the command line can be specified with the chosen persistent name type. --pretty Make the Device Utilization Report easier to read by a human. The device name will be printed on the right side. The report may also be broken into sub-reports if there are many metrics to display (use --compact option to prevent this). -s Display a short (narrow) version of the report that should fit in 80 characters wide screens. -t Print the time for each report displayed. The timestamp format may depend on the value of the S_TIME_FORMAT environment variable (see below). -V Print version number then exit. -x Display extended statistics. -y Omit first report with statistics since system boot, if displaying multiple records at given interval. -z Tell iostat to omit output for any devices for which there was no activity during the sample period. "
  },
  {
    "command": "pathchk",
    "description": " Diagnose invalid or unportable file names. -p check for most POSIX systems -P check for empty names and leading \"-\" --portability check for all POSIX systems (equivalent to -p -P) --help display this help and exit --version output version information and exit "
  },
  {
    "command": "git-tag",
    "description": " Add a tag reference in refs/tags/, unless -d/-l/-v is given to delete, list or verify tags. Unless -f is given, the named tag must not yet exist. If one of -a, -s, or -u <key-id> is passed, the command creates a tag object, and requires a tag message. Unless -m <msg> or -F <file> is given, an editor is started for the user to type in the tag message. If -m <msg> or -F <file> is given and -a, -s, and -u <key-id> are absent, -a is implied. Otherwise, a tag reference that points directly at the given object (i.e., a lightweight tag) is created. A GnuPG signed tag object will be created when -s or -u <key-id> is used. When -u <key-id> is not used, the committer identity for the current user is used to find the GnuPG key for signing. The configuration variable gpg.program is used to specify custom GnuPG binary. Tag objects (created with -a, -s, or -u) are called \"annotated\" tags; they contain a creation date, the tagger name and e-mail, a tagging message, and an optional GnuPG signature. Whereas a \"lightweight\" tag is simply a name for an object (usually a commit object). Annotated tags are meant for release while lightweight tags are meant for private or temporary object labels. For this reason, some git commands for naming objects (like git describe) will ignore lightweight tags by default. -a, --annotate Make an unsigned, annotated tag object -s, --sign Make a GPG-signed tag, using the default e-mail address\u2019s key. The default behavior of tag GPG-signing is controlled by tag.gpgSign configuration variable if it exists, or disabled otherwise. See git-config(1). --no-sign Override tag.gpgSign configuration variable that is set to force each and every tag to be signed. -u <key-id>, --local-user=<key-id> Make a GPG-signed tag, using the given key. -f, --force Replace an existing tag with the given name (instead of failing) -d, --delete Delete existing tags with the given names. -v, --verify Verify the GPG signature of the given tag names. -n<num> <num> specifies how many lines from the annotation, if any, are printed when using -l. Implies --list. The default is not to print any annotation lines. If no number is given to -n, only the first line is printed. If the tag is not annotated, the commit message is displayed instead. -l, --list List tags. With optional <pattern>..., e.g. git tag --list 'v-*', list only the tags that match the pattern(s). Running \"git tag\" without arguments also lists all tags. The pattern is a shell wildcard (i.e., matched using fnmatch(3)). Multiple patterns may be given; if any of them matches, the tag is shown. This option is implicitly supplied if any other list-like option such as --contains is provided. See the documentation for each of those options for details. --sort=<key> Sort based on the key given. Prefix - to sort in descending order of the value. You may use the --sort=<key> option multiple times, in which case the last key becomes the primary key. Also supports \"version:refname\" or \"v:refname\" (tag names are treated as versions). The \"version:refname\" sort order can also be affected by the \"versionsort.suffix\" configuration variable. The keys supported are the same as those in git for-each-ref. Sort order defaults to the value configured for the tag.sort variable if it exists, or lexicographic order otherwise. See git-config(1). --color[=<when>] Respect any colors specified in the --format option. The <when> field must be one of always, never, or auto (if <when> is absent, behave as if always was given). -i, --ignore-case Sorting and filtering tags are case insensitive. --omit-empty Do not print a newline after formatted refs where the format expands to the empty string. --column[=<options>], --no-column Display tag listing in columns. See configuration variable column.tag for option syntax. --column and --no-column without options are equivalent to always and never respectively. This option is only applicable when listing tags without annotation lines. --contains [<commit>] Only list tags which contain the specified commit (HEAD if not specified). Implies --list. --no-contains [<commit>] Only list tags which don\u2019t contain the specified commit (HEAD if not specified). Implies --list. --merged [<commit>] Only list tags whose commits are reachable from the specified commit (HEAD if not specified). --no-merged [<commit>] Only list tags whose commits are not reachable from the specified commit (HEAD if not specified). --points-at <object> Only list tags of the given object (HEAD if not specified). Implies --list. -m <msg>, --message=<msg> Use the given tag message (instead of prompting). If multiple -m options are given, their values are concatenated as separate paragraphs. Implies -a if none of -a, -s, or -u <key-id> is given. -F <file>, --file=<file> Take the tag message from the given file. Use - to read the message from the standard input. Implies -a if none of -a, -s, or -u <key-id> is given. -e, --edit The message taken from file with -F and command line with -m are usually used as the tag message unmodified. This option lets you further edit the message taken from these sources. --cleanup=<mode> This option sets how the tag message is cleaned up. The <mode> can be one of verbatim, whitespace and strip. The strip mode is default. The verbatim mode does not change message at all, whitespace removes just leading/trailing whitespace lines and strip removes both whitespace and commentary. --create-reflog Create a reflog for the tag. To globally enable reflogs for tags, see core.logAllRefUpdates in git-config(1). The negated form --no-create-reflog only overrides an earlier --create-reflog, but currently does not negate the setting of core.logAllRefUpdates. --format=<format> A string that interpolates %(fieldname) from a tag ref being shown and the object it points at. The format is the same as that of git-for-each-ref(1). When unspecified, defaults to %(refname:strip=2). <tagname> The name of the tag to create, delete, or describe. The new tag name must pass all checks defined by git-check-ref-format(1). Some of these checks may restrict the characters allowed in a tag name. <commit>, <object> The object that the new tag will refer to, usually a commit. Defaults to HEAD. "
  },
  {
    "command": "last",
    "description": " last looks through the file wtmp (which records all logins/logouts) and prints information about connect times of users. Records are printed from most recent to least recent. Records can be specified by tty and username. tty names can be abbreviated: last 0 is equivalent to last tty0. Multiple arguments can be specified: last root console will print all of the entries for the user root and all entries logged in on the console tty. The special users reboot and shutdown log in when the system reboots or (surprise) shuts down. last reboot will produce a record of reboot times. If last is interrupted by a quit signal, it prints out how far its search in the wtmp file had reached and then quits. -n num, --lines num Limit the number of lines that last outputs. This is different from u*x last, which lets you specify the number right after a dash. -f filename, --file filename Read from the file filename instead of the system's wtmp file. --complain When the wtmp file has a problem (a time-warp, missing record, or whatever), print out an appropriate error. --tw-leniency num Set the time warp leniency to num seconds. Records in wtmp files might be slightly out of order (most notably when two logins occur within a one-second period - the second one gets written first). By default, this value is set to 60. If the program notices this problem, time is not assigned to users unless the --timewarps flag is used. --tw-suspicious num Set the time warp suspicious value to num seconds. If two records in the wtmp file are farther than this number of seconds apart, there is a problem with the wtmp file (or your machine hasn't been used in a year). If the program notices this problem, time is not assigned to users unless the --timewarps flag is used. --no-truncate-ftp-entries When printing out the information, don't chop the number part off of `ftp'XXXX entries. -x, --more-records Print out run level changes, shutdowns, and time changes in addition to the normal records. -a, --all-records Print out all records in the wtmp file. -i, --ip-address Some machines store the IP address of a connection in a utmp record. Enabling this option makes last print the IP address instead of the hostname. -w, --wide By default, last tries to print each entry within in 80 columns. Use this option to instruct last to print out the fields in the wtmp file with full field widths. --debug Print verbose internal information. -s, --print-seconds Print seconds when displaying dates. -y, --print-year Print year when displaying dates. -V, --version Print last's version number. -h, --help Prints the usage string and default locations of system files to standard output and exits. "
  },
  {
    "command": "git-fetch",
    "description": " Fetch branches and/or tags (collectively, \"refs\") from one or more other repositories, along with the objects necessary to complete their histories. Remote-tracking branches are updated (see the description of <refspec> below for ways to control this behavior). By default, any tag that points into the histories being fetched is also fetched; the effect is to fetch tags that point at branches that you are interested in. This default behavior can be changed by using the --tags or --no-tags options or by configuring remote.<name>.tagOpt. By using a refspec that fetches tags explicitly, you can fetch tags that do not point into branches you are interested in as well. git fetch can fetch from either a single named repository or URL, or from several repositories at once if <group> is given and there is a remotes.<group> entry in the configuration file. (See git-config(1)). When no remote is specified, by default the origin remote will be used, unless there\u2019s an upstream branch configured for the current branch. The names of refs that are fetched, together with the object names they point at, are written to .git/FETCH_HEAD. This information may be used by scripts or other git commands, such as git-pull(1). --all Fetch all remotes. -a, --append Append ref names and object names of fetched refs to the existing contents of .git/FETCH_HEAD. Without this option old data in .git/FETCH_HEAD will be overwritten. --atomic Use an atomic transaction to update local refs. Either all refs are updated, or on error, no refs are updated. --depth=<depth> Limit fetching to the specified number of commits from the tip of each remote branch history. If fetching to a shallow repository created by git clone with --depth=<depth> option (see git-clone(1)), deepen or shorten the history to the specified number of commits. Tags for the deepened commits are not fetched. --deepen=<depth> Similar to --depth, except it specifies the number of commits from the current shallow boundary instead of from the tip of each remote branch history. --shallow-since=<date> Deepen or shorten the history of a shallow repository to include all reachable commits after <date>. --shallow-exclude=<revision> Deepen or shorten the history of a shallow repository to exclude commits reachable from a specified remote branch or tag. This option can be specified multiple times. --unshallow If the source repository is complete, convert a shallow repository to a complete one, removing all the limitations imposed by shallow repositories. If the source repository is shallow, fetch as much as possible so that the current repository has the same history as the source repository. --update-shallow By default when fetching from a shallow repository, git fetch refuses refs that require updating .git/shallow. This option updates .git/shallow and accept such refs. --negotiation-tip=<commit|glob> By default, Git will report, to the server, commits reachable from all local refs to find common commits in an attempt to reduce the size of the to-be-received packfile. If specified, Git will only report commits reachable from the given tips. This is useful to speed up fetches when the user knows which local ref is likely to have commits in common with the upstream ref being fetched. This option may be specified more than once; if so, Git will report commits reachable from any of the given commits. The argument to this option may be a glob on ref names, a ref, or the (possibly abbreviated) SHA-1 of a commit. Specifying a glob is equivalent to specifying this option multiple times, one for each matching ref name. See also the fetch.negotiationAlgorithm and push.negotiate configuration variables documented in git-config(1), and the --negotiate-only option below. --negotiate-only Do not fetch anything from the server, and instead print the ancestors of the provided --negotiation-tip=* arguments, which we have in common with the server. This is incompatible with --recurse-submodules=[yes|on-demand]. Internally this is used to implement the push.negotiate option, see git-config(1). --dry-run Show what would be done, without making any changes. --porcelain Print the output to standard output in an easy-to-parse format for scripts. See section OUTPUT in git-fetch(1) for details. This is incompatible with --recurse-submodules=[yes|on-demand] and takes precedence over the fetch.output config option. --[no-]write-fetch-head Write the list of remote refs fetched in the FETCH_HEAD file directly under $GIT_DIR. This is the default. Passing --no-write-fetch-head from the command line tells Git not to write the file. Under --dry-run option, the file is never written. -f, --force When git fetch is used with <src>:<dst> refspec it may refuse to update the local branch as discussed in the <refspec> part below. This option overrides that check. -k, --keep Keep downloaded pack. --multiple Allow several <repository> and <group> arguments to be specified. No <refspec>s may be specified. --[no-]auto-maintenance, --[no-]auto-gc Run git maintenance run --auto at the end to perform automatic repository maintenance if needed. (--[no-]auto-gc is a synonym.) This is enabled by default. --[no-]write-commit-graph Write a commit-graph after fetching. This overrides the config setting fetch.writeCommitGraph. --prefetch Modify the configured refspec to place all refs into the refs/prefetch/ namespace. See the prefetch task in git-maintenance(1). -p, --prune Before fetching, remove any remote-tracking references that no longer exist on the remote. Tags are not subject to pruning if they are fetched only because of the default tag auto-following or due to a --tags option. However, if tags are fetched due to an explicit refspec (either on the command line or in the remote configuration, for example if the remote was cloned with the --mirror option), then they are also subject to pruning. Supplying --prune-tags is a shorthand for providing the tag refspec. See the PRUNING section below for more details. -P, --prune-tags Before fetching, remove any local tags that no longer exist on the remote if --prune is enabled. This option should be used more carefully, unlike --prune it will remove any local references (local tags) that have been created. This option is a shorthand for providing the explicit tag refspec along with --prune, see the discussion about that in its documentation. See the PRUNING section below for more details. -n, --no-tags By default, tags that point at objects that are downloaded from the remote repository are fetched and stored locally. This option disables this automatic tag following. The default behavior for a remote may be specified with the remote.<name>.tagOpt setting. See git-config(1). --refetch Instead of negotiating with the server to avoid transferring commits and associated objects that are already present locally, this option fetches all objects as a fresh clone would. Use this to reapply a partial clone filter from configuration or using --filter= when the filter definition has changed. Automatic post-fetch maintenance will perform object database pack consolidation to remove any duplicate objects. --refmap=<refspec> When fetching refs listed on the command line, use the specified refspec (can be given more than once) to map the refs to remote-tracking branches, instead of the values of remote.*.fetch configuration variables for the remote repository. Providing an empty <refspec> to the --refmap option causes Git to ignore the configured refspecs and rely entirely on the refspecs supplied as command-line arguments. See section on \"Configured Remote-tracking Branches\" for details. -t, --tags Fetch all tags from the remote (i.e., fetch remote tags refs/tags/* into local tags with the same name), in addition to whatever else would otherwise be fetched. Using this option alone does not subject tags to pruning, even if --prune is used (though tags may be pruned anyway if they are also the destination of an explicit refspec; see --prune). --recurse-submodules[=yes|on-demand|no] This option controls if and under what conditions new commits of submodules should be fetched too. When recursing through submodules, git fetch always attempts to fetch \"changed\" submodules, that is, a submodule that has commits that are referenced by a newly fetched superproject commit but are missing in the local submodule clone. A changed submodule can be fetched as long as it is present locally e.g. in $GIT_DIR/modules/ (see gitsubmodules(7)); if the upstream adds a new submodule, that submodule cannot be fetched until it is cloned e.g. by git submodule update. When set to on-demand, only changed submodules are fetched. When set to yes, all populated submodules are fetched and submodules that are both unpopulated and changed are fetched. When set to no, submodules are never fetched. When unspecified, this uses the value of fetch.recurseSubmodules if it is set (see git-config(1)), defaulting to on-demand if unset. When this option is used without any value, it defaults to yes. -j, --jobs=<n> Number of parallel children to be used for all forms of fetching. If the --multiple option was specified, the different remotes will be fetched in parallel. If multiple submodules are fetched, they will be fetched in parallel. To control them independently, use the config settings fetch.parallel and submodule.fetchJobs (see git-config(1)). Typically, parallel recursive and multi-remote fetches will be faster. By default fetches are performed sequentially, not in parallel. --no-recurse-submodules Disable recursive fetching of submodules (this has the same effect as using the --recurse-submodules=no option). --set-upstream If the remote is fetched successfully, add upstream (tracking) reference, used by argument-less git-pull(1) and other commands. For more information, see branch.<name>.merge and branch.<name>.remote in git-config(1). --submodule-prefix=<path> Prepend <path> to paths printed in informative messages such as \"Fetching submodule foo\". This option is used internally when recursing over submodules. --recurse-submodules-default=[yes|on-demand] This option is used internally to temporarily provide a non-negative default value for the --recurse-submodules option. All other methods of configuring fetch\u2019s submodule recursion (such as settings in gitmodules(5) and git-config(1)) override this option, as does specifying --[no-]recurse-submodules directly. -u, --update-head-ok By default git fetch refuses to update the head which corresponds to the current branch. This flag disables the check. This is purely for the internal use for git pull to communicate with git fetch, and unless you are implementing your own Porcelain you are not supposed to use it. --upload-pack <upload-pack> When given, and the repository to fetch from is handled by git fetch-pack, --exec=<upload-pack> is passed to the command to specify non-default path for the command run on the other end. -q, --quiet Pass --quiet to git-fetch-pack and silence any other internally used git commands. Progress is not reported to the standard error stream. -v, --verbose Be verbose. --progress Progress status is reported on the standard error stream by default when it is attached to a terminal, unless -q is specified. This flag forces progress status even if the standard error stream is not directed to a terminal. -o <option>, --server-option=<option> Transmit the given string to the server when communicating using protocol version 2. The given string must not contain a NUL or LF character. The server\u2019s handling of server options, including unknown ones, is server-specific. When multiple --server-option=<option> are given, they are all sent to the other side in the order listed on the command line. --show-forced-updates By default, git checks if a branch is force-updated during fetch. This can be disabled through fetch.showForcedUpdates, but the --show-forced-updates option guarantees this check occurs. See git-config(1). --no-show-forced-updates By default, git checks if a branch is force-updated during fetch. Pass --no-show-forced-updates or set fetch.showForcedUpdates to false to skip this check for performance reasons. If used during git-pull the --ff-only option will still check for forced updates before attempting a fast-forward update. See git-config(1). -4, --ipv4 Use IPv4 addresses only, ignoring IPv6 addresses. -6, --ipv6 Use IPv6 addresses only, ignoring IPv4 addresses. <repository> The \"remote\" repository that is the source of a fetch or pull operation. This parameter can be either a URL (see the section GIT URLS below) or the name of a remote (see the section REMOTES below). <group> A name referring to a list of repositories as the value of remotes.<group> in the configuration file. (See git-config(1)). <refspec> Specifies which refs to fetch and which local refs to update. When no <refspec>s appear on the command line, the refs to fetch are read from remote.<repository>.fetch variables instead (see CONFIGURED REMOTE-TRACKING BRANCHES below). The format of a <refspec> parameter is an optional plus +, followed by the source <src>, followed by a colon :, followed by the destination ref <dst>. The colon can be omitted when <dst> is empty. <src> is typically a ref, but it can also be a fully spelled hex object name. A <refspec> may contain a * in its <src> to indicate a simple pattern match. Such a refspec functions like a glob that matches any ref with the same prefix. A pattern <refspec> must have a * in both the <src> and <dst>. It will map refs to the destination by replacing the * with the contents matched from the source. If a refspec is prefixed by ^, it will be interpreted as a negative refspec. Rather than specifying which refs to fetch or which local refs to update, such a refspec will instead specify refs to exclude. A ref will be considered to match if it matches at least one positive refspec, and does not match any negative refspec. Negative refspecs can be useful to restrict the scope of a pattern refspec so that it will not include specific refs. Negative refspecs can themselves be pattern refspecs. However, they may only contain a <src> and do not specify a <dst>. Fully spelled out hex object names are also not supported. tag <tag> means the same as refs/tags/<tag>:refs/tags/<tag>; it requests fetching everything up to the given tag. The remote ref that matches <src> is fetched, and if <dst> is not an empty string, an attempt is made to update the local ref that matches it. Whether that update is allowed without --force depends on the ref namespace it\u2019s being fetched to, the type of object being fetched, and whether the update is considered to be a fast-forward. Generally, the same rules apply for fetching as when pushing, see the <refspec>... section of git-push(1) for what those are. Exceptions to those rules particular to git fetch are noted below. Until Git version 2.20, and unlike when pushing with git-push(1), any updates to refs/tags/* would be accepted without + in the refspec (or --force). When fetching, we promiscuously considered all tag updates from a remote to be forced fetches. Since Git version 2.20, fetching to update refs/tags/* works the same way as when pushing. I.e. any updates will be rejected without + in the refspec (or --force). Unlike when pushing with git-push(1), any updates outside of refs/{tags,heads}/* will be accepted without + in the refspec (or --force), whether that\u2019s swapping e.g. a tree object for a blob, or a commit for another commit that\u2019s doesn\u2019t have the previous commit as an ancestor etc. Unlike when pushing with git-push(1), there is no configuration which\u2019ll amend these rules, and nothing like a pre-fetch hook analogous to the pre-receive hook. As with pushing with git-push(1), all of the rules described above about what\u2019s not allowed as an update can be overridden by adding an the optional leading + to a refspec (or using --force command line option). The only exception to this is that no amount of forcing will make the refs/heads/* namespace accept a non-commit object. Note When the remote branch you want to fetch is known to be rewound and rebased regularly, it is expected that its new tip will not be descendant of its previous tip (as stored in your remote-tracking branch the last time you fetched). You would want to use the + sign to indicate non-fast-forward updates will be needed for such branches. There is no way to determine or declare that a branch will be made available in a repository with this behavior; the pulling user simply must know this is the expected usage pattern for a branch. --stdin Read refspecs, one per line, from stdin in addition to those provided as arguments. The \"tag <name>\" format is not supported. "
  },
  {
    "command": "xargs",
    "description": " The xargs utility shall construct a command line consisting of the utility and argument operands specified followed by as many arguments read in sequence from standard input as fit in length and number constraints specified by the options. The xargs utility shall then invoke the constructed command line and wait for its completion. This sequence shall be repeated until one of the following occurs: * An end-of-file condition is detected on standard input. * An argument consisting of just the logical end-of-file string (see the -E eofstr option) is found on standard input after double-quote processing, <apostrophe> processing, and <backslash>-escape processing (see next paragraph). All arguments up to but not including the argument consisting of just the logical end-of-file string shall be used as arguments in constructed command lines. * An invocation of a constructed command line returns an exit status of 255. The application shall ensure that arguments in the standard input are separated by unquoted <blank> characters, unescaped <blank> characters, or <newline> characters. A string of zero or more non-double-quote ('\"') characters and non-<newline> characters can be quoted by enclosing them in double-quotes. A string of zero or more non-<apostrophe> ('\\'') characters and non-<newline> characters can be quoted by enclosing them in <apostrophe> characters. Any unquoted character can be escaped by preceding it with a <backslash>. The utility named by utility shall be executed one or more times until the end-of-file is reached or the logical end-of file string is found. The results are unspecified if the utility named by utility attempts to read from its standard input. The generated command line length shall be the sum of the size in bytes of the utility name and each argument treated as strings, including a null byte terminator for each of these strings. The xargs utility shall limit the command line length such that when the command line is invoked, the combined argument and environment lists (see the exec family of functions in the System Interfaces volume of POSIX.1\u20102017) shall not exceed {ARG_MAX}-2048 bytes. Within this constraint, if neither the -n nor the -s option is specified, the default command line length shall be at least {LINE_MAX}. The xargs utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -E eofstr Use eofstr as the logical end-of-file string. If -E is not specified, it is unspecified whether the logical end-of-file string is the <underscore> character ('_') or the end-of-file string capability is disabled. When eofstr is the null string, the logical end-of-file string capability shall be disabled and <underscore> characters shall be taken literally. -I replstr Insert mode: utility is executed for each logical line from standard input. Arguments in the standard input shall be separated only by unescaped <newline> characters, not by <blank> characters. Any unquoted unescaped <blank> characters at the beginning of each line shall be ignored. The resulting argument shall be inserted in arguments in place of each occurrence of replstr. At least five arguments in arguments can each contain one or more instances of replstr. Each of these constructed arguments cannot grow larger than an implementation-defined limit greater than or equal to 255 bytes. Option -x shall be forced on. -L number The utility shall be executed for each non-empty number lines of arguments from standard input. The last invocation of utility shall be with fewer lines of arguments if fewer than number remain. A line is considered to end with the first <newline> unless the last character of the line is an unescaped <blank>; a trailing unescaped <blank> signals continuation to the next non-empty line, inclusive. -n number Invoke utility using as many standard input arguments as possible, up to number (a positive decimal integer) arguments maximum. Fewer arguments shall be used if: * The command line length accumulated exceeds the size specified by the -s option (or {LINE_MAX} if there is no -s option). * The last iteration has fewer than number, but not zero, operands remaining. -p Prompt mode: the user is asked whether to execute utility at each invocation. Trace mode (-t) is turned on to write the command instance to be executed, followed by a prompt to standard error. An affirmative response read from /dev/tty shall execute the command; otherwise, that particular invocation of utility shall be skipped. -s size Invoke utility using as many standard input arguments as possible yielding a command line length less than size (a positive decimal integer) bytes. Fewer arguments shall be used if: * The total number of arguments exceeds that specified by the -n option. * The total number of lines exceeds that specified by the -L option. * End-of-file is encountered on standard input before size bytes are accumulated. Values of size up to at least {LINE_MAX} bytes shall be supported, provided that the constraints specified in the DESCRIPTION are met. It shall not be considered an error if a value larger than that supported by the implementation or exceeding the constraints specified in the DESCRIPTION is given; xargs shall use the largest value it supports within the constraints. -t Enable trace mode. Each generated command line shall be written to standard error just prior to invocation. -x Terminate if a constructed command line will not fit in the implied or specified size (see the -s option above). "
  },
  {
    "command": "jobs",
    "description": " The jobs utility shall display the status of jobs that were started in the current shell environment; see Section 2.12, Shell Execution Environment. When jobs reports the termination status of a job, the shell shall remove its process ID from the list of those ``known in the current shell execution environment''; see Section 2.9.3.1, Examples. The jobs utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -l (The letter ell.) Provide more information about each job listed. This information shall include the job number, current job, process group ID, state, and the command that formed the job. -p Display only the process IDs for the process group leaders of the selected jobs. By default, the jobs utility shall display the status of all stopped jobs, running background jobs and all jobs whose status has changed and have not been reported by the shell. "
  },
  {
    "command": "objdump",
    "description": " objdump displays information about one or more object files. The options control what particular information to display. This information is mostly useful to programmers who are working on the compilation tools, as opposed to programmers who just want their program to compile and work. objfile... are the object files to be examined. When you specify archives, objdump shows information on each of the member object files. The long and short forms of options, shown here as alternatives, are equivalent. At least one option from the list -a,-d,-D,-e,-f,-g,-G,-h,-H,-p,-P,-r,-R,-s,-S,-t,-T,-V,-x must be given. -a --archive-header If any of the objfile files are archives, display the archive header information (in a format similar to ls -l). Besides the information you could list with ar tv, objdump -a shows the object file format of each archive member. --adjust-vma=offset When dumping information, first add offset to all the section addresses. This is useful if the section addresses do not correspond to the symbol table, which can happen when putting sections at particular addresses when using a format which can not represent section addresses, such as a.out. -b bfdname --target=bfdname Specify that the object-code format for the object files is bfdname. This option may not be necessary; objdump can automatically recognize many formats. For example, objdump -b oasys -m vax -h fu.o displays summary information from the section headers (-h) of fu.o, which is explicitly identified (-m) as a VAX object file in the format produced by Oasys compilers. You can list the formats available with the -i option. -C --demangle[=style] Decode (demangle) low-level symbol names into user-level names. Besides removing any initial underscore prepended by the system, this makes C++ function names readable. Different compilers have different mangling styles. The optional demangling style argument can be used to choose an appropriate demangling style for your compiler. --recurse-limit --no-recurse-limit --recursion-limit --no-recursion-limit Enables or disables a limit on the amount of recursion performed whilst demangling strings. Since the name mangling formats allow for an infinite level of recursion it is possible to create strings whose decoding will exhaust the amount of stack space available on the host machine, triggering a memory fault. The limit tries to prevent this from happening by restricting recursion to 2048 levels of nesting. The default is for this limit to be enabled, but disabling it may be necessary in order to demangle truly complicated names. Note however that if the recursion limit is disabled then stack exhaustion is possible and any bug reports about such an event will be rejected. -g --debugging Display debugging information. This attempts to parse STABS debugging format information stored in the file and print it out using a C like syntax. If no STABS debugging was found this option falls back on the -W option to print any DWARF information in the file. -e --debugging-tags Like -g, but the information is generated in a format compatible with ctags tool. -d --disassemble --disassemble=symbol Display the assembler mnemonics for the machine instructions from the input file. This option only disassembles those sections which are expected to contain instructions. If the optional symbol argument is given, then display the assembler mnemonics starting at symbol. If symbol is a function name then disassembly will stop at the end of the function, otherwise it will stop when the next symbol is encountered. If there are no matches for symbol then nothing will be displayed. Note if the --dwarf=follow-links option is enabled then any symbol tables in linked debug info files will be read in and used when disassembling. -D --disassemble-all Like -d, but disassemble the contents of all sections, not just those expected to contain instructions. This option also has a subtle effect on the disassembly of instructions in code sections. When option -d is in effect objdump will assume that any symbols present in a code section occur on the boundary between instructions and it will refuse to disassemble across such a boundary. When option -D is in effect however this assumption is supressed. This means that it is possible for the output of -d and -D to differ if, for example, data is stored in code sections. If the target is an ARM architecture this switch also has the effect of forcing the disassembler to decode pieces of data found in code sections as if they were instructions. Note if the --dwarf=follow-links option is enabled then any symbol tables in linked debug info files will be read in and used when disassembling. --no-addresses When disassembling, don't print addresses on each line or for symbols and relocation offsets. In combination with --no-show-raw-insn this may be useful for comparing compiler output. --prefix-addresses When disassembling, print the complete address on each line. This is the older disassembly format. -EB -EL --endian={big|little} Specify the endianness of the object files. This only affects disassembly. This can be useful when disassembling a file format which does not describe endianness information, such as S-records. -f --file-headers Display summary information from the overall header of each of the objfile files. -F --file-offsets When disassembling sections, whenever a symbol is displayed, also display the file offset of the region of data that is about to be dumped. If zeroes are being skipped, then when disassembly resumes, tell the user how many zeroes were skipped and the file offset of the location from where the disassembly resumes. When dumping sections, display the file offset of the location from where the dump starts. --file-start-context Specify that when displaying interlisted source code/disassembly (assumes -S) from a file that has not yet been displayed, extend the context to the start of the file. -h --section-headers --headers Display summary information from the section headers of the object file. File segments may be relocated to nonstandard addresses, for example by using the -Ttext, -Tdata, or -Tbss options to ld. However, some object file formats, such as a.out, do not store the starting address of the file segments. In those situations, although ld relocates the sections correctly, using objdump -h to list the file section headers cannot show the correct addresses. Instead, it shows the usual addresses, which are implicit for the target. Note, in some cases it is possible for a section to have both the READONLY and the NOREAD attributes set. In such cases the NOREAD attribute takes precedence, but objdump will report both since the exact setting of the flag bits might be important. -H --help Print a summary of the options to objdump and exit. -i --info Display a list showing all architectures and object formats available for specification with -b or -m. -j name --section=name Display information only for section name. -L --process-links Display the contents of non-debug sections found in separate debuginfo files that are linked to the main file. This option automatically implies the -WK option, and only sections requested by other command line options will be displayed. -l --line-numbers Label the display (using debugging information) with the filename and source line numbers corresponding to the object code or relocs shown. Only useful with -d, -D, or -r. -m machine --architecture=machine Specify the architecture to use when disassembling object files. This can be useful when disassembling object files which do not describe architecture information, such as S-records. You can list the available architectures with the -i option. For most architectures it is possible to supply an architecture name and a machine name, separated by a colon. For example foo:bar would refer to the bar machine type in the foo architecture. This can be helpful if objdump has been configured to support multiple architectures. If the target is an ARM architecture then this switch has an additional effect. It restricts the disassembly to only those instructions supported by the architecture specified by machine. If it is necessary to use this switch because the input file does not contain any architecture information, but it is also desired to disassemble all the instructions use -marm. -M options --disassembler-options=options Pass target specific information to the disassembler. Only supported on some targets. If it is necessary to specify more than one disassembler option then multiple -M options can be used or can be placed together into a comma separated list. For ARC, dsp controls the printing of DSP instructions, spfp selects the printing of FPX single precision FP instructions, dpfp selects the printing of FPX double precision FP instructions, quarkse_em selects the printing of special QuarkSE-EM instructions, fpuda selects the printing of double precision assist instructions, fpus selects the printing of FPU single precision FP instructions, while fpud selects the printing of FPU double precision FP instructions. Additionally, one can choose to have all the immediates printed in hexadecimal using hex. By default, the short immediates are printed using the decimal representation, while the long immediate values are printed as hexadecimal. cpu=... allows one to enforce a particular ISA when disassembling instructions, overriding the -m value or whatever is in the ELF file. This might be useful to select ARC EM or HS ISA, because architecture is same for those and disassembler relies on private ELF header data to decide if code is for EM or HS. This option might be specified multiple times - only the latest value will be used. Valid values are same as for the assembler -mcpu=... option. If the target is an ARM architecture then this switch can be used to select which register name set is used during disassembler. Specifying -M reg-names-std (the default) will select the register names as used in ARM's instruction set documentation, but with register 13 called 'sp', register 14 called 'lr' and register 15 called 'pc'. Specifying -M reg- names-apcs will select the name set used by the ARM Procedure Call Standard, whilst specifying -M reg-names-raw will just use r followed by the register number. There are also two variants on the APCS register naming scheme enabled by -M reg-names-atpcs and -M reg-names- special-atpcs which use the ARM/Thumb Procedure Call Standard naming conventions. (Either with the normal register names or the special register names). This option can also be used for ARM architectures to force the disassembler to interpret all instructions as Thumb instructions by using the switch --disassembler-options=force-thumb. This can be useful when attempting to disassemble thumb code produced by other compilers. For AArch64 targets this switch can be used to set whether instructions are disassembled as the most general instruction using the -M no-aliases option or whether instruction notes should be generated as comments in the disasssembly using -M notes. For the x86, some of the options duplicate functions of the -m switch, but allow finer grained control. \"x86-64\" \"i386\" \"i8086\" Select disassembly for the given architecture. \"intel\" \"att\" Select between intel syntax mode and AT&T syntax mode. \"amd64\" \"intel64\" Select between AMD64 ISA and Intel64 ISA. \"intel-mnemonic\" \"att-mnemonic\" Select between intel mnemonic mode and AT&T mnemonic mode. Note: \"intel-mnemonic\" implies \"intel\" and \"att-mnemonic\" implies \"att\". \"addr64\" \"addr32\" \"addr16\" \"data32\" \"data16\" Specify the default address size and operand size. These five options will be overridden if \"x86-64\", \"i386\" or \"i8086\" appear later in the option string. \"suffix\" When in AT&T mode and also for a limited set of instructions when in Intel mode, instructs the disassembler to print a mnemonic suffix even when the suffix could be inferred by the operands or, for certain instructions, the execution mode's defaults. For PowerPC, the -M argument raw selects disasssembly of hardware insns rather than aliases. For example, you will see \"rlwinm\" rather than \"clrlwi\", and \"addi\" rather than \"li\". All of the -m arguments for gas that select a CPU are supported. These are: 403, 405, 440, 464, 476, 601, 603, 604, 620, 7400, 7410, 7450, 7455, 750cl, 821, 850, 860, a2, booke, booke32, cell, com, e200z2, e200z4, e300, e500, e500mc, e500mc64, e500x2, e5500, e6500, efs, power4, power5, power6, power7, power8, power9, power10, ppc, ppc32, ppc64, ppc64bridge, ppcps, pwr, pwr2, pwr4, pwr5, pwr5x, pwr6, pwr7, pwr8, pwr9, pwr10, pwrx, titan, vle, and future. 32 and 64 modify the default or a prior CPU selection, disabling and enabling 64-bit insns respectively. In addition, altivec, any, lsp, htm, vsx, spe and spe2 add capabilities to a previous or later CPU selection. any will disassemble any opcode known to binutils, but in cases where an opcode has two different meanings or different arguments, you may not see the disassembly you expect. If you disassemble without giving a CPU selection, a default will be chosen from information gleaned by BFD from the object files headers, but the result again may not be as you expect. For MIPS, this option controls the printing of instruction mnemonic names and register names in disassembled instructions. Multiple selections from the following may be specified as a comma separated string, and invalid options are ignored: \"no-aliases\" Print the 'raw' instruction mnemonic instead of some pseudo instruction mnemonic. I.e., print 'daddu' or 'or' instead of 'move', 'sll' instead of 'nop', etc. \"msa\" Disassemble MSA instructions. \"virt\" Disassemble the virtualization ASE instructions. \"xpa\" Disassemble the eXtended Physical Address (XPA) ASE instructions. \"gpr-names=ABI\" Print GPR (general-purpose register) names as appropriate for the specified ABI. By default, GPR names are selected according to the ABI of the binary being disassembled. \"fpr-names=ABI\" Print FPR (floating-point register) names as appropriate for the specified ABI. By default, FPR numbers are printed rather than names. \"cp0-names=ARCH\" Print CP0 (system control coprocessor; coprocessor 0) register names as appropriate for the CPU or architecture specified by ARCH. By default, CP0 register names are selected according to the architecture and CPU of the binary being disassembled. \"hwr-names=ARCH\" Print HWR (hardware register, used by the \"rdhwr\" instruction) names as appropriate for the CPU or architecture specified by ARCH. By default, HWR names are selected according to the architecture and CPU of the binary being disassembled. \"reg-names=ABI\" Print GPR and FPR names as appropriate for the selected ABI. \"reg-names=ARCH\" Print CPU-specific register names (CP0 register and HWR names) as appropriate for the selected CPU or architecture. For any of the options listed above, ABI or ARCH may be specified as numeric to have numbers printed rather than names, for the selected types of registers. You can list the available values of ABI and ARCH using the --help option. For VAX, you can specify function entry addresses with -M entry:0xf00ba. You can use this multiple times to properly disassemble VAX binary files that don't contain symbol tables (like ROM dumps). In these cases, the function entry mask would otherwise be decoded as VAX instructions, which would probably lead the rest of the function being wrongly disassembled. -p --private-headers Print information that is specific to the object file format. The exact information printed depends upon the object file format. For some object file formats, no additional information is printed. -P options --private=options Print information that is specific to the object file format. The argument options is a comma separated list that depends on the format (the lists of options is displayed with the help). For XCOFF, the available options are: \"header\" \"aout\" \"sections\" \"syms\" \"relocs\" \"lineno,\" \"loader\" \"except\" \"typchk\" \"traceback\" \"toc\" \"ldinfo\" Not all object formats support this option. In particular the ELF format does not use it. -r --reloc Print the relocation entries of the file. If used with -d or -D, the relocations are printed interspersed with the disassembly. -R --dynamic-reloc Print the dynamic relocation entries of the file. This is only meaningful for dynamic objects, such as certain types of shared libraries. As for -r, if used with -d or -D, the relocations are printed interspersed with the disassembly. -s --full-contents Display the full contents of any sections requested. By default all non-empty sections are displayed. -S --source Display source code intermixed with disassembly, if possible. Implies -d. --show-all-symbols When disassembling, show all the symbols that match a given address, not just the first one. --source-comment[=txt] Like the -S option, but all source code lines are displayed with a prefix of txt. Typically txt will be a comment string which can be used to distinguish the assembler code from the source code. If txt is not provided then a default string of \"# \" (hash followed by a space), will be used. --prefix=prefix Specify prefix to add to the absolute paths when used with -S. --prefix-strip=level Indicate how many initial directory names to strip off the hardwired absolute paths. It has no effect without --prefix=prefix. --show-raw-insn When disassembling instructions, print the instruction in hex as well as in symbolic form. This is the default except when --prefix-addresses is used. --no-show-raw-insn When disassembling instructions, do not print the instruction bytes. This is the default when --prefix-addresses is used. --insn-width=width Display width bytes on a single line when disassembling instructions. --visualize-jumps[=color|=extended-color|=off] Visualize jumps that stay inside a function by drawing ASCII art between the start and target addresses. The optional =color argument adds color to the output using simple terminal colors. Alternatively the =extended-color argument will add color using 8bit colors, but these might not work on all terminals. If it is necessary to disable the visualize-jumps option after it has previously been enabled then use visualize-jumps=off. --disassembler-color=off --disassembler-color=terminal --disassembler-color=on|color|colour --disassembler-color=extened|extended-color|extened-colour Enables or disables the use of colored syntax highlighting in disassembly output. The default behaviour is determined via a configure time option. Note, not all architectures support colored syntax highlighting, and depending upon the terminal used, colored output may not actually be legible. The on argument adds colors using simple terminal colors. The terminal argument does the same, but only if the output device is a terminal. The extended-color argument is similar to the on argument, but it uses 8-bit colors. These may not work on all terminals. The off argument disables colored disassembly. -W[lLiaprmfFsoORtUuTgAckK] --dwarf[=rawline,=decodedline,=info,=abbrev,=pubnames,=aranges,=macro,=frames,=frames-interp,=str,=str-offsets,=loc,=Ranges,=pubtypes,=trace_info,=trace_abbrev,=trace_aranges,=gdb_index,=addr,=cu_index,=links,=follow-links] Displays the contents of the DWARF debug sections in the file, if any are present. Compressed debug sections are automatically decompressed (temporarily) before they are displayed. If one or more of the optional letters or words follows the switch then only those type(s) of data will be dumped. The letters and words refer to the following information: \"a\" \"=abbrev\" Displays the contents of the .debug_abbrev section. \"A\" \"=addr\" Displays the contents of the .debug_addr section. \"c\" \"=cu_index\" Displays the contents of the .debug_cu_index and/or .debug_tu_index sections. \"f\" \"=frames\" Display the raw contents of a .debug_frame section. \"F\" \"=frames-interp\" Display the interpreted contents of a .debug_frame section. \"g\" \"=gdb_index\" Displays the contents of the .gdb_index and/or .debug_names sections. \"i\" \"=info\" Displays the contents of the .debug_info section. Note: the output from this option can also be restricted by the use of the --dwarf-depth and --dwarf-start options. \"k\" \"=links\" Displays the contents of the .gnu_debuglink, .gnu_debugaltlink and .debug_sup sections, if any of them are present. Also displays any links to separate dwarf object files (dwo), if they are specified by the DW_AT_GNU_dwo_name or DW_AT_dwo_name attributes in the .debug_info section. \"K\" \"=follow-links\" Display the contents of any selected debug sections that are found in linked, separate debug info file(s). This can result in multiple versions of the same debug section being displayed if it exists in more than one file. In addition, when displaying DWARF attributes, if a form is found that references the separate debug info file, then the referenced contents will also be displayed. Note - in some distributions this option is enabled by default. It can be disabled via the N debug option. The default can be chosen when configuring the binutils via the --enable-follow-debug-links=yes or --enable-follow-debug-links=no options. If these are not used then the default is to enable the following of debug links. Note - if support for the debuginfod protocol was enabled when the binutils were built then this option will also include an attempt to contact any debuginfod servers mentioned in the DEBUGINFOD_URLS environment variable. This could take some time to resolve. This behaviour can be disabled via the =do-not-use-debuginfod debug option. \"N\" \"=no-follow-links\" Disables the following of links to separate debug info files. \"D\" \"=use-debuginfod\" Enables contacting debuginfod servers if there is a need to follow debug links. This is the default behaviour. \"E\" \"=do-not-use-debuginfod\" Disables contacting debuginfod servers when there is a need to follow debug links. \"l\" \"=rawline\" Displays the contents of the .debug_line section in a raw format. \"L\" \"=decodedline\" Displays the interpreted contents of the .debug_line section. \"m\" \"=macro\" Displays the contents of the .debug_macro and/or .debug_macinfo sections. \"o\" \"=loc\" Displays the contents of the .debug_loc and/or .debug_loclists sections. \"O\" \"=str-offsets\" Displays the contents of the .debug_str_offsets section. \"p\" \"=pubnames\" Displays the contents of the .debug_pubnames and/or .debug_gnu_pubnames sections. \"r\" \"=aranges\" Displays the contents of the .debug_aranges section. \"R\" \"=Ranges\" Displays the contents of the .debug_ranges and/or .debug_rnglists sections. \"s\" \"=str\" Displays the contents of the .debug_str, .debug_line_str and/or .debug_str_offsets sections. \"t\" \"=pubtype\" Displays the contents of the .debug_pubtypes and/or .debug_gnu_pubtypes sections. \"T\" \"=trace_aranges\" Displays the contents of the .trace_aranges section. \"u\" \"=trace_abbrev\" Displays the contents of the .trace_abbrev section. \"U\" \"=trace_info\" Displays the contents of the .trace_info section. Note: displaying the contents of .debug_static_funcs, .debug_static_vars and debug_weaknames sections is not currently supported. --dwarf-depth=n Limit the dump of the \".debug_info\" section to n children. This is only useful with --debug-dump=info. The default is to print all DIEs; the special value 0 for n will also have this effect. With a non-zero value for n, DIEs at or deeper than n levels will not be printed. The range for n is zero-based. --dwarf-start=n Print only DIEs beginning with the DIE numbered n. This is only useful with --debug-dump=info. If specified, this option will suppress printing of any header information and all DIEs before the DIE numbered n. Only siblings and children of the specified DIE will be printed. This can be used in conjunction with --dwarf-depth. --dwarf-check Enable additional checks for consistency of Dwarf information. --ctf[=section] Display the contents of the specified CTF section. CTF sections themselves contain many subsections, all of which are displayed in order. By default, display the name of the section named .ctf, which is the name emitted by ld. --ctf-parent=member If the CTF section contains ambiguously-defined types, it will consist of an archive of many CTF dictionaries, all inheriting from one dictionary containing unambiguous types. This member is by default named .ctf, like the section containing it, but it is possible to change this name using the \"ctf_link_set_memb_name_changer\" function at link time. When looking at CTF archives that have been created by a linker that uses the name changer to rename the parent archive member, --ctf-parent can be used to specify the name used for the parent. --sframe[=section] Display the contents of the specified SFrame section. By default, display the name of the section named .sframe, which is the name emitted by ld. -G --stabs Display the full contents of any sections requested. Display the contents of the .stab and .stab.index and .stab.excl sections from an ELF file. This is only useful on systems (such as Solaris 2.0) in which \".stab\" debugging symbol-table entries are carried in an ELF section. In most other file formats, debugging symbol-table entries are interleaved with linkage symbols, and are visible in the --syms output. --start-address=address Start displaying data at the specified address. This affects the output of the -d, -r and -s options. --stop-address=address Stop displaying data at the specified address. This affects the output of the -d, -r and -s options. -t --syms Print the symbol table entries of the file. This is similar to the information provided by the nm program, although the display format is different. The format of the output depends upon the format of the file being dumped, but there are two main types. One looks like this: [ 4](sec 3)(fl 0x00)(ty 0)(scl 3) (nx 1) 0x00000000 .bss [ 6](sec 1)(fl 0x00)(ty 0)(scl 2) (nx 0) 0x00000000 fred where the number inside the square brackets is the number of the entry in the symbol table, the sec number is the section number, the fl value are the symbol's flag bits, the ty number is the symbol's type, the scl number is the symbol's storage class and the nx value is the number of auxiliary entries associated with the symbol. The last two fields are the symbol's value and its name. The other common output format, usually seen with ELF based files, looks like this: 00000000 l d .bss 00000000 .bss 00000000 g .text 00000000 fred Here the first number is the symbol's value (sometimes referred to as its address). The next field is actually a set of characters and spaces indicating the flag bits that are set on the symbol. These characters are described below. Next is the section with which the symbol is associated or *ABS* if the section is absolute (ie not connected with any section), or *UND* if the section is referenced in the file being dumped, but not defined there. After the section name comes another field, a number, which for common symbols is the alignment and for other symbol is the size. Finally the symbol's name is displayed. The flag characters are divided into 7 groups as follows: \"l\" \"g\" \"u\" \"!\" The symbol is a local (l), global (g), unique global (u), neither global nor local (a space) or both global and local (!). A symbol can be neither local or global for a variety of reasons, e.g., because it is used for debugging, but it is probably an indication of a bug if it is ever both local and global. Unique global symbols are a GNU extension to the standard set of ELF symbol bindings. For such a symbol the dynamic linker will make sure that in the entire process there is just one symbol with this name and type in use. \"w\" The symbol is weak (w) or strong (a space). \"C\" The symbol denotes a constructor (C) or an ordinary symbol (a space). \"W\" The symbol is a warning (W) or a normal symbol (a space). A warning symbol's name is a message to be displayed if the symbol following the warning symbol is ever referenced. \"I\" \"i\" The symbol is an indirect reference to another symbol (I), a function to be evaluated during reloc processing (i) or a normal symbol (a space). \"d\" \"D\" The symbol is a debugging symbol (d) or a dynamic symbol (D) or a normal symbol (a space). \"F\" \"f\" \"O\" The symbol is the name of a function (F) or a file (f) or an object (O) or just a normal symbol (a space). -T --dynamic-syms Print the dynamic symbol table entries of the file. This is only meaningful for dynamic objects, such as certain types of shared libraries. This is similar to the information provided by the nm program when given the -D (--dynamic) option. The output format is similar to that produced by the --syms option, except that an extra field is inserted before the symbol's name, giving the version information associated with the symbol. If the version is the default version to be used when resolving unversioned references to the symbol then it's displayed as is, otherwise it's put into parentheses. --special-syms When displaying symbols include those which the target considers to be special in some way and which would not normally be of interest to the user. -U [d|i|l|e|x|h] --unicode=[default|invalid|locale|escape|hex|highlight] Controls the display of UTF-8 encoded multibyte characters in strings. The default (--unicode=default) is to give them no special treatment. The --unicode=locale option displays the sequence in the current locale, which may or may not support them. The options --unicode=hex and --unicode=invalid display them as hex byte sequences enclosed by either angle brackets or curly braces. The --unicode=escape option displays them as escape sequences (\\uxxxx) and the --unicode=highlight option displays them as escape sequences highlighted in red (if supported by the output device). The colouring is intended to draw attention to the presence of unicode sequences where they might not be expected. -V --version Print the version number of objdump and exit. -x --all-headers Display all available header information, including the symbol table and relocation entries. Using -x is equivalent to specifying all of -a -f -h -p -r -t. -w --wide Format some lines for output devices that have more than 80 columns. Also do not truncate symbol names when they are displayed. -z --disassemble-zeroes Normally the disassembly output will skip blocks of zeroes. This option directs the disassembler to disassemble those blocks, just like any other data. @file Read command-line options from file. The options read are inserted in place of the original @file option. If file does not exist, or cannot be read, then the option will be treated literally, and not removed. Options in file are separated by whitespace. A whitespace character may be included in an option by surrounding the entire option in either single or double quotes. Any character (including a backslash) may be included by prefixing the character to be included with a backslash. The file may itself contain additional @file options; any such options will be processed recursively. "
  },
  {
    "command": "git-worktree",
    "description": " Manage multiple working trees attached to the same repository. A git repository can support multiple working trees, allowing you to check out more than one branch at a time. With git worktree add a new working tree is associated with the repository, along with additional metadata that differentiates that working tree from others in the same repository. The working tree, along with this metadata, is called a \"worktree\". This new worktree is called a \"linked worktree\" as opposed to the \"main worktree\" prepared by git-init(1) or git-clone(1). A repository has one main worktree (if it\u2019s not a bare repository) and zero or more linked worktrees. When you are done with a linked worktree, remove it with git worktree remove. In its simplest form, git worktree add <path> automatically creates a new branch whose name is the final component of <path>, which is convenient if you plan to work on a new topic. For instance, git worktree add ../hotfix creates new branch hotfix and checks it out at path ../hotfix. To instead work on an existing branch in a new worktree, use git worktree add <path> <branch>. On the other hand, if you just plan to make some experimental changes or do testing without disturbing existing development, it is often convenient to create a throwaway worktree not associated with any branch. For instance, git worktree add -d <path> creates a new worktree with a detached HEAD at the same commit as the current branch. If a working tree is deleted without using git worktree remove, then its associated administrative files, which reside in the repository (see \"DETAILS\" below), will eventually be removed automatically (see gc.worktreePruneExpire in git-config(1)), or you can run git worktree prune in the main or any linked worktree to clean up any stale administrative files. If the working tree for a linked worktree is stored on a portable device or network share which is not always mounted, you can prevent its administrative files from being pruned by issuing the git worktree lock command, optionally specifying --reason to explain why the worktree is locked. -f, --force By default, add refuses to create a new worktree when <commit-ish> is a branch name and is already checked out by another worktree, or if <path> is already assigned to some worktree but is missing (for instance, if <path> was deleted manually). This option overrides these safeguards. To add a missing but locked worktree path, specify --force twice. move refuses to move a locked worktree unless --force is specified twice. If the destination is already assigned to some other worktree but is missing (for instance, if <new-path> was deleted manually), then --force allows the move to proceed; use --force twice if the destination is locked. remove refuses to remove an unclean worktree unless --force is used. To remove a locked worktree, specify --force twice. -b <new-branch>, -B <new-branch> With add, create a new branch named <new-branch> starting at <commit-ish>, and check out <new-branch> into the new worktree. If <commit-ish> is omitted, it defaults to HEAD. By default, -b refuses to create a new branch if it already exists. -B overrides this safeguard, resetting <new-branch> to <commit-ish>. -d, --detach With add, detach HEAD in the new worktree. See \"DETACHED HEAD\" in git-checkout(1). --[no-]checkout By default, add checks out <commit-ish>, however, --no-checkout can be used to suppress checkout in order to make customizations, such as configuring sparse-checkout. See \"Sparse checkout\" in git-read-tree(1). --[no-]guess-remote With worktree add <path>, without <commit-ish>, instead of creating a new branch from HEAD, if there exists a tracking branch in exactly one remote matching the basename of <path>, base the new branch on the remote-tracking branch, and mark the remote-tracking branch as \"upstream\" from the new branch. This can also be set up as the default behaviour by using the worktree.guessRemote config option. --[no-]track When creating a new branch, if <commit-ish> is a branch, mark it as \"upstream\" from the new branch. This is the default if <commit-ish> is a remote-tracking branch. See --track in git-branch(1) for details. --lock Keep the worktree locked after creation. This is the equivalent of git worktree lock after git worktree add, but without a race condition. -n, --dry-run With prune, do not remove anything; just report what it would remove. --orphan With add, make the new worktree and index empty, associating the worktree with a new orphan/unborn branch named <new-branch>. --porcelain With list, output in an easy-to-parse format for scripts. This format will remain stable across Git versions and regardless of user configuration. It is recommended to combine this with -z. See below for details. -z Terminate each line with a NUL rather than a newline when --porcelain is specified with list. This makes it possible to parse the output when a worktree path contains a newline character. -q, --quiet With add, suppress feedback messages. -v, --verbose With prune, report all removals. With list, output additional information about worktrees (see below). --expire <time> With prune, only expire unused worktrees older than <time>. With list, annotate missing worktrees as prunable if they are older than <time>. --reason <string> With lock or with add --lock, an explanation why the worktree is locked. <worktree> Worktrees can be identified by path, either relative or absolute. If the last path components in the worktree\u2019s path is unique among worktrees, it can be used to identify a worktree. For example if you only have two worktrees, at /abc/def/ghi and /abc/def/ggg, then ghi or def/ghi is enough to point to the former worktree. "
  },
  {
    "command": "tee",
    "description": " Copy standard input to each FILE, and also to standard output. -a, --append append to the given FILEs, do not overwrite -i, --ignore-interrupts ignore interrupt signals -p operate in a more appropriate MODE with pipes. --output-error[=MODE] set behavior on write error. See MODE below --help display this help and exit --version output version information and exit MODE determines behavior with write errors on the outputs: warn diagnose errors writing to any output warn-nopipe diagnose errors writing to any output not a pipe exit exit on error writing to any output exit-nopipe exit on error writing to any output not a pipe The default MODE for the -p option is 'warn-nopipe'. With \"nopipe\" MODEs, exit immediately if all outputs become broken pipes. The default operation when --output-error is not specified, is to exit immediately on error writing to a pipe, and diagnose errors writing to non pipe outputs. "
  },
  {
    "command": "git-cvsexportcommit",
    "description": " Exports a commit from Git to a CVS checkout, making it easier to merge patches from a Git repository into a CVS repository. Specify the name of a CVS checkout using the -w switch or execute it from the root of the CVS working copy. In the latter case GIT_DIR must be defined. See examples below. It does its best to do the safe thing, it will check that the files are unchanged and up to date in the CVS checkout, and it will not autocommit by default. Supports file additions, removals, and commits that affect binary files. If the commit is a merge commit, you must tell git cvsexportcommit what parent the changeset should be done against. -c Commit automatically if the patch applied cleanly. It will not commit if any hunks fail to apply or there were other problems. -p Be pedantic (paranoid) when applying patches. Invokes patch with --fuzz=0 -a Add authorship information. Adds Author line, and Committer (if different from Author) to the message. -d Set an alternative CVSROOT to use. This corresponds to the CVS -d parameter. Usually users will not want to set this, except if using CVS in an asymmetric fashion. -f Force the merge even if the files are not up to date. -P Force the parent commit, even if it is not a direct parent. -m Prepend the commit message with the provided prefix. Useful for patch series and the like. -u Update affected files from CVS repository before attempting export. -k Reverse CVS keyword expansion (e.g. $Revision: 1.2.3.4$ becomes $Revision$) in working CVS checkout before applying patch. -w Specify the location of the CVS checkout to use for the export. This option does not require GIT_DIR to be set before execution if the current directory is within a Git repository. The default is the value of cvsexportcommit.cvsdir. -W Tell cvsexportcommit that the current working directory is not only a Git checkout, but also the CVS checkout. Therefore, Git will reset the working directory to the parent commit before proceeding. -v Verbose. "
  },
  {
    "command": "sdiff",
    "description": " Side-by-side merge of differences between FILE1 and FILE2. Mandatory arguments to long options are mandatory for short options too. -o, --output=FILE operate interactively, sending output to FILE -i, --ignore-case consider upper- and lower-case to be the same -E, --ignore-tab-expansion ignore changes due to tab expansion -Z, --ignore-trailing-space ignore white space at line end -b, --ignore-space-change ignore changes in the amount of white space -W, --ignore-all-space ignore all white space -B, --ignore-blank-lines ignore changes whose lines are all blank -I, --ignore-matching-lines=RE ignore changes all whose lines match RE --strip-trailing-cr strip trailing carriage return on input -a, --text treat all files as text -w, --width=NUM output at most NUM (default 130) print columns -l, --left-column output only the left column of common lines -s, --suppress-common-lines do not output common lines -t, --expand-tabs expand tabs to spaces in output --tabsize=NUM tab stops at every NUM (default 8) print columns -d, --minimal try hard to find a smaller set of changes -H, --speed-large-files assume large files, many scattered small changes --diff-program=PROGRAM use PROGRAM to compare files --help display this help and exit -v, --version output version information and exit If a FILE is '-', read standard input. Exit status is 0 if inputs are the same, 1 if different, 2 if trouble. "
  },
  {
    "command": "dir",
    "description": " List information about the FILEs (the current directory by default). Sort entries alphabetically if none of -cftuvSUX nor --sort is specified. Mandatory arguments to long options are mandatory for short options too. -a, --all do not ignore entries starting with . -A, --almost-all do not list implied . and .. --author with -l, print the author of each file -b, --escape print C-style escapes for nongraphic characters --block-size=SIZE with -l, scale sizes by SIZE when printing them; e.g., '--block-size=M'; see SIZE format below -B, --ignore-backups do not list implied entries ending with ~ -c with -lt: sort by, and show, ctime (time of last change of file status information); with -l: show ctime and sort by name; otherwise: sort by ctime, newest first -C list entries by columns --color[=WHEN] color the output WHEN; more info below -d, --directory list directories themselves, not their contents -D, --dired generate output designed for Emacs' dired mode -f list all entries in directory order -F, --classify[=WHEN] append indicator (one of */=>@|) to entries WHEN --file-type likewise, except do not append '*' --format=WORD across -x, commas -m, horizontal -x, long -l, single-column -1, verbose -l, vertical -C --full-time like -l --time-style=full-iso -g like -l, but do not list owner --group-directories-first group directories before files; can be augmented with a --sort option, but any use of --sort=none (-U) disables grouping -G, --no-group in a long listing, don't print group names -h, --human-readable with -l and -s, print sizes like 1K 234M 2G etc. --si likewise, but use powers of 1000 not 1024 -H, --dereference-command-line follow symbolic links listed on the command line --dereference-command-line-symlink-to-dir follow each command line symbolic link that points to a directory --hide=PATTERN do not list implied entries matching shell PATTERN (overridden by -a or -A) --hyperlink[=WHEN] hyperlink file names WHEN --indicator-style=WORD append indicator with style WORD to entry names: none (default), slash (-p), file-type (--file-type), classify (-F) -i, --inode print the index number of each file -I, --ignore=PATTERN do not list implied entries matching shell PATTERN -k, --kibibytes default to 1024-byte blocks for file system usage; used only with -s and per directory totals -l use a long listing format -L, --dereference when showing file information for a symbolic link, show information for the file the link references rather than for the link itself -m fill width with a comma separated list of entries -n, --numeric-uid-gid like -l, but list numeric user and group IDs -N, --literal print entry names without quoting -o like -l, but do not list group information -p, --indicator-style=slash append / indicator to directories -q, --hide-control-chars print ? instead of nongraphic characters --show-control-chars show nongraphic characters as-is (the default, unless program is 'ls' and output is a terminal) -Q, --quote-name enclose entry names in double quotes --quoting-style=WORD use quoting style WORD for entry names: literal, locale, shell, shell-always, shell-escape, shell-escape-always, c, escape (overrides QUOTING_STYLE environment variable) -r, --reverse reverse order while sorting -R, --recursive list subdirectories recursively -s, --size print the allocated size of each file, in blocks -S sort by file size, largest first --sort=WORD sort by WORD instead of name: none (-U), size (-S), time (-t), version (-v), extension (-X), width --time=WORD select which timestamp used to display or sort; access time (-u): atime, access, use; metadata change time (-c): ctime, status; modified time (default): mtime, modification; birth time: birth, creation; with -l, WORD determines which time to show; with --sort=time, sort by WORD (newest first) --time-style=TIME_STYLE time/date format with -l; see TIME_STYLE below -t sort by time, newest first; see --time -T, --tabsize=COLS assume tab stops at each COLS instead of 8 -u with -lt: sort by, and show, access time; with -l: show access time and sort by name; otherwise: sort by access time, newest first -U do not sort; list entries in directory order -v natural sort of (version) numbers within text -w, --width=COLS set output width to COLS. 0 means no limit -x list entries by lines instead of by columns -X sort alphabetically by entry extension -Z, --context print any security context of each file --zero end each output line with NUL, not newline -1 list one file per line --help display this help and exit --version output version information and exit The SIZE argument is an integer and optional unit (example: 10K is 10*1024). Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or KB,MB,... (powers of 1000). Binary prefixes can be used, too: KiB=K, MiB=M, and so on. The TIME_STYLE argument can be full-iso, long-iso, iso, locale, or +FORMAT. FORMAT is interpreted like in date(1). If FORMAT is FORMAT1<newline>FORMAT2, then FORMAT1 applies to non-recent files and FORMAT2 to recent files. TIME_STYLE prefixed with 'posix-' takes effect only outside the POSIX locale. Also the TIME_STYLE environment variable sets the default style to use. The WHEN argument defaults to 'always' and can also be 'auto' or 'never'. Using color to distinguish file types is disabled both by default and with --color=never. With --color=auto, ls emits color codes only when standard output is connected to a terminal. The LS_COLORS environment variable can change the settings. Use the dircolors(1) command to set it. Exit status: 0 if OK, 1 if minor problems (e.g., cannot access subdirectory), 2 if serious trouble (e.g., cannot access command-line argument). "
  },
  {
    "command": "cd",
    "description": " The cd utility shall change the working directory of the current shell execution environment (see Section 2.12, Shell Execution Environment) by executing the following steps in sequence. (In the following steps, the symbol curpath represents an intermediate value used to simplify the description of the algorithm used by cd. There is no requirement that curpath be made visible to the application.) 1. If no directory operand is given and the HOME environment variable is empty or undefined, the default behavior is implementation-defined and no further steps shall be taken. 2. If no directory operand is given and the HOME environment variable is set to a non-empty value, the cd utility shall behave as if the directory named in the HOME environment variable was specified as the directory operand. 3. If the directory operand begins with a <slash> character, set curpath to the operand and proceed to step 7. 4. If the first component of the directory operand is dot or dot-dot, proceed to step 6. 5. Starting with the first pathname in the <colon>-separated pathnames of CDPATH (see the ENVIRONMENT VARIABLES section) if the pathname is non-null, test if the concatenation of that pathname, a <slash> character if that pathname did not end with a <slash> character, and the directory operand names a directory. If the pathname is null, test if the concatenation of dot, a <slash> character, and the operand names a directory. In either case, if the resulting string names an existing directory, set curpath to that string and proceed to step 7. Otherwise, repeat this step with the next pathname in CDPATH until all pathnames have been tested. 6. Set curpath to the directory operand. 7. If the -P option is in effect, proceed to step 10. If curpath does not begin with a <slash> character, set curpath to the string formed by the concatenation of the value of PWD, a <slash> character if the value of PWD did not end with a <slash> character, and curpath. 8. The curpath value shall then be converted to canonical form as follows, considering each component from beginning to end, in sequence: a. Dot components and any <slash> characters that separate them from the next component shall be deleted. b. For each dot-dot component, if there is a preceding component and it is neither root nor dot-dot, then: i. If the preceding component does not refer (in the context of pathname resolution with symbolic links followed) to a directory, then the cd utility shall display an appropriate error message and no further steps shall be taken. ii. The preceding component, all <slash> characters separating the preceding component from dot-dot, dot-dot, and all <slash> characters separating dot- dot from the following component (if any) shall be deleted. c. An implementation may further simplify curpath by removing any trailing <slash> characters that are not also leading <slash> characters, replacing multiple non- leading consecutive <slash> characters with a single <slash>, and replacing three or more leading <slash> characters with a single <slash>. If, as a result of this canonicalization, the curpath variable is null, no further steps shall be taken. 9. If curpath is longer than {PATH_MAX} bytes (including the terminating null) and the directory operand was not longer than {PATH_MAX} bytes (including the terminating null), then curpath shall be converted from an absolute pathname to an equivalent relative pathname if possible. This conversion shall always be considered possible if the value of PWD, with a trailing <slash> added if it does not already have one, is an initial substring of curpath. Whether or not it is considered possible under other circumstances is unspecified. Implementations may also apply this conversion if curpath is not longer than {PATH_MAX} bytes or the directory operand was longer than {PATH_MAX} bytes. 10. The cd utility shall then perform actions equivalent to the chdir() function called with curpath as the path argument. If these actions fail for any reason, the cd utility shall display an appropriate error message and the remainder of this step shall not be executed. If the -P option is not in effect, the PWD environment variable shall be set to the value that curpath had on entry to step 9 (i.e., before conversion to a relative pathname). If the -P option is in effect, the PWD environment variable shall be set to the string that would be output by pwd -P. If there is insufficient permission on the new directory, or on any parent of that directory, to determine the current working directory, the value of the PWD environment variable is unspecified. If, during the execution of the above steps, the PWD environment variable is set, the OLDPWD environment variable shall also be set to the value of the old working directory (that is the current working directory immediately prior to the call to cd). The cd utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported by the implementation: -L Handle the operand dot-dot logically; symbolic link components shall not be resolved before dot-dot components are processed (see steps 8. and 9. in the DESCRIPTION). -P Handle the operand dot-dot physically; symbolic link components shall be resolved before dot-dot components are processed (see step 7. in the DESCRIPTION). If both -L and -P options are specified, the last of these options shall be used and all others ignored. If neither -L nor -P is specified, the operand shall be handled dot-dot logically; see the DESCRIPTION. "
  },
  {
    "command": "git-revert",
    "description": " Given one or more existing commits, revert the changes that the related patches introduce, and record some new commits that record them. This requires your working tree to be clean (no modifications from the HEAD commit). Note: git revert is used to record some new commits to reverse the effect of some earlier commits (often only a faulty one). If you want to throw away all uncommitted changes in your working directory, you should see git-reset(1), particularly the --hard option. If you want to extract specific files as they were in another commit, you should see git-restore(1), specifically the --source option. Take care with these alternatives as both will discard uncommitted changes in your working directory. See \"Reset, restore and revert\" in git(1) for the differences between the three commands. <commit>... Commits to revert. For a more complete list of ways to spell commit names, see gitrevisions(7). Sets of commits can also be given but no traversal is done by default, see git-rev-list(1) and its --no-walk option. -e, --edit With this option, git revert will let you edit the commit message prior to committing the revert. This is the default if you run the command from a terminal. -m parent-number, --mainline parent-number Usually you cannot revert a merge because you do not know which side of the merge should be considered the mainline. This option specifies the parent number (starting from 1) of the mainline and allows revert to reverse the change relative to the specified parent. Reverting a merge commit declares that you will never want the tree changes brought in by the merge. As a result, later merges will only bring in tree changes introduced by commits that are not ancestors of the previously reverted merge. This may or may not be what you want. See the revert-a-faulty-merge How-To[1] for more details. --no-edit With this option, git revert will not start the commit message editor. --cleanup=<mode> This option determines how the commit message will be cleaned up before being passed on to the commit machinery. See git-commit(1) for more details. In particular, if the <mode> is given a value of scissors, scissors will be appended to MERGE_MSG before being passed on in the case of a conflict. -n, --no-commit Usually the command automatically creates some commits with commit log messages stating which commits were reverted. This flag applies the changes necessary to revert the named commits to your working tree and the index, but does not make the commits. In addition, when this option is used, your index does not have to match the HEAD commit. The revert is done against the beginning state of your index. This is useful when reverting more than one commits' effect to your index in a row. -S[<keyid>], --gpg-sign[=<keyid>], --no-gpg-sign GPG-sign commits. The keyid argument is optional and defaults to the committer identity; if specified, it must be stuck to the option without a space. --no-gpg-sign is useful to countermand both commit.gpgSign configuration variable, and earlier --gpg-sign. -s, --signoff Add a Signed-off-by trailer at the end of the commit message. See the signoff option in git-commit(1) for more information. --strategy=<strategy> Use the given merge strategy. Should only be used once. See the MERGE STRATEGIES section in git-merge(1) for details. -X<option>, --strategy-option=<option> Pass the merge strategy-specific option through to the merge strategy. See git-merge(1) for details. --rerere-autoupdate, --no-rerere-autoupdate After the rerere mechanism reuses a recorded resolution on the current conflict to update the files in the working tree, allow it to also update the index with the result of resolution. --no-rerere-autoupdate is a good way to double-check what rerere did and catch potential mismerges, before committing the result to the index with a separate git add. --reference Instead of starting the body of the log message with \"This reverts <full object name of the commit being reverted>.\", refer to the commit using \"--pretty=reference\" format (cf. git-log(1)). The revert.reference configuration variable can be used to enable this option by default. "
  },
  {
    "command": "pathchk",
    "description": " Diagnose invalid or unportable file names. -p check for most POSIX systems -P check for empty names and leading \"-\" --portability check for all POSIX systems (equivalent to -p -P) --help display this help and exit --version output version information and exit "
  },
  {
    "command": "man",
    "description": " man is the system's manual pager. Each page argument given to man is normally the name of a program, utility or function. The manual page associated with each of these arguments is then found and displayed. A section, if provided, will direct man to look only in that section of the manual. The default action is to search in all of the available sections following a pre-defined order (see DEFAULTS), and to show only the first page found, even if page exists in several sections. The table below shows the section numbers of the manual followed by the types of pages they contain. 1 Executable programs or shell commands 2 System calls (functions provided by the kernel) 3 Library calls (functions within program libraries) 4 Special files (usually found in /dev) 5 File formats and conventions, e.g. /etc/passwd 6 Games 7 Miscellaneous (including macro packages and conventions), e.g. man(7), groff(7), man-pages(7) 8 System administration commands (usually only for root) 9 Kernel routines [Non standard] A manual page consists of several sections. Conventional section names include NAME, SYNOPSIS, CONFIGURATION, DESCRIPTION, OPTIONS, EXIT STATUS, RETURN VALUE, ERRORS, ENVIRONMENT, FILES, VERSIONS, CONFORMING TO, NOTES, BUGS, EXAMPLE, AUTHORS, and SEE ALSO. The following conventions apply to the SYNOPSIS section and can be used as a guide in other sections. bold text type exactly as shown. italic text replace with appropriate argument. [-abc] any or all arguments within [ ] are optional. -a|-b options delimited by | cannot be used together. argument ... argument is repeatable. [expression] ... entire expression within [ ] is repeatable. Exact rendering may vary depending on the output device. For instance, man will usually not be able to render italics when running in a terminal, and will typically use underlined or coloured text instead. The command or function illustration is a pattern that should match all possible invocations. In some cases it is advisable to illustrate several exclusive invocations as is shown in the SYNOPSIS section of this manual page. Non-argument options that are duplicated either on the command line, in $MANOPT, or both, are not harmful. For options that require an argument, each duplication will override the previous argument value. General options -C file, --config-file=file Use this user configuration file rather than the default of ~/.manpath. -d, --debug Print debugging information. -D, --default This option is normally issued as the very first option and resets man's behaviour to its default. Its use is to reset those options that may have been set in $MANOPT. Any options that follow -D will have their usual effect. --warnings[=warnings] Enable warnings from groff. This may be used to perform sanity checks on the source text of manual pages. warnings is a comma-separated list of warning names; if it is not supplied, the default is \"mac\". See the \u201cWarnings\u201d node in info groff for a list of available warning names. Main modes of operation -f, --whatis Equivalent to whatis. Display a short description from the manual page, if available. See whatis(1) for details. -k, --apropos Equivalent to apropos. Search the short manual page descriptions for keywords and display any matches. See apropos(1) for details. -K, --global-apropos Search for text in all manual pages. This is a brute- force search, and is likely to take some time; if you can, you should specify a section to reduce the number of pages that need to be searched. Search terms may be simple strings (the default), or regular expressions if the --regex option is used. Note that this searches the sources of the manual pages, not the rendered text, and so may include false positives due to things like comments in source files. Searching the rendered text would be much slower. -l, --local-file Activate \"local\" mode. Format and display local manual files instead of searching through the system's manual collection. Each manual page argument will be interpreted as an nroff source file in the correct format. No cat file is produced. If '-' is listed as one of the arguments, input will be taken from stdin. When this option is not used, and man fails to find the page required, before displaying the error message, it attempts to act as if this option was supplied, using the name as a filename and looking for an exact match. -w, --where, --path, --location Don't actually display the manual page, but do print the location of the source nroff file that would be formatted. If the -a option is also used, then print the locations of all source files that match the search criteria. -W, --where-cat, --location-cat Don't actually display the manual page, but do print the location of the preformatted cat file that would be displayed. If the -a option is also used, then print the locations of all preformatted cat files that match the search criteria. If -w and -W are both used, then print both source file and cat file separated by a space. If all of -w, -W, and -a are used, then do this for each possible match. -c, --catman This option is not for general use and should only be used by the catman program. -R encoding, --recode=encoding Instead of formatting the manual page in the usual way, output its source converted to the specified encoding. If you already know the encoding of the source file, you can also use manconv(1) directly. However, this option allows you to convert several manual pages to a single encoding without having to explicitly state the encoding of each, provided that they were already installed in a structure similar to a manual page hierarchy. Consider using man-recode(1) instead for converting multiple manual pages, since it has an interface designed for bulk conversion and so can be much faster. Finding manual pages -L locale, --locale=locale man will normally determine your current locale by a call to the C function setlocale(3) which interrogates various environment variables, possibly including $LC_MESSAGES and $LANG. To temporarily override the determined value, use this option to supply a locale string directly to man. Note that it will not take effect until the search for pages actually begins. Output such as the help message will always be displayed in the initially determined locale. -m system[,...], --systems=system[,...] If this system has access to other operating systems' manual pages, they can be accessed using this option. To search for a manual page from NewOS's manual page collection, use the option -m NewOS. The system specified can be a combination of comma delimited operating system names. To include a search of the native operating system's manual pages, include the system name man in the argument string. This option will override the $SYSTEM environment variable. -M path, --manpath=path Specify an alternate manpath to use. By default, man uses manpath derived code to determine the path to search. This option overrides the $MANPATH environment variable and causes option -m to be ignored. A path specified as a manpath must be the root of a manual page hierarchy structured into sections as described in the man-db manual (under \"The manual page system\"). To view manual pages outside such hierarchies, see the -l option. -S list, -s list, --sections=list The given list is a colon- or comma-separated list of sections, used to determine which manual sections to search and in what order. This option overrides the $MANSECT environment variable. (The -s spelling is for compatibility with System V.) -e sub-extension, --extension=sub-extension Some systems incorporate large packages of manual pages, such as those that accompany the Tcl package, into the main manual page hierarchy. To get around the problem of having two manual pages with the same name such as exit(3), the Tcl pages were usually all assigned to section l. As this is unfortunate, it is now possible to put the pages in the correct section, and to assign a specific \"extension\" to them, in this case, exit(3tcl). Under normal operation, man will display exit(3) in preference to exit(3tcl). To negotiate this situation and to avoid having to know which section the page you require resides in, it is now possible to give man a sub-extension string indicating which package the page must belong to. Using the above example, supplying the option -e tcl to man will restrict the search to pages having an extension of *tcl. -i, --ignore-case Ignore case when searching for manual pages. This is the default. -I, --match-case Search for manual pages case-sensitively. --regex Show all pages with any part of either their names or their descriptions matching each page argument as a regular expression, as with apropos(1). Since there is usually no reasonable way to pick a \"best\" page when searching for a regular expression, this option implies -a. --wildcard Show all pages with any part of either their names or their descriptions matching each page argument using shell-style wildcards, as with apropos(1) --wildcard. The page argument must match the entire name or description, or match on word boundaries in the description. Since there is usually no reasonable way to pick a \"best\" page when searching for a wildcard, this option implies -a. --names-only If the --regex or --wildcard option is used, match only page names, not page descriptions, as with whatis(1). Otherwise, no effect. -a, --all By default, man will exit after displaying the most suitable manual page it finds. Using this option forces man to display all the manual pages with names that match the search criteria. -u, --update This option causes man to update its database caches of installed manual pages. This is only needed in rare situations, and it is normally better to run mandb(8) instead. --no-subpages By default, man will try to interpret pairs of manual page names given on the command line as equivalent to a single manual page name containing a hyphen or an underscore. This supports the common pattern of programs that implement a number of subcommands, allowing them to provide manual pages for each that can be accessed using similar syntax as would be used to invoke the subcommands themselves. For example: $ man -aw git diff /usr/share/man/man1/git-diff.1.gz To disable this behaviour, use the --no-subpages option. $ man -aw --no-subpages git diff /usr/share/man/man1/git.1.gz /usr/share/man/man3/Git.3pm.gz /usr/share/man/man1/diff.1.gz Controlling formatted output -P pager, --pager=pager Specify which output pager to use. By default, man uses less, falling back to cat if less is not found or is not executable. This option overrides the $MANPAGER environment variable, which in turn overrides the $PAGER environment variable. It is not used in conjunction with -f or -k. The value may be a simple command name or a command with arguments, and may use shell quoting (backslashes, single quotes, or double quotes). It may not use pipes to connect multiple commands; if you need that, use a wrapper script, which may take the file to display either as an argument or on standard input. -r prompt, --prompt=prompt If a recent version of less is used as the pager, man will attempt to set its prompt and some sensible options. The default prompt looks like Manual page name(sec) line x where name denotes the manual page name, sec denotes the section it was found under and x the current line number. This is achieved by using the $LESS environment variable. Supplying -r with a string will override this default. The string may contain the text $MAN_PN which will be expanded to the name of the current manual page and its section name surrounded by \"(\" and \")\". The string used to produce the default could be expressed as \\ Manual\\ page\\ \\$MAN_PN\\ ?ltline\\ %lt?L/%L.: byte\\ %bB?s/%s..?\\ (END):?pB\\ %pB\\\\%.. (press h for help or q to quit) It is broken into three lines here for the sake of readability only. For its meaning see the less(1) manual page. The prompt string is first evaluated by the shell. All double quotes, back-quotes and backslashes in the prompt must be escaped by a preceding backslash. The prompt string may end in an escaped $ which may be followed by further options for less. By default man sets the -ix8 options. The $MANLESS environment variable described below may be used to set a default prompt string if none is supplied on the command line. -7, --ascii When viewing a pure ascii(7) manual page on a 7 bit terminal or terminal emulator, some characters may not display correctly when using the latin1(7) device description with GNU nroff. This option allows pure ascii manual pages to be displayed in ascii with the latin1 device. It will not translate any latin1 text. The following table shows the translations performed: some parts of it may only be displayed properly when using GNU nroff's latin1(7) device. Description Octal latin1 ascii \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 continuation 255 \u2010 - hyphen bullet (middle 267 \u2022 o dot) acute accent 264 \u00b4 ' multiplication 327 \u00d7 x sign If the latin1 column displays correctly, your terminal may be set up for latin1 characters and this option is not necessary. If the latin1 and ascii columns are identical, you are reading this page using this option or man did not format this page using the latin1 device description. If the latin1 column is missing or corrupt, you may need to view manual pages with this option. This option is ignored when using options -t, -H, -T, or -Z and may be useless for nroff other than GNU's. -E encoding, --encoding=encoding Generate output for a character encoding other than the default. For backward compatibility, encoding may be an nroff device such as ascii, latin1, or utf8 as well as a true character encoding such as UTF-8. --no-hyphenation, --nh Normally, nroff will automatically hyphenate text at line breaks even in words that do not contain hyphens, if it is necessary to do so to lay out words on a line without excessive spacing. This option disables automatic hyphenation, so words will only be hyphenated if they already contain hyphens. If you are writing a manual page and simply want to prevent nroff from hyphenating a word at an inappropriate point, do not use this option, but consult the nroff documentation instead; for instance, you can put \"\\%\" inside a word to indicate that it may be hyphenated at that point, or put \"\\%\" at the start of a word to prevent it from being hyphenated. --no-justification, --nj Normally, nroff will automatically justify text to both margins. This option disables full justification, leaving justified only to the left margin, sometimes called \"ragged-right\" text. If you are writing a manual page and simply want to prevent nroff from justifying certain paragraphs, do not use this option, but consult the nroff documentation instead; for instance, you can use the \".na\", \".nf\", \".fi\", and \".ad\" requests to temporarily disable adjusting and filling. -p string, --preprocessor=string Specify the sequence of preprocessors to run before nroff or troff/groff. Not all installations will have a full set of preprocessors. Some of the preprocessors and the letters used to designate them are: eqn (e), grap (g), pic (p), tbl (t), vgrind (v), refer (r). This option overrides the $MANROFFSEQ environment variable. zsoelim is always run as the very first preprocessor. -t, --troff Use groff -mandoc to format the manual page to stdout. This option is not required in conjunction with -H, -T, or -Z. -T[device], --troff-device[=device] This option is used to change groff (or possibly troff's) output to be suitable for a device other than the default. It implies -t. Examples (provided with Groff-1.17) include dvi, latin1, ps, utf8, X75 and X100. -H[browser], --html[=browser] This option will cause groff to produce HTML output, and will display that output in a web browser. The choice of browser is determined by the optional browser argument if one is provided, by the $BROWSER environment variable, or by a compile-time default if that is unset (usually lynx). This option implies -t, and will only work with GNU troff. -X[dpi], --gxditview[=dpi] This option displays the output of groff in a graphical window using the gxditview program. The dpi (dots per inch) may be 75, 75-12, 100, or 100-12, defaulting to 75; the -12 variants use a 12-point base font. This option implies -T with the X75, X75-12, X100, or X100-12 device respectively. -Z, --ditroff groff will run troff and then use an appropriate post- processor to produce output suitable for the chosen device. If groff -mandoc is groff, this option is passed to groff and will suppress the use of a post-processor. It implies -t. Getting help -?, --help Print a help message and exit. --usage Print a short usage message and exit. -V, --version Display version information. "
  },
  {
    "command": "ps",
    "description": " The ps utility shall write information about processes, subject to having appropriate privileges to obtain information about those processes. By default, ps shall select all processes with the same effective user ID as the current user and the same controlling terminal as the invoker. The ps utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -a Write information for all processes associated with terminals. Implementations may omit session leaders from this list. -A Write information for all processes. -d Write information for all processes, except session leaders. -e Write information for all processes. (Equivalent to -A.) -f Generate a full listing. (See the STDOUT section for the contents of a full listing.) -g grouplist Write information for processes whose session leaders are given in grouplist. The application shall ensure that the grouplist is a single argument in the form of a <blank> or <comma>-separated list. -G grouplist Write information for processes whose real group ID numbers are given in grouplist. The application shall ensure that the grouplist is a single argument in the form of a <blank> or <comma>-separated list. -l Generate a long listing. (See STDOUT for the contents of a long listing.) -n namelist Specify the name of an alternative system namelist file in place of the default. The name of the default file and the format of a namelist file are unspecified. -o format Write information according to the format specification given in format. This is fully described in the STDOUT section. Multiple -o options can be specified; the format specification shall be interpreted as the <space>-separated concatenation of all the format option-arguments. -p proclist Write information for processes whose process ID numbers are given in proclist. The application shall ensure that the proclist is a single argument in the form of a <blank> or <comma>-separated list. -t termlist Write information for processes associated with terminals given in termlist. The application shall ensure that the termlist is a single argument in the form of a <blank> or <comma>-separated list. Terminal identifiers shall be given in an implementation-defined format. On XSI-conformant systems, they shall be given in one of two forms: the device's filename (for example, tty04) or, if the device's filename starts with tty, just the identifier following the characters tty (for example, \"04\"). -u userlist Write information for processes whose user ID numbers or login names are given in userlist. The application shall ensure that the userlist is a single argument in the form of a <blank> or <comma>-separated list. In the listing, the numerical user ID shall be written unless the -f option is used, in which case the login name shall be written. -U userlist Write information for processes whose real user ID numbers or login names are given in userlist. The application shall ensure that the userlist is a single argument in the form of a <blank> or <comma>-separated list. With the exception of -f, -l, -n namelist, and -o format, all of the options shown are used to select processes. If any are specified, the default list shall be ignored and ps shall select the processes represented by the inclusive OR of all the selection-criteria options. "
  },
  {
    "command": "git-ls-tree",
    "description": " Lists the contents of a given tree object, like what \"/bin/ls -a\" does in the current working directory. Note that: \u2022 the behaviour is slightly different from that of \"/bin/ls\" in that the <path> denotes just a list of patterns to match, e.g. so specifying directory name (without -r) will behave differently, and order of the arguments does not matter. \u2022 the behaviour is similar to that of \"/bin/ls\" in that the <path> is taken as relative to the current working directory. E.g. when you are in a directory sub that has a directory dir, you can run git ls-tree -r HEAD dir to list the contents of the tree (that is sub/dir in HEAD). You don\u2019t want to give a tree that is not at the root level (e.g. git ls-tree -r HEAD:sub dir) in this case, as that would result in asking for sub/sub/dir in the HEAD commit. However, the current working directory can be ignored by passing --full-tree option. <tree-ish> Id of a tree-ish. -d Show only the named tree entry itself, not its children. -r Recurse into sub-trees. -t Show tree entries even when going to recurse them. Has no effect if -r was not passed. -d implies -t. -l, --long Show object size of blob (file) entries. -z \\0 line termination on output and do not quote filenames. See OUTPUT FORMAT below for more information. --name-only, --name-status List only filenames (instead of the \"long\" output), one per line. Cannot be combined with --object-only. --object-only List only names of the objects, one per line. Cannot be combined with --name-only or --name-status. This is equivalent to specifying --format='%(objectname)', but for both this option and that exact format the command takes a hand-optimized codepath instead of going through the generic formatting mechanism. --abbrev[=<n>] Instead of showing the full 40-byte hexadecimal object lines, show the shortest prefix that is at least <n> hexdigits long that uniquely refers the object. Non default number of digits can be specified with --abbrev=<n>. --full-name Instead of showing the path names relative to the current working directory, show the full path names. --full-tree Do not limit the listing to the current working directory. Implies --full-name. --format=<format> A string that interpolates %(fieldname) from the result being shown. It also interpolates %% to %, and %xNN where NN are hex digits interpolates to character with hex code NN; for example %x00 interpolates to \\0 (NUL), %x09 to \\t (TAB) and %x0a to \\n (LF). When specified, --format cannot be combined with other format-altering options, including --long, --name-only and --object-only. [<path>...] When paths are given, show them (note that this isn\u2019t really raw pathnames, but rather a list of patterns to match). Otherwise implicitly uses the root level of the tree as the sole path argument. "
  },
  {
    "command": "ssh",
    "description": " ssh (SSH client) is a program for logging into a remote machine and for executing commands on a remote machine. It is intended to provide secure encrypted communications between two untrusted hosts over an insecure network. X11 connections, arbitrary TCP ports and UNIX-domain sockets can also be forwarded over the secure channel. ssh connects and logs into the specified destination, which may be specified as either [user@]hostname or a URI of the form ssh://[user@]hostname[:port]. The user must prove their identity to the remote machine using one of several methods (see below). If a command is specified, it will be executed on the remote host instead of a login shell. A complete command line may be specified as command, or it may have additional arguments. If supplied, the arguments will be appended to the command, separated by spaces, before it is sent to the server to be executed. The options are as follows: -4 Forces ssh to use IPv4 addresses only. -6 Forces ssh to use IPv6 addresses only. -A Enables forwarding of connections from an authentication agent such as ssh-agent(1). This can also be specified on a per-host basis in a configuration file. Agent forwarding should be enabled with caution. Users with the ability to bypass file permissions on the remote host (for the agent's UNIX-domain socket) can access the local agent through the forwarded connection. An attacker cannot obtain key material from the agent, however they can perform operations on the keys that enable them to authenticate using the identities loaded into the agent. A safer alternative may be to use a jump host (see -J). -a Disables forwarding of the authentication agent connection. -B bind_interface Bind to the address of bind_interface before attempting to connect to the destination host. This is only useful on systems with more than one address. -b bind_address Use bind_address on the local machine as the source address of the connection. Only useful on systems with more than one address. -C Requests compression of all data (including stdin, stdout, stderr, and data for forwarded X11, TCP and UNIX-domain connections). The compression algorithm is the same used by gzip(1). Compression is desirable on modem lines and other slow connections, but will only slow down things on fast networks. The default value can be set on a host-by- host basis in the configuration files; see the Compression option in ssh_config(5). -c cipher_spec Selects the cipher specification for encrypting the session. cipher_spec is a comma-separated list of ciphers listed in order of preference. See the Ciphers keyword in ssh_config(5) for more information. -D [bind_address:]port Specifies a local \u201cdynamic\u201d application-level port forwarding. This works by allocating a socket to listen to port on the local side, optionally bound to the specified bind_address. Whenever a connection is made to this port, the connection is forwarded over the secure channel, and the application protocol is then used to determine where to connect to from the remote machine. Currently the SOCKS4 and SOCKS5 protocols are supported, and ssh will act as a SOCKS server. Only root can forward privileged ports. Dynamic port forwardings can also be specified in the configuration file. IPv6 addresses can be specified by enclosing the address in square brackets. Only the superuser can forward privileged ports. By default, the local port is bound in accordance with the GatewayPorts setting. However, an explicit bind_address may be used to bind the connection to a specific address. The bind_address of \u201clocalhost\u201d indicates that the listening port be bound for local use only, while an empty address or \u2018*\u2019 indicates that the port should be available from all interfaces. -E log_file Append debug logs to log_file instead of standard error. -e escape_char Sets the escape character for sessions with a pty (default: \u2018~\u2019). The escape character is only recognized at the beginning of a line. The escape character followed by a dot (\u2018.\u2019) closes the connection; followed by control-Z suspends the connection; and followed by itself sends the escape character once. Setting the character to \u201cnone\u201d disables any escapes and makes the session fully transparent. -F configfile Specifies an alternative per-user configuration file. If a configuration file is given on the command line, the system-wide configuration file (/etc/ssh/ssh_config) will be ignored. The default for the per-user configuration file is ~/.ssh/config. If set to \u201cnone\u201d, no configuration files will be read. -f Requests ssh to go to background just before command execution. This is useful if ssh is going to ask for passwords or passphrases, but the user wants it in the background. This implies -n. The recommended way to start X11 programs at a remote site is with something like ssh -f host xterm. If the ExitOnForwardFailure configuration option is set to \u201cyes\u201d, then a client started with -f will wait for all remote port forwards to be successfully established before placing itself in the background. Refer to the description of ForkAfterAuthentication in ssh_config(5) for details. -G Causes ssh to print its configuration after evaluating Host and Match blocks and exit. -g Allows remote hosts to connect to local forwarded ports. If used on a multiplexed connection, then this option must be specified on the master process. -I pkcs11 Specify the PKCS#11 shared library ssh should use to communicate with a PKCS#11 token providing keys for user authentication. -i identity_file Selects a file from which the identity (private key) for public key authentication is read. You can also specify a public key file to use the corresponding private key that is loaded in ssh-agent(1) when the private key file is not present locally. The default is ~/.ssh/id_rsa, ~/.ssh/id_ecdsa, ~/.ssh/id_ecdsa_sk, ~/.ssh/id_ed25519, ~/.ssh/id_ed25519_sk and ~/.ssh/id_dsa. Identity files may also be specified on a per-host basis in the configuration file. It is possible to have multiple -i options (and multiple identities specified in configuration files). If no certificates have been explicitly specified by the CertificateFile directive, ssh will also try to load certificate information from the filename obtained by appending -cert.pub to identity filenames. -J destination Connect to the target host by first making a ssh connection to the jump host described by destination and then establishing a TCP forwarding to the ultimate destination from there. Multiple jump hops may be specified separated by comma characters. This is a shortcut to specify a ProxyJump configuration directive. Note that configuration directives supplied on the command-line generally apply to the destination host and not any specified jump hosts. Use ~/.ssh/config to specify configuration for jump hosts. -K Enables GSSAPI-based authentication and forwarding (delegation) of GSSAPI credentials to the server. -k Disables forwarding (delegation) of GSSAPI credentials to the server. -L [bind_address:]port:host:hostport -L [bind_address:]port:remote_socket -L local_socket:host:hostport -L local_socket:remote_socket Specifies that connections to the given TCP port or Unix socket on the local (client) host are to be forwarded to the given host and port, or Unix socket, on the remote side. This works by allocating a socket to listen to either a TCP port on the local side, optionally bound to the specified bind_address, or to a Unix socket. Whenever a connection is made to the local port or socket, the connection is forwarded over the secure channel, and a connection is made to either host port hostport, or the Unix socket remote_socket, from the remote machine. Port forwardings can also be specified in the configuration file. Only the superuser can forward privileged ports. IPv6 addresses can be specified by enclosing the address in square brackets. By default, the local port is bound in accordance with the GatewayPorts setting. However, an explicit bind_address may be used to bind the connection to a specific address. The bind_address of \u201clocalhost\u201d indicates that the listening port be bound for local use only, while an empty address or \u2018*\u2019 indicates that the port should be available from all interfaces. -l login_name Specifies the user to log in as on the remote machine. This also may be specified on a per-host basis in the configuration file. -M Places the ssh client into \u201cmaster\u201d mode for connection sharing. Multiple -M options places ssh into \u201cmaster\u201d mode but with confirmation required using ssh-askpass(1) before each operation that changes the multiplexing state (e.g. opening a new session). Refer to the description of ControlMaster in ssh_config(5) for details. -m mac_spec A comma-separated list of MAC (message authentication code) algorithms, specified in order of preference. See the MACs keyword in ssh_config(5) for more information. -N Do not execute a remote command. This is useful for just forwarding ports. Refer to the description of SessionType in ssh_config(5) for details. -n Redirects stdin from /dev/null (actually, prevents reading from stdin). This must be used when ssh is run in the background. A common trick is to use this to run X11 programs on a remote machine. For example, ssh -n shadows.cs.hut.fi emacs & will start an emacs on shadows.cs.hut.fi, and the X11 connection will be automatically forwarded over an encrypted channel. The ssh program will be put in the background. (This does not work if ssh needs to ask for a password or passphrase; see also the -f option.) Refer to the description of StdinNull in ssh_config(5) for details. -O ctl_cmd Control an active connection multiplexing master process. When the -O option is specified, the ctl_cmd argument is interpreted and passed to the master process. Valid commands are: \u201ccheck\u201d (check that the master process is running), \u201cforward\u201d (request forwardings without command execution), \u201ccancel\u201d (cancel forwardings), \u201cexit\u201d (request the master to exit), and \u201cstop\u201d (request the master to stop accepting further multiplexing requests). -o option Can be used to give options in the format used in the configuration file. This is useful for specifying options for which there is no separate command-line flag. For full details of the options listed below, and their possible values, see ssh_config(5). AddKeysToAgent AddressFamily BatchMode BindAddress CanonicalDomains CanonicalizeFallbackLocal CanonicalizeHostname CanonicalizeMaxDots CanonicalizePermittedCNAMEs CASignatureAlgorithms CertificateFile CheckHostIP Ciphers ClearAllForwardings Compression ConnectionAttempts ConnectTimeout ControlMaster ControlPath ControlPersist DynamicForward EnableEscapeCommandline EscapeChar ExitOnForwardFailure FingerprintHash ForkAfterAuthentication ForwardAgent ForwardX11 ForwardX11Timeout ForwardX11Trusted GatewayPorts GlobalKnownHostsFile GSSAPIAuthentication GSSAPIDelegateCredentials HashKnownHosts Host HostbasedAcceptedAlgorithms HostbasedAuthentication HostKeyAlgorithms HostKeyAlias Hostname IdentitiesOnly IdentityAgent IdentityFile IPQoS KbdInteractiveAuthentication KbdInteractiveDevices KexAlgorithms KnownHostsCommand LocalCommand LocalForward LogLevel MACs Match NoHostAuthenticationForLocalhost NumberOfPasswordPrompts PasswordAuthentication PermitLocalCommand PermitRemoteOpen PKCS11Provider Port PreferredAuthentications ProxyCommand ProxyJump ProxyUseFdpass PubkeyAcceptedAlgorithms PubkeyAuthentication RekeyLimit RemoteCommand RemoteForward RequestTTY RequiredRSASize SendEnv ServerAliveInterval ServerAliveCountMax SessionType SetEnv StdinNull StreamLocalBindMask StreamLocalBindUnlink StrictHostKeyChecking TCPKeepAlive Tunnel TunnelDevice UpdateHostKeys User UserKnownHostsFile VerifyHostKeyDNS VisualHostKey XAuthLocation -p port Port to connect to on the remote host. This can be specified on a per-host basis in the configuration file. -Q query_option Queries for the algorithms supported by one of the following features: cipher (supported symmetric ciphers), cipher-auth (supported symmetric ciphers that support authenticated encryption), help (supported query terms for use with the -Q flag), mac (supported message integrity codes), kex (key exchange algorithms), key (key types), key-cert (certificate key types), key-plain (non- certificate key types), key-sig (all key types and signature algorithms), protocol-version (supported SSH protocol versions), and sig (supported signature algorithms). Alternatively, any keyword from ssh_config(5) or sshd_config(5) that takes an algorithm list may be used as an alias for the corresponding query_option. -q Quiet mode. Causes most warning and diagnostic messages to be suppressed. -R [bind_address:]port:host:hostport -R [bind_address:]port:local_socket -R remote_socket:host:hostport -R remote_socket:local_socket -R [bind_address:]port Specifies that connections to the given TCP port or Unix socket on the remote (server) host are to be forwarded to the local side. This works by allocating a socket to listen to either a TCP port or to a Unix socket on the remote side. Whenever a connection is made to this port or Unix socket, the connection is forwarded over the secure channel, and a connection is made from the local machine to either an explicit destination specified by host port hostport, or local_socket, or, if no explicit destination was specified, ssh will act as a SOCKS 4/5 proxy and forward connections to the destinations requested by the remote SOCKS client. Port forwardings can also be specified in the configuration file. Privileged ports can be forwarded only when logging in as root on the remote machine. IPv6 addresses can be specified by enclosing the address in square brackets. By default, TCP listening sockets on the server will be bound to the loopback interface only. This may be overridden by specifying a bind_address. An empty bind_address, or the address \u2018*\u2019, indicates that the remote socket should listen on all interfaces. Specifying a remote bind_address will only succeed if the server's GatewayPorts option is enabled (see sshd_config(5)). If the port argument is \u20180\u2019, the listen port will be dynamically allocated on the server and reported to the client at run time. When used together with -O forward, the allocated port will be printed to the standard output. -S ctl_path Specifies the location of a control socket for connection sharing, or the string \u201cnone\u201d to disable connection sharing. Refer to the description of ControlPath and ControlMaster in ssh_config(5) for details. -s May be used to request invocation of a subsystem on the remote system. Subsystems facilitate the use of SSH as a secure transport for other applications (e.g. sftp(1)). The subsystem is specified as the remote command. Refer to the description of SessionType in ssh_config(5) for details. -T Disable pseudo-terminal allocation. -t Force pseudo-terminal allocation. This can be used to execute arbitrary screen-based programs on a remote machine, which can be very useful, e.g. when implementing menu services. Multiple -t options force tty allocation, even if ssh has no local tty. -V Display the version number and exit. -v Verbose mode. Causes ssh to print debugging messages about its progress. This is helpful in debugging connection, authentication, and configuration problems. Multiple -v options increase the verbosity. The maximum is 3. -W host:port Requests that standard input and output on the client be forwarded to host on port over the secure channel. Implies -N, -T, ExitOnForwardFailure and ClearAllForwardings, though these can be overridden in the configuration file or using -o command line options. -w local_tun[:remote_tun] Requests tunnel device forwarding with the specified tun(4) devices between the client (local_tun) and the server (remote_tun). The devices may be specified by numerical ID or the keyword \u201cany\u201d, which uses the next available tunnel device. If remote_tun is not specified, it defaults to \u201cany\u201d. See also the Tunnel and TunnelDevice directives in ssh_config(5). If the Tunnel directive is unset, it will be set to the default tunnel mode, which is \u201cpoint-to-point\u201d. If a different Tunnel forwarding mode it desired, then it should be specified before -w. -X Enables X11 forwarding. This can also be specified on a per-host basis in a configuration file. X11 forwarding should be enabled with caution. Users with the ability to bypass file permissions on the remote host (for the user's X authorization database) can access the local X11 display through the forwarded connection. An attacker may then be able to perform activities such as keystroke monitoring. For this reason, X11 forwarding is subjected to X11 SECURITY extension restrictions by default. Refer to the ssh -Y option and the ForwardX11Trusted directive in ssh_config(5) for more information. -x Disables X11 forwarding. -Y Enables trusted X11 forwarding. Trusted X11 forwardings are not subjected to the X11 SECURITY extension controls. -y Send log information using the syslog(3) system module. By default this information is sent to stderr. ssh may additionally obtain configuration data from a per-user configuration file and a system-wide configuration file. The file format and configuration options are described in ssh_config(5). "
  },
  {
    "command": "set",
    "description": " If no options or arguments are specified, set shall write the names and values of all shell variables in the collation sequence of the current locale. Each name shall start on a separate line, using the format: \"%s=%s\\n\", <name>, <value> The value string shall be written with appropriate quoting; see the description of shell quoting in Section 2.2, Quoting. The output shall be suitable for reinput to the shell, setting or resetting, as far as possible, the variables that are currently set; read-only variables cannot be reset. When options are specified, they shall set or unset attributes of the shell, as described below. When arguments are specified, they cause positional parameters to be set or unset, as described below. Setting or unsetting attributes and positional parameters are not necessarily related actions, but they can be combined in a single invocation of set. The set special built-in shall support the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines except that options can be specified with either a leading <hyphen-minus> (meaning enable the option) or <plus-sign> (meaning disable it) unless otherwise specified. Implementations shall support the options in the following list in both their <hyphen-minus> and <plus-sign> forms. These options can also be specified as options to sh. -a When this option is on, the export attribute shall be set for each variable to which an assignment is performed; see the Base Definitions volume of POSIX.1\u20102017, Section 4.23, Variable Assignment. If the assignment precedes a utility name in a command, the export attribute shall not persist in the current execution environment after the utility completes, with the exception that preceding one of the special built-in utilities causes the export attribute to persist after the built-in has completed. If the assignment does not precede a utility name in the command, or if the assignment is a result of the operation of the getopts or read utilities, the export attribute shall persist until the variable is unset. -b This option shall be supported if the implementation supports the User Portability Utilities option. It shall cause the shell to notify the user asynchronously of background job completions. The following message is written to standard error: \"[%d]%c %s%s\\n\", <job-number>, <current>, <status>, <job-name> where the fields shall be as follows: <current> The character '+' identifies the job that would be used as a default for the fg or bg utilities; this job can also be specified using the job_id \"%+\" or \"%%\". The character '-' identifies the job that would become the default if the current default job were to exit; this job can also be specified using the job_id \"%-\". For other jobs, this field is a <space>. At most one job can be identified with '+' and at most one job can be identified with '-'. If there is any suspended job, then the current job shall be a suspended job. If there are at least two suspended jobs, then the previous job also shall be a suspended job. <job-number> A number that can be used to identify the process group to the wait, fg, bg, and kill utilities. Using these utilities, the job can be identified by prefixing the job number with '%'. <status> Unspecified. <job-name> Unspecified. When the shell notifies the user a job has been completed, it may remove the job's process ID from the list of those known in the current shell execution environment; see Section 2.9.3.1, Examples. Asynchronous notification shall not be enabled by default. -C (Uppercase C.) Prevent existing files from being overwritten by the shell's '>' redirection operator (see Section 2.7.2, Redirecting Output); the \">|\" redirection operator shall override this noclobber option for an individual file. -e When this option is on, when any command fails (for any of the reasons listed in Section 2.8.1, Consequences of Shell Errors or by returning an exit status greater than zero), the shell immediately shall exit, as if by executing the exit special built-in utility with no arguments, with the following exceptions: 1. The failure of any individual command in a multi- command pipeline shall not cause the shell to exit. Only the failure of the pipeline itself shall be considered. 2. The -e setting shall be ignored when executing the compound list following the while, until, if, or elif reserved word, a pipeline beginning with the ! reserved word, or any command of an AND-OR list other than the last. 3. If the exit status of a compound command other than a subshell command was the result of a failure while -e was being ignored, then -e shall not apply to this command. This requirement applies to the shell environment and each subshell environment separately. For example, in: set -e; (false; echo one) | cat; echo two the false command causes the subshell to exit without executing echo one; however, echo two is executed because the exit status of the pipeline (false; echo one) | cat is zero. -f The shell shall disable pathname expansion. -h Locate and remember utilities invoked by functions as those functions are defined (the utilities are normally located when the function is executed). -m This option shall be supported if the implementation supports the User Portability Utilities option. All jobs shall be run in their own process groups. Immediately before the shell issues a prompt after completion of the background job, a message reporting the exit status of the background job shall be written to standard error. If a foreground job stops, the shell shall write a message to standard error to that effect, formatted as described by the jobs utility. In addition, if a job changes status other than exiting (for example, if it stops for input or output or is stopped by a SIGSTOP signal), the shell shall write a similar message immediately prior to writing the next prompt. This option is enabled by default for interactive shells. -n The shell shall read commands but does not execute them; this can be used to check for shell script syntax errors. An interactive shell may ignore this option. -o Write the current settings of the options to standard output in an unspecified format. +o Write the current option settings to standard output in a format that is suitable for reinput to the shell as commands that achieve the same options settings. -o option This option is supported if the system supports the User Portability Utilities option. It shall set various options, many of which shall be equivalent to the single option letters. The following values of option shall be supported: allexport Equivalent to -a. errexit Equivalent to -e. ignoreeof Prevent an interactive shell from exiting on end- of-file. This setting prevents accidental logouts when <control>\u2010D is entered. A user shall explicitly exit to leave the interactive shell. monitor Equivalent to -m. This option is supported if the system supports the User Portability Utilities option. noclobber Equivalent to -C (uppercase C). noglob Equivalent to -f. noexec Equivalent to -n. nolog Prevent the entry of function definitions into the command history; see Command History List. notify Equivalent to -b. nounset Equivalent to -u. verbose Equivalent to -v. vi Allow shell command line editing using the built- in vi editor. Enabling vi mode shall disable any other command line editing mode provided as an implementation extension. It need not be possible to set vi mode on for certain block-mode terminals. xtrace Equivalent to -x. -u When the shell tries to expand an unset parameter other than the '@' and '*' special parameters, it shall write a message to standard error and the expansion shall fail with the consequences specified in Section 2.8.1, Consequences of Shell Errors. -v The shell shall write its input to standard error as it is read. -x The shell shall write to standard error a trace for each command after it expands the command and before it executes it. It is unspecified whether the command that turns tracing off is traced. The default for all these options shall be off (unset) unless stated otherwise in the description of the option or unless the shell was invoked with them on; see sh. The remaining arguments shall be assigned in order to the positional parameters. The special parameter '#' shall be set to reflect the number of positional parameters. All positional parameters shall be unset before any new values are assigned. If the first argument is '-', the results are unspecified. The special argument \"--\" immediately following the set command name can be used to delimit the arguments if the first argument begins with '+' or '-', or to prevent inadvertent listing of all shell variables when there are no arguments. The command set -- without argument shall unset all positional parameters and set the special parameter '#' to zero. See the DESCRIPTION. "
  },
  {
    "command": "cut",
    "description": " The cut utility shall cut out bytes (-b option), characters (-c option), or character-delimited fields (-f option) from each line in one or more files, concatenate them, and write them to standard output. The cut utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The application shall ensure that the option-argument list (see options -b, -c, and -f below) is a <comma>-separated list or <blank>-separated list of positive numbers and ranges. Ranges can be in three forms. The first is two positive numbers separated by a <hyphen-minus> (low-high), which represents all fields from the first number to the second number. The second is a positive number preceded by a <hyphen-minus> (-high), which represents all fields from field number 1 to that number. The third is a positive number followed by a <hyphen-minus> (low-), which represents that number to the last field, inclusive. The elements in list can be repeated, can overlap, and can be specified in any order, but the bytes, characters, or fields selected shall be written in the order of the input data. If an element appears in the selection list more than once, it shall be written exactly once. The following options shall be supported: -b list Cut based on a list of bytes. Each selected byte shall be output unless the -n option is also specified. It shall not be an error to select bytes not present in the input line. -c list Cut based on a list of characters. Each selected character shall be output. It shall not be an error to select characters not present in the input line. -d delim Set the field delimiter to the character delim. The default is the <tab>. -f list Cut based on a list of fields, assumed to be separated in the file by a delimiter character (see -d). Each selected field shall be output. Output fields shall be separated by a single occurrence of the field delimiter character. Lines with no field delimiters shall be passed through intact, unless -s is specified. It shall not be an error to select fields not present in the input line. -n Do not split characters. When specified with the -b option, each element in list of the form low-high (<hyphen-minus>-separated numbers) shall be modified as follows: * If the byte selected by low is not the first byte of a character, low shall be decremented to select the first byte of the character originally selected by low. If the byte selected by high is not the last byte of a character, high shall be decremented to select the last byte of the character prior to the character originally selected by high, or zero if there is no prior character. If the resulting range element has high equal to zero or low greater than high, the list element shall be dropped from list for that input line without causing an error. Each element in list of the form low- shall be treated as above with high set to the number of bytes in the current line, not including the terminating <newline>. Each element in list of the form -high shall be treated as above with low set to 1. Each element in list of the form num (a single number) shall be treated as above with low set to num and high set to num. -s Suppress lines with no delimiter characters, when used with the -f option. Unless specified, lines with no delimiters shall be passed through untouched. "
  },
  {
    "command": "chfn",
    "description": " chfn is used to change your finger information. This information is stored in the /etc/passwd file, and is displayed by the finger program. The Linux finger command will display four pieces of information that can be changed by chfn: your real name, your work room and phone, and your home phone. Any of the four pieces of information can be specified on the command line. If no information is given on the command line, chfn enters interactive mode. In interactive mode, chfn will prompt for each field. At a prompt, you can enter the new information, or just press return to leave the field unchanged. Enter the keyword \"none\" to make the field blank. chfn supports non-local entries (kerberos, LDAP, etc.) if linked with libuser, otherwise use ypchfn(1), lchfn(1) or any other implementation for non-local entries. -f, --full-name full-name Specify your real name. -o, --office office Specify your office room number. -p, --office-phone office-phone Specify your office phone number. -h, --home-phone home-phone Specify your home phone number. -u, --help Display help text and exit. -V, --version Print version and exit. The short options -V have been used since version 2.39; old versions use deprecated -v. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "taskset",
    "description": " The taskset command is used to set or retrieve the CPU affinity of a running process given its pid, or to launch a new command with a given CPU affinity. CPU affinity is a scheduler property that \"bonds\" a process to a given set of CPUs on the system. The Linux scheduler will honor the given CPU affinity and the process will not run on any other CPUs. Note that the Linux scheduler also supports natural CPU affinity: the scheduler attempts to keep processes on the same CPU as long as practical for performance reasons. Therefore, forcing a specific CPU affinity is useful only in certain applications. The affinity of some processes like kernel per-CPU threads cannot be set. The CPU affinity is represented as a bitmask, with the lowest order bit corresponding to the first logical CPU and the highest order bit corresponding to the last logical CPU. Not all CPUs may exist on a given system but a mask may specify more CPUs than are present. A retrieved mask will reflect only the bits that correspond to CPUs physically on the system. If an invalid mask is given (i.e., one that corresponds to no valid CPUs on the current system) an error is returned. The masks may be specified in hexadecimal (with or without a leading \"0x\"), or as a CPU list with the --cpu-list option. For example, 0x00000001 is processor #0, 0x00000003 is processors #0 and #1, FFFFFFFF is processors #0 through #31, 0x32 is processors #1, #4, and #5, --cpu-list 0-2,6 is processors #0, #1, #2, and #6. --cpu-list 0-10:2 is processors #0, #2, #4, #6, #8 and #10. The suffix \":N\" specifies stride in the range, for example 0-10:3 is interpreted as 0,3,6,9 list. When taskset returns, it is guaranteed that the given program has been scheduled to a legal CPU. -a, --all-tasks Set or retrieve the CPU affinity of all the tasks (threads) for a given PID. -c, --cpu-list Interpret mask as numerical list of processors instead of a bitmask. Numbers are separated by commas and may include ranges. For example: 0,5,8-11. -p, --pid Operate on an existing PID and do not launch a new task. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "script",
    "description": " script makes a typescript of everything on your terminal session. The terminal data are stored in raw form to the log file and information about timing to another (optional) structured log file. The timing log file is necessary to replay the session later by scriptreplay(1) and to store additional information about the session. Since version 2.35, script supports multiple streams and allows the logging of input and output to separate files or all the one file. This version also supports a new timing file which records additional information. The command scriptreplay --summary then provides all the information. If the argument file or option --log-out file is given, script saves the dialogue in this file. If no filename is given, the dialogue is saved in the file typescript. Note that logging input using --log-in or --log-io may record security-sensitive information as the log file contains all terminal session input (e.g., passwords) independently of the terminal echo flag setting. Below, the size argument may be followed by the multiplicative suffixes KiB (=1024), MiB (=1024*1024), and so on for GiB, TiB, PiB, EiB, ZiB and YiB (the \"iB\" is optional, e.g., \"K\" has the same meaning as \"KiB\"), or the suffixes KB (=1000), MB (=1000*1000), and so on for GB, TB, PB, EB, ZB and YB. -a, --append Append the output to file or to typescript, retaining the prior contents. -c, --command command Run the command rather than an interactive shell. This makes it easy for a script to capture the output of a program that behaves differently when its stdout is not a tty. -E, --echo when This option controls the ECHO flag for the slave end of the session\u2019s pseudoterminal. The supported modes are always, never, or auto. The default is auto \u2014 in this case, ECHO enabled for the pseudoterminal slave; if the current standard input is a terminal, ECHO is disabled for it to prevent double echo; if the current standard input is not a terminal (for example pipe: echo date | script) then keeping ECHO enabled for the pseudoterminal slave enables the standard input data to be viewed on screen while being recorded to session log simultaneously. Note that 'never' mode affects content of the session output log, because users input is not repeated on output. -e, --return Return the exit status of the child process. Uses the same format as bash termination on signal termination (i.e., exit status is 128 + the signal number). The exit status of the child process is always stored in the type script file too. -f, --flush Flush output after each write. This is nice for telecooperation: one person does mkfifo foo; script -f foo, and another can supervise in real-time what is being done using cat foo. Note that flush has an impact on performance; it\u2019s possible to use SIGUSR1 to flush logs on demand. --force Allow the default output file typescript to be a hard or symbolic link. The command will follow a symbolic link. -B, --log-io file Log input and output to the same file. Note, this option makes sense only if --log-timing is also specified, otherwise it\u2019s impossible to separate output and input streams from the log file. -I, --log-in file Log input to the file. The log output is disabled if only --log-in specified. Use this logging functionality carefully as it logs all input, including input when terminal has disabled echo flag (for example, password inputs). -O, --log-out file Log output to the file. The default is to log output to the file with name typescript if the option --log-out or --log-in is not given. The log output is disabled if only --log-in specified. -T, --log-timing file Log timing information to the file. Two timing file formats are supported now. The classic format is used when only one stream (input or output) logging is enabled. The multi-stream format is used on --log-io or when --log-in and --log-out are used together. See also --logging-format. -m, --logging-format format Force use of advanced or classic timing log format. The default is the classic format to log only output and the advanced format when input as well as output logging is requested. Classic format The timing log contains two fields, separated by a space. The first field indicates how much time elapsed since the previous output. The second field indicates how many characters were output this time. Advanced (multi-stream) format The first field is an entry type identifier ('I\u2019nput, 'O\u2019utput, 'H\u2019eader, 'S\u2019ignal). The second field is how much time elapsed since the previous entry, and the rest of the entry is type-specific data. -o, --output-limit size Limit the size of the typescript and timing files to size and stop the child process after this size is exceeded. The calculated file size does not include the start and done messages that the script command prepends and appends to the child process output. Due to buffering, the resulting output file might be larger than the specified value. -q, --quiet Be quiet (do not write start and done messages to standard output). -t[file], --timing[=file] Output timing data to standard error, or to file when given. This option is deprecated in favour of --log-timing where the file argument is not optional. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "chown",
    "description": " The chown utility shall set the user ID of the file named by each file operand to the user ID specified by the owner operand. For each file operand, or, if the -R option is used, each file encountered while walking the directory trees specified by the file operands, the chown utility shall perform actions equivalent to the chown() function defined in the System Interfaces volume of POSIX.1\u20102017, called with the following arguments: 1. The file operand shall be used as the path argument. 2. The user ID indicated by the owner portion of the first operand shall be used as the owner argument. 3. If the group portion of the first operand is given, the group ID indicated by it shall be used as the group argument; otherwise, the group ownership shall not be changed. Unless chown is invoked by a process with appropriate privileges, the set-user-ID and set-group-ID bits of a regular file shall be cleared upon successful completion; the set-user-ID and set- group-ID bits of other file types may be cleared. The chown utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported by the implementation: -h For each file operand that names a file of type symbolic link, chown shall attempt to set the user ID of the symbolic link. If a group ID was specified, for each file operand that names a file of type symbolic link, chown shall attempt to set the group ID of the symbolic link. -H If the -R option is specified and a symbolic link referencing a file of type directory is specified on the command line, chown shall change the user ID (and group ID, if specified) of the directory referenced by the symbolic link and all files in the file hierarchy below it. -L If the -R option is specified and a symbolic link referencing a file of type directory is specified on the command line or encountered during the traversal of a file hierarchy, chown shall change the user ID (and group ID, if specified) of the directory referenced by the symbolic link and all files in the file hierarchy below it. -P If the -R option is specified and a symbolic link is specified on the command line or encountered during the traversal of a file hierarchy, chown shall change the owner ID (and group ID, if specified) of the symbolic link. The chown utility shall not follow the symbolic link to any other part of the file hierarchy. -R Recursively change file user and group IDs. For each file operand that names a directory, chown shall change the user ID (and group ID, if specified) of the directory and all files in the file hierarchy below it. Unless a -H, -L, or -P option is specified, it is unspecified which of these options will be used as the default. Specifying more than one of the mutually-exclusive options -H, -L, and -P shall not be considered an error. The last option specified shall determine the behavior of the utility. "
  },
  {
    "command": "g++",
    "description": " When you invoke GCC, it normally does preprocessing, compilation, assembly and linking. The \"overall options\" allow you to stop this process at an intermediate stage. For example, the -c option says not to run the linker. Then the output consists of object files output by the assembler. Other options are passed on to one or more stages of processing. Some options control the preprocessor and others the compiler itself. Yet other options control the assembler and linker; most of these are not documented here, since you rarely need to use any of them. Most of the command-line options that you can use with GCC are useful for C programs; when an option is only useful with another language (usually C++), the explanation says so explicitly. If the description for a particular option does not mention a source language, you can use that option with all supported languages. The usual way to run GCC is to run the executable called gcc, or machine-gcc when cross-compiling, or machine-gcc-version to run a specific version of GCC. When you compile C++ programs, you should invoke GCC as g++ instead. The gcc program accepts options and file names as operands. Many options have multi-letter names; therefore multiple single-letter options may not be grouped: -dv is very different from -d -v. You can mix options and other arguments. For the most part, the order you use doesn't matter. Order does matter when you use several options of the same kind; for example, if you specify -L more than once, the directories are searched in the order specified. Also, the placement of the -l option is significant. Many options have long names starting with -f or with -W---for example, -fmove-loop-invariants, -Wformat and so on. Most of these have both positive and negative forms; the negative form of -ffoo is -fno-foo. This manual documents only one of these two forms, whichever one is not the default. Some options take one or more arguments typically separated either by a space or by the equals sign (=) from the option name. Unless documented otherwise, an argument can be either numeric or a string. Numeric arguments must typically be small unsigned decimal or hexadecimal integers. Hexadecimal arguments must begin with the 0x prefix. Arguments to options that specify a size threshold of some sort may be arbitrarily large decimal or hexadecimal integers followed by a byte size suffix designating a multiple of bytes such as \"kB\" and \"KiB\" for kilobyte and kibibyte, respectively, \"MB\" and \"MiB\" for megabyte and mebibyte, \"GB\" and \"GiB\" for gigabyte and gigibyte, and so on. Such arguments are designated by byte-size in the following text. Refer to the NIST, IEC, and other relevant national and international standards for the full listing and explanation of the binary and decimal byte size prefixes. Option Summary Here is a summary of all the options, grouped by type. Explanations are in the following sections. Overall Options -c -S -E -o file -x language -v -"
  },
  {
    "command": "cp",
    "description": " Copy SOURCE to DEST, or multiple SOURCE(s) to DIRECTORY. Mandatory arguments to long options are mandatory for short options too. -a, --archive same as -dR --preserve=all --attributes-only don't copy the file data, just the attributes --backup[=CONTROL] make a backup of each existing destination file -b like --backup but does not accept an argument --copy-contents copy contents of special files when recursive -d same as --no-dereference --preserve=links --debug explain how a file is copied. Implies -v -f, --force if an existing destination file cannot be opened, remove it and try again (this option is ignored when the -n option is also used) -i, --interactive prompt before overwrite (overrides a previous -n option) -H follow command-line symbolic links in SOURCE -l, --link hard link files instead of copying -L, --dereference always follow symbolic links in SOURCE -n, --no-clobber do not overwrite an existing file (overrides a -u or previous -i option). See also --update -P, --no-dereference never follow symbolic links in SOURCE -p same as --preserve=mode,ownership,timestamps --preserve[=ATTR_LIST] preserve the specified attributes --no-preserve=ATTR_LIST don't preserve the specified attributes --parents use full source file name under DIRECTORY -R, -r, --recursive copy directories recursively --reflink[=WHEN] control clone/CoW copies. See below --remove-destination remove each existing destination file before attempting to open it (contrast with --force) --sparse=WHEN control creation of sparse files. See below --strip-trailing-slashes remove any trailing slashes from each SOURCE argument -s, --symbolic-link make symbolic links instead of copying -S, --suffix=SUFFIX override the usual backup suffix -t, --target-directory=DIRECTORY copy all SOURCE arguments into DIRECTORY -T, --no-target-directory treat DEST as a normal file --update[=UPDATE] control which existing files are updated; UPDATE={all,none,older(default)}. See below -u equivalent to --update[=older] -v, --verbose explain what is being done -x, --one-file-system stay on this file system -Z set SELinux security context of destination file to default type --context[=CTX] like -Z, or if CTX is specified then set the SELinux or SMACK security context to CTX --help display this help and exit --version output version information and exit ATTR_LIST is a comma-separated list of attributes. Attributes are 'mode' for permissions (including any ACL and xattr permissions), 'ownership' for user and group, 'timestamps' for file timestamps, 'links' for hard links, 'context' for security context, 'xattr' for extended attributes, and 'all' for all attributes. By default, sparse SOURCE files are detected by a crude heuristic and the corresponding DEST file is made sparse as well. That is the behavior selected by --sparse=auto. Specify --sparse=always to create a sparse DEST file whenever the SOURCE file contains a long enough sequence of zero bytes. Use --sparse=never to inhibit creation of sparse files. UPDATE controls which existing files in the destination are replaced. 'all' is the default operation when an --update option is not specified, and results in all existing files in the destination being replaced. 'none' is similar to the --no-clobber option, in that no files in the destination are replaced, but also skipped files do not induce a failure. 'older' is the default operation when --update is specified, and results in files being replaced if they're older than the corresponding source file. When --reflink[=always] is specified, perform a lightweight copy, where the data blocks are copied only when modified. If this is not possible the copy fails, or if --reflink=auto is specified, fall back to a standard copy. Use --reflink=never to ensure a standard copy is performed. The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX. The version control method may be selected via the --backup option or through the VERSION_CONTROL environment variable. Here are the values: none, off never make backups (even if --backup is given) numbered, t make numbered backups existing, nil numbered if numbered backups exist, simple otherwise simple, never always make simple backups As a special case, cp makes a backup of SOURCE when the force and backup options are given and SOURCE and DEST are the same name for an existing, regular file. "
  },
  {
    "command": "sar",
    "description": " The sar command writes to standard output the contents of selected cumulative activity counters in the operating system. The accounting system, based on the values in the count and interval parameters, writes information the specified number of times spaced at the specified intervals in seconds. If the interval parameter is set to zero, the sar command displays the average statistics for the time since the system was started. If the interval parameter is specified without the count parameter, then reports are generated continuously. The collected data can also be saved in the file specified by the -o filename flag, in addition to being displayed onto the screen. If filename is omitted, sar uses the standard system activity daily data file (see below). By default all the data available from the kernel are saved in the data file. The sar command extracts and writes to standard output records previously saved in a file. This file can be either the one specified by the -f flag or, by default, the standard system activity daily data file. It is also possible to enter -1, -2 etc. as an argument to sar to display data of that days ago. For example, -1 will point at the standard system activity file of yesterday. Standard system activity daily data files are named saDD or saYYYYMMDD, where YYYY stands for the current year, MM for the current month and DD for the current day. They are the default files used by sar only when no filename has been explicitly specified. When used to write data to files (with its option -o), sar will use saYYYYMMDD if option -D has also been specified, else it will use saDD. When used to display the records previously saved in a file, sar will look for the most recent of saDD and saYYYYMMDD, and use it. Standard system activity daily data files are located in the /var/log/sa directory by default. Yet it is possible to specify an alternate location for them: If a directory (instead of a plain file) is used with options -f or -o then it will be considered as the directory containing the data files. Without the -P flag, the sar command reports system-wide (global among all processors) statistics, which are calculated as averages for values expressed as percentages, and as sums otherwise. If the -P flag is given, the sar command reports activity which relates to the specified processor or processors. If -P ALL is given, the sar command reports statistics for each individual processor and global statistics among all processors. Offline processors are not displayed. You can select information about specific system activities using flags. Not specifying any flags selects only CPU activity. Specifying the -A flag selects all possible activities. The default version of the sar command (CPU utilization report) might be one of the first facilities the user runs to begin system activity investigation, because it monitors major system resources. If CPU utilization is near 100 percent (user + nice + system), the workload sampled is CPU-bound. If multiple samples and multiple reports are desired, it is convenient to specify an output file for the sar command. Run the sar command as a background process. The syntax for this is: sar -o datafile interval count >/dev/null 2>&1 & All data are captured in binary form and saved to a file (datafile). The data can then be selectively displayed with the sar command using the -f option. Set the interval and count parameters to select count records at interval second intervals. If the count parameter is not set, all the records saved in the file will be selected. Collection of data in this manner is useful to characterize system usage over a period of time and determine peak usage hours. Note: The sar command only reports on local activities. -A This is equivalent to specifying -bBdFHISvwWy -m ALL -n ALL -q ALL -r ALL -u ALL. This option also implies specifying -I ALL -P ALL unless these options are explicitly set on the command line. -B Report paging statistics. The following values are displayed: pgpgin/s Total number of kilobytes the system paged in from disk per second. pgpgout/s Total number of kilobytes the system paged out to disk per second. fault/s Number of page faults (major + minor) made by the system per second. This is not a count of page faults that generate I/O, because some page faults can be resolved without I/O. majflt/s Number of major faults the system has made per second, those which have required loading a memory page from disk. pgfree/s Number of pages placed on the free list by the system per second. pgscank/s Number of pages scanned by the kswapd daemon per second. pgscand/s Number of pages scanned directly per second. pgsteal/s Number of pages the system has reclaimed from cache (pagecache and swapcache) per second to satisfy its memory demands. %vmeff Calculated as pgsteal / pgscan, this is a metric of the efficiency of page reclaim. If it is near 100% then almost every page coming off the tail of the inactive list is being reaped. If it gets too low (e.g. less than 30%) then the virtual memory is having some difficulty. This field is displayed as zero if no pages have been scanned during the interval of time. -b Report I/O and transfer rate statistics. The following values are displayed: tps Total number of transfers per second that were issued to physical devices. A transfer is an I/O request to a physical device. Multiple logical requests can be combined into a single I/O request to the device. A transfer is of indeterminate size. rtps Total number of read requests per second issued to physical devices. wtps Total number of write requests per second issued to physical devices. dtps Total number of discard requests per second issued to physical devices. bread/s Total amount of data read from the devices in blocks per second. Blocks are equivalent to sectors and therefore have a size of 512 bytes. bwrtn/s Total amount of data written to devices in blocks per second. bdscd/s Total amount of data discarded for devices in blocks per second. -C When reading data from a file, tell sar to display comments that have been inserted by sadc. -D Use saYYYYMMDD instead of saDD as the standard system activity daily data file name. This option works only when used in conjunction with option -o to save data to file. -d Report activity for each block device. When data are displayed, the device name is displayed as it (should) appear in /dev. sar uses data in /sys to determine the device name based on its major and minor numbers. If this name resolution fails, sar will use name mapping controlled by /etc/sysconfig/sysstat.ioconf file. Persistent device names can also be printed if option -j is used (see below). Statistics for all devices are displayed unless a restricted list is specified using option --dev= (see corresponding option entry). Note that disk activity depends on sadc's options -S DISK and -S XDISK to be collected. The following values are displayed: tps Total number of transfers per second that were issued to physical devices. A transfer is an I/O request to a physical device. Multiple logical requests can be combined into a single I/O request to the device. A transfer is of indeterminate size. rkB/s Number of kilobytes read from the device per second. wkB/s Number of kilobytes written to the device per second. dkB/s Number of kilobytes discarded for the device per second. areq-sz The average size (in kilobytes) of the I/O requests that were issued to the device. Note: In previous versions, this field was known as avgrq-sz and was expressed in sectors. aqu-sz The average queue length of the requests that were issued to the device. Note: In previous versions, this field was known as avgqu-sz. await The average time (in milliseconds) for I/O requests issued to the device to be served. This includes the time spent by the requests in queue and the time spent servicing them. %util Percentage of elapsed time during which I/O requests were issued to the device (bandwidth utilization for the device). Device saturation occurs when this value is close to 100% for devices serving requests serially. But for devices serving requests in parallel, such as RAID arrays and modern SSDs, this number does not reflect their performance limits. --dec={ 0 | 1 | 2 } Specify the number of decimal places to use (0 to 2, default value is 2). --dev=dev_list Specify the block devices for which statistics are to be displayed by sar. dev_list is a list of comma-separated device names. -e [ hh:mm[:ss] ] -e [ seconds_since_the_epoch ] Set the ending time of the report. The default ending time is 18:00:00. Hours must be given in 24-hour format, or as the number of seconds since the epoch (given as a 10 digit number). This option can be used when data are read from or written to a file (options -f or -o). -F [ MOUNT ] Display statistics for currently mounted filesystems. Pseudo-filesystems are ignored. At the end of the report, sar will display a summary of all those filesystems. Use of the MOUNT parameter keyword indicates that mountpoint will be reported instead of filesystem device. Statistics for all filesystems are displayed unless a restricted list is specified using option --fs= (see corresponding option entry). Note that filesystems statistics depend on sadc's option -S XDISK to be collected. The following values are displayed: MBfsfree Total amount of free space in megabytes (including space available only to privileged user). MBfsused Total amount of space used in megabytes. %fsused Percentage of filesystem space used, as seen by a privileged user. %ufsused Percentage of filesystem space used, as seen by an unprivileged user. Ifree Total number of free file nodes in filesystem. Iused Total number of file nodes used in filesystem. %Iused Percentage of file nodes used in filesystem. -f [ filename ] Extract records from filename (created by the -o filename flag). The default value of the filename parameter is the current standard system activity daily data file. If filename is a directory instead of a plain file then it is considered as the directory where the standard system activity daily data files are located. Option -f is exclusive of option -o. --fs=fs_list Specify the filesystems for which statistics are to be displayed by sar. fs_list is a list of comma-separated filesystem names or mountpoints. -H Report hugepages utilization statistics. The following values are displayed: kbhugfree Amount of hugepages memory in kilobytes that is not yet allocated. kbhugused Amount of hugepages memory in kilobytes that has been allocated. %hugused Percentage of total hugepages memory that has been allocated. kbhugrsvd Amount of reserved hugepages memory in kilobytes. kbhugsurp Amount of surplus hugepages memory in kilobytes. -h This option is equivalent to specifying --pretty --human. --help Display a short help message then exit. --human Print sizes in human readable format (e.g. 1.0k, 1.2M, etc.) The units displayed with this option supersede any other default units (e.g. kilobytes, sectors...) associated with the metrics. -I [ SUM | ALL ] Report statistics for interrupts. The values displayed are the number of interrupts per second for the given processor or among all processors. A list of interrupts can be specified using --int= (see this option). The SUM keyword indicates that the total number of interrupts received per second is to be displayed. The ALL keyword indicates that statistics from all interrupts are to be reported (this is the default). Note that interrupts statistics depend on sadc's option -S INT to be collected. -i interval Select data records at seconds as close as possible to the number specified by the interval parameter. --iface=iface_list Specify the network interfaces for which statistics are to be displayed by sar. iface_list is a list of comma- separated interface names. --int=int_list Specify the interrupts names for which statistics are to be displayed by sar. int_list is a list of comma- separated values or range of values (e.g., 0-16,35,40-). -j { SID | ID | LABEL | PATH | UUID | ... } Display persistent device names. Use this option in conjunction with option -d. Keywords ID, LABEL, etc. specify the type of the persistent name. These keywords are not limited, only prerequisite is that directory with required persistent names is present in /dev/disk. Keyword SID tries to get a stable identifier to use as the device name. A stable identifier won't change across reboots for the same physical device. If it exists, this identifier is normally the WWN (World Wide Name) of the device, as read from the /dev/disk/by-id directory. -m { keyword[,...] | ALL } Report power management statistics. Note that these statistics depend on sadc's option -S POWER to be collected. Possible keywords are BAT, CPU, FAN, FREQ, IN, TEMP and USB. With the BAT keyword, statistics about batteries capacity are reported. The following values are displayed: %cap Battery capacity. cap/min Capacity lost or gained per minute by the battery. status Charging status of the battery: \u2191 (full), \u2197 (charging), \u2192 (not charging), \u2198 (discharging), ? (unknown). With the CPU keyword, statistics about CPU are reported. The following value is displayed: MHz Instantaneous CPU clock frequency in MHz. With the FAN keyword, statistics about fans speed are reported. The following values are displayed: rpm Fan speed expressed in revolutions per minute. drpm This field is calculated as the difference between current fan speed (rpm) and its low limit (fan_min). DEVICE Sensor device name. With the FREQ keyword, statistics about CPU clock frequency are reported. The following value is displayed: wghMHz Weighted average CPU clock frequency in MHz. Note that the cpufreq-stats driver must be compiled in the kernel for this option to work. With the IN keyword, statistics about voltage inputs are reported. The following values are displayed: inV Voltage input expressed in Volts. %in Relative input value. A value of 100% means that voltage input has reached its high limit (in_max) whereas a value of 0% means that it has reached its low limit (in_min). DEVICE Sensor device name. With the TEMP keyword, statistics about devices temperature are reported. The following values are displayed: degC Device temperature expressed in degrees Celsius. %temp Relative device temperature. A value of 100% means that temperature has reached its high limit (temp_max). DEVICE Sensor device name. With the USB keyword, the sar command takes a snapshot of all the USB devices currently plugged into the system. At the end of the report, sar will display a summary of all those USB devices. The following values are displayed: BUS Root hub number of the USB device. idvendor Vendor ID number (assigned by USB organization). idprod Product ID number (assigned by Manufacturer). maxpower Maximum power consumption of the device (expressed in mA). manufact Manufacturer name. product Product name. The ALL keyword is equivalent to specifying all the keywords above and therefore all the power management statistics are reported. -n { keyword[,...] | ALL } Report network statistics. Possible keywords are DEV, EDEV, FC, ICMP, EICMP, ICMP6, EICMP6, IP, EIP, IP6, EIP6, NFS, NFSD, SOCK, SOCK6, SOFT, TCP, ETCP, UDP and UDP6. With the DEV keyword, statistics from the network devices are reported. Statistics for all network interfaces are displayed unless a restricted list is specified using option --iface= (see corresponding option entry). The following values are displayed: IFACE Name of the network interface for which statistics are reported. rxpck/s Total number of packets received per second. txpck/s Total number of packets transmitted per second. rxkB/s Total number of kilobytes received per second. txkB/s Total number of kilobytes transmitted per second. rxcmp/s Number of compressed packets received per second (for cslip etc.). txcmp/s Number of compressed packets transmitted per second. rxmcst/s Number of multicast packets received per second. %ifutil Utilization percentage of the network interface. For half-duplex interfaces, utilization is calculated using the sum of rxkB/s and txkB/s as a percentage of the interface speed. For full-duplex, this is the greater of rxkB/S or txkB/s. With the EDEV keyword, statistics on failures (errors) from the network devices are reported. Statistics for all network interfaces are displayed unless a restricted list is specified using option --iface= (see corresponding option entry). The following values are displayed: IFACE Name of the network interface for which statistics are reported. rxerr/s Total number of bad packets received per second. txerr/s Total number of errors that happened per second while transmitting packets. coll/s Number of collisions that happened per second while transmitting packets. rxdrop/s Number of received packets dropped per second because of a lack of space in linux buffers. txdrop/s Number of transmitted packets dropped per second because of a lack of space in linux buffers. txcarr/s Number of carrier-errors that happened per second while transmitting packets. rxfram/s Number of frame alignment errors that happened per second on received packets. rxfifo/s Number of FIFO overrun errors that happened per second on received packets. txfifo/s Number of FIFO overrun errors that happened per second on transmitted packets. With the FC keyword, statistics about fibre channel traffic are reported. Note that fibre channel statistics depend on sadc's option -S DISK to be collected. The following values are displayed: FCHOST Name of the fibre channel host bus adapter (HBA) interface for which statistics are reported. fch_rxf/s The total number of frames received per second. fch_txf/s The total number of frames transmitted per second. fch_rxw/s The total number of transmission words received per second. fch_txw/s The total number of transmission words transmitted per second. With the ICMP keyword, statistics about ICMPv4 network traffic are reported. Note that ICMPv4 statistics depend on sadc's option -S SNMP to be collected. The following values are displayed (formal SNMP names between square brackets): imsg/s The total number of ICMP messages which the entity received per second [icmpInMsgs]. Note that this counter includes all those counted by ierr/s. omsg/s The total number of ICMP messages which this entity attempted to send per second [icmpOutMsgs]. Note that this counter includes all those counted by oerr/s. iech/s The number of ICMP Echo (request) messages received per second [icmpInEchos]. iechr/s The number of ICMP Echo Reply messages received per second [icmpInEchoReps]. oech/s The number of ICMP Echo (request) messages sent per second [icmpOutEchos]. oechr/s The number of ICMP Echo Reply messages sent per second [icmpOutEchoReps]. itm/s The number of ICMP Timestamp (request) messages received per second [icmpInTimestamps]. itmr/s The number of ICMP Timestamp Reply messages received per second [icmpInTimestampReps]. otm/s The number of ICMP Timestamp (request) messages sent per second [icmpOutTimestamps]. otmr/s The number of ICMP Timestamp Reply messages sent per second [icmpOutTimestampReps]. iadrmk/s The number of ICMP Address Mask Request messages received per second [icmpInAddrMasks]. iadrmkr/s The number of ICMP Address Mask Reply messages received per second [icmpInAddrMaskReps]. oadrmk/s The number of ICMP Address Mask Request messages sent per second [icmpOutAddrMasks]. oadrmkr/s The number of ICMP Address Mask Reply messages sent per second [icmpOutAddrMaskReps]. With the EICMP keyword, statistics about ICMPv4 error messages are reported. Note that ICMPv4 statistics depend on sadc's option -S SNMP to be collected. The following values are displayed (formal SNMP names between square brackets): ierr/s The number of ICMP messages per second which the entity received but determined as having ICMP- specific errors (bad ICMP checksums, bad length, etc.) [icmpInErrors]. oerr/s The number of ICMP messages per second which this entity did not send due to problems discovered within ICMP such as a lack of buffers [icmpOutErrors]. idstunr/s The number of ICMP Destination Unreachable messages received per second [icmpInDestUnreachs]. odstunr/s The number of ICMP Destination Unreachable messages sent per second [icmpOutDestUnreachs]. itmex/s The number of ICMP Time Exceeded messages received per second [icmpInTimeExcds]. otmex/s The number of ICMP Time Exceeded messages sent per second [icmpOutTimeExcds]. iparmpb/s The number of ICMP Parameter Problem messages received per second [icmpInParmProbs]. oparmpb/s The number of ICMP Parameter Problem messages sent per second [icmpOutParmProbs]. isrcq/s The number of ICMP Source Quench messages received per second [icmpInSrcQuenchs]. osrcq/s The number of ICMP Source Quench messages sent per second [icmpOutSrcQuenchs]. iredir/s The number of ICMP Redirect messages received per second [icmpInRedirects]. oredir/s The number of ICMP Redirect messages sent per second [icmpOutRedirects]. With the ICMP6 keyword, statistics about ICMPv6 network traffic are reported. Note that ICMPv6 statistics depend on sadc's option -S IPV6 to be collected. The following values are displayed (formal SNMP names between square brackets): imsg6/s The total number of ICMP messages received by the interface per second which includes all those counted by ierr6/s [ipv6IfIcmpInMsgs]. omsg6/s The total number of ICMP messages which this interface attempted to send per second [ipv6IfIcmpOutMsgs]. iech6/s The number of ICMP Echo (request) messages received by the interface per second [ipv6IfIcmpInEchos]. iechr6/s The number of ICMP Echo Reply messages received by the interface per second [ipv6IfIcmpInEchoReplies]. oechr6/s The number of ICMP Echo Reply messages sent by the interface per second [ipv6IfIcmpOutEchoReplies]. igmbq6/s The number of ICMPv6 Group Membership Query messages received by the interface per second [ipv6IfIcmpInGroupMembQueries]. igmbr6/s The number of ICMPv6 Group Membership Response messages received by the interface per second [ipv6IfIcmpInGroupMembResponses]. ogmbr6/s The number of ICMPv6 Group Membership Response messages sent per second [ipv6IfIcmpOutGroupMembResponses]. igmbrd6/s The number of ICMPv6 Group Membership Reduction messages received by the interface per second [ipv6IfIcmpInGroupMembReductions]. ogmbrd6/s The number of ICMPv6 Group Membership Reduction messages sent per second [ipv6IfIcmpOutGroupMembReductions]. irtsol6/s The number of ICMP Router Solicit messages received by the interface per second [ipv6IfIcmpInRouterSolicits]. ortsol6/s The number of ICMP Router Solicitation messages sent by the interface per second [ipv6IfIcmpOutRouterSolicits]. irtad6/s The number of ICMP Router Advertisement messages received by the interface per second [ipv6IfIcmpInRouterAdvertisements]. inbsol6/s The number of ICMP Neighbor Solicit messages received by the interface per second [ipv6IfIcmpInNeighborSolicits]. onbsol6/s The number of ICMP Neighbor Solicitation messages sent by the interface per second [ipv6IfIcmpOutNeighborSolicits]. inbad6/s The number of ICMP Neighbor Advertisement messages received by the interface per second [ipv6IfIcmpInNeighborAdvertisements]. onbad6/s The number of ICMP Neighbor Advertisement messages sent by the interface per second [ipv6IfIcmpOutNeighborAdvertisements]. With the EICMP6 keyword, statistics about ICMPv6 error messages are reported. Note that ICMPv6 statistics depend on sadc's option -S IPV6 to be collected. The following values are displayed (formal SNMP names between square brackets): ierr6/s The number of ICMP messages per second which the interface received but determined as having ICMP- specific errors (bad ICMP checksums, bad length, etc.) [ipv6IfIcmpInErrors] idtunr6/s The number of ICMP Destination Unreachable messages received by the interface per second [ipv6IfIcmpInDestUnreachs]. odtunr6/s The number of ICMP Destination Unreachable messages sent by the interface per second [ipv6IfIcmpOutDestUnreachs]. itmex6/s The number of ICMP Time Exceeded messages received by the interface per second [ipv6IfIcmpInTimeExcds]. otmex6/s The number of ICMP Time Exceeded messages sent by the interface per second [ipv6IfIcmpOutTimeExcds]. iprmpb6/s The number of ICMP Parameter Problem messages received by the interface per second [ipv6IfIcmpInParmProblems]. oprmpb6/s The number of ICMP Parameter Problem messages sent by the interface per second [ipv6IfIcmpOutParmProblems]. iredir6/s The number of Redirect messages received by the interface per second [ipv6IfIcmpInRedirects]. oredir6/s The number of Redirect messages sent by the interface by second [ipv6IfIcmpOutRedirects]. ipck2b6/s The number of ICMP Packet Too Big messages received by the interface per second [ipv6IfIcmpInPktTooBigs]. opck2b6/s The number of ICMP Packet Too Big messages sent by the interface per second [ipv6IfIcmpOutPktTooBigs]. With the IP keyword, statistics about IPv4 network traffic are reported. Note that IPv4 statistics depend on sadc's option -S SNMP to be collected. The following values are displayed (formal SNMP names between square brackets): irec/s The total number of input datagrams received from interfaces per second, including those received in error [ipInReceives]. fwddgm/s The number of input datagrams per second, for which this entity was not their final IP destination, as a result of which an attempt was made to find a route to forward them to that final destination [ipForwDatagrams]. idel/s The total number of input datagrams successfully delivered per second to IP user-protocols (including ICMP) [ipInDelivers]. orq/s The total number of IP datagrams which local IP user-protocols (including ICMP) supplied per second to IP in requests for transmission [ipOutRequests]. Note that this counter does not include any datagrams counted in fwddgm/s. asmrq/s The number of IP fragments received per second which needed to be reassembled at this entity [ipReasmReqds]. asmok/s The number of IP datagrams successfully re- assembled per second [ipReasmOKs]. fragok/s The number of IP datagrams that have been successfully fragmented at this entity per second [ipFragOKs]. fragcrt/s The number of IP datagram fragments that have been generated per second as a result of fragmentation at this entity [ipFragCreates]. With the EIP keyword, statistics about IPv4 network errors are reported. Note that IPv4 statistics depend on sadc's option -S SNMP to be collected. The following values are displayed (formal SNMP names between square brackets): ihdrerr/s The number of input datagrams discarded per second due to errors in their IP headers, including bad checksums, version number mismatch, other format errors, time-to-live exceeded, errors discovered in processing their IP options, etc. [ipInHdrErrors] iadrerr/s The number of input datagrams discarded per second because the IP address in their IP header's destination field was not a valid address to be received at this entity. This count includes invalid addresses (e.g., 0.0.0.0) and addresses of unsupported Classes (e.g., Class E). For entities which are not IP routers and therefore do not forward datagrams, this counter includes datagrams discarded because the destination address was not a local address [ipInAddrErrors]. iukwnpr/s The number of locally-addressed datagrams received successfully but discarded per second because of an unknown or unsupported protocol [ipInUnknownProtos]. idisc/s The number of input IP datagrams per second for which no problems were encountered to prevent their continued processing, but which were discarded (e.g., for lack of buffer space) [ipInDiscards]. Note that this counter does not include any datagrams discarded while awaiting re-assembly. odisc/s The number of output IP datagrams per second for which no problem was encountered to prevent their transmission to their destination, but which were discarded (e.g., for lack of buffer space) [ipOutDiscards]. Note that this counter would include datagrams counted in fwddgm/s if any such packets met this (discretionary) discard criterion. onort/s The number of IP datagrams discarded per second because no route could be found to transmit them to their destination [ipOutNoRoutes]. Note that this counter includes any packets counted in fwddgm/s which meet this 'no-route' criterion. Note that this includes any datagrams which a host cannot route because all of its default routers are down. asmf/s The number of failures detected per second by the IP re-assembly algorithm (for whatever reason: timed out, errors, etc) [ipReasmFails]. Note that this is not necessarily a count of discarded IP fragments since some algorithms can lose track of the number of fragments by combining them as they are received. fragf/s The number of IP datagrams that have been discarded per second because they needed to be fragmented at this entity but could not be, e.g., because their Don't Fragment flag was set [ipFragFails]. With the IP6 keyword, statistics about IPv6 network traffic are reported. Note that IPv6 statistics depend on sadc's option -S IPV6 to be collected. The following values are displayed (formal SNMP names between square brackets): irec6/s The total number of input datagrams received from interfaces per second, including those received in error [ipv6IfStatsInReceives]. fwddgm6/s The number of output datagrams per second which this entity received and forwarded to their final destinations [ipv6IfStatsOutForwDatagrams]. idel6/s The total number of datagrams successfully delivered per second to IPv6 user-protocols (including ICMP) [ipv6IfStatsInDelivers]. orq6/s The total number of IPv6 datagrams which local IPv6 user-protocols (including ICMP) supplied per second to IPv6 in requests for transmission [ipv6IfStatsOutRequests]. Note that this counter does not include any datagrams counted in fwddgm6/s. asmrq6/s The number of IPv6 fragments received per second which needed to be reassembled at this interface [ipv6IfStatsReasmReqds]. asmok6/s The number of IPv6 datagrams successfully reassembled per second [ipv6IfStatsReasmOKs]. imcpck6/s The number of multicast packets received per second by the interface [ipv6IfStatsInMcastPkts]. omcpck6/s The number of multicast packets transmitted per second by the interface [ipv6IfStatsOutMcastPkts]. fragok6/s The number of IPv6 datagrams that have been successfully fragmented at this output interface per second [ipv6IfStatsOutFragOKs]. fragcr6/s The number of output datagram fragments that have been generated per second as a result of fragmentation at this output interface [ipv6IfStatsOutFragCreates]. With the EIP6 keyword, statistics about IPv6 network errors are reported. Note that IPv6 statistics depend on sadc's option -S IPV6 to be collected. The following values are displayed (formal SNMP names between square brackets): ihdrer6/s The number of input datagrams discarded per second due to errors in their IPv6 headers, including version number mismatch, other format errors, hop count exceeded, errors discovered in processing their IPv6 options, etc. [ipv6IfStatsInHdrErrors] iadrer6/s The number of input datagrams discarded per second because the IPv6 address in their IPv6 header's destination field was not a valid address to be received at this entity. This count includes invalid addresses (e.g., ::0) and unsupported addresses (e.g., addresses with unallocated prefixes). For entities which are not IPv6 routers and therefore do not forward datagrams, this counter includes datagrams discarded because the destination address was not a local address [ipv6IfStatsInAddrErrors]. iukwnp6/s The number of locally-addressed datagrams received successfully but discarded per second because of an unknown or unsupported protocol [ipv6IfStatsInUnknownProtos]. i2big6/s The number of input datagrams that could not be forwarded per second because their size exceeded the link MTU of outgoing interface [ipv6IfStatsInTooBigErrors]. idisc6/s The number of input IPv6 datagrams per second for which no problems were encountered to prevent their continued processing, but which were discarded (e.g., for lack of buffer space) [ipv6IfStatsInDiscards]. Note that this counter does not include any datagrams discarded while awaiting re-assembly. odisc6/s The number of output IPv6 datagrams per second for which no problem was encountered to prevent their transmission to their destination, but which were discarded (e.g., for lack of buffer space) [ipv6IfStatsOutDiscards]. Note that this counter would include datagrams counted in fwddgm6/s if any such packets met this (discretionary) discard criterion. inort6/s The number of input datagrams discarded per second because no route could be found to transmit them to their destination [ipv6IfStatsInNoRoutes]. onort6/s The number of locally generated IP datagrams discarded per second because no route could be found to transmit them to their destination [unknown formal SNMP name]. asmf6/s The number of failures detected per second by the IPv6 re-assembly algorithm (for whatever reason: timed out, errors, etc.) [ipv6IfStatsReasmFails]. Note that this is not necessarily a count of discarded IPv6 fragments since some algorithms can lose track of the number of fragments by combining them as they are received. fragf6/s The number of IPv6 datagrams that have been discarded per second because they needed to be fragmented at this output interface but could not be [ipv6IfStatsOutFragFails]. itrpck6/s The number of input datagrams discarded per second because datagram frame didn't carry enough data [ipv6IfStatsInTruncatedPkts]. With the NFS keyword, statistics about NFS client activity are reported. The following values are displayed: call/s Number of RPC requests made per second. retrans/s Number of RPC requests per second, those which needed to be retransmitted (for example because of a server timeout). read/s Number of 'read' RPC calls made per second. write/s Number of 'write' RPC calls made per second. access/s Number of 'access' RPC calls made per second. getatt/s Number of 'getattr' RPC calls made per second. With the NFSD keyword, statistics about NFS server activity are reported. The following values are displayed: scall/s Number of RPC requests received per second. badcall/s Number of bad RPC requests received per second, those whose processing generated an error. packet/s Number of network packets received per second. udp/s Number of UDP packets received per second. tcp/s Number of TCP packets received per second. hit/s Number of reply cache hits per second. miss/s Number of reply cache misses per second. sread/s Number of 'read' RPC calls received per second. swrite/s Number of 'write' RPC calls received per second. saccess/s Number of 'access' RPC calls received per second. sgetatt/s Number of 'getattr' RPC calls received per second. With the SOCK keyword, statistics on sockets in use are reported (IPv4). The following values are displayed: totsck Total number of sockets used by the system. tcpsck Number of TCP sockets currently in use. udpsck Number of UDP sockets currently in use. rawsck Number of RAW sockets currently in use. ip-frag Number of IP fragments currently in queue. tcp-tw Number of TCP sockets in TIME_WAIT state. With the SOCK6 keyword, statistics on sockets in use are reported (IPv6). Note that IPv6 statistics depend on sadc's option -S IPV6 to be collected. The following values are displayed: tcp6sck Number of TCPv6 sockets currently in use. udp6sck Number of UDPv6 sockets currently in use. raw6sck Number of RAWv6 sockets currently in use. ip6-frag Number of IPv6 fragments currently in use. With the SOFT keyword, statistics about software-based network processing are reported. The following values are displayed: total/s The total number of network frames processed per second. dropd/s The total number of network frames dropped per second because there was no room on the processing queue. squeezd/s The number of times the softirq handler function terminated per second because its budget was consumed or the time limit was reached, but more work could have been done. rx_rps/s The number of times the CPU has been woken up per second to process packets via an inter-processor interrupt. flw_lim/s The number of times the flow limit has been reached per second. Flow limiting is an optional RPS feature that can be used to limit the number of packets queued to the backlog for each flow to a certain amount. This can help ensure that smaller flows are processed even though much larger flows are pushing packets in. blg_len The length of the network backlog. With the TCP keyword, statistics about TCPv4 network traffic are reported. Note that TCPv4 statistics depend on sadc's option -S SNMP to be collected. The following values are displayed (formal SNMP names between square brackets): active/s The number of times TCP connections have made a direct transition to the SYN-SENT state from the CLOSED state per second [tcpActiveOpens]. passive/s The number of times TCP connections have made a direct transition to the SYN-RCVD state from the LISTEN state per second [tcpPassiveOpens]. iseg/s The total number of segments received per second, including those received in error [tcpInSegs]. This count includes segments received on currently established connections. oseg/s The total number of segments sent per second, including those on current connections but excluding those containing only retransmitted octets [tcpOutSegs]. With the ETCP keyword, statistics about TCPv4 network errors are reported. Note that TCPv4 statistics depend on sadc's option -S SNMP to be collected. The following values are displayed (formal SNMP names between square brackets): atmptf/s The number of times per second TCP connections have made a direct transition to the CLOSED state from either the SYN-SENT state or the SYN-RCVD state, plus the number of times per second TCP connections have made a direct transition to the LISTEN state from the SYN-RCVD state [tcpAttemptFails]. estres/s The number of times per second TCP connections have made a direct transition to the CLOSED state from either the ESTABLISHED state or the CLOSE-WAIT state [tcpEstabResets]. retrans/s The total number of segments retransmitted per second - that is, the number of TCP segments transmitted containing one or more previously transmitted octets [tcpRetransSegs]. isegerr/s The total number of segments received in error (e.g., bad TCP checksums) per second [tcpInErrs]. orsts/s The number of TCP segments sent per second containing the RST flag [tcpOutRsts]. With the UDP keyword, statistics about UDPv4 network traffic are reported. Note that UDPv4 statistics depend on sadc's option -S SNMP to be collected. The following values are displayed (formal SNMP names between square brackets): idgm/s The total number of UDP datagrams delivered per second to UDP users [udpInDatagrams]. odgm/s The total number of UDP datagrams sent per second from this entity [udpOutDatagrams]. noport/s The total number of received UDP datagrams per second for which there was no application at the destination port [udpNoPorts]. idgmerr/s The number of received UDP datagrams per second that could not be delivered for reasons other than the lack of an application at the destination port [udpInErrors]. With the UDP6 keyword, statistics about UDPv6 network traffic are reported. Note that UDPv6 statistics depend on sadc's option -S IPV6 to be collected. The following values are displayed (formal SNMP names between square brackets): idgm6/s The total number of UDP datagrams delivered per second to UDP users [udpInDatagrams]. odgm6/s The total number of UDP datagrams sent per second from this entity [udpOutDatagrams]. noport6/s The total number of received UDP datagrams per second for which there was no application at the destination port [udpNoPorts]. idgmer6/s The number of received UDP datagrams per second that could not be delivered for reasons other than the lack of an application at the destination port [udpInErrors]. The ALL keyword is equivalent to specifying all the keywords above and therefore all the network activities are reported. -o [ filename ] Save the readings in the file in binary form. Each reading is in a separate record. The default value of the filename parameter is the current standard system activity daily data file. If filename is a directory instead of a plain file then it is considered as the directory where the standard system activity daily data files are located. Option -o is exclusive of option -f. All the data available from the kernel are saved in the file (in fact, sar calls its data collector sadc with the option -S ALL. See sadc(8) manual page). -P { cpu_list | ALL } Report per-processor statistics for the specified processor or processors. cpu_list is a list of comma- separated values or range of values (e.g., 0,2,4-7,12-). Note that processor 0 is the first processor, and processor all is the global average among all processors. Specifying the ALL keyword reports statistics for each individual processor, and globally for all processors. Offline processors are not displayed. -p, --pretty Make reports easier to read by a human. This option may be especially useful when displaying e.g., network interfaces or block devices statistics. -q [ keyword[,...] | ALL ] Report system load and pressure-stall statistics. Possible keywords are CPU, IO, LOAD, MEM and PSI. With the CPU keyword, CPU pressure statistics are reported. The following values are displayed: %scpu-10 Percentage of the time that at least some runnable tasks were delayed because the CPU was unavailable to them, over the last 10 second window. %scpu-60 Percentage of the time that at least some runnable tasks were delayed because the CPU was unavailable to them, over the last 60 second window. %scpu-300 Percentage of the time that at least some runnable tasks were delayed because the CPU was unavailable to them, over the last 300 second window. %scpu Percentage of the time that at least some runnable tasks were delayed because the CPU was unavailable to them, over the last time interval. With the IO keyword, I/O pressure statistics are reported. The following values are displayed: %sio-10 Percentage of the time that at least some tasks lost waiting for I/O, over the last 10 second window. %sio-60 Percentage of the time that at least some tasks lost waiting for I/O, over the last 60 second window. %sio-300 Percentage of the time that at least some tasks lost waiting for I/O, over the last 300 second window. %sio Percentage of the time that at least some tasks lost waiting for I/O, over the last time interval. %fio-10 Percentage of the time during which all non-idle tasks were stalled waiting for I/O, over the last 10 second window. %fio-60 Percentage of the time during which all non-idle tasks were stalled waiting for I/O, over the last 60 second window. %fio-300 Percentage of the time during which all non-idle tasks were stalled waiting for I/O, over the last 300 second window. %fio Percentage of the time during which all non-idle tasks were stalled waiting for I/O, over the last time interval. With the LOAD keyword, queue length and load averages statistics are reported. The following values are displayed: runq-sz Run queue length (number of tasks running or waiting for run time). plist-sz Number of tasks in the task list. ldavg-1 System load average for the last minute. The load average is calculated as the average number of runnable or running tasks (R state), and the number of tasks in uninterruptible sleep (D state) over the specified interval. ldavg-5 System load average for the past 5 minutes. ldavg-15 System load average for the past 15 minutes. blocked Number of tasks currently blocked, waiting for I/O to complete. With the MEM keyword, memory pressure statistics are reported. The following values are displayed: %smem-10 Percentage of the time during which at least some tasks were waiting for memory resources, over the last 10 second window. %smem-60 Percentage of the time during which at least some tasks were waiting for memory resources, over the last 60 second window. %smem-300 Percentage of the time during which at least some tasks were waiting for memory resources, over the last 300 second window. %smem Percentage of the time during which at least some tasks were waiting for memory resources, over the last time interval. %fmem-10 Percentage of the time during which all non-idle tasks were stalled waiting for memory resources, over the last 10 second window. %fmem-60 Percentage of the time during which all non-idle tasks were stalled waiting for memory resources, over the last 60 second window. %fmem-300 Percentage of the time during which all non-idle tasks were stalled waiting for memory resources, over the last 300 second window. %fmem Percentage of the time during which all non-idle tasks were stalled waiting for memory resources, over the last time interval. The PSI keyword is equivalent to specifying CPU, IO and MEM keywords together and therefore all the pressure-stall statistics are reported. The ALL keyword is equivalent to specifying all the keywords above and therefore all the statistics are reported. -r [ ALL ] Report memory utilization statistics. The ALL keyword indicates that all the memory fields should be displayed. The following values may be displayed: kbmemfree Amount of free memory available in kilobytes. kbavail Estimate of how much memory in kilobytes is available for starting new applications, without swapping. The estimate takes into account that the system needs some page cache to function well, and that not all reclaimable slab will be reclaimable, due to items being in use. The impact of those factors will vary from system to system. kbmemused Amount of used memory in kilobytes (calculated as total installed memory - kbmemfree - kbbuffers - kbcached - kbslab). %memused Percentage of used memory. kbbuffers Amount of memory used as buffers by the kernel in kilobytes. kbcached Amount of memory used to cache data by the kernel in kilobytes. kbcommit Amount of memory in kilobytes needed for current workload. This is an estimate of how much RAM/swap is needed to guarantee that there never is out of memory. %commit Percentage of memory needed for current workload in relation to the total amount of memory (RAM+swap). This number may be greater than 100% because the kernel usually overcommits memory. kbactive Amount of active memory in kilobytes (memory that has been used more recently and usually not reclaimed unless absolutely necessary). kbinact Amount of inactive memory in kilobytes (memory which has been less recently used. It is more eligible to be reclaimed for other purposes). kbdirty Amount of memory in kilobytes waiting to get written back to the disk. kbanonpg Amount of non-file backed pages in kilobytes mapped into userspace page tables. kbslab Amount of memory in kilobytes used by the kernel to cache data structures for its own use. kbkstack Amount of memory in kilobytes used for kernel stack space. kbpgtbl Amount of memory in kilobytes dedicated to the lowest level of page tables. kbvmused Amount of memory in kilobytes of used virtual address space. -S Report swap space utilization statistics. The following values are displayed: kbswpfree Amount of free swap space in kilobytes. kbswpused Amount of used swap space in kilobytes. %swpused Percentage of used swap space. kbswpcad Amount of cached swap memory in kilobytes. This is memory that once was swapped out, is swapped back in but still also is in the swap area (if memory is needed it doesn't need to be swapped out again because it is already in the swap area. This saves I/O). %swpcad Percentage of cached swap memory in relation to the amount of used swap space. -s [ hh:mm[:ss] ] -s [ seconds_since_the_epoch ] Set the starting time of the data, causing the sar command to extract records time-tagged at, or following, the time specified. The default starting time is 08:00:00. Hours must be given in 24-hour format, or as the number of seconds since the epoch (given as a 10 digit number). This option can be used only when data are read from a file (option -f). --sadc Indicate which data collector is called by sar. If the data collector is sought in PATH then enter \"which sadc\" to know where it is located. -t When reading data from a daily data file, indicate that sar should display the timestamps in the original local time of the data file creator. Without this option, the sar command displays the timestamps in the user's local time. -u [ ALL ] Report CPU utilization. The ALL keyword indicates that all the CPU fields should be displayed. The report may show the following fields: %user Percentage of CPU utilization that occurred while executing at the user level (application). Note that this field includes time spent running virtual processors. %usr Percentage of CPU utilization that occurred while executing at the user level (application). Note that this field does NOT include time spent running virtual processors. %nice Percentage of CPU utilization that occurred while executing at the user level with nice priority. %system Percentage of CPU utilization that occurred while executing at the system level (kernel). Note that this field includes time spent servicing hardware and software interrupts. %sys Percentage of CPU utilization that occurred while executing at the system level (kernel). Note that this field does NOT include time spent servicing hardware or software interrupts. %iowait Percentage of time that the CPU or CPUs were idle during which the system had an outstanding disk I/O request. %steal Percentage of time spent in involuntary wait by the virtual CPU or CPUs while the hypervisor was servicing another virtual processor. %irq Percentage of time spent by the CPU or CPUs to service hardware interrupts. %soft Percentage of time spent by the CPU or CPUs to service software interrupts. %guest Percentage of time spent by the CPU or CPUs to run a virtual processor. %gnice Percentage of time spent by the CPU or CPUs to run a niced guest. %idle Percentage of time that the CPU or CPUs were idle and the system did not have an outstanding disk I/O request. -V Print version number then exit. -v Report status of inode, file and other kernel tables. The following values are displayed: dentunusd Number of unused cache entries in the directory cache. file-nr Number of file handles used by the system. inode-nr Number of inode handlers used by the system. pty-nr Number of pseudo-terminals used by the system. -W Report swapping statistics. The following values are displayed: pswpin/s Total number of swap pages the system brought in per second. pswpout/s Total number of swap pages the system brought out per second. -w Report task creation and system switching activity. The following values are displayed: proc/s Total number of tasks created per second. cswch/s Total number of context switches per second. -x Extended reports: Display minimum and maximum values in addition to average ones at the end of the report. -y Report TTY devices activity. The following values are displayed: rcvin/s Number of receive interrupts per second for current serial line. Serial line number is given in the TTY column. xmtin/s Number of transmit interrupts per second for current serial line. framerr/s Number of frame errors per second for current serial line. prtyerr/s Number of parity errors per second for current serial line. brk/s Number of breaks per second for current serial line. ovrun/s Number of overrun errors per second for current serial line. -z Tell sar to omit output for any devices for which there was no activity during the sample period. "
  },
  {
    "command": "rename",
    "description": " rename will rename the specified files by replacing the first occurrence of expression in their name by replacement. -s, --symlink Do not rename a symlink but change where it points. -v, --verbose Show which files were renamed, if any. -n, --no-act Do not make any changes; add --verbose to see what would be made. -a, --all Replace all occurrences of expression rather than only the first one. -l, --last Replace the last occurrence of expression rather than the first one. -o, --no-overwrite Do not overwrite existing files. When --symlink is active, do not overwrite symlinks pointing to existing targets. -i, --interactive Ask before overwriting existing files. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "strip",
    "description": " GNU strip discards all symbols from object files objfile. The list of object files may include archives. At least one object file must be given. strip modifies the files named in its argument, rather than writing modified copies under different names. -F bfdname --target=bfdname Treat the original objfile as a file with the object code format bfdname, and rewrite it in the same format. --help Show a summary of the options to strip and exit. --info Display a list showing all architectures and object formats available. -I bfdname --input-target=bfdname Treat the original objfile as a file with the object code format bfdname. -O bfdname --output-target=bfdname Replace objfile with a file in the output format bfdname. -R sectionname --remove-section=sectionname Remove any section named sectionname from the output file, in addition to whatever sections would otherwise be removed. This option may be given more than once. Note that using this option inappropriately may make the output file unusable. The wildcard character * may be given at the end of sectionname. If so, then any section starting with sectionname will be removed. If the first character of sectionpattern is the exclamation point (!) then matching sections will not be removed even if an earlier use of --remove-section on the same command line would otherwise remove it. For example: --remove-section=.text.* --remove-section=!.text.foo will remove all sections matching the pattern '.text.*', but will not remove the section '.text.foo'. --keep-section=sectionpattern When removing sections from the output file, keep sections that match sectionpattern. --remove-relocations=sectionpattern Remove relocations from the output file for any section matching sectionpattern. This option may be given more than once. Note that using this option inappropriately may make the output file unusable. Wildcard characters are accepted in sectionpattern. For example: --remove-relocations=.text.* will remove the relocations for all sections matching the patter '.text.*'. If the first character of sectionpattern is the exclamation point (!) then matching sections will not have their relocation removed even if an earlier use of --remove-relocations on the same command line would otherwise cause the relocations to be removed. For example: --remove-relocations=.text.* --remove-relocations=!.text.foo will remove all relocations for sections matching the pattern '.text.*', but will not remove relocations for the section '.text.foo'. -s --strip-all Remove all symbols. -g -S -d --strip-debug Remove debugging symbols only. --strip-dwo Remove the contents of all DWARF .dwo sections, leaving the remaining debugging sections and all symbols intact. See the description of this option in the objcopy section for more information. --strip-unneeded Remove all symbols that are not needed for relocation processing in addition to debugging symbols and sections stripped by --strip-debug. -K symbolname --keep-symbol=symbolname When stripping symbols, keep symbol symbolname even if it would normally be stripped. This option may be given more than once. -M --merge-notes --no-merge-notes For ELF files, attempt (or do not attempt) to reduce the size of any SHT_NOTE type sections by removing duplicate notes. The default is to attempt this reduction unless stripping debug or DWO information. -N symbolname --strip-symbol=symbolname Remove symbol symbolname from the source file. This option may be given more than once, and may be combined with strip options other than -K. -o file Put the stripped output in file, rather than replacing the existing file. When this argument is used, only one objfile argument may be specified. -p --preserve-dates Preserve the access and modification dates of the file. -D --enable-deterministic-archives Operate in deterministic mode. When copying archive members and writing the archive index, use zero for UIDs, GIDs, timestamps, and use consistent file modes for all files. If binutils was configured with --enable-deterministic-archives, then this mode is on by default. It can be disabled with the -U option, below. -U --disable-deterministic-archives Do not operate in deterministic mode. This is the inverse of the -D option, above: when copying archive members and writing the archive index, use their actual UID, GID, timestamp, and file mode values. This is the default unless binutils was configured with --enable-deterministic-archives. -w --wildcard Permit regular expressions in symbolnames used in other command line options. The question mark (?), asterisk (*), backslash (\\) and square brackets ([]) operators can be used anywhere in the symbol name. If the first character of the symbol name is the exclamation point (!) then the sense of the switch is reversed for that symbol. For example: -w -K !foo -K fo* would cause strip to only keep symbols that start with the letters \"fo\", but to discard the symbol \"foo\". -x --discard-all Remove non-global symbols. -X --discard-locals Remove compiler-generated local symbols. (These usually start with L or ..) --keep-section-symbols When stripping a file, perhaps with --strip-debug or --strip-unneeded, retain any symbols specifying section names, which would otherwise get stripped. --keep-file-symbols When stripping a file, perhaps with --strip-debug or --strip-unneeded, retain any symbols specifying source file names, which would otherwise get stripped. --only-keep-debug Strip a file, emptying the contents of any sections that would not be stripped by --strip-debug and leaving the debugging sections intact. In ELF files, this preserves all the note sections in the output as well. Note - the section headers of the stripped sections are preserved, including their sizes, but the contents of the section are discarded. The section headers are preserved so that other tools can match up the debuginfo file with the real executable, even if that executable has been relocated to a different address space. The intention is that this option will be used in conjunction with --add-gnu-debuglink to create a two part executable. One a stripped binary which will occupy less space in RAM and in a distribution and the second a debugging information file which is only needed if debugging abilities are required. The suggested procedure to create these files is as follows: 1.<Link the executable as normal. Assuming that it is called> \"foo\" then... 1.<Run \"objcopy --only-keep-debug foo foo.dbg\" to> create a file containing the debugging info. 1.<Run \"objcopy --strip-debug foo\" to create a> stripped executable. 1.<Run \"objcopy --add-gnu-debuglink=foo.dbg foo\"> to add a link to the debugging info into the stripped executable. Note---the choice of \".dbg\" as an extension for the debug info file is arbitrary. Also the \"--only-keep-debug\" step is optional. You could instead do this: 1.<Link the executable as normal.> 1.<Copy \"foo\" to \"foo.full\"> 1.<Run \"strip --strip-debug foo\"> 1.<Run \"objcopy --add-gnu-debuglink=foo.full foo\"> i.e., the file pointed to by the --add-gnu-debuglink can be the full executable. It does not have to be a file created by the --only-keep-debug switch. Note---this switch is only intended for use on fully linked files. It does not make sense to use it on object files where the debugging information may be incomplete. Besides the gnu_debuglink feature currently only supports the presence of one filename containing debugging information, not multiple filenames on a one-per-object-file basis. -V --version Show the version number for strip. -v --verbose Verbose output: list all object files modified. In the case of archives, strip -v lists all members of the archive. @file Read command-line options from file. The options read are inserted in place of the original @file option. If file does not exist, or cannot be read, then the option will be treated literally, and not removed. Options in file are separated by whitespace. A whitespace character may be included in an option by surrounding the entire option in either single or double quotes. Any character (including a backslash) may be included by prefixing the character to be included with a backslash. The file may itself contain additional @file options; any such options will be processed recursively. "
  },
  {
    "command": "head",
    "description": " The head utility shall copy its input files to the standard output, ending the output for each file at a designated point. Copying shall end at the point in each input file indicated by the -n number option. The option-argument number shall be counted in units of lines. The head utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -n number The first number lines of each input file shall be copied to standard output. The application shall ensure that the number option-argument is a positive decimal integer. When a file contains less than number lines, it shall be copied to standard output in its entirety. This shall not be an error. If no options are specified, head shall act as if -n 10 had been specified. "
  },
  {
    "command": "wall",
    "description": " wall displays a message, or the contents of a file, or otherwise its standard input, on the terminals of all currently logged in users. The command will wrap lines that are longer than 79 characters. Short lines are whitespace padded to have 79 characters. The command will always put a carriage return and new line at the end of each line. Only the superuser can write on the terminals of users who have chosen to deny messages or are using a program which automatically denies messages. Reading from a file is refused when the invoker is not superuser and the program is set-user-ID or set-group-ID. -n, --nobanner Suppress the banner. -t, --timeout timeout Abandon the write attempt to the terminals after timeout seconds. This timeout must be a positive integer. The default value is 300 seconds, which is a legacy from the time when people ran terminals over modem lines. -g, --group group Limit printing message to members of group defined as a group argument. The argument can be group name or GID. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "stat",
    "description": " Display file or file system status. Mandatory arguments to long options are mandatory for short options too. -L, --dereference follow links -f, --file-system display file system status instead of file status --cached=MODE specify how to use cached attributes; useful on remote file systems. See MODE below -c --format=FORMAT use the specified FORMAT instead of the default; output a newline after each use of FORMAT --printf=FORMAT like --format, but interpret backslash escapes, and do not output a mandatory trailing newline; if you want a newline, include \\n in FORMAT -t, --terse print the information in terse form --help display this help and exit --version output version information and exit The MODE argument of --cached can be: always, never, or default. 'always' will use cached attributes if available, while 'never' will try to synchronize with the latest attributes, and 'default' will leave it up to the underlying file system. The valid format sequences for files (without --file-system): %a permission bits in octal (note '#' and '0' printf flags) %A permission bits and file type in human readable form %b number of blocks allocated (see %B) %B the size in bytes of each block reported by %b %C SELinux security context string %d device number in decimal (st_dev) %D device number in hex (st_dev) %Hd major device number in decimal %Ld minor device number in decimal %f raw mode in hex %F file type %g group ID of owner %G group name of owner %h number of hard links %i inode number %m mount point %n file name %N quoted file name with dereference if symbolic link %o optimal I/O transfer size hint %s total size, in bytes %r device type in decimal (st_rdev) %R device type in hex (st_rdev) %Hr major device type in decimal, for character/block device special files %Lr minor device type in decimal, for character/block device special files %t major device type in hex, for character/block device special files %T minor device type in hex, for character/block device special files %u user ID of owner %U user name of owner %w time of file birth, human-readable; - if unknown %W time of file birth, seconds since Epoch; 0 if unknown %x time of last access, human-readable %X time of last access, seconds since Epoch %y time of last data modification, human-readable %Y time of last data modification, seconds since Epoch %z time of last status change, human-readable %Z time of last status change, seconds since Epoch Valid format sequences for file systems: %a free blocks available to non-superuser %b total data blocks in file system %c total file nodes in file system %d free file nodes in file system %f free blocks in file system %i file system ID in hex %l maximum length of filenames %n file name %s block size (for faster transfers) %S fundamental block size (for block counts) %t file system type in hex %T file system type in human readable form --terse is equivalent to the following FORMAT: %n %s %b %f %u %g %D %i %h %t %T %X %Y %Z %W %o %C --terse --file-system is equivalent to the following FORMAT: %n %i %l %t %s %S %b %f %a %c %d NOTE: your shell may have its own version of stat, which usually supersedes the version described here. Please refer to your shell's documentation for details about the options it supports. "
  },
  {
    "command": "ar",
    "description": " The ar utility is part of the Software Development Utilities option. The ar utility can be used to create and maintain groups of files combined into an archive. Once an archive has been created, new files can be added, and existing files in an archive can be extracted, deleted, or replaced. When an archive consists entirely of valid object files, the implementation shall format the archive so that it is usable as a library for link editing (see c99 and fort77). When some of the archived files are not valid object files, the suitability of the archive for library use is undefined. If an archive consists entirely of printable files, the entire archive shall be printable. When ar creates an archive, it creates administrative information indicating whether a symbol table is present in the archive. When there is at least one object file that ar recognizes as such in the archive, an archive symbol table shall be created in the archive and maintained by ar; it is used by the link editor to search the archive. Whenever the ar utility is used to create or update the contents of such an archive, the symbol table shall be rebuilt. The -s option shall force the symbol table to be rebuilt. All file operands can be pathnames. However, files within archives shall be named by a filename, which is the last component of the pathname used when the file was entered into the archive. The comparison of file operands to the names of files in archives shall be performed by comparing the last component of the operand to the name of the file in the archive. It is unspecified whether multiple files in the archive may be identically named. In the case of such files, however, each file and posname operand shall match only the first file in the archive having a name that is the same as the last component of the operand. The ar utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for Guideline 9. The following options shall be supported: -a Position new files in the archive after the file named by the posname operand. -b Position new files in the archive before the file named by the posname operand. -c Suppress the diagnostic message that is written to standard error by default when the archive archive is created. -C Prevent extracted files from replacing like-named files in the file system. This option is useful when -T is also used, to prevent truncated filenames from replacing files with the same prefix. -d Delete one or more files from archive. -i Position new files in the archive before the file in the archive named by the posname operand (equivalent to -b). -m Move the named files in the archive. The -a, -b, or -i options with the posname operand indicate the position; otherwise, move the names files in the archive to the end of the archive. -p Write the contents of the files in the archive named by file operands from archive to the standard output. If no file operands are specified, the contents of all files in the archive shall be written in the order of the archive. -q Append the named files to the end of the archive. In this case ar does not check whether the added files are already in the archive. This is useful to bypass the searching otherwise done when creating a large archive piece by piece. -r Replace or add files to archive. If the archive named by archive does not exist, a new archive shall be created and a diagnostic message shall be written to standard error (unless the -c option is specified). If no files are specified and the archive exists, the results are undefined. Files that replace existing files in the archive shall not change the order of the archive. Files that do not replace existing files in the archive shall be appended to the archive unless a -a, -b, or -i option specifies another position. -s Force the regeneration of the archive symbol table even if ar is not invoked with an option that modifies the archive contents. This option is useful to restore the archive symbol table after it has been stripped; see strip. -t Write a table of contents of archive to the standard output. Only the files specified by the file operands shall be included in the written list. If no file operands are specified, all files in archive shall be included in the order of the archive. -T Allow filename truncation of extracted files whose archive names are longer than the file system can support. By default, extracting a file with a name that is too long shall be an error; a diagnostic message shall be written and the file shall not be extracted. -u Update older files in the archive. When used with the -r option, files in the archive shall be replaced only if the corresponding file has a modification time that is at least as new as the modification time of the file in the archive. -v Give verbose output. When used with the option characters -d, -r, or -x, write a detailed file-by-file description of the archive creation and maintenance activity, as described in the STDOUT section. When used with -p, write the name of the file in the archive to the standard output before writing the file in the archive itself to the standard output, as described in the STDOUT section. When used with -t, include a long listing of information about the files in the archive, as described in the STDOUT section. -x Extract the files in the archive named by the file operands from archive. The contents of the archive shall not be changed. If no file operands are given, all files in the archive shall be extracted. The modification time of each file extracted shall be set to the time the file is extracted from the archive. "
  },
  {
    "command": "git",
    "description": " Git is a fast, scalable, distributed revision control system with an unusually rich command set that provides both high-level operations and full access to internals. See gittutorial(7) to get started, then see giteveryday(7) for a useful minimum set of commands. The Git User\u2019s Manual[1] has a more in-depth introduction. After you mastered the basic concepts, you can come back to this page to learn what commands Git offers. You can learn more about individual Git commands with \"git help command\". gitcli(7) manual page gives you an overview of the command-line command syntax. A formatted and hyperlinked copy of the latest Git documentation can be viewed at https://git.github.io/htmldocs/git.html or https://git-scm.com/docs . -v, --version Prints the Git suite version that the git program came from. This option is internally converted to git version ... and accepts the same options as the git-version(1) command. If --help is also given, it takes precedence over --version. -h, --help Prints the synopsis and a list of the most commonly used commands. If the option --all or -a is given then all available commands are printed. If a Git command is named this option will bring up the manual page for that command. Other options are available to control how the manual page is displayed. See git-help(1) for more information, because git --help ... is converted internally into git help .... -C <path> Run as if git was started in <path> instead of the current working directory. When multiple -C options are given, each subsequent non-absolute -C <path> is interpreted relative to the preceding -C <path>. If <path> is present but empty, e.g. -C \"\", then the current working directory is left unchanged. This option affects options that expect path name like --git-dir and --work-tree in that their interpretations of the path names would be made relative to the working directory caused by the -C option. For example the following invocations are equivalent: git --git-dir=a.git --work-tree=b -C c status git --git-dir=c/a.git --work-tree=c/b status -c <name>=<value> Pass a configuration parameter to the command. The value given will override values from configuration files. The <name> is expected in the same format as listed by git config (subkeys separated by dots). Note that omitting the = in git -c foo.bar ... is allowed and sets foo.bar to the boolean true value (just like [foo]bar would in a config file). Including the equals but with an empty value (like git -c foo.bar= ...) sets foo.bar to the empty string which git config --type=bool will convert to false. --config-env=<name>=<envvar> Like -c <name>=<value>, give configuration variable <name> a value, where <envvar> is the name of an environment variable from which to retrieve the value. Unlike -c there is no shortcut for directly setting the value to an empty string, instead the environment variable itself must be set to the empty string. It is an error if the <envvar> does not exist in the environment. <envvar> may not contain an equals sign to avoid ambiguity with <name> containing one. This is useful for cases where you want to pass transitory configuration options to git, but are doing so on OS\u2019s where other processes might be able to read your cmdline (e.g. /proc/self/cmdline), but not your environ (e.g. /proc/self/environ). That behavior is the default on Linux, but may not be on your system. Note that this might add security for variables such as http.extraHeader where the sensitive information is part of the value, but not e.g. url.<base>.insteadOf where the sensitive information can be part of the key. --exec-path[=<path>] Path to wherever your core Git programs are installed. This can also be controlled by setting the GIT_EXEC_PATH environment variable. If no path is given, git will print the current setting and then exit. --html-path Print the path, without trailing slash, where Git\u2019s HTML documentation is installed and exit. --man-path Print the manpath (see man(1)) for the man pages for this version of Git and exit. --info-path Print the path where the Info files documenting this version of Git are installed and exit. -p, --paginate Pipe all output into less (or if set, $PAGER) if standard output is a terminal. This overrides the pager.<cmd> configuration options (see the \"Configuration Mechanism\" section below). -P, --no-pager Do not pipe Git output into a pager. --git-dir=<path> Set the path to the repository (\".git\" directory). This can also be controlled by setting the GIT_DIR environment variable. It can be an absolute path or relative path to current working directory. Specifying the location of the \".git\" directory using this option (or GIT_DIR environment variable) turns off the repository discovery that tries to find a directory with \".git\" subdirectory (which is how the repository and the top-level of the working tree are discovered), and tells Git that you are at the top level of the working tree. If you are not at the top-level directory of the working tree, you should tell Git where the top-level of the working tree is, with the --work-tree=<path> option (or GIT_WORK_TREE environment variable) If you just want to run git as if it was started in <path> then use git -C <path>. --work-tree=<path> Set the path to the working tree. It can be an absolute path or a path relative to the current working directory. This can also be controlled by setting the GIT_WORK_TREE environment variable and the core.worktree configuration variable (see core.worktree in git-config(1) for a more detailed discussion). --namespace=<path> Set the Git namespace. See gitnamespaces(7) for more details. Equivalent to setting the GIT_NAMESPACE environment variable. --bare Treat the repository as a bare repository. If GIT_DIR environment is not set, it is set to the current working directory. --no-replace-objects Do not use replacement refs to replace Git objects. See git-replace(1) for more information. --literal-pathspecs Treat pathspecs literally (i.e. no globbing, no pathspec magic). This is equivalent to setting the GIT_LITERAL_PATHSPECS environment variable to 1. --glob-pathspecs Add \"glob\" magic to all pathspec. This is equivalent to setting the GIT_GLOB_PATHSPECS environment variable to 1. Disabling globbing on individual pathspecs can be done using pathspec magic \":(literal)\" --noglob-pathspecs Add \"literal\" magic to all pathspec. This is equivalent to setting the GIT_NOGLOB_PATHSPECS environment variable to 1. Enabling globbing on individual pathspecs can be done using pathspec magic \":(glob)\" --icase-pathspecs Add \"icase\" magic to all pathspec. This is equivalent to setting the GIT_ICASE_PATHSPECS environment variable to 1. --no-optional-locks Do not perform optional operations that require locks. This is equivalent to setting the GIT_OPTIONAL_LOCKS to 0. --list-cmds=group[,group...] List commands by group. This is an internal/experimental option and may change or be removed in the future. Supported groups are: builtins, parseopt (builtin commands that use parse-options), main (all commands in libexec directory), others (all other commands in $PATH that have git- prefix), list-<category> (see categories in command-list.txt), nohelpers (exclude helper commands), alias and config (retrieve command list from config variable completion.commands) --attr-source=<tree-ish> Read gitattributes from <tree-ish> instead of the worktree. See gitattributes(5). This is equivalent to setting the GIT_ATTR_SOURCE environment variable. "
  },
  {
    "command": "printenv",
    "description": " Print the values of the specified environment VARIABLE(s). If no VARIABLE is specified, print name and value pairs for them all. -0, --null end each output line with NUL, not newline --help display this help and exit --version output version information and exit NOTE: your shell may have its own version of printenv, which usually supersedes the version described here. Please refer to your shell's documentation for details about the options it supports. "
  },
  {
    "command": "chsh",
    "description": " The chsh command changes the user login shell. This determines the name of the user's initial login command. A normal user may only change the login shell for her own account; the superuser may change the login shell for any account. The options which apply to the chsh command are: -h, --help Display help message and exit. -R, --root CHROOT_DIR Apply changes in the CHROOT_DIR directory and use the configuration files from the CHROOT_DIR directory. Only absolute paths are supported. -s, --shell SHELL The name of the user's new login shell. Setting this field to blank causes the system to select the default login shell. If the -s option is not selected, chsh operates in an interactive fashion, prompting the user with the current login shell. Enter the new value to change the shell, or leave the line blank to use the current one. The current shell is displayed between a pair of [ ] marks. "
  },
  {
    "command": "pax",
    "description": " The pax utility shall read, write, and write lists of the members of archive files and copy directory hierarchies. A variety of archive formats shall be supported; see the -x format option. The action to be taken depends on the presence of the -r and -w options. The four combinations of -r and -w are referred to as the four modes of operation: list, read, write, and copy modes, corresponding respectively to the four forms shown in the SYNOPSIS section. list In list mode (when neither -r nor -w are specified), pax shall write the names of the members of the archive file read from the standard input, with pathnames matching the specified patterns, to standard output. If a named file is of type directory, the file hierarchy rooted at that file shall be listed as well. read In read mode (when -r is specified, but -w is not), pax shall extract the members of the archive file read from the standard input, with pathnames matching the specified patterns. If an extracted file is of type directory, the file hierarchy rooted at that file shall be extracted as well. The extracted files shall be created performing pathname resolution with the directory in which pax was invoked as the current working directory. If an attempt is made to extract a directory when the directory already exists, this shall not be considered an error. If an attempt is made to extract a FIFO when the FIFO already exists, this shall not be considered an error. The ownership, access, and modification times, and file mode of the restored files are discussed under the -p option. write In write mode (when -w is specified, but -r is not), pax shall write the contents of the file operands to the standard output in an archive format. If no file operands are specified, a list of files to copy, one per line, shall be read from the standard input and each entry in this list shall be processed as if it had been a file operand on the command line. A file of type directory shall include all of the files in the file hierarchy rooted at the file. copy In copy mode (when both -r and -w are specified), pax shall copy the file operands to the destination directory. If no file operands are specified, a list of files to copy, one per line, shall be read from the standard input. A file of type directory shall include all of the files in the file hierarchy rooted at the file. The effect of the copy shall be as if the copied files were written to a pax format archive file and then subsequently extracted, except that copying of sockets may be supported even if archiving them in write mode is not supported, and that there may be hard links between the original and the copied files. If the destination directory is a subdirectory of one of the files to be copied, the results are unspecified. If the destination directory is a file of a type not defined by the System Interfaces volume of POSIX.1\u20102017, the results are implementation-defined; otherwise, it shall be an error for the file named by the directory operand not to exist, not be writable by the user, or not be a file of type directory. In read or copy modes, if intermediate directories are necessary to extract an archive member, pax shall perform actions equivalent to the mkdir() function defined in the System Interfaces volume of POSIX.1\u20102017, called with the following arguments: * The intermediate directory used as the path argument * The value of the bitwise-inclusive OR of S_IRWXU, S_IRWXG, and S_IRWXO as the mode argument If any specified pattern or file operands are not matched by at least one file or archive member, pax shall write a diagnostic message to standard error for each one that did not match and exit with a non-zero exit status. The archive formats described in the EXTENDED DESCRIPTION section shall be automatically detected on input. The default output archive format shall be implementation-defined. A single archive can span multiple files. The pax utility shall determine, in an implementation-defined manner, what file to read or write as the next file. If the selected archive format supports the specification of linked files, it shall be an error if these files cannot be linked when the archive is extracted. For archive formats that do not store file contents with each name that causes a hard link, if the file that contains the data is not extracted during this pax session, either the data shall be restored from the original file, or a diagnostic message shall be displayed with the name of a file that can be used to extract the data. In traversing directories, pax shall detect infinite loops; that is, entering a previously visited directory that is an ancestor of the last file visited. When it detects an infinite loop, pax shall write a diagnostic message to standard error and shall terminate. The pax utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except that the order of presentation of the -o, -p, and -s options is significant. The following options shall be supported: -r Read an archive file from standard input. -w Write files to the standard output in the specified archive format. -a Append files to the end of the archive. It is implementation-defined which devices on the system support appending. Additional file formats unspecified by this volume of POSIX.1\u20102017 may impose restrictions on appending. -b blocksize Block the output at a positive decimal integer number of bytes per write to the archive file. Devices and archive formats may impose restrictions on blocking. Blocking shall be automatically determined on input. Conforming applications shall not specify a blocksize value larger than 32256. Default blocking when creating archives depends on the archive format. (See the -x option below.) -c Match all file or archive members except those specified by the pattern or file operands. -d Cause files of type directory being copied or archived or archive members of type directory being extracted or listed to match only the file or archive member itself and not the file hierarchy rooted at the file. -f archive Specify the pathname of the input or output archive, overriding the default standard input (in list or read modes) or standard output (write mode). -H If a symbolic link referencing a file of type directory is specified on the command line, pax shall archive the file hierarchy rooted in the file referenced by the link, using the name of the link as the root of the file hierarchy. Otherwise, if a symbolic link referencing a file of any other file type which pax can normally archive is specified on the command line, then pax shall archive the file referenced by the link, using the name of the link. The default behavior, when neither -H or -L are specified, shall be to archive the symbolic link itself. -i Interactively rename files or archive members. For each archive member matching a pattern operand or file matching a file operand, a prompt shall be written to the file /dev/tty. The prompt shall contain the name of the file or archive member, but the format is otherwise unspecified. A line shall then be read from /dev/tty. If this line is blank, the file or archive member shall be skipped. If this line consists of a single period, the file or archive member shall be processed with no modification to its name. Otherwise, its name shall be replaced with the contents of the line. The pax utility shall immediately exit with a non-zero exit status if end-of-file is encountered when reading a response or if /dev/tty cannot be opened for reading and writing. The results of extracting a hard link to a file that has been renamed during extraction are unspecified. -k Prevent the overwriting of existing files. -l (The letter ell.) In copy mode, hard links shall be made between the source and destination file hierarchies whenever possible. If specified in conjunction with -H or -L, when a symbolic link is encountered, the hard link created in the destination file hierarchy shall be to the file referenced by the symbolic link. If specified when neither -H nor -L is specified, when a symbolic link is encountered, the implementation shall create a hard link to the symbolic link in the source file hierarchy or copy the symbolic link to the destination. -L If a symbolic link referencing a file of type directory is specified on the command line or encountered during the traversal of a file hierarchy, pax shall archive the file hierarchy rooted in the file referenced by the link, using the name of the link as the root of the file hierarchy. Otherwise, if a symbolic link referencing a file of any other file type which pax can normally archive is specified on the command line or encountered during the traversal of a file hierarchy, pax shall archive the file referenced by the link, using the name of the link. The default behavior, when neither -H or -L are specified, shall be to archive the symbolic link itself. -n Select the first archive member that matches each pattern operand. No more than one archive member shall be matched for each pattern (although members of type directory shall still match the file hierarchy rooted at that file). -o options Provide information to the implementation to modify the algorithm for extracting or writing files. The value of options shall consist of one or more <comma>-separated keywords of the form: keyword[[:]=value][,keyword[[:]=value], ...] Some keywords apply only to certain file formats, as indicated with each description. Use of keywords that are inapplicable to the file format being processed produces undefined results. Keywords in the options argument shall be a string that would be a valid portable filename as described in the Base Definitions volume of POSIX.1\u20102017, Section 3.282, Portable Filename Character Set. Note: Keywords are not expected to be filenames, merely to follow the same character composition rules as portable filenames. Keywords can be preceded with white space. The value field shall consist of zero or more characters; within value, the application shall precede any literal <comma> with a <backslash>, which shall be ignored, but preserves the <comma> as part of value. A <comma> as the final character, or a <comma> followed solely by white space as the final characters, in options shall be ignored. Multiple -o options can be specified; if keywords given to these multiple -o options conflict, the keywords and values appearing later in command line sequence shall take precedence and the earlier shall be silently ignored. The following keyword values of options shall be supported for the file formats as indicated: delete=pattern (Applicable only to the -x pax format.) When used in write or copy mode, pax shall omit from extended header records that it produces any keywords matching the string pattern. When used in read or list mode, pax shall ignore any keywords matching the string pattern in the extended header records. In both cases, matching shall be performed using the pattern matching notation described in Section 2.13.1, Patterns Matching a Single Character and Section 2.13.2, Patterns Matching Multiple Characters. For example: -o delete=security.* would suppress security-related information. See pax Extended Header for extended header record keyword usage. When multiple -odelete=pattern options are specified, the patterns shall be additive; all keywords matching the specified string patterns shall be omitted from extended header records that pax produces. exthdr.name=string (Applicable only to the -x pax format.) This keyword allows user control over the name that is written into the ustar header blocks for the extended header produced under the circumstances described in pax Header Block. The name shall be the contents of string, after the following character substitutions have been made: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 string \u2502 \u2502 \u2502Includes: \u2502 Replaced by: \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502%d \u2502 The directory name of the file, \u2502 \u2502 \u2502 equivalent to the result of the \u2502 \u2502 \u2502 dirname utility on the translated \u2502 \u2502 \u2502 pathname. \u2502 \u2502%f \u2502 The filename of the file, equivalent \u2502 \u2502 \u2502 to the result of the basename utility \u2502 \u2502 \u2502 on the translated pathname. \u2502 \u2502%p \u2502 The process ID of the pax process. \u2502 \u2502%% \u2502 A '%' character. \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Any other '%' characters in string produce undefined results. If no -o exthdr.name=string is specified, pax shall use the following default value: %d/PaxHeaders.%p/%f globexthdr.name=string (Applicable only to the -x pax format.) When used in write or copy mode with the appropriate options, pax shall create global extended header records with ustar header blocks that will be treated as regular files by previous versions of pax. This keyword allows user control over the name that is written into the ustar header blocks for global extended header records. The name shall be the contents of string, after the following character substitutions have been made: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 string \u2502 \u2502 \u2502Includes: \u2502 Replaced by: \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502%n \u2502 An integer that represents the \u2502 \u2502 \u2502 sequence number of the global extended \u2502 \u2502 \u2502 header record in the archive, starting \u2502 \u2502 \u2502 at 1. \u2502 \u2502%p \u2502 The process ID of the pax process. \u2502 \u2502%% \u2502 A '%' character. \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Any other '%' characters in string produce undefined results. If no -o globexthdr.name=string is specified, pax shall use the following default value: $TMPDIR/GlobalHead.%p.%n where $TMPDIR represents the value of the TMPDIR environment variable. If TMPDIR is not set, pax shall use /tmp. invalid=action (Applicable only to the -x pax format.) This keyword allows user control over the action pax takes upon encountering values in an extended header record that, in read or copy mode, are invalid in the destination hierarchy or, in list mode, cannot be written in the codeset and current locale of the implementation. The following are invalid values that shall be recognized by pax: -- In read or copy mode, a filename or link name that contains character encodings invalid in the destination hierarchy. (For example, the name may contain embedded NULs.) -- In read or copy mode, a filename or link name that is longer than the maximum allowed in the destination hierarchy (for either a pathname component or the entire pathname). -- In list mode, any character string value (filename, link name, user name, and so on) that cannot be written in the codeset and current locale of the implementation. The following mutually-exclusive values of the action argument are supported: binary In write mode, pax shall generate a hdrcharset=BINARY extended header record for each file with a filename, link name, group name, owner name, or any other field in an extended header record that cannot be translated to the UTF\u20108 codeset, allowing the archive to contain the files with unencoded extended header record values. In read or copy mode, pax shall use the values specified in the header without translation, regardless of whether this may overwrite an existing file with a valid name. In list mode, pax shall behave identically to the bypass action. bypass In read or copy mode, pax shall bypass the file, causing no change to the destination hierarchy. In list mode, pax shall write all requested valid values for the file, but its method for writing invalid values is unspecified. rename In read or copy mode, pax shall act as if the -i option were in effect for each file with invalid filename or link name values, allowing the user to provide a replacement name interactively. In list mode, pax shall behave identically to the bypass action. UTF\u20108 When used in read, copy, or list mode and a filename, link name, owner name, or any other field in an extended header record cannot be translated from the pax UTF\u20108 codeset format to the codeset and current locale of the implementation, pax shall use the actual UTF\u20108 encoding for the name. If a hdrcharset extended header record is in effect for this file, the character set specified by that record shall be used instead of UTF\u20108. If a hdrcharset=BINARY extended header record is in effect for this file, no translation shall be performed. write In read or copy mode, pax shall write the file, translating the name, regardless of whether this may overwrite an existing file with a valid name. In list mode, pax shall behave identically to the bypass action. If no -o invalid=option is specified, pax shall act as if -oinvalid=bypass were specified. Any overwriting of existing files that may be allowed by the -oinvalid= actions shall be subject to permission (-p) and modification time (-u) restrictions, and shall be suppressed if the -k option is also specified. linkdata (Applicable only to the -x pax format.) In write mode, pax shall write the contents of a file to the archive even when that file is merely a hard link to a file whose contents have already been written to the archive. listopt=format This keyword specifies the output format of the table of contents produced when the -v option is specified in list mode. See List Mode Format Specifications. To avoid ambiguity, the listopt=format shall be the only or final keyword=value pair in a -o option-argument; all characters in the remainder of the option- argument shall be considered part of the format string. When multiple -olistopt=format options are specified, the format strings shall be considered a single, concatenated string, evaluated in command line order. times (Applicable only to the -x pax format.) When used in write or copy mode, pax shall include atime and mtime extended header records for each file. See pax Extended Header File Times. In addition to these keywords, if the -x pax format is specified, any of the keywords and values defined in pax Extended Header, including implementation extensions, can be used in -o option-arguments, in either of two modes: keyword=value When used in write or copy mode, these keyword/value pairs shall be included at the beginning of the archive as typeflag g global extended header records. When used in read or list mode, these keyword/value pairs shall act as if they had been at the beginning of the archive as typeflag g global extended header records. keyword:=value When used in write or copy mode, these keyword/value pairs shall be included as records at the beginning of a typeflag x extended header for each file. (This shall be equivalent to the <equals-sign> form except that it creates no typeflag g global extended header records.) When used in read or list mode, these keyword/value pairs shall act as if they were included as records at the end of each extended header; thus, they shall override any global or file-specific extended header record keywords of the same names. For example, in the command: pax -r -o \" gname:=mygroup, \" <archive the group name will be forced to a new value for all files read from the archive. The precedence of -o keywords over various fields in the archive is described in pax Extended Header Keyword Precedence. If the -o delete=pattern, -o keyword=value, or -o keyword:=value options are used to override or remove any extended header data needed to find files in an archive (e.g., -o delete=size for a file whose size cannot be represented in a ustar header or -o size=100 for a file whose size is not 100 bytes), the behavior is undefined. -p string Specify one or more file characteristic options (privileges). The string option-argument shall be a string specifying file characteristics to be retained or discarded on extraction. The string shall consist of the specification characters a, e, m, o, and p. Other implementation-defined characters can be included. Multiple characteristics can be concatenated within the same string and multiple -p options can be specified. The meaning of the specification characters are as follows: a Do not preserve file access times. e Preserve the user ID, group ID, file mode bits (see the Base Definitions volume of POSIX.1\u20102017, Section 3.169, File Mode Bits), access time, modification time, and any other implementation- defined file characteristics. m Do not preserve file modification times. o Preserve the user ID and group ID. p Preserve the file mode bits. Other implementation-defined file mode attributes may be preserved. In the preceding list, ``preserve'' indicates that an attribute stored in the archive shall be given to the extracted file, subject to the permissions of the invoking process. The access and modification times of the file shall be preserved unless otherwise specified with the -p option or not stored in the archive. All attributes that are not preserved shall be determined as part of the normal file creation action (see Section 1.1.1.4, File Read, Write, and Creation). If neither the e nor the o specification character is specified, or the user ID and group ID are not preserved for any reason, pax shall not set the S_ISUID and S_ISGID bits of the file mode. If the preservation of any of these items fails for any reason, pax shall write a diagnostic message to standard error. Failure to preserve these items shall affect the final exit status, but shall not cause the extracted file to be deleted. If file characteristic letters in any of the string option-arguments are duplicated or conflict with each other, the ones given last shall take precedence. For example, if -p eme is specified, file modification times are preserved. -s replstr Modify file or archive member names named by pattern or file operands according to the substitution expression replstr, using the syntax of the ed utility. The concepts of ``address'' and ``line'' are meaningless in the context of the pax utility, and shall not be supplied. The format shall be: -s /old/new/[gp] where as in ed, old is a basic regular expression and new can contain an <ampersand>, '\\n' (where n is a digit) back-references, or subexpression matching. The old string shall also be permitted to contain <newline> characters. Any non-null character can be used as a delimiter ('/' shown here). Multiple -s expressions can be specified; the expressions shall be applied in the order specified, terminating with the first successful substitution. The optional trailing 'g' is as defined in the ed utility. The optional trailing 'p' shall cause successful substitutions to be written to standard error. File or archive member names that substitute to the empty string shall be ignored when reading and writing archives. -t When reading files from the file system, and if the user has the permissions required by utime() to do so, set the access time of each file read to the access time that it had before being read by pax. -u Ignore files that are older (having a less recent file modification time) than a pre-existing file or archive member with the same name. In read mode, an archive member with the same name as a file in the file system shall be extracted if the archive member is newer than the file. In write mode, an archive file member with the same name as a file in the file system shall be superseded if the file is newer than the archive member. If -a is also specified, this is accomplished by appending to the archive; otherwise, it is unspecified whether this is accomplished by actual replacement in the archive or by appending to the archive. In copy mode, the file in the destination hierarchy shall be replaced by the file in the source hierarchy or by a link to the file in the source hierarchy if the file in the source hierarchy is newer. -v In list mode, produce a verbose table of contents (see the STDOUT section). Otherwise, write archive member pathnames to standard error (see the STDERR section). -x format Specify the output archive format. The pax utility shall support the following formats: cpio The cpio interchange format; see the EXTENDED DESCRIPTION section. The default blocksize for this format for character special archive files shall be 5120. Implementations shall support all blocksize values less than or equal to 32256 that are multiples of 512. pax The pax interchange format; see the EXTENDED DESCRIPTION section. The default blocksize for this format for character special archive files shall be 5120. Implementations shall support all blocksize values less than or equal to 32256 that are multiples of 512. ustar The tar interchange format; see the EXTENDED DESCRIPTION section. The default blocksize for this format for character special archive files shall be 10240. Implementations shall support all blocksize values less than or equal to 32256 that are multiples of 512. Implementation-defined formats shall specify a default block size as well as any other block sizes supported for character special archive files. Any attempt to append to an archive file in a format different from the existing archive format shall cause pax to exit immediately with a non-zero exit status. -X When traversing the file hierarchy specified by a pathname, pax shall not descend into directories that have a different device ID (st_dev; see the System Interfaces volume of POSIX.1\u20102017, stat()). Specifying more than one of the mutually-exclusive options -H and -L shall not be considered an error and the last option specified shall determine the behavior of the utility. The options that operate on the names of files or archive members (-c, -i, -n, -s, -u, and -v) shall interact as follows. In read mode, the archive members shall be selected based on the user- specified pattern operands as modified by the -c, -n, and -u options. Then, any -s and -i options shall modify, in that order, the names of the selected files. The -v option shall write names resulting from these modifications. In write mode, the files shall be selected based on the user- specified pathnames as modified by the -n and -u options. Then, any -s and -i options shall modify, in that order, the names of these selected files. The -v option shall write names resulting from these modifications. If both the -u and -n options are specified, pax shall not consider a file selected unless it is newer than the file to which it is compared. List Mode Format Specifications In list mode with the -o listopt=format option, the format argument shall be applied for each selected file. The pax utility shall append a <newline> to the listopt output for each selected file. The format argument shall be used as the format string described in the Base Definitions volume of POSIX.1\u20102017, Chapter 5, File Format Notation, with the exceptions 1. through 6. defined in the EXTENDED DESCRIPTION section of printf, plus the following exceptions: 7. The sequence (keyword) can occur before a format conversion specifier. The conversion argument is defined by the value of keyword. The implementation shall support the following keywords: -- Any of the Field Name entries in Table 4-14, ustar Header Block and Table 4-16, Octet-Oriented cpio Archive Entry. The implementation may support the cpio keywords without the leading c_ in addition to the form required by Table 4-16, Octet-Oriented cpio Archive Entry. -- Any keyword defined for the extended header in pax Extended Header. -- Any keyword provided as an implementation-defined extension within the extended header defined in pax Extended Header. For example, the sequence \"%(charset)s\" is the string value of the name of the character set in the extended header. The result of the keyword conversion argument shall be the value from the applicable header field or extended header, without any trailing NULs. All keyword values used as conversion arguments shall be translated from the UTF\u20108 encoding (or alternative encoding specified by any hdrcharset extended header record) to the character set appropriate for the local file system, user database, and so on, as applicable. 8. An additional conversion specifier character, T, shall be used to specify time formats. The T conversion specifier character can be preceded by the sequence (keyword=subformat), where subformat is a date format as defined by date operands. The default keyword shall be mtime and the default subformat shall be: %b %e %H:%M %Y 9. An additional conversion specifier character, M, shall be used to specify the file mode string as defined in ls Standard Output. If (keyword) is omitted, the mode keyword shall be used. For example, %.1M writes the single character corresponding to the <entry type> field of the ls -l command. 10. An additional conversion specifier character, D, shall be used to specify the device for block or special files, if applicable, in an implementation-defined format. If not applicable, and (keyword) is specified, then this conversion shall be equivalent to %(keyword)u. If not applicable, and (keyword) is omitted, then this conversion shall be equivalent to <space>. 11. An additional conversion specifier character, F, shall be used to specify a pathname. The F conversion character can be preceded by a sequence of <comma>-separated keywords: (keyword[,keyword] ... ) The values for all the keywords that are non-null shall be concatenated together, each separated by a '/'. The default shall be (path) if the keyword path is defined; otherwise, the default shall be (prefix,name). 12. An additional conversion specifier character, L, shall be used to specify a symbolic link expansion. If the current file is a symbolic link, then %L shall expand to: \"%s -> %s\", <value of keyword>, <contents of link> Otherwise, the %L conversion specification shall be the equivalent of %F. "
  },
  {
    "command": "git-replace",
    "description": " Adds a replace reference in refs/replace/ namespace. The name of the replace reference is the SHA-1 of the object that is replaced. The content of the replace reference is the SHA-1 of the replacement object. The replaced object and the replacement object must be of the same type. This restriction can be bypassed using -f. Unless -f is given, the replace reference must not yet exist. There is no other restriction on the replaced and replacement objects. Merge commits can be replaced by non-merge commits and vice versa. Replacement references will be used by default by all Git commands except those doing reachability traversal (prune, pack transfer and fsck). It is possible to disable use of replacement references for any command using the --no-replace-objects option just after git. For example if commit foo has been replaced by commit bar: $ git --no-replace-objects cat-file commit foo shows information about commit foo, while: $ git cat-file commit foo shows information about commit bar. The GIT_NO_REPLACE_OBJECTS environment variable can be set to achieve the same effect as the --no-replace-objects option. -f, --force If an existing replace ref for the same object exists, it will be overwritten (instead of failing). -d, --delete Delete existing replace refs for the given objects. --edit <object> Edit an object\u2019s content interactively. The existing content for <object> is pretty-printed into a temporary file, an editor is launched on the file, and the result is parsed to create a new object of the same type as <object>. A replacement ref is then created to replace <object> with the newly created object. See git-var(1) for details about how the editor will be chosen. --raw When editing, provide the raw object contents rather than pretty-printed ones. Currently this only affects trees, which will be shown in their binary form. This is harder to work with, but can help when repairing a tree that is so corrupted it cannot be pretty-printed. Note that you may need to configure your editor to cleanly read and write binary data. --graft <commit> [<parent>...] Create a graft commit. A new commit is created with the same content as <commit> except that its parents will be [<parent>...] instead of <commit>'s parents. A replacement ref is then created to replace <commit> with the newly created commit. Use --convert-graft-file to convert a $GIT_DIR/info/grafts file and use replace refs instead. --convert-graft-file Creates graft commits for all entries in $GIT_DIR/info/grafts and deletes that file upon success. The purpose is to help users with transitioning off of the now-deprecated graft file. -l <pattern>, --list <pattern> List replace refs for objects that match the given pattern (or all if no pattern is given). Typing \"git replace\" without arguments, also lists all replace refs. --format=<format> When listing, use the specified <format>, which can be one of short, medium and long. When omitted, the format defaults to short. "
  },
  {
    "command": "yes",
    "description": " Repeatedly output a line with all specified STRING(s), or 'y'. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "mkdir",
    "description": " The mkdir utility shall create the directories specified by the operands, in the order specified. For each dir operand, the mkdir utility shall perform actions equivalent to the mkdir() function defined in the System Interfaces volume of POSIX.1\u20102017, called with the following arguments: 1. The dir operand is used as the path argument. 2. The value of the bitwise-inclusive OR of S_IRWXU, S_IRWXG, and S_IRWXO is used as the mode argument. (If the -m option is specified, the value of the mkdir() mode argument is unspecified, but the directory shall at no time have permissions less restrictive than the -m mode option- argument.) The mkdir utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -m mode Set the file permission bits of the newly-created directory to the specified mode value. The mode option- argument shall be the same as the mode operand defined for the chmod utility. In the symbolic_mode strings, the op characters '+' and '-' shall be interpreted relative to an assumed initial mode of a=rwx; '+' shall add permissions to the default mode, '-' shall delete permissions from the default mode. -p Create any missing intermediate pathname components. For each dir operand that does not name an existing directory, before performing the actions described in the DESCRIPTION above, the mkdir utility shall create any pathname components of the path prefix of dir that do not name an existing directory by performing actions equivalent to first calling the mkdir() function with the following arguments: 1. A pathname naming the missing pathname component, ending with a trailing <slash> character, as the path argument 2. The value zero as the mode argument and then calling the chmod() function with the following arguments: 1. The same path argument as in the mkdir() call 2. The value (S_IWUSR|S_IXUSR|~filemask)&0777 as the mode argument, where filemask is the file mode creation mask of the process (see the System Interfaces volume of POSIX.1\u20102017, umask(3p)) Each dir operand that names an existing directory shall be ignored without error. "
  },
  {
    "command": "ipcrm",
    "description": " ipcrm removes System V inter-process communication (IPC) objects and associated data structures from the system. In order to delete such objects, you must be superuser, or the creator or owner of the object. System V IPC objects are of three types: shared memory, message queues, and semaphores. Deletion of a message queue or semaphore object is immediate (regardless of whether any process still holds an IPC identifier for the object). A shared memory object is only removed after all currently attached processes have detached (shmdt(2)) the object from their virtual address space. Two syntax styles are supported. The old Linux historical syntax specifies a three-letter keyword indicating which class of object is to be deleted, followed by one or more IPC identifiers for objects of this type. The SUS-compliant syntax allows the specification of zero or more objects of all three types in a single command line, with objects specified either by key or by identifier (see below). Both keys and identifiers may be specified in decimal, hexadecimal (specified with an initial '0x' or '0X'), or octal (specified with an initial '0'). The details of the removes are described in shmctl(2), msgctl(2), and semctl(2). The identifiers and keys can be found by using ipcs(1). -a, --all [shm] [msg] [sem] Remove all resources. When an option argument is provided, the removal is performed only for the specified resource types. Warning! Do not use -a if you are unsure how the software using the resources might react to missing objects. Some programs create these resources at startup and may not have any code to deal with an unexpected disappearance. -M, --shmem-key shmkey Remove the shared memory segment created with shmkey after the last detach is performed. -m, --shmem-id shmid Remove the shared memory segment identified by shmid after the last detach is performed. -Q, --queue-key msgkey Remove the message queue created with msgkey. -q, --queue-id msgid Remove the message queue identified by msgid. -S, --semaphore-key semkey Remove the semaphore created with semkey. -s, --semaphore-id semid Remove the semaphore identified by semid. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "chmod",
    "description": " The chmod utility shall change any or all of the file mode bits of the file named by each file operand in the way specified by the mode operand. It is implementation-defined whether and how the chmod utility affects any alternate or additional file access control mechanism (see the Base Definitions volume of POSIX.1\u20102017, Section 4.5, File Access Permissions) being used for the specified file. Only a process whose effective user ID matches the user ID of the file, or a process with appropriate privileges, shall be permitted to change the file mode bits of a file. Upon successfully changing the file mode bits of a file, the chmod utility shall mark for update the last file status change timestamp of the file. The chmod utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -R Recursively change file mode bits. For each file operand that names a directory, chmod shall change the file mode bits of the directory and all files in the file hierarchy below it. "
  },
  {
    "command": "git-help",
    "description": " With no options and no <command> or <doc> given, the synopsis of the git command and a list of the most commonly used Git commands are printed on the standard output. If the option --all or -a is given, all available commands are printed on the standard output. If the option --guides or -g is given, a list of the Git concept guides is also printed on the standard output. If a command or other documentation is given, the relevant manual page will be brought up. The man program is used by default for this purpose, but this can be overridden by other options or configuration variables. If an alias is given, git shows the definition of the alias on standard output. To get the manual page for the aliased command, use git <command> --help. Note that git --help ... is identical to git help ... because the former is internally converted into the latter. To display the git(1) man page, use git help git. This page can be displayed with git help help or git help --help -a, --all Prints all the available commands on the standard output. --no-external-commands When used with --all, exclude the listing of external \"git-*\" commands found in the $PATH. --no-aliases When used with --all, exclude the listing of configured aliases. --verbose When used with --all print description for all recognized commands. This is the default. -c, --config List all available configuration variables. This is a short summary of the list in git-config(1). -g, --guides Prints a list of the Git concept guides on the standard output. --user-interfaces Prints a list of the repository, command and file interfaces documentation on the standard output. In-repository file interfaces such as .git/info/exclude are documented here (see gitrepository-layout(5)), as well as in-tree configuration such as .mailmap (see gitmailmap(5)). This section of the documentation also covers general or widespread user-interface conventions (e.g. gitcli(7)), and pseudo-configuration such as the file-based .git/hooks/* interface described in githooks(5). --developer-interfaces Print list of file formats, protocols and other developer interfaces documentation on the standard output. -i, --info Display manual page for the command in the info format. The info program will be used for that purpose. -m, --man Display manual page for the command in the man format. This option may be used to override a value set in the help.format configuration variable. By default the man program will be used to display the manual page, but the man.viewer configuration variable may be used to choose other display programs (see below). -w, --web Display manual page for the command in the web (HTML) format. A web browser will be used for that purpose. The web browser can be specified using the configuration variable help.browser, or web.browser if the former is not set. If none of these config variables is set, the git web--browse helper script (called by git help) will pick a suitable default. See git-web--browse(1) for more information about this. "
  },
  {
    "command": "sort",
    "description": " The sort utility shall perform one of the following functions: 1. Sort lines of all the named files together and write the result to the specified output. 2. Merge lines of all the named (presorted) files together and write the result to the specified output. 3. Check that a single input file is correctly presorted. Comparisons shall be based on one or more sort keys extracted from each line of input (or, if no sort keys are specified, the entire line up to, but not including, the terminating <newline>), and shall be performed using the collating sequence of the current locale. If this collating sequence does not have a total ordering of all characters (see the Base Definitions volume of POSIX.1\u20102017, Section 7.3.2, LC_COLLATE), any lines of input that collate equally should be further compared byte-by-byte using the collating sequence for the POSIX locale. The sort utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for Guideline 9, and the -k keydef option should follow the -b, -d, -f, -i, -n, and -r options. In addition, '+' may be recognized as an option delimiter as well as '-'. The following options shall be supported: -c Check that the single input file is ordered as specified by the arguments and the collating sequence of the current locale. Output shall not be sent to standard output. The exit code shall indicate whether or not disorder was detected or an error occurred. If disorder (or, with -u, a duplicate key) is detected, a warning message shall be sent to standard error indicating where the disorder or duplicate key was found. -C Same as -c, except that a warning message shall not be sent to standard error if disorder or, with -u, a duplicate key is detected. -m Merge only; the input file shall be assumed to be already sorted. -o output Specify the name of an output file to be used instead of the standard output. This file can be the same as one of the input files. -u Unique: suppress all but one in each set of lines having equal keys. If used with the -c option, check that there are no lines with duplicate keys, in addition to checking that the input file is sorted. The following options shall override the default ordering rules. When ordering options appear independent of any key field specifications, the requested field ordering rules shall be applied globally to all sort keys. When attached to a specific key (see -k), the specified ordering options shall override all global ordering options for that key. -d Specify that only <blank> characters and alphanumeric characters, according to the current setting of LC_CTYPE, shall be significant in comparisons. The behavior is undefined for a sort key to which -i or -n also applies. -f Consider all lowercase characters that have uppercase equivalents, according to the current setting of LC_CTYPE, to be the uppercase equivalent for the purposes of comparison. -i Ignore all characters that are non-printable, according to the current setting of LC_CTYPE. The behavior is undefined for a sort key for which -n also applies. -n Restrict the sort key to an initial numeric string, consisting of optional <blank> characters, optional <hyphen-minus> character, and zero or more digits with an optional radix character and thousands separators (as defined in the current locale), which shall be sorted by arithmetic value. An empty digit string shall be treated as zero. Leading zeros and signs on zeros shall not affect ordering. -r Reverse the sense of comparisons. The treatment of field separators can be altered using the options: -b Ignore leading <blank> characters when determining the starting and ending positions of a restricted sort key. If the -b option is specified before the first -k option, it shall be applied to all -k options. Otherwise, the -b option can be attached independently to each -k field_start or field_end option-argument (see below). -t char Use char as the field separator character; char shall not be considered to be part of a field (although it can be included in a sort key). Each occurrence of char shall be significant (for example, <char><char> delimits an empty field). If -t is not specified, <blank> characters shall be used as default field separators; each maximal non-empty sequence of <blank> characters that follows a non-<blank> shall be a field separator. Sort keys can be specified using the options: -k keydef The keydef argument is a restricted sort key field definition. The format of this definition is: field_start[type][,field_end[type]] where field_start and field_end define a key field restricted to a portion of the line (see the EXTENDED DESCRIPTION section), and type is one or more modifiers from the list of characters 'b', 'd', 'f', 'i', 'n', 'r'. The 'b' modifier shall behave like the -b option, but shall apply only to the field_start or field_end to which it is attached. The other modifiers shall behave like the corresponding options, but shall apply only to the key field to which they are attached; they shall have this effect if specified with field_start, field_end, or both. If any modifier is attached to a field_start or to a field_end, no option shall apply to either. Implementations shall support at least nine occurrences of the -k option, which shall be significant in command line order. If no -k option is specified, a default sort key of the entire line shall be used. When there are multiple key fields, later keys shall be compared only after all earlier keys compare equal. Except when the -u option is specified, lines that otherwise compare equal shall be ordered as if none of the options -d, -f, -i, -n, or -k were present (but with -r still in effect, if it was specified) and with all bytes in the lines significant to the comparison. The order in which lines that still compare equal are written is unspecified. "
  },
  {
    "command": "md5sum",
    "description": " Print or check MD5 (128-bit) checksums. With no FILE, or when FILE is -, read standard input. -b, --binary read in binary mode -c, --check read checksums from the FILEs and check them --tag create a BSD-style checksum -t, --text read in text mode (default) -z, --zero end each output line with NUL, not newline, and disable file name escaping The following five options are useful only when verifying checksums: --ignore-missing don't fail or report status for missing files --quiet don't print OK for each successfully verified file --status don't output anything, status code shows success --strict exit non-zero for improperly formatted checksum lines -w, --warn warn about improperly formatted checksum lines --help display this help and exit --version output version information and exit The sums are computed as described in RFC 1321. When checking, the input should be a former output of this program. The default mode is to print a line with: checksum, a space, a character indicating input mode ('*' for binary, ' ' for text or where binary is insignificant), and name for each FILE. Note: There is no difference between binary mode and text mode on GNU systems. "
  },
  {
    "command": "kill",
    "description": " The default signal for kill is TERM. Use -l or -L to list available signals. Particularly useful signals include HUP, INT, KILL, STOP, CONT, and 0. Alternate signals may be specified in three ways: -9, -SIGKILL or -KILL. Negative PID values may be used to choose whole process groups; see the PGID column in ps command output. A PID of -1 is special; it indicates all processes except the kill process itself and init. <pid> [...] Send signal to every <pid> listed. -<signal> -s <signal> --signal <signal> Specify the signal to be sent. The signal can be specified by using name or number. The behavior of signals is explained in signal(7) manual page. -q, --queue value Use sigqueue(3) rather than kill(2) and the value argument is used to specify an integer to be sent with the signal. If the receiving process has installed a handler for this signal using the SA_SIGINFO flag to sigaction(2), then it can obtain this data via the si_value field of the siginfo_t structure. -l, --list [signal] List signal names. This option has optional argument, which will convert signal number to signal name, or other way round. -L, --table List signal names in a nice table. "
  },
  {
    "command": "groff",
    "description": " groff is the primary front end to the GNU roff document formatting system. GNU roff is a typesetting system that reads plain text input files that include formatting commands to produce output in PostScript, PDF, HTML, DVI, or other formats, or for display to a terminal. Formatting commands can be low- level typesetting primitives, macros from a supplied package, or user-defined macros. All three approaches can be combined. If no file operands are specified, or if file is \u201c-\u201d, groff reads the standard input stream. A reimplementation and extension of the typesetter from AT&T Unix, groff is present on most POSIX systems owing to its long association with Unix manuals (including man pages). It and its predecessor are notable for their production of several best- selling software engineering texts. groff is capable of producing typographically sophisticated documents while consuming minimal system resources. The groff command orchestrates the execution of preprocessors, the transformation of input documents into a device-independent page description language, and the production of output from that language. -h and --help display a usage message and exit. Because groff is intended to subsume most users' direct invocations of the troff(1) formatter, the two programs share a set of options. However, groff has some options that troff does not share, and others which groff interprets differently. At the same time, not all valid troff options can be given to groff. groff-specific options The following options either do not exist in GNU troff or are interpreted differently by groff. -D enc Set fallback input encoding used by preconv(1) to enc; implies -k. -e Run eqn(1) preprocessor. -g Run grn(1) preprocessor. -G Run grap(1) preprocessor; implies -p. -I dir Works as troff's option (see below), but also implies -g and -s. It is passed to soelim(1) and the output driver, and grn is passed an -M option with dir as its argument. -j Run chem(1) preprocessor; implies -p. -k Run preconv(1) preprocessor. Refer to its man page for its behavior if neither of groff's -K or -D options is also specified. -K enc Set input encoding used by preconv(1) to enc; implies -k. -l Send the output to a spooler program for printing. The \u201cprint\u201d directive in the device description file specifies the default command to be used; see groff_font(5). If no such directive is present for the output device, output is piped to lpr(1). See options -L and -X. -L arg Pass arg to the print spooler program. If multiple args are required, pass each with a separate -L option. groff does not prefix an option dash to arg before passing it to the spooler program. -M Works as troff's option (see below), but is also passed to eqn(1), grap(1), and grn(1). -N Prohibit newlines between eqn delimiters: pass -N to eqn(1). -p Run pic(1) preprocessor. -P arg Pass arg to the postprocessor. If multiple args are required, pass each with a separate -P option. groff does not prefix an option dash to arg before passing it to the postprocessor. -R Run refer(1) preprocessor. No mechanism is provided for passing arguments to refer because most refer options have equivalent language elements that can be specified within the document. -s Run soelim(1) preprocessor. -S Operate in \u201csafer\u201d mode; see -U below for its opposite. For security reasons, safer mode is enabled by default. -t Run tbl(1) preprocessor. -T dev Direct troff to format the input for the output device dev. groff then calls an output driver to convert troff's output to a form appropriate for dev; see subsection \u201cOutput devices\u201d below. -U Operate in unsafe mode: pass the -U option to pic and troff. -v --version Write version information for groff and all programs run by it to the standard output stream; that is, the given command line is processed in the usual way, passing -v to the formatter and any pre- or postprocessors invoked. -V Output the pipeline that groff would run to the standard output stream, but do not execute it. If given more than once, groff both writes and runs the pipeline. -X Use gxditview(1) instead of the usual postprocessor to (pre)view a document on an X11 display. Combining this option with -Tps uses the font metrics of the PostScript device, whereas the -TX75 and -TX100 options use the metrics of X11 fonts. -Z Disable postprocessing. troff output will appear on the standard output stream (unless suppressed with -z); see groff_out(5) for a description of this format. Transparent options The following options are passed as-is to the formatter program troff(1) and described in more detail in its man page. -a Generate a plain text approximation of the typeset output. -b Write a backtrace to the standard error stream on each error or warning. -c Start with color output disabled. -C Enable AT&T troff compatibility mode; implies -c. -d cs -d name=string Define string. -E Inhibit troff error messages; implies -Ww. -f fam Set default font family. -F dir Search in directory dir for the selected output device's directory of device and font description files. -i Process standard input after the specified input files. -I dir Search dir for input files. -m name Process name.tmac before input files. -M dir Search directory dir for macro files. -n num Number the first page num. -o list Output only pages in list. -r cnumeric-expression -r register=numeric-expression Define register. -w name -W name Enable (-w) or inhibit (-W) emission of warnings in category name. -z Suppress formatted device-independent output of troff. "
  },
  {
    "command": "git-checkout-index",
    "description": " Will copy all files listed from the index to the working directory (not overwriting existing files). -u, --index update stat information for the checked out entries in the index file. -q, --quiet be quiet if files exist or are not in the index -f, --force forces overwrite of existing files -a, --all checks out all files in the index except for those with the skip-worktree bit set (see --ignore-skip-worktree-bits). Cannot be used together with explicit filenames. -n, --no-create Don\u2019t checkout new files, only refresh files already checked out. --prefix=<string> When creating files, prepend <string> (usually a directory including a trailing /) --stage=<number>|all Instead of checking out unmerged entries, copy out the files from named stage. <number> must be between 1 and 3. Note: --stage=all automatically implies --temp. --temp Instead of copying the files to the working directory write the content to temporary files. The temporary name associations will be written to stdout. --ignore-skip-worktree-bits Check out all files, including those with the skip-worktree bit set. --stdin Instead of taking list of paths from the command line, read list of paths from the standard input. Paths are separated by LF (i.e. one path per line) by default. -z Only meaningful with --stdin; paths are separated with NUL character instead of LF. -- Do not interpret any more arguments as options. The order of the flags used to matter, but not anymore. Just doing git checkout-index does nothing. You probably meant git checkout-index -a. And if you want to force it, you want git checkout-index -f -a. Intuitiveness is not the goal here. Repeatability is. The reason for the \"no arguments means no work\" behavior is that from scripts you are supposed to be able to do: $ find . -name '*.h' -print0 | xargs -0 git checkout-index -f -- which will force all existing *.h files to be replaced with their cached copies. If an empty command line implied \"all\", then this would force-refresh everything in the index, which was not the point. But since git checkout-index accepts --stdin it would be faster to use: $ find . -name '*.h' -print0 | git checkout-index -f -z --stdin The -- is just a good idea when you know the rest will be filenames; it will prevent problems with a filename of, for example, -a. Using -- is probably a good policy in scripts. "
  },
  {
    "command": "trace-cmd",
    "description": " The trace-cmd(1) command interacts with the Ftrace tracer that is built inside the Linux kernel. It interfaces with the Ftrace specific files found in the debugfs file system under the tracing directory. A COMMAND must be specified to tell trace-cmd what to do. -h, --help Display the help text. Other options see the man page for the corresponding command. "
  },
  {
    "command": "umask",
    "description": " The umask utility shall set the file mode creation mask of the current shell execution environment (see Section 2.12, Shell Execution Environment) to the value specified by the mask operand. This mask shall affect the initial value of the file permission bits of subsequently created files. If umask is called in a subshell or separate utility execution environment, such as one of the following: (umask 002) nohup umask ... find . -exec umask ... \\; it shall not affect the file mode creation mask of the caller's environment. If the mask operand is not specified, the umask utility shall write to standard output the value of the file mode creation mask of the invoking process. The umask utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -S Produce symbolic output. The default output style is unspecified, but shall be recognized on a subsequent invocation of umask on the same system as a mask operand to restore the previous file mode creation mask. "
  },
  {
    "command": "touch",
    "description": " Update the access and modification times of each FILE to the current time. A FILE argument that does not exist is created empty, unless -c or -h is supplied. A FILE argument string of - is handled specially and causes touch to change the times of the file associated with standard output. Mandatory arguments to long options are mandatory for short options too. -a change only the access time -c, --no-create do not create any files -d, --date=STRING parse STRING and use it instead of current time -f (ignored) -h, --no-dereference affect each symbolic link instead of any referenced file (useful only on systems that can change the timestamps of a symlink) -m change only the modification time -r, --reference=FILE use this file's times instead of current time -t STAMP use [[CC]YY]MMDDhhmm[.ss] instead of current time --time=WORD change the specified time: WORD is access, atime, or use: equivalent to -a WORD is modify or mtime: equivalent to -m --help display this help and exit --version output version information and exit Note that the -d and -t options accept different time-date formats. "
  },
  {
    "command": "echo",
    "description": " Echo the STRING(s) to standard output. -n do not output the trailing newline -e enable interpretation of backslash escapes -E disable interpretation of backslash escapes (default) --help display this help and exit --version output version information and exit If -e is in effect, the following sequences are recognized: \\\\ backslash \\a alert (BEL) \\b backspace \\c produce no further output \\e escape \\f form feed \\n new line \\r carriage return \\t horizontal tab \\v vertical tab \\0NNN byte with octal value NNN (1 to 3 digits) \\xHH byte with hexadecimal value HH (1 to 2 digits) NOTE: your shell may have its own version of echo, which usually supersedes the version described here. Please refer to your shell's documentation for details about the options it supports. NOTE: printf(1) is a preferred alternative, which does not have issues outputting option-like strings. "
  },
  {
    "command": "systemctl",
    "description": " systemctl may be used to introspect and control the state of the \"systemd\" system and service manager. Please refer to systemd(1) for an introduction into the basic concepts and functionality this tool manages. The following options are understood: -t, --type= The argument is a comma-separated list of unit types such as service and socket. When units are listed with list-units, list-dependencies, show, or status, only units of the specified types will be shown. By default, units of all types are shown. As a special case, if one of the arguments is help, a list of allowed values will be printed and the program will exit. --state= The argument is a comma-separated list of unit LOAD, SUB, or ACTIVE states. When listing units with list-units, list-dependencies, show or status, show only those in the specified states. Use --state=failed or --failed to show only failed units. As a special case, if one of the arguments is help, a list of allowed values will be printed and the program will exit. -p, --property= When showing unit/job/manager properties with the show command, limit display to properties specified in the argument. The argument should be a comma-separated list of property names, such as \"MainPID\". Unless specified, all known properties are shown. If specified more than once, all properties with the specified names are shown. Shell completion is implemented for property names. For the manager itself, systemctl show will show all available properties, most of which are derived or closely match the options described in systemd-system.conf(5). Properties for units vary by unit type, so showing any unit (even a non-existent one) is a way to list properties pertaining to this type. Similarly, showing any job will list properties pertaining to all jobs. Properties for units are documented in systemd.unit(5), and the pages for individual unit types systemd.service(5), systemd.socket(5), etc. -P Equivalent to --value --property=, i.e. shows the value of the property without the property name or \"=\". Note that using -P once will also affect all properties listed with -p/--property=. -a, --all When listing units with list-units, also show inactive units and units which are following other units. When showing unit/job/manager properties, show all properties regardless whether they are set or not. To list all units installed in the file system, use the list-unit-files command instead. When listing units with list-dependencies, recursively show dependencies of all dependent units (by default only dependencies of target units are shown). When used with status, show journal messages in full, even if they include unprintable characters or are very long. By default, fields with unprintable characters are abbreviated as \"blob data\". (Note that the pager may escape unprintable characters again.) -r, --recursive When listing units, also show units of local containers. Units of local containers will be prefixed with the container name, separated by a single colon character (\":\"). --reverse Show reverse dependencies between units with list-dependencies, i.e. follow dependencies of type WantedBy=, RequiredBy=, UpheldBy=, PartOf=, BoundBy=, instead of Wants= and similar. --after With list-dependencies, show the units that are ordered before the specified unit. In other words, recursively list units following the After= dependency. Note that any After= dependency is automatically mirrored to create a Before= dependency. Temporal dependencies may be specified explicitly, but are also created implicitly for units which are WantedBy= targets (see systemd.target(5)), and as a result of other directives (for example RequiresMountsFor=). Both explicitly and implicitly introduced dependencies are shown with list-dependencies. When passed to the list-jobs command, for each printed job show which other jobs are waiting for it. May be combined with --before to show both the jobs waiting for each job as well as all jobs each job is waiting for. --before With list-dependencies, show the units that are ordered after the specified unit. In other words, recursively list units following the Before= dependency. When passed to the list-jobs command, for each printed job show which other jobs it is waiting for. May be combined with --after to show both the jobs waiting for each job as well as all jobs each job is waiting for. --with-dependencies When used with status, cat, list-units, and list-unit-files, those commands print all specified units and the dependencies of those units. Options --reverse, --after, --before may be used to change what types of dependencies are shown. -l, --full Do not ellipsize unit names, process tree entries, journal output, or truncate unit descriptions in the output of status, list-units, list-jobs, and list-timers. Also, show installation targets in the output of is-enabled. --value When printing properties with show, only print the value, and skip the property name and \"=\". Also see option -P above. --show-types When showing sockets, show the type of the socket. --job-mode= When queuing a new job, this option controls how to deal with already queued jobs. It takes one of \"fail\", \"replace\", \"replace-irreversibly\", \"isolate\", \"ignore-dependencies\", \"ignore-requirements\", \"flush\", or \"triggering\". Defaults to \"replace\", except when the isolate command is used which implies the \"isolate\" job mode. If \"fail\" is specified and a requested operation conflicts with a pending job (more specifically: causes an already pending start job to be reversed into a stop job or vice versa), cause the operation to fail. If \"replace\" (the default) is specified, any conflicting pending job will be replaced, as necessary. If \"replace-irreversibly\" is specified, operate like \"replace\", but also mark the new jobs as irreversible. This prevents future conflicting transactions from replacing these jobs (or even being enqueued while the irreversible jobs are still pending). Irreversible jobs can still be cancelled using the cancel command. This job mode should be used on any transaction which pulls in shutdown.target. \"isolate\" is only valid for start operations and causes all other units to be stopped when the specified unit is started. This mode is always used when the isolate command is used. \"flush\" will cause all queued jobs to be canceled when the new job is enqueued. If \"ignore-dependencies\" is specified, then all unit dependencies are ignored for this new job and the operation is executed immediately. If passed, no required units of the unit passed will be pulled in, and no ordering dependencies will be honored. This is mostly a debugging and rescue tool for the administrator and should not be used by applications. \"ignore-requirements\" is similar to \"ignore-dependencies\", but only causes the requirement dependencies to be ignored, the ordering dependencies will still be honored. \"triggering\" may only be used with systemctl stop. In this mode, the specified unit and any active units that trigger it are stopped. See the discussion of Triggers= in systemd.unit(5) for more information about triggering units. -T, --show-transaction When enqueuing a unit job (for example as effect of a systemctl start invocation or similar), show brief information about all jobs enqueued, covering both the requested job and any added because of unit dependencies. Note that the output will only include jobs immediately part of the transaction requested. It is possible that service start-up program code run as effect of the enqueued jobs might request further jobs to be pulled in. This means that completion of the listed jobs might ultimately entail more jobs than the listed ones. --fail Shorthand for --job-mode=fail. When used with the kill command, if no units were killed, the operation results in an error. --check-inhibitors= When system shutdown or sleep state is requested, this option controls checking of inhibitor locks. It takes one of \"auto\", \"yes\" or \"no\". Defaults to \"auto\", which will behave like \"yes\" for interactive invocations (i.e. from a TTY) and \"no\" for non-interactive invocations. \"yes\" lets the request respect inhibitor locks. \"no\" lets the request ignore inhibitor locks. Applications can establish inhibitor locks to prevent certain important operations (such as CD burning) from being interrupted by system shutdown or sleep. Any user may take these locks and privileged users may override these locks. If any locks are taken, shutdown and sleep state requests will normally fail (unless privileged). However, if \"no\" is specified or \"auto\" is specified on a non-interactive requests, the operation will be attempted. If locks are present, the operation may require additional privileges. Option --force provides another way to override inhibitors. -i Shortcut for --check-inhibitors=no. --dry-run Just print what would be done. Currently supported by verbs halt, poweroff, reboot, kexec, suspend, hibernate, hybrid-sleep, suspend-then-hibernate, default, rescue, emergency, and exit. -q, --quiet Suppress printing of the results of various commands and also the hints about truncated log lines. This does not suppress output of commands for which the printed output is the only result (like show). Errors are always printed. --no-warn Don't generate the warnings shown by default in the following cases: \u2022 when systemctl is invoked without procfs mounted on /proc/, \u2022 when using enable or disable on units without install information (i.e. don't have or have an empty [Install] section), \u2022 when using disable combined with --user on units that are enabled in global scope. --no-block Do not synchronously wait for the requested operation to finish. If this is not specified, the job will be verified, enqueued and systemctl will wait until the unit's start-up is completed. By passing this argument, it is only verified and enqueued. This option may not be combined with --wait. --wait Synchronously wait for started units to terminate again. This option may not be combined with --no-block. Note that this will wait forever if any given unit never terminates (by itself or by getting stopped explicitly); particularly services which use \"RemainAfterExit=yes\". When used with is-system-running, wait until the boot process is completed before returning. --user Talk to the service manager of the calling user, rather than the service manager of the system. --system Talk to the service manager of the system. This is the implied default. --failed List units in failed state. This is equivalent to --state=failed. --no-wall Do not send wall message before halt, power-off and reboot. --global When used with enable and disable, operate on the global user configuration directory, thus enabling or disabling a unit file globally for all future logins of all users. --no-reload When used with enable and disable, do not implicitly reload daemon configuration after executing the changes. --no-ask-password When used with start and related commands, disables asking for passwords. Background services may require input of a password or passphrase string, for example to unlock system hard disks or cryptographic certificates. Unless this option is specified and the command is invoked from a terminal, systemctl will query the user on the terminal for the necessary secrets. Use this option to switch this behavior off. In this case, the password must be supplied by some other means (for example graphical password agents) or the service might fail. This also disables querying the user for authentication for privileged operations. --kill-whom= When used with kill, choose which processes to send a UNIX process signal to. Must be one of main, control or all to select whether to kill only the main process, the control process or all processes of the unit. The main process of the unit is the one that defines the life-time of it. A control process of a unit is one that is invoked by the manager to induce state changes of it. For example, all processes started due to the ExecStartPre=, ExecStop= or ExecReload= settings of service units are control processes. Note that there is only one control process per unit at a time, as only one state change is executed at a time. For services of type Type=forking, the initial process started by the manager for ExecStart= is a control process, while the process ultimately forked off by that one is then considered the main process of the unit (if it can be determined). This is different for service units of other types, where the process forked off by the manager for ExecStart= is always the main process itself. A service unit consists of zero or one main process, zero or one control process plus any number of additional processes. Not all unit types manage processes of these types however. For example, for mount units, control processes are defined (which are the invocations of /usr/bin/mount and /usr/bin/umount), but no main process is defined. If omitted, defaults to all. --kill-value=INT If used with the kill command, enqueues a signal along with the specified integer value parameter to the specified process(es). This operation is only available for POSIX Realtime Signals (i.e. --signal=SIGRTMIN+... or --signal=SIGRTMAX-...), and ensures the signals are generated via the sigqueue(3) system call, rather than kill(3). The specified value must be a 32bit signed integer, and may be specified either in decimal, in hexadecimal (if prefixed with \"0x\"), octal (if prefixed with \"0o\") or binary (if prefixed with \"0b\") If this option is used the signal will only be enqueued on the control or main process of the unit, never on other processes belonging to the unit, i.e. --kill-whom=all will only affect main and control processes but no other processes. -s, --signal= When used with kill, choose which signal to send to selected processes. Must be one of the well-known signal specifiers such as SIGTERM, SIGINT or SIGSTOP. If omitted, defaults to SIGTERM. The special value \"help\" will list the known values and the program will exit immediately, and the special value \"list\" will list known values along with the numerical signal numbers and the program will exit immediately. --what= Select what type of per-unit resources to remove when the clean command is invoked, see above. Takes one of configuration, state, cache, logs, runtime, fdstore to select the type of resource. This option may be specified more than once, in which case all specified resource types are removed. Also accepts the special value all as a shortcut for specifying all six resource types. If this option is not specified defaults to the combination of cache, runtime and fdstore, i.e. the three kinds of resources that are generally considered to be redundant and can be reconstructed on next invocation. Note that the explicit removal of the fdstore resource type is only useful if the FileDescriptorStorePreserve= option is enabled, since the file descriptor store is otherwise cleaned automatically when the unit is stopped. -f, --force When used with enable, overwrite any existing conflicting symlinks. When used with edit, create all of the specified units which do not already exist. When used with halt, poweroff, reboot or kexec, execute the selected operation without shutting down all units. However, all processes will be killed forcibly and all file systems are unmounted or remounted read-only. This is hence a drastic but relatively safe option to request an immediate reboot. If --force is specified twice for these operations (with the exception of kexec), they will be executed immediately, without terminating any processes or unmounting any file systems. Warning: specifying --force twice with any of these operations might result in data loss. Note that when --force is specified twice the selected operation is executed by systemctl itself, and the system manager is not contacted. This means the command should succeed even when the system manager has crashed. --message= When used with halt, poweroff or reboot, set a short message explaining the reason for the operation. The message will be logged together with the default shutdown message. --now When used with enable, the units will also be started. When used with disable or mask, the units will also be stopped. The start or stop operation is only carried out when the respective enable or disable operation has been successful. --root= When used with enable/disable/is-enabled (and related commands), use the specified root path when looking for unit files. If this option is present, systemctl will operate on the file system directly, instead of communicating with the systemd daemon to carry out changes. --image=image Takes a path to a disk image file or block device node. If specified, all operations are applied to file system in the indicated disk image. This option is similar to --root=, but operates on file systems stored in disk images or block devices. The disk image should either contain just a file system or a set of file systems within a GPT partition table, following the Discoverable Partitions Specification[2]. For further information on supported disk images, see systemd-nspawn(1)'s switch of the same name. --image-policy=policy Takes an image policy string as argument, as per systemd.image-policy(7). The policy is enforced when operating on the disk image specified via --image=, see above. If not specified defaults to the \"*\" policy, i.e. all recognized file systems in the image are used. --runtime When used with enable, disable, edit, (and related commands), make changes only temporarily, so that they are lost on the next reboot. This will have the effect that changes are not made in subdirectories of /etc/ but in /run/, with identical immediate effects, however, since the latter is lost on reboot, the changes are lost too. Similarly, when used with set-property, make changes only temporarily, so that they are lost on the next reboot. --preset-mode= Takes one of \"full\" (the default), \"enable-only\", \"disable-only\". When used with the preset or preset-all commands, controls whether units shall be disabled and enabled according to the preset rules, or only enabled, or only disabled. -n, --lines= When used with status, controls the number of journal lines to show, counting from the most recent ones. Takes a positive integer argument, or 0 to disable journal output. Defaults to 10. -o, --output= When used with status, controls the formatting of the journal entries that are shown. For the available choices, see journalctl(1). Defaults to \"short\". --firmware-setup When used with the reboot command, indicate to the system's firmware to reboot into the firmware setup interface. Note that this functionality is not available on all systems. --boot-loader-menu=timeout When used with the reboot command, indicate to the system's boot loader to show the boot loader menu on the following boot. Takes a time value as parameter \u2014 indicating the menu timeout. Pass zero in order to disable the menu timeout. Note that not all boot loaders support this functionality. --boot-loader-entry=ID When used with the reboot command, indicate to the system's boot loader to boot into a specific boot loader entry on the following boot. Takes a boot loader entry identifier as argument, or \"help\" in order to list available entries. Note that not all boot loaders support this functionality. --reboot-argument= This switch is used with reboot. The value is architecture and firmware specific. As an example, \"recovery\" might be used to trigger system recovery, and \"fota\" might be used to trigger a \u201cfirmware over the air\u201d update. --plain When used with list-dependencies, list-units or list-machines, the output is printed as a list instead of a tree, and the bullet circles are omitted. --timestamp= Change the format of printed timestamps. The following values may be used: pretty (this is the default) \"Day YYYY-MM-DD HH:MM:SS TZ\" unix \"@seconds-since-the-epoch\" us, \u03bcs \"Day YYYY-MM-DD HH:MM:SS.UUUUUU TZ\" utc \"Day YYYY-MM-DD HH:MM:SS UTC\" us+utc, \u03bcs+utc \"Day YYYY-MM-DD HH:MM:SS.UUUUUU UTC\" --mkdir When used with bind, creates the destination file or directory before applying the bind mount. Note that even though the name of this option suggests that it is suitable only for directories, this option also creates the destination file node to mount over if the object to mount is not a directory, but a regular file, device node, socket or FIFO. --marked Only allowed with reload-or-restart. Enqueues restart jobs for all units that have the \"needs-restart\" mark, and reload jobs for units that have the \"needs-reload\" mark. When a unit marked for reload does not support reload, restart will be queued. Those properties can be set using set-property Markers=.... Unless --no-block is used, systemctl will wait for the queued jobs to finish. --read-only When used with bind, creates a read-only bind mount. --drop-in= When used with edit, use the given drop-in file name instead of override.conf. --when= When used with halt, poweroff, reboot or kexec, schedule the action to be performed at the given timestamp, which should adhere to the syntax documented in systemd.time(7) section \"PARSING TIMESTAMPS\". Specially, if \"show\" is given, the currently scheduled action will be shown, which can be canceled by passing an empty string or \"cancel\". -H, --host= Execute the operation remotely. Specify a hostname, or a username and hostname separated by \"@\", to connect to. The hostname may optionally be suffixed by a port ssh is listening on, separated by \":\", and then a container name, separated by \"/\", which connects directly to a specific container on the specified host. This will use SSH to talk to the remote machine manager instance. Container names may be enumerated with machinectl -H HOST. Put IPv6 addresses in brackets. -M, --machine= Execute operation on a local container. Specify a container name to connect to, optionally prefixed by a user name to connect as and a separating \"@\" character. If the special string \".host\" is used in place of the container name, a connection to the local system is made (which is useful to connect to a specific user's user bus: \"--user --machine=lennart@.host\"). If the \"@\" syntax is not used, the connection is made as root user. If the \"@\" syntax is used either the left hand side or the right hand side may be omitted (but not both) in which case the local user name and \".host\" are implied. --no-pager Do not pipe output into a pager. --legend=BOOL Enable or disable printing of the legend, i.e. column headers and the footer with hints. The legend is printed by default, unless disabled with --quiet or similar. -h, --help Print a short help text and exit. --version Print a short version string and exit. "
  },
  {
    "command": "patch",
    "description": " The patch utility shall read a source (patch) file containing any of four forms of difference (diff) listings produced by the diff utility (normal, copied context, unified context, or in the style of ed) and apply those differences to a file. By default, patch shall read from the standard input. The patch utility shall attempt to determine the type of the diff listing, unless overruled by a -c, -e, -n, or -u option. If the patch file contains more than one patch, patch shall attempt to apply each of them as if they came from separate patch files. (In this case, the application shall ensure that the name of the patch file is determinable for each diff listing.) The patch utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -b Save a copy of the original contents of each modified file, before the differences are applied, in a file of the same name with the suffix .orig appended to it. If the file already exists, it shall be overwritten; if multiple patches are applied to the same file, the .orig file shall be written only for the first patch. When the -o outfile option is also specified, file.orig shall not be created but, if outfile already exists, outfile.orig shall be created. -c Interpret the patch file as a copied context difference (the output of the utility diff when the -c or -C options are specified). -d dir Change the current directory to dir before processing as described in the EXTENDED DESCRIPTION section. -D define Mark changes with one of the following C preprocessor constructs: #ifdef define ... #endif #ifndef define ... #endif optionally combined with the C preprocessor construct #else. If the patched file is processed with the C preprocessor, where the macro define is defined, the output shall contain the changes from the patch file; otherwise, the output shall not contain the patches specified in the patch file. -e Interpret the patch file as an ed script, rather than a diff script. -i patchfile Read the patch information from the file named by the pathname patchfile, rather than the standard input. -l (The letter ell.) Cause any sequence of <blank> characters in the difference script to match any sequence of <blank> characters in the input file. Other characters shall be matched exactly. -n Interpret the script as a normal difference. -N Ignore patches where the differences have already been applied to the file; by default, already-applied patches shall be rejected. -o outfile Instead of modifying the files (specified by the file operand or the difference listings) directly, write a copy of the file referenced by each patch, with the appropriate differences applied, to outfile. Multiple patches for a single file shall be applied to the intermediate versions of the file created by any previous patches, and shall result in multiple, concatenated versions of the file being written to outfile. -p num For all pathnames in the patch file that indicate the names of files to be patched, delete num pathname components from the beginning of each pathname. If the pathname in the patch file is absolute, any leading <slash> characters shall be considered the first component (that is, -p 1 shall remove the leading <slash> characters). Specifying -p 0 shall cause the full pathname to be used. If -p is not specified, only the basename (the final pathname component) shall be used. -R Reverse the sense of the patch script; that is, assume that the difference script was created from the new version to the old version. The -R option cannot be used with ed scripts. The patch utility shall attempt to reverse each portion of the script before applying it. Rejected differences shall be saved in swapped format. If this option is not specified, and until a portion of the patch file is successfully applied, patch attempts to apply each portion in its reversed sense as well as in its normal sense. If the attempt is successful, the user shall be prompted to determine whether the -R option should be set. -r rejectfile Override the default reject filename. In the default case, the reject file shall have the same name as the output file, with the suffix .rej appended to it; see Patch Application. -u Interpret the patch file as a unified context difference (the output of the diff utility when the -u or -U options are specified). "
  },
  {
    "command": "find",
    "description": " This manual page documents the GNU version of find. GNU find searches the directory tree rooted at each given starting-point by evaluating the given expression from left to right, according to the rules of precedence (see section OPERATORS), until the outcome is known (the left hand side is false for and operations, true for or), at which point find moves on to the next file name. If no starting-point is specified, `.' is assumed. If you are using find in an environment where security is important (for example if you are using it to search directories that are writable by other users), you should read the `Security Considerations' chapter of the findutils documentation, which is called Finding Files and comes with findutils. That document also includes a lot more detail and discussion than this manual page, so you may find it a more useful source of information. The -H, -L and -P options control the treatment of symbolic links. Command-line arguments following these are taken to be names of files or directories to be examined, up to the first argument that begins with `-', or the argument `(' or `!'. That argument and any following arguments are taken to be the expression describing what is to be searched for. If no paths are given, the current directory is used. If no expression is given, the expression -print is used (but you should probably consider using -print0 instead, anyway). This manual page talks about `options' within the expression list. These options control the behaviour of find but are specified immediately after the last path name. The five `real' options -H, -L, -P, -D and -O must appear before the first path name, if at all. A double dash -- could theoretically be used to signal that any remaining arguments are not options, but this does not really work due to the way find determines the end of the following path arguments: it does that by reading until an expression argument comes (which also starts with a `-'). Now, if a path argument would start with a `-', then find would treat it as expression argument instead. Thus, to ensure that all start points are taken as such, and especially to prevent that wildcard patterns expanded by the calling shell are not mistakenly treated as expression arguments, it is generally safer to prefix wildcards or dubious path names with either `./' or to use absolute path names starting with '/'. Alternatively, it is generally safe though non-portable to use the GNU option -files0-from to pass arbitrary starting points to find. -P Never follow symbolic links. This is the default behaviour. When find examines or prints information about files, and the file is a symbolic link, the information used shall be taken from the properties of the symbolic link itself. -L Follow symbolic links. When find examines or prints information about files, the information used shall be taken from the properties of the file to which the link points, not from the link itself (unless it is a broken symbolic link or find is unable to examine the file to which the link points). Use of this option implies -noleaf. If you later use the -P option, -noleaf will still be in effect. If -L is in effect and find discovers a symbolic link to a subdirectory during its search, the subdirectory pointed to by the symbolic link will be searched. When the -L option is in effect, the -type predicate will always match against the type of the file that a symbolic link points to rather than the link itself (unless the symbolic link is broken). Actions that can cause symbolic links to become broken while find is executing (for example -delete) can give rise to confusing behaviour. Using -L causes the -lname and -ilname predicates always to return false. -H Do not follow symbolic links, except while processing the command line arguments. When find examines or prints information about files, the information used shall be taken from the properties of the symbolic link itself. The only exception to this behaviour is when a file specified on the command line is a symbolic link, and the link can be resolved. For that situation, the information used is taken from whatever the link points to (that is, the link is followed). The information about the link itself is used as a fallback if the file pointed to by the symbolic link cannot be examined. If -H is in effect and one of the paths specified on the command line is a symbolic link to a directory, the contents of that directory will be examined (though of course -maxdepth 0 would prevent this). If more than one of -H, -L and -P is specified, each overrides the others; the last one appearing on the command line takes effect. Since it is the default, the -P option should be considered to be in effect unless either -H or -L is specified. GNU find frequently stats files during the processing of the command line itself, before any searching has begun. These options also affect how those arguments are processed. Specifically, there are a number of tests that compare files listed on the command line against a file we are currently considering. In each case, the file specified on the command line will have been examined and some of its properties will have been saved. If the named file is in fact a symbolic link, and the -P option is in effect (or if neither -H nor -L were specified), the information used for the comparison will be taken from the properties of the symbolic link. Otherwise, it will be taken from the properties of the file the link points to. If find cannot follow the link (for example because it has insufficient privileges or the link points to a nonexistent file) the properties of the link itself will be used. When the -H or -L options are in effect, any symbolic links listed as the argument of -newer will be dereferenced, and the timestamp will be taken from the file to which the symbolic link points. The same consideration applies to -newerXY, -anewer and -cnewer. The -follow option has a similar effect to -L, though it takes effect at the point where it appears (that is, if -L is not used but -follow is, any symbolic links appearing after -follow on the command line will be dereferenced, and those before it will not). -D debugopts Print diagnostic information; this can be helpful to diagnose problems with why find is not doing what you want. The list of debug options should be comma separated. Compatibility of the debug options is not guaranteed between releases of findutils. For a complete list of valid debug options, see the output of find -D help. Valid debug options include exec Show diagnostic information relating to -exec, -execdir, -ok and -okdir opt Prints diagnostic information relating to the optimisation of the expression tree; see the -O option. rates Prints a summary indicating how often each predicate succeeded or failed. search Navigate the directory tree verbosely. stat Print messages as files are examined with the stat and lstat system calls. The find program tries to minimise such calls. tree Show the expression tree in its original and optimised form. all Enable all of the other debug options (but help). help Explain the debugging options. -Olevel Enables query optimisation. The find program reorders tests to speed up execution while preserving the overall effect; that is, predicates with side effects are not reordered relative to each other. The optimisations performed at each optimisation level are as follows. 0 Equivalent to optimisation level 1. 1 This is the default optimisation level and corresponds to the traditional behaviour. Expressions are reordered so that tests based only on the names of files (for example -name and -regex) are performed first. 2 Any -type or -xtype tests are performed after any tests based only on the names of files, but before any tests that require information from the inode. On many modern versions of Unix, file types are returned by readdir() and so these predicates are faster to evaluate than predicates which need to stat the file first. If you use the -fstype FOO predicate and specify a filesystem type FOO which is not known (that is, present in `/etc/mtab') at the time find starts, that predicate is equivalent to -false. 3 At this optimisation level, the full cost-based query optimiser is enabled. The order of tests is modified so that cheap (i.e. fast) tests are performed first and more expensive ones are performed later, if necessary. Within each cost band, predicates are evaluated earlier or later according to whether they are likely to succeed or not. For -o, predicates which are likely to succeed are evaluated earlier, and for -a, predicates which are likely to fail are evaluated earlier. The cost-based optimiser has a fixed idea of how likely any given test is to succeed. In some cases the probability takes account of the specific nature of the test (for example, -type f is assumed to be more likely to succeed than -type c). The cost-based optimiser is currently being evaluated. If it does not actually improve the performance of find, it will be removed again. Conversely, optimisations that prove to be reliable, robust and effective may be enabled at lower optimisation levels over time. However, the default behaviour (i.e. optimisation level 1) will not be changed in the 4.3.x release series. The findutils test suite runs all the tests on find at each optimisation level and ensures that the result is the same. "
  },
  {
    "command": "expect",
    "description": " Expect is a program that \"talks\" to other interactive programs according to a script. Following the script, Expect knows what can be expected from a program and what the correct response should be. An interpreted language provides branching and high- level control structures to direct the dialogue. In addition, the user can take control and interact directly when desired, afterward returning control to the script. Expectk is a mixture of Expect and Tk. It behaves just like Expect and Tk's wish. Expect can also be used directly in C or C++ (that is, without Tcl). See libexpect(3). The name \"Expect\" comes from the idea of send/expect sequences popularized by uucp, kermit and other modem control programs. However unlike uucp, Expect is generalized so that it can be run as a user-level command with any program and task in mind. Expect can actually talk to several programs at the same time. For example, here are some things Expect can do: \u2022 Cause your computer to dial you back, so that you can login without paying for the call. \u2022 Start a game (e.g., rogue) and if the optimal configuration doesn't appear, restart it (again and again) until it does, then hand over control to you. \u2022 Run fsck, and in response to its questions, answer \"yes\", \"no\" or give control back to you, based on predetermined criteria. \u2022 Connect to another network or BBS (e.g., MCI Mail, CompuServe) and automatically retrieve your mail so that it appears as if it was originally sent to your local system. \u2022 Carry environment variables, current directory, or any kind of information across rlogin, telnet, tip, su, chgrp, etc. There are a variety of reasons why the shell cannot perform these tasks. (Try, you'll see.) All are possible with Expect. In general, Expect is useful for running any program which requires interaction between the program and the user. All that is necessary is that the interaction can be characterized programmatically. Expect can also give the user back control (without halting the program being controlled) if desired. Similarly, the user can return control to the script at any time. "
  },
  {
    "command": "du",
    "description": " By default, the du utility shall write to standard output the size of the file space allocated to, and the size of the file space allocated to each subdirectory of, the file hierarchy rooted in each of the specified files. By default, when a symbolic link is encountered on the command line or in the file hierarchy, du shall count the size of the symbolic link (rather than the file referenced by the link), and shall not follow the link to another portion of the file hierarchy. The size of the file space allocated to a file of type directory shall be defined as the sum total of space allocated to all files in the file hierarchy rooted in the directory plus the space allocated to the directory itself. When du cannot stat() files or stat() or read directories, it shall report an error condition and the final exit status is affected. A file that occurs multiple times under one file operand and that has a link count greater than 1 shall be counted and written for only one entry. It is implementation-defined whether a file that has a link count no greater than 1 is counted and written just once, or is counted and written for each occurrence. It is implementation-defined whether a file that occurs under one file operand is counted for other file operands. The directory entry that is selected in the report is unspecified. By default, file sizes shall be written in 512-byte units, rounded up to the next 512-byte unit. The du utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -a In addition to the default output, report the size of each file not of type directory in the file hierarchy rooted in the specified file. The -a option shall not affect whether non-directories given as file operands are listed. -H If a symbolic link is specified on the command line, du shall count the size of the file or file hierarchy referenced by the link. -k Write the files sizes in units of 1024 bytes, rather than the default 512-byte units. -L If a symbolic link is specified on the command line or encountered during the traversal of a file hierarchy, du shall count the size of the file or file hierarchy referenced by the link. -s Instead of the default output, report only the total sum for each of the specified files. -x When evaluating file sizes, evaluate only those files that have the same device as the file specified by the file operand. Specifying more than one of the mutually-exclusive options -H and -L shall not be considered an error. The last option specified shall determine the behavior of the utility. "
  },
  {
    "command": "fold",
    "description": " The fold utility is a filter that shall fold lines from its input files, breaking the lines to have a maximum of width column positions (or bytes, if the -b option is specified). Lines shall be broken by the insertion of a <newline> such that each output line (referred to later in this section as a segment) is the maximum width possible that does not exceed the specified number of column positions (or bytes). A line shall not be broken in the middle of a character. The behavior is undefined if width is less than the number of columns any single character in the input would occupy. If the <carriage-return>, <backspace>, or <tab> characters are encountered in the input, and the -b option is not specified, they shall be treated specially: <backspace> The current count of line width shall be decremented by one, although the count never shall become negative. The fold utility shall not insert a <newline> immediately before or after any <backspace>, unless the following character has a width greater than 1 and would cause the line width to exceed width. <carriage-return> The current count of line width shall be set to zero. The fold utility shall not insert a <newline> immediately before or after any <carriage-return>. <tab> Each <tab> encountered shall advance the column position pointer to the next tab stop. Tab stops shall be at each column position n such that n modulo 8 equals 1. The fold utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -b Count width in bytes rather than column positions. -s If a segment of a line contains a <blank> within the first width column positions (or bytes), break the line after the last such <blank> meeting the width constraints. If there is no <blank> meeting the requirements, the -s option shall have no effect for that output segment of the input line. -w width Specify the maximum line length, in column positions (or bytes if -b is specified). The results are unspecified if width is not a positive decimal number. The default value shall be 80. "
  },
  {
    "command": "nohup",
    "description": " The nohup utility shall invoke the utility named by the utility operand with arguments supplied as the argument operands. At the time the named utility is invoked, the SIGHUP signal shall be set to be ignored. If standard input is associated with a terminal, the nohup utility may redirect standard input from an unspecified file. If the standard output is a terminal, all output written by the named utility to its standard output shall be appended to the end of the file nohup.out in the current directory. If nohup.out cannot be created or opened for appending, the output shall be appended to the end of the file nohup.out in the directory specified by the HOME environment variable. If neither file can be created or opened for appending, utility shall not be invoked. If a file is created, the file's permission bits shall be set to S_IRUSR | S_IWUSR. If standard error is a terminal and standard output is open but is not a terminal, all output written by the named utility to its standard error shall be redirected to the same open file description as the standard output. If standard error is a terminal and standard output either is a terminal or is closed, the same output shall instead be appended to the end of the nohup.out file as described above. None. "
  },
  {
    "command": "git-rm",
    "description": " Remove files matching pathspec from the index, or from the working tree and the index. git rm will not remove a file from just your working directory. (There is no option to remove a file only from the working tree and yet keep it in the index; use /bin/rm if you want to do that.) The files being removed have to be identical to the tip of the branch, and no updates to their contents can be staged in the index, though that default behavior can be overridden with the -f option. When --cached is given, the staged content has to match either the tip of the branch or the file on disk, allowing the file to be removed from just the index. When sparse-checkouts are in use (see git-sparse-checkout(1)), git rm will only remove paths within the sparse-checkout patterns. <pathspec>... Files to remove. A leading directory name (e.g. dir to remove dir/file1 and dir/file2) can be given to remove all files in the directory, and recursively all sub-directories, but this requires the -r option to be explicitly given. The command removes only the paths that are known to Git. File globbing matches across directory boundaries. Thus, given two directories d and d2, there is a difference between using git rm 'd*' and git rm 'd/*', as the former will also remove all of directory d2. For more details, see the pathspec entry in gitglossary(7). -f, --force Override the up-to-date check. -n, --dry-run Don\u2019t actually remove any file(s). Instead, just show if they exist in the index and would otherwise be removed by the command. -r Allow recursive removal when a leading directory name is given. -- This option can be used to separate command-line options from the list of files, (useful when filenames might be mistaken for command-line options). --cached Use this option to unstage and remove paths only from the index. Working tree files, whether modified or not, will be left alone. --ignore-unmatch Exit with a zero status even if no files matched. --sparse Allow updating index entries outside of the sparse-checkout cone. Normally, git rm refuses to update index entries whose paths do not fit within the sparse-checkout cone. See git-sparse-checkout(1) for more. -q, --quiet git rm normally outputs one line (in the form of an rm command) for each file removed. This option suppresses that output. --pathspec-from-file=<file> Pathspec is passed in <file> instead of commandline args. If <file> is exactly - then standard input is used. Pathspec elements are separated by LF or CR/LF. Pathspec elements can be quoted as explained for the configuration variable core.quotePath (see git-config(1)). See also --pathspec-file-nul and global --literal-pathspecs. --pathspec-file-nul Only meaningful with --pathspec-from-file. Pathspec elements are separated with NUL character and all other characters are taken literally (including newlines and quotes). "
  },
  {
    "command": "getconf",
    "description": " In the first synopsis form, the getconf utility shall write to the standard output the value of the variable specified by the system_var operand. In the second synopsis form, the getconf utility shall write to the standard output the value of the variable specified by the path_var operand for the path specified by the pathname operand. The value of each configuration variable shall be determined as if it were obtained by calling the function from which it is defined to be available by this volume of POSIX.1\u20102017 or by the System Interfaces volume of POSIX.1\u20102017 (see the OPERANDS section). The value shall reflect conditions in the current operating environment. The getconf utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -v specification Indicate a specific specification and version for which configuration variables shall be determined. If this option is not specified, the values returned correspond to an implementation default conforming compilation environment. If the command: getconf _POSIX_V7_ILP32_OFF32 does not write \"-1\\n\" or \"undefined\\n\" to standard output, then commands of the form: getconf -v POSIX_V7_ILP32_OFF32 ... determine values for configuration variables corresponding to the POSIX_V7_ILP32_OFF32 compilation environment specified in c99(1p), the EXTENDED DESCRIPTION. If the command: getconf _POSIX_V7_ILP32_OFFBIG does not write \"-1\\n\" or \"undefined\\n\" to standard output, then commands of the form: getconf -v POSIX_V7_ILP32_OFFBIG ... determine values for configuration variables corresponding to the POSIX_V7_ILP32_OFFBIG compilation environment specified in c99(1p), the EXTENDED DESCRIPTION. If the command: getconf _POSIX_V7_LP64_OFF64 does not write \"-1\\n\" or \"undefined\\n\" to standard output, then commands of the form: getconf -v POSIX_V7_LP64_OFF64 ... determine values for configuration variables corresponding to the POSIX_V7_LP64_OFF64 compilation environment specified in c99(1p), the EXTENDED DESCRIPTION. If the command: getconf _POSIX_V7_LPBIG_OFFBIG does not write \"-1\\n\" or \"undefined\\n\" to standard output, then commands of the form: getconf -v POSIX_V7_LPBIG_OFFBIG ... determine values for configuration variables corresponding to the POSIX_V7_LPBIG_OFFBIG compilation environment specified in c99(1p), the EXTENDED DESCRIPTION. "
  },
  {
    "command": "wget",
    "description": " GNU Wget is a free utility for non-interactive download of files from the Web. It supports HTTP, HTTPS, and FTP protocols, as well as retrieval through HTTP proxies. Wget is non-interactive, meaning that it can work in the background, while the user is not logged on. This allows you to start a retrieval and disconnect from the system, letting Wget finish the work. By contrast, most of the Web browsers require constant user's presence, which can be a great hindrance when transferring a lot of data. Wget can follow links in HTML, XHTML, and CSS pages, to create local versions of remote web sites, fully recreating the directory structure of the original site. This is sometimes referred to as \"recursive downloading.\" While doing that, Wget respects the Robot Exclusion Standard (/robots.txt). Wget can be instructed to convert the links in downloaded files to point at the local files, for offline viewing. Wget has been designed for robustness over slow or unstable network connections; if a download fails due to a network problem, it will keep retrying until the whole file has been retrieved. If the server supports regetting, it will instruct the server to continue the download from where it left off. Option Syntax Since Wget uses GNU getopt to process command-line arguments, every option has a long form along with the short one. Long options are more convenient to remember, but take time to type. You may freely mix different option styles, or specify options after the command-line arguments. Thus you may write: wget -r --tries=10 http://fly.srk.fer.hr/ -o log The space between the option accepting an argument and the argument may be omitted. Instead of -o log you can write -olog. You may put several options that do not require arguments together, like: wget -drc <URL> This is completely equivalent to: wget -d -r -c <URL> Since the options can be specified after the arguments, you may terminate them with --. So the following will try to download URL -x, reporting failure to log: wget -o log -- -x The options that accept comma-separated lists all respect the convention that specifying an empty list clears its value. This can be useful to clear the .wgetrc settings. For instance, if your .wgetrc sets \"exclude_directories\" to /cgi-bin, the following example will first reset it, and then set it to exclude /~nobody and /~somebody. You can also clear the lists in .wgetrc. wget -X \"\" -X /~nobody,/~somebody Most options that do not accept arguments are boolean options, so named because their state can be captured with a yes-or-no (\"boolean\") variable. For example, --follow-ftp tells Wget to follow FTP links from HTML files and, on the other hand, --no-glob tells it not to perform file globbing on FTP URLs. A boolean option is either affirmative or negative (beginning with --no). All such options share several properties. Unless stated otherwise, it is assumed that the default behavior is the opposite of what the option accomplishes. For example, the documented existence of --follow-ftp assumes that the default is to not follow FTP links from HTML pages. Affirmative options can be negated by prepending the --no- to the option name; negative options can be negated by omitting the --no- prefix. This might seem superfluous---if the default for an affirmative option is to not do something, then why provide a way to explicitly turn it off? But the startup file may in fact change the default. For instance, using \"follow_ftp = on\" in .wgetrc makes Wget follow FTP links by default, and using --no-follow-ftp is the only way to restore the factory default from the command line. Basic Startup Options -V --version Display the version of Wget. -h --help Print a help message describing all of Wget's command-line options. -b --background Go to background immediately after startup. If no output file is specified via the -o, output is redirected to wget- log. -e command --execute command Execute command as if it were a part of .wgetrc. A command thus invoked will be executed after the commands in .wgetrc, thus taking precedence over them. If you need to specify more than one wgetrc command, use multiple instances of -e. Logging and Input File Options -o logfile --output-file=logfile Log all messages to logfile. The messages are normally reported to standard error. -a logfile --append-output=logfile Append to logfile. This is the same as -o, only it appends to logfile instead of overwriting the old log file. If logfile does not exist, a new file is created. -d --debug Turn on debug output, meaning various information important to the developers of Wget if it does not work properly. Your system administrator may have chosen to compile Wget without debug support, in which case -d will not work. Please note that compiling with debug support is always safe---Wget compiled with the debug support will not print any debug info unless requested with -d. -q --quiet Turn off Wget's output. -v --verbose Turn on verbose output, with all the available data. The default output is verbose. -nv --no-verbose Turn off verbose without being completely quiet (use -q for that), which means that error messages and basic information still get printed. --report-speed=type Output bandwidth as type. The only accepted value is bits. -i file --input-file=file Read URLs from a local or external file. If - is specified as file, URLs are read from the standard input. (Use ./- to read from a file literally named -.) If this function is used, no URLs need be present on the command line. If there are URLs both on the command line and in an input file, those on the command lines will be the first ones to be retrieved. If --force-html is not specified, then file should consist of a series of URLs, one per line. However, if you specify --force-html, the document will be regarded as html. In that case you may have problems with relative links, which you can solve either by adding \"<base href=\"url\">\" to the documents or by specifying --base=url on the command line. If the file is an external one, the document will be automatically treated as html if the Content-Type matches text/html. Furthermore, the file's location will be implicitly used as base href if none was specified. --input-metalink=file Downloads files covered in local Metalink file. Metalink version 3 and 4 are supported. --keep-badhash Keeps downloaded Metalink's files with a bad hash. It appends .badhash to the name of Metalink's files which have a checksum mismatch, except without overwriting existing files. --metalink-over-http Issues HTTP HEAD request instead of GET and extracts Metalink metadata from response headers. Then it switches to Metalink download. If no valid Metalink metadata is found, it falls back to ordinary HTTP download. Enables Content-Type: application/metalink4+xml files download/processing. --metalink-index=number Set the Metalink application/metalink4+xml metaurl ordinal NUMBER. From 1 to the total number of \"application/metalink4+xml\" available. Specify 0 or inf to choose the first good one. Metaurls, such as those from a --metalink-over-http, may have been sorted by priority key's value; keep this in mind to choose the right NUMBER. --preferred-location Set preferred location for Metalink resources. This has effect if multiple resources with same priority are available. --xattr Enable use of file system's extended attributes to save the original URL and the Referer HTTP header value if used. Be aware that the URL might contain private information like access tokens or credentials. -F --force-html When input is read from a file, force it to be treated as an HTML file. This enables you to retrieve relative links from existing HTML files on your local disk, by adding \"<base href=\"url\">\" to HTML, or using the --base command-line option. -B URL --base=URL Resolves relative links using URL as the point of reference, when reading links from an HTML file specified via the -i/--input-file option (together with --force-html, or when the input file was fetched remotely from a server describing it as HTML). This is equivalent to the presence of a \"BASE\" tag in the HTML input file, with URL as the value for the \"href\" attribute. For instance, if you specify http://foo/bar/a.html for URL, and Wget reads ../baz/b.html from the input file, it would be resolved to http://foo/baz/b.html . --config=FILE Specify the location of a startup file you wish to use instead of the default one(s). Use --no-config to disable reading of config files. If both --config and --no-config are given, --no-config is ignored. --rejected-log=logfile Logs all URL rejections to logfile as comma separated values. The values include the reason of rejection, the URL and the parent URL it was found in. Download Options --bind-address=ADDRESS When making client TCP/IP connections, bind to ADDRESS on the local machine. ADDRESS may be specified as a hostname or IP address. This option can be useful if your machine is bound to multiple IPs. --bind-dns-address=ADDRESS [libcares only] This address overrides the route for DNS requests. If you ever need to circumvent the standard settings from /etc/resolv.conf, this option together with --dns-servers is your friend. ADDRESS must be specified either as IPv4 or IPv6 address. Wget needs to be built with libcares for this option to be available. --dns-servers=ADDRESSES [libcares only] The given address(es) override the standard nameserver addresses, e.g. as configured in /etc/resolv.conf. ADDRESSES may be specified either as IPv4 or IPv6 addresses, comma-separated. Wget needs to be built with libcares for this option to be available. -t number --tries=number Set number of tries to number. Specify 0 or inf for infinite retrying. The default is to retry 20 times, with the exception of fatal errors like \"connection refused\" or \"not found\" (404), which are not retried. -O file --output-document=file The documents will not be written to the appropriate files, but all will be concatenated together and written to file. If - is used as file, documents will be printed to standard output, disabling link conversion. (Use ./- to print to a file literally named -.) Use of -O is not intended to mean simply \"use the name file instead of the one in the URL;\" rather, it is analogous to shell redirection: wget -O file http://foo is intended to work like wget -O - http://foo > file; file will be truncated immediately, and all downloaded content will be written there. For this reason, -N (for timestamp-checking) is not supported in combination with -O: since file is always newly created, it will always have a very new timestamp. A warning will be issued if this combination is used. Similarly, using -r or -p with -O may not work as you expect: Wget won't just download the first file to file and then download the rest to their normal names: all downloaded content will be placed in file. This was disabled in version 1.11, but has been reinstated (with a warning) in 1.11.2, as there are some cases where this behavior can actually have some use. A combination with -nc is only accepted if the given output file does not exist. Note that a combination with -k is only permitted when downloading a single document, as in that case it will just convert all relative URIs to external ones; -k makes no sense for multiple URIs when they're all being downloaded to a single file; -k can be used only when the output is a regular file. -nc --no-clobber If a file is downloaded more than once in the same directory, Wget's behavior depends on a few options, including -nc. In certain cases, the local file will be clobbered, or overwritten, upon repeated download. In other cases it will be preserved. When running Wget without -N, -nc, -r, or -p, downloading the same file in the same directory will result in the original copy of file being preserved and the second copy being named file.1. If that file is downloaded yet again, the third copy will be named file.2, and so on. (This is also the behavior with -nd, even if -r or -p are in effect.) When -nc is specified, this behavior is suppressed, and Wget will refuse to download newer copies of file. Therefore, \"\"no-clobber\"\" is actually a misnomer in this mode---it's not clobbering that's prevented (as the numeric suffixes were already preventing clobbering), but rather the multiple version saving that's prevented. When running Wget with -r or -p, but without -N, -nd, or -nc, re-downloading a file will result in the new copy simply overwriting the old. Adding -nc will prevent this behavior, instead causing the original version to be preserved and any newer copies on the server to be ignored. When running Wget with -N, with or without -r or -p, the decision as to whether or not to download a newer copy of a file depends on the local and remote timestamp and size of the file. -nc may not be specified at the same time as -N. A combination with -O/--output-document is only accepted if the given output file does not exist. Note that when -nc is specified, files with the suffixes .html or .htm will be loaded from the local disk and parsed as if they had been retrieved from the Web. --backups=backups Before (over)writing a file, back up an existing file by adding a .1 suffix (_1 on VMS) to the file name. Such backup files are rotated to .2, .3, and so on, up to backups (and lost beyond that). --no-netrc Do not try to obtain credentials from .netrc file. By default .netrc file is searched for credentials in case none have been passed on command line and authentication is required. -c --continue Continue getting a partially-downloaded file. This is useful when you want to finish up a download started by a previous instance of Wget, or by another program. For instance: wget -c ftp://sunsite.doc.ic.ac.uk/ls-lR.Z If there is a file named ls-lR.Z in the current directory, Wget will assume that it is the first portion of the remote file, and will ask the server to continue the retrieval from an offset equal to the length of the local file. Note that you don't need to specify this option if you just want the current invocation of Wget to retry downloading a file should the connection be lost midway through. This is the default behavior. -c only affects resumption of downloads started prior to this invocation of Wget, and whose local files are still sitting around. Without -c, the previous example would just download the remote file to ls-lR.Z.1, leaving the truncated ls-lR.Z file alone. If you use -c on a non-empty file, and the server does not support continued downloading, Wget will restart the download from scratch and overwrite the existing file entirely. Beginning with Wget 1.7, if you use -c on a file which is of equal size as the one on the server, Wget will refuse to download the file and print an explanatory message. The same happens when the file is smaller on the server than locally (presumably because it was changed on the server since your last download attempt)---because \"continuing\" is not meaningful, no download occurs. On the other side of the coin, while using -c, any file that's bigger on the server than locally will be considered an incomplete download and only \"(length(remote) - length(local))\" bytes will be downloaded and tacked onto the end of the local file. This behavior can be desirable in certain cases---for instance, you can use wget -c to download just the new portion that's been appended to a data collection or log file. However, if the file is bigger on the server because it's been changed, as opposed to just appended to, you'll end up with a garbled file. Wget has no way of verifying that the local file is really a valid prefix of the remote file. You need to be especially careful of this when using -c in conjunction with -r, since every file will be considered as an \"incomplete download\" candidate. Another instance where you'll get a garbled file if you try to use -c is if you have a lame HTTP proxy that inserts a \"transfer interrupted\" string into the local file. In the future a \"rollback\" option may be added to deal with this case. Note that -c only works with FTP servers and with HTTP servers that support the \"Range\" header. --start-pos=OFFSET Start downloading at zero-based position OFFSET. Offset may be expressed in bytes, kilobytes with the `k' suffix, or megabytes with the `m' suffix, etc. --start-pos has higher precedence over --continue. When --start-pos and --continue are both specified, wget will emit a warning then proceed as if --continue was absent. Server support for continued download is required, otherwise --start-pos cannot help. See -c for details. --progress=type Select the type of the progress indicator you wish to use. Legal indicators are \"dot\" and \"bar\". The \"bar\" indicator is used by default. It draws an ASCII progress bar graphics (a.k.a \"thermometer\" display) indicating the status of retrieval. If the output is not a TTY, the \"dot\" bar will be used by default. Use --progress=dot to switch to the \"dot\" display. It traces the retrieval by printing dots on the screen, each dot representing a fixed amount of downloaded data. The progress type can also take one or more parameters. The parameters vary based on the type selected. Parameters to type are passed by appending them to the type sperated by a colon (:) like this: --progress=type:parameter1:parameter2. When using the dotted retrieval, you may set the style by specifying the type as dot:style. Different styles assign different meaning to one dot. With the \"default\" style each dot represents 1K, there are ten dots in a cluster and 50 dots in a line. The \"binary\" style has a more \"computer\"-like orientation---8K dots, 16-dots clusters and 48 dots per line (which makes for 384K lines). The \"mega\" style is suitable for downloading large files---each dot represents 64K retrieved, there are eight dots in a cluster, and 48 dots on each line (so each line contains 3M). If \"mega\" is not enough then you can use the \"giga\" style---each dot represents 1M retrieved, there are eight dots in a cluster, and 32 dots on each line (so each line contains 32M). With --progress=bar, there are currently two possible parameters, force and noscroll. When the output is not a TTY, the progress bar always falls back to \"dot\", even if --progress=bar was passed to Wget during invocation. This behaviour can be overridden and the \"bar\" output forced by using the \"force\" parameter as --progress=bar:force. By default, the bar style progress bar scroll the name of the file from left to right for the file being downloaded if the filename exceeds the maximum length allotted for its display. In certain cases, such as with --progress=bar:force, one may not want the scrolling filename in the progress bar. By passing the \"noscroll\" parameter, Wget can be forced to display as much of the filename as possible without scrolling through it. Note that you can set the default style using the \"progress\" command in .wgetrc. That setting may be overridden from the command line. For example, to force the bar output without scrolling, use --progress=bar:force:noscroll. --show-progress Force wget to display the progress bar in any verbosity. By default, wget only displays the progress bar in verbose mode. One may however, want wget to display the progress bar on screen in conjunction with any other verbosity modes like --no-verbose or --quiet. This is often a desired a property when invoking wget to download several small/large files. In such a case, wget could simply be invoked with this parameter to get a much cleaner output on the screen. This option will also force the progress bar to be printed to stderr when used alongside the --output-file option. -N --timestamping Turn on time-stamping. --no-if-modified-since Do not send If-Modified-Since header in -N mode. Send preliminary HEAD request instead. This has only effect in -N mode. --no-use-server-timestamps Don't set the local file's timestamp by the one on the server. By default, when a file is downloaded, its timestamps are set to match those from the remote file. This allows the use of --timestamping on subsequent invocations of wget. However, it is sometimes useful to base the local file's timestamp on when it was actually downloaded; for that purpose, the --no-use-server-timestamps option has been provided. -S --server-response Print the headers sent by HTTP servers and responses sent by FTP servers. --spider When invoked with this option, Wget will behave as a Web spider, which means that it will not download the pages, just check that they are there. For example, you can use Wget to check your bookmarks: wget --spider --force-html -i bookmarks.html This feature needs much more work for Wget to get close to the functionality of real web spiders. -T seconds --timeout=seconds Set the network timeout to seconds seconds. This is equivalent to specifying --dns-timeout, --connect-timeout, and --read-timeout, all at the same time. When interacting with the network, Wget can check for timeout and abort the operation if it takes too long. This prevents anomalies like hanging reads and infinite connects. The only timeout enabled by default is a 900-second read timeout. Setting a timeout to 0 disables it altogether. Unless you know what you are doing, it is best not to change the default timeout settings. All timeout-related options accept decimal values, as well as subsecond values. For example, 0.1 seconds is a legal (though unwise) choice of timeout. Subsecond timeouts are useful for checking server response times or for testing network latency. --dns-timeout=seconds Set the DNS lookup timeout to seconds seconds. DNS lookups that don't complete within the specified time will fail. By default, there is no timeout on DNS lookups, other than that implemented by system libraries. --connect-timeout=seconds Set the connect timeout to seconds seconds. TCP connections that take longer to establish will be aborted. By default, there is no connect timeout, other than that implemented by system libraries. --read-timeout=seconds Set the read (and write) timeout to seconds seconds. The \"time\" of this timeout refers to idle time: if, at any point in the download, no data is received for more than the specified number of seconds, reading fails and the download is restarted. This option does not directly affect the duration of the entire download. Of course, the remote server may choose to terminate the connection sooner than this option requires. The default read timeout is 900 seconds. --limit-rate=amount Limit the download speed to amount bytes per second. Amount may be expressed in bytes, kilobytes with the k suffix, or megabytes with the m suffix. For example, --limit-rate=20k will limit the retrieval rate to 20KB/s. This is useful when, for whatever reason, you don't want Wget to consume the entire available bandwidth. This option allows the use of decimal numbers, usually in conjunction with power suffixes; for example, --limit-rate=2.5k is a legal value. Note that Wget implements the limiting by sleeping the appropriate amount of time after a network read that took less time than specified by the rate. Eventually this strategy causes the TCP transfer to slow down to approximately the specified rate. However, it may take some time for this balance to be achieved, so don't be surprised if limiting the rate doesn't work well with very small files. -w seconds --wait=seconds Wait the specified number of seconds between the retrievals. Use of this option is recommended, as it lightens the server load by making the requests less frequent. Instead of in seconds, the time can be specified in minutes using the \"m\" suffix, in hours using \"h\" suffix, or in days using \"d\" suffix. Specifying a large value for this option is useful if the network or the destination host is down, so that Wget can wait long enough to reasonably expect the network error to be fixed before the retry. The waiting interval specified by this function is influenced by \"--random-wait\", which see. --waitretry=seconds If you don't want Wget to wait between every retrieval, but only between retries of failed downloads, you can use this option. Wget will use linear backoff, waiting 1 second after the first failure on a given file, then waiting 2 seconds after the second failure on that file, up to the maximum number of seconds you specify. By default, Wget will assume a value of 10 seconds. --random-wait Some web sites may perform log analysis to identify retrieval programs such as Wget by looking for statistically significant similarities in the time between requests. This option causes the time between requests to vary between 0.5 and 1.5 * wait seconds, where wait was specified using the --wait option, in order to mask Wget's presence from such analysis. A 2001 article in a publication devoted to development on a popular consumer platform provided code to perform this analysis on the fly. Its author suggested blocking at the class C address level to ensure automated retrieval programs were blocked despite changing DHCP-supplied addresses. The --random-wait option was inspired by this ill-advised recommendation to block many unrelated users from a web site due to the actions of one. --no-proxy Don't use proxies, even if the appropriate *_proxy environment variable is defined. -Q quota --quota=quota Specify download quota for automatic retrievals. The value can be specified in bytes (default), kilobytes (with k suffix), or megabytes (with m suffix). Note that quota will never affect downloading a single file. So if you specify wget -Q10k https://example.com/ls-lR.gz, all of the ls-lR.gz will be downloaded. The same goes even when several URLs are specified on the command-line. The quota is checked only at the end of each downloaded file, so it will never result in a partially downloaded file. Thus you may safely type wget -Q2m -i sites---download will be aborted after the file that exhausts the quota is completely downloaded. Setting quota to 0 or to inf unlimits the download quota. --no-dns-cache Turn off caching of DNS lookups. Normally, Wget remembers the IP addresses it looked up from DNS so it doesn't have to repeatedly contact the DNS server for the same (typically small) set of hosts it retrieves from. This cache exists in memory only; a new Wget run will contact DNS again. However, it has been reported that in some situations it is not desirable to cache host names, even for the duration of a short-running application like Wget. With this option Wget issues a new DNS lookup (more precisely, a new call to \"gethostbyname\" or \"getaddrinfo\") each time it makes a new connection. Please note that this option will not affect caching that might be performed by the resolving library or by an external caching layer, such as NSCD. If you don't understand exactly what this option does, you probably won't need it. --restrict-file-names=modes Change which characters found in remote URLs must be escaped during generation of local filenames. Characters that are restricted by this option are escaped, i.e. replaced with %HH, where HH is the hexadecimal number that corresponds to the restricted character. This option may also be used to force all alphabetical cases to be either lower- or uppercase. By default, Wget escapes the characters that are not valid or safe as part of file names on your operating system, as well as control characters that are typically unprintable. This option is useful for changing these defaults, perhaps because you are downloading to a non-native partition, or because you want to disable escaping of the control characters, or you want to further restrict characters to only those in the ASCII range of values. The modes are a comma-separated set of text values. The acceptable values are unix, windows, nocontrol, ascii, lowercase, and uppercase. The values unix and windows are mutually exclusive (one will override the other), as are lowercase and uppercase. Those last are special cases, as they do not change the set of characters that would be escaped, but rather force local file paths to be converted either to lower- or uppercase. When \"unix\" is specified, Wget escapes the character / and the control characters in the ranges 0--31 and 128--159. This is the default on Unix-like operating systems. When \"windows\" is given, Wget escapes the characters \\, |, /, :, ?, \", *, <, >, and the control characters in the ranges 0--31 and 128--159. In addition to this, Wget in Windows mode uses + instead of : to separate host and port in local file names, and uses @ instead of ? to separate the query portion of the file name from the rest. Therefore, a URL that would be saved as www.xemacs.org:4300/search.pl?input=blah in Unix mode would be saved as www.xemacs.org+4300/search.pl@input=blah in Windows mode. This mode is the default on Windows. If you specify nocontrol, then the escaping of the control characters is also switched off. This option may make sense when you are downloading URLs whose names contain UTF-8 characters, on a system which can save and display filenames in UTF-8 (some possible byte values used in UTF-8 byte sequences fall in the range of values designated by Wget as \"controls\"). The ascii mode is used to specify that any bytes whose values are outside the range of ASCII characters (that is, greater than 127) shall be escaped. This can be useful when saving filenames whose encoding does not match the one used locally. -4 --inet4-only -6 --inet6-only Force connecting to IPv4 or IPv6 addresses. With --inet4-only or -4, Wget will only connect to IPv4 hosts, ignoring AAAA records in DNS, and refusing to connect to IPv6 addresses specified in URLs. Conversely, with --inet6-only or -6, Wget will only connect to IPv6 hosts and ignore A records and IPv4 addresses. Neither options should be needed normally. By default, an IPv6-aware Wget will use the address family specified by the host's DNS record. If the DNS responds with both IPv4 and IPv6 addresses, Wget will try them in sequence until it finds one it can connect to. (Also see \"--prefer-family\" option described below.) These options can be used to deliberately force the use of IPv4 or IPv6 address families on dual family systems, usually to aid debugging or to deal with broken network configuration. Only one of --inet6-only and --inet4-only may be specified at the same time. Neither option is available in Wget compiled without IPv6 support. --prefer-family=none/IPv4/IPv6 When given a choice of several addresses, connect to the addresses with specified address family first. The address order returned by DNS is used without change by default. This avoids spurious errors and connect attempts when accessing hosts that resolve to both IPv6 and IPv4 addresses from IPv4 networks. For example, www.kame.net resolves to 2001:200:0:8002:203:47ff:fea5:3085 and to 203.178.141.194. When the preferred family is \"IPv4\", the IPv4 address is used first; when the preferred family is \"IPv6\", the IPv6 address is used first; if the specified value is \"none\", the address order returned by DNS is used without change. Unlike -4 and -6, this option doesn't inhibit access to any address family, it only changes the order in which the addresses are accessed. Also note that the reordering performed by this option is stable---it doesn't affect order of addresses of the same family. That is, the relative order of all IPv4 addresses and of all IPv6 addresses remains intact in all cases. --retry-connrefused Consider \"connection refused\" a transient error and try again. Normally Wget gives up on a URL when it is unable to connect to the site because failure to connect is taken as a sign that the server is not running at all and that retries would not help. This option is for mirroring unreliable sites whose servers tend to disappear for short periods of time. --user=user --password=password Specify the username user and password password for both FTP and HTTP file retrieval. These parameters can be overridden using the --ftp-user and --ftp-password options for FTP connections and the --http-user and --http-password options for HTTP connections. --ask-password Prompt for a password for each connection established. Cannot be specified when --password is being used, because they are mutually exclusive. --use-askpass=command Prompt for a user and password using the specified command. If no command is specified then the command in the environment variable WGET_ASKPASS is used. If WGET_ASKPASS is not set then the command in the environment variable SSH_ASKPASS is used. You can set the default command for use-askpass in the .wgetrc. That setting may be overridden from the command line. --no-iri Turn off internationalized URI (IRI) support. Use --iri to turn it on. IRI support is activated by default. You can set the default state of IRI support using the \"iri\" command in .wgetrc. That setting may be overridden from the command line. --local-encoding=encoding Force Wget to use encoding as the default system encoding. That affects how Wget converts URLs specified as arguments from locale to UTF-8 for IRI support. Wget use the function nl_langinfo() and then the \"CHARSET\" environment variable to get the locale. If it fails, ASCII is used. You can set the default local encoding using the \"local_encoding\" command in .wgetrc. That setting may be overridden from the command line. --remote-encoding=encoding Force Wget to use encoding as the default remote server encoding. That affects how Wget converts URIs found in files from remote encoding to UTF-8 during a recursive fetch. This options is only useful for IRI support, for the interpretation of non-ASCII characters. For HTTP, remote encoding can be found in HTTP \"Content-Type\" header and in HTML \"Content-Type http-equiv\" meta tag. You can set the default encoding using the \"remoteencoding\" command in .wgetrc. That setting may be overridden from the command line. --unlink Force Wget to unlink file instead of clobbering existing file. This option is useful for downloading to the directory with hardlinks. Directory Options -nd --no-directories Do not create a hierarchy of directories when retrieving recursively. With this option turned on, all files will get saved to the current directory, without clobbering (if a name shows up more than once, the filenames will get extensions .n). -x --force-directories The opposite of -nd---create a hierarchy of directories, even if one would not have been created otherwise. E.g. wget -x http://fly.srk.fer.hr/robots.txt will save the downloaded file to fly.srk.fer.hr/robots.txt. -nH --no-host-directories Disable generation of host-prefixed directories. By default, invoking Wget with -r http://fly.srk.fer.hr/ will create a structure of directories beginning with fly.srk.fer.hr/. This option disables such behavior. --protocol-directories Use the protocol name as a directory component of local file names. For example, with this option, wget -r http://host will save to http/host/... rather than just to host/.... --cut-dirs=number Ignore number directory components. This is useful for getting a fine-grained control over the directory where recursive retrieval will be saved. Take, for example, the directory at ftp://ftp.xemacs.org/pub/xemacs/. If you retrieve it with -r, it will be saved locally under ftp.xemacs.org/pub/xemacs/. While the -nH option can remove the ftp.xemacs.org/ part, you are still stuck with pub/xemacs. This is where --cut-dirs comes in handy; it makes Wget not \"see\" number remote directory components. Here are several examples of how --cut-dirs option works. No options -> ftp.xemacs.org/pub/xemacs/ -nH -> pub/xemacs/ -nH --cut-dirs=1 -> xemacs/ -nH --cut-dirs=2 -> . --cut-dirs=1 -> ftp.xemacs.org/xemacs/ ... If you just want to get rid of the directory structure, this option is similar to a combination of -nd and -P. However, unlike -nd, --cut-dirs does not lose with subdirectories---for instance, with -nH --cut-dirs=1, a beta/ subdirectory will be placed to xemacs/beta, as one would expect. -P prefix --directory-prefix=prefix Set directory prefix to prefix. The directory prefix is the directory where all other files and subdirectories will be saved to, i.e. the top of the retrieval tree. The default is . (the current directory). HTTP Options --default-page=name Use name as the default file name when it isn't known (i.e., for URLs that end in a slash), instead of index.html. -E --adjust-extension If a file of type application/xhtml+xml or text/html is downloaded and the URL does not end with the regexp \\.[Hh][Tt][Mm][Ll]?, this option will cause the suffix .html to be appended to the local filename. This is useful, for instance, when you're mirroring a remote site that uses .asp pages, but you want the mirrored pages to be viewable on your stock Apache server. Another good use for this is when you're downloading CGI-generated materials. A URL like http://site.com/article.cgi?25 will be saved as article.cgi?25.html. Note that filenames changed in this way will be re-downloaded every time you re-mirror a site, because Wget can't tell that the local X.html file corresponds to remote URL X (since it doesn't yet know that the URL produces output of type text/html or application/xhtml+xml. As of version 1.12, Wget will also ensure that any downloaded files of type text/css end in the suffix .css, and the option was renamed from --html-extension, to better reflect its new behavior. The old option name is still acceptable, but should now be considered deprecated. As of version 1.19.2, Wget will also ensure that any downloaded files with a \"Content-Encoding\" of br, compress, deflate or gzip end in the suffix .br, .Z, .zlib and .gz respectively. At some point in the future, this option may well be expanded to include suffixes for other types of content, including content types that are not parsed by Wget. --http-user=user --http-password=password Specify the username user and password password on an HTTP server. According to the type of the challenge, Wget will encode them using either the \"basic\" (insecure), the \"digest\", or the Windows \"NTLM\" authentication scheme. Another way to specify username and password is in the URL itself. Either method reveals your password to anyone who bothers to run \"ps\". To prevent the passwords from being seen, use the --use-askpass or store them in .wgetrc or .netrc, and make sure to protect those files from other users with \"chmod\". If the passwords are really important, do not leave them lying in those files either---edit the files and delete them after Wget has started the download. --no-http-keep-alive Turn off the \"keep-alive\" feature for HTTP downloads. Normally, Wget asks the server to keep the connection open so that, when you download more than one document from the same server, they get transferred over the same TCP connection. This saves time and at the same time reduces the load on the server. This option is useful when, for some reason, persistent (keep-alive) connections don't work for you, for example due to a server bug or due to the inability of server-side scripts to cope with the connections. --no-cache Disable server-side cache. In this case, Wget will send the remote server appropriate directives (Cache-Control: no-cache and Pragma: no-cache) to get the file from the remote service, rather than returning the cached version. This is especially useful for retrieving and flushing out-of-date documents on proxy servers. Caching is allowed by default. --no-cookies Disable the use of cookies. Cookies are a mechanism for maintaining server-side state. The server sends the client a cookie using the \"Set-Cookie\" header, and the client responds with the same cookie upon further requests. Since cookies allow the server owners to keep track of visitors and for sites to exchange this information, some consider them a breach of privacy. The default is to use cookies; however, storing cookies is not on by default. --load-cookies file Load cookies from file before the first HTTP retrieval. file is a textual file in the format originally used by Netscape's cookies.txt file. You will typically use this option when mirroring sites that require that you be logged in to access some or all of their content. The login process typically works by the web server issuing an HTTP cookie upon receiving and verifying your credentials. The cookie is then resent by the browser when accessing that part of the site, and so proves your identity. Mirroring such a site requires Wget to send the same cookies your browser sends when communicating with the site. This is achieved by --load-cookies---simply point Wget to the location of the cookies.txt file, and it will send the same cookies your browser would send in the same situation. Different browsers keep textual cookie files in different locations: \"Netscape 4.x.\" The cookies are in ~/.netscape/cookies.txt. \"Mozilla and Netscape 6.x.\" Mozilla's cookie file is also named cookies.txt, located somewhere under ~/.mozilla, in the directory of your profile. The full path usually ends up looking somewhat like ~/.mozilla/default/some-weird-string/cookies.txt. \"Internet Explorer.\" You can produce a cookie file Wget can use by using the File menu, Import and Export, Export Cookies. This has been tested with Internet Explorer 5; it is not guaranteed to work with earlier versions. \"Other browsers.\" If you are using a different browser to create your cookies, --load-cookies will only work if you can locate or produce a cookie file in the Netscape format that Wget expects. If you cannot use --load-cookies, there might still be an alternative. If your browser supports a \"cookie manager\", you can use it to view the cookies used when accessing the site you're mirroring. Write down the name and value of the cookie, and manually instruct Wget to send those cookies, bypassing the \"official\" cookie support: wget --no-cookies --header \"Cookie: <name>=<value>\" --save-cookies file Save cookies to file before exiting. This will not save cookies that have expired or that have no expiry time (so- called \"session cookies\"), but also see --keep-session-cookies. --keep-session-cookies When specified, causes --save-cookies to also save session cookies. Session cookies are normally not saved because they are meant to be kept in memory and forgotten when you exit the browser. Saving them is useful on sites that require you to log in or to visit the home page before you can access some pages. With this option, multiple Wget runs are considered a single browser session as far as the site is concerned. Since the cookie file format does not normally carry session cookies, Wget marks them with an expiry timestamp of 0. Wget's --load-cookies recognizes those as session cookies, but it might confuse other browsers. Also note that cookies so loaded will be treated as other session cookies, which means that if you want --save-cookies to preserve them again, you must use --keep-session-cookies again. --ignore-length Unfortunately, some HTTP servers (CGI programs, to be more precise) send out bogus \"Content-Length\" headers, which makes Wget go wild, as it thinks not all the document was retrieved. You can spot this syndrome if Wget retries getting the same document again and again, each time claiming that the (otherwise normal) connection has closed on the very same byte. With this option, Wget will ignore the \"Content-Length\" header---as if it never existed. --header=header-line Send header-line along with the rest of the headers in each HTTP request. The supplied header is sent as-is, which means it must contain name and value separated by colon, and must not contain newlines. You may define more than one additional header by specifying --header more than once. wget --header='Accept-Charset: iso-8859-2' \\ --header='Accept-Language: hr' \\ http://fly.srk.fer.hr/ Specification of an empty string as the header value will clear all previous user-defined headers. As of Wget 1.10, this option can be used to override headers otherwise generated automatically. This example instructs Wget to connect to localhost, but to specify foo.bar in the \"Host\" header: wget --header=\"Host: foo.bar\" http://localhost/ In versions of Wget prior to 1.10 such use of --header caused sending of duplicate headers. --compression=type Choose the type of compression to be used. Legal values are auto, gzip and none. If auto or gzip are specified, Wget asks the server to compress the file using the gzip compression format. If the server compresses the file and responds with the \"Content-Encoding\" header field set appropriately, the file will be decompressed automatically. If none is specified, wget will not ask the server to compress the file and will not decompress any server responses. This is the default. Compression support is currently experimental. In case it is turned on, please report any bugs to \"bug-wget@gnu.org\". --max-redirect=number Specifies the maximum number of redirections to follow for a resource. The default is 20, which is usually far more than necessary. However, on those occasions where you want to allow more (or fewer), this is the option to use. --proxy-user=user --proxy-password=password Specify the username user and password password for authentication on a proxy server. Wget will encode them using the \"basic\" authentication scheme. Security considerations similar to those with --http-password pertain here as well. --referer=url Include `Referer: url' header in HTTP request. Useful for retrieving documents with server-side processing that assume they are always being retrieved by interactive web browsers and only come out properly when Referer is set to one of the pages that point to them. --save-headers Save the headers sent by the HTTP server to the file, preceding the actual contents, with an empty line as the separator. -U agent-string --user-agent=agent-string Identify as agent-string to the HTTP server. The HTTP protocol allows the clients to identify themselves using a \"User-Agent\" header field. This enables distinguishing the WWW software, usually for statistical purposes or for tracing of protocol violations. Wget normally identifies as Wget/version, version being the current version number of Wget. However, some sites have been known to impose the policy of tailoring the output according to the \"User-Agent\"-supplied information. While this is not such a bad idea in theory, it has been abused by servers denying information to clients other than (historically) Netscape or, more frequently, Microsoft Internet Explorer. This option allows you to change the \"User-Agent\" line issued by Wget. Use of this option is discouraged, unless you really know what you are doing. Specifying empty user agent with --user-agent=\"\" instructs Wget not to send the \"User-Agent\" header in HTTP requests. --post-data=string --post-file=file Use POST as the method for all HTTP requests and send the specified data in the request body. --post-data sends string as data, whereas --post-file sends the contents of file. Other than that, they work in exactly the same way. In particular, they both expect content of the form \"key1=value1&key2=value2\", with percent-encoding for special characters; the only difference is that one expects its content as a command-line parameter and the other accepts its content from a file. In particular, --post-file is not for transmitting files as form attachments: those must appear as \"key=value\" data (with appropriate percent-coding) just like everything else. Wget does not currently support \"multipart/form-data\" for transmitting POST data; only \"application/x-www-form-urlencoded\". Only one of --post-data and --post-file should be specified. Please note that wget does not require the content to be of the form \"key1=value1&key2=value2\", and neither does it test for it. Wget will simply transmit whatever data is provided to it. Most servers however expect the POST data to be in the above format when processing HTML Forms. When sending a POST request using the --post-file option, Wget treats the file as a binary file and will send every character in the POST request without stripping trailing newline or formfeed characters. Any other control characters in the text will also be sent as-is in the POST request. Please be aware that Wget needs to know the size of the POST data in advance. Therefore the argument to \"--post-file\" must be a regular file; specifying a FIFO or something like /dev/stdin won't work. It's not quite clear how to work around this limitation inherent in HTTP/1.0. Although HTTP/1.1 introduces chunked transfer that doesn't require knowing the request length in advance, a client can't use chunked unless it knows it's talking to an HTTP/1.1 server. And it can't know that until it receives a response, which in turn requires the request to have been completed -- a chicken-and-egg problem. Note: As of version 1.15 if Wget is redirected after the POST request is completed, its behaviour will depend on the response code returned by the server. In case of a 301 Moved Permanently, 302 Moved Temporarily or 307 Temporary Redirect, Wget will, in accordance with RFC2616, continue to send a POST request. In case a server wants the client to change the Request method upon redirection, it should send a 303 See Other response code. This example shows how to log in to a server using POST and then proceed to download the desired pages, presumably only accessible to authorized users: # Log in to the server. This can be done only once. wget --save-cookies cookies.txt \\ --post-data 'user=foo&password=bar' \\ http://example.com/auth.php # Now grab the page or pages we care about. wget --load-cookies cookies.txt \\ -p http://example.com/interesting/article.php If the server is using session cookies to track user authentication, the above will not work because --save-cookies will not save them (and neither will browsers) and the cookies.txt file will be empty. In that case use --keep-session-cookies along with --save-cookies to force saving of session cookies. --method=HTTP-Method For the purpose of RESTful scripting, Wget allows sending of other HTTP Methods without the need to explicitly set them using --header=Header-Line. Wget will use whatever string is passed to it after --method as the HTTP Method to the server. --body-data=Data-String --body-file=Data-File Must be set when additional data needs to be sent to the server along with the Method specified using --method. --body-data sends string as data, whereas --body-file sends the contents of file. Other than that, they work in exactly the same way. Currently, --body-file is not for transmitting files as a whole. Wget does not currently support \"multipart/form-data\" for transmitting data; only \"application/x-www-form-urlencoded\". In the future, this may be changed so that wget sends the --body-file as a complete file instead of sending its contents to the server. Please be aware that Wget needs to know the contents of BODY Data in advance, and hence the argument to --body-file should be a regular file. See --post-file for a more detailed explanation. Only one of --body-data and --body-file should be specified. If Wget is redirected after the request is completed, Wget will suspend the current method and send a GET request till the redirection is completed. This is true for all redirection response codes except 307 Temporary Redirect which is used to explicitly specify that the request method should not change. Another exception is when the method is set to \"POST\", in which case the redirection rules specified under --post-data are followed. --content-disposition If this is set to on, experimental (not fully-functional) support for \"Content-Disposition\" headers is enabled. This can currently result in extra round-trips to the server for a \"HEAD\" request, and is known to suffer from a few bugs, which is why it is not currently enabled by default. This option is useful for some file-downloading CGI programs that use \"Content-Disposition\" headers to describe what the name of a downloaded file should be. When combined with --metalink-over-http and --trust-server-names, a Content-Type: application/metalink4+xml file is named using the \"Content-Disposition\" filename field, if available. --content-on-error If this is set to on, wget will not skip the content when the server responds with a http status code that indicates error. --trust-server-names If this is set, on a redirect, the local file name will be based on the redirection URL. By default the local file name is based on the original URL. When doing recursive retrieving this can be helpful because in many web sites redirected URLs correspond to an underlying file structure, while link URLs do not. --auth-no-challenge If this option is given, Wget will send Basic HTTP authentication information (plaintext username and password) for all requests, just like Wget 1.10.2 and prior did by default. Use of this option is not recommended, and is intended only to support some few obscure servers, which never send HTTP authentication challenges, but accept unsolicited auth info, say, in addition to form-based authentication. --retry-on-host-error Consider host errors, such as \"Temporary failure in name resolution\", as non-fatal, transient errors. --retry-on-http-error=code[,code,...] Consider given HTTP response codes as non-fatal, transient errors. Supply a comma-separated list of 3-digit HTTP response codes as argument. Useful to work around special circumstances where retries are required, but the server responds with an error code normally not retried by Wget. Such errors might be 503 (Service Unavailable) and 429 (Too Many Requests). Retries enabled by this option are performed subject to the normal retry timing and retry count limitations of Wget. Using this option is intended to support special use cases only and is generally not recommended, as it can force retries even in cases where the server is actually trying to decrease its load. Please use wisely and only if you know what you are doing. HTTPS (SSL/TLS) Options To support encrypted HTTP (HTTPS) downloads, Wget must be compiled with an external SSL library. The current default is GnuTLS. In addition, Wget also supports HSTS (HTTP Strict Transport Security). If Wget is compiled without SSL support, none of these options are available. --secure-protocol=protocol Choose the secure protocol to be used. Legal values are auto, SSLv2, SSLv3, TLSv1, TLSv1_1, TLSv1_2, TLSv1_3 and PFS. If auto is used, the SSL library is given the liberty of choosing the appropriate protocol automatically, which is achieved by sending a TLSv1 greeting. This is the default. Specifying SSLv2, SSLv3, TLSv1, TLSv1_1, TLSv1_2 or TLSv1_3 forces the use of the corresponding protocol. This is useful when talking to old and buggy SSL server implementations that make it hard for the underlying SSL library to choose the correct protocol version. Fortunately, such servers are quite rare. Specifying PFS enforces the use of the so-called Perfect Forward Security cipher suites. In short, PFS adds security by creating a one-time key for each SSL connection. It has a bit more CPU impact on client and server. We use known to be secure ciphers (e.g. no MD4) and the TLS protocol. This mode also explicitly excludes non-PFS key exchange methods, such as RSA. --https-only When in recursive mode, only HTTPS links are followed. --ciphers Set the cipher list string. Typically this string sets the cipher suites and other SSL/TLS options that the user wish should be used, in a set order of preference (GnuTLS calls it 'priority string'). This string will be fed verbatim to the SSL/TLS engine (OpenSSL or GnuTLS) and hence its format and syntax is dependent on that. Wget will not process or manipulate it in any way. Refer to the OpenSSL or GnuTLS documentation for more information. --no-check-certificate Don't check the server certificate against the available certificate authorities. Also don't require the URL host name to match the common name presented by the certificate. As of Wget 1.10, the default is to verify the server's certificate against the recognized certificate authorities, breaking the SSL handshake and aborting the download if the verification fails. Although this provides more secure downloads, it does break interoperability with some sites that worked with previous Wget versions, particularly those using self-signed, expired, or otherwise invalid certificates. This option forces an \"insecure\" mode of operation that turns the certificate verification errors into warnings and allows you to proceed. If you encounter \"certificate verification\" errors or ones saying that \"common name doesn't match requested host name\", you can use this option to bypass the verification and proceed with the download. Only use this option if you are otherwise convinced of the site's authenticity, or if you really don't care about the validity of its certificate. It is almost always a bad idea not to check the certificates when transmitting confidential or important data. For self-signed/internal certificates, you should download the certificate and verify against that instead of forcing this insecure mode. If you are really sure of not desiring any certificate verification, you can specify --check-certificate=quiet to tell wget to not print any warning about invalid certificates, albeit in most cases this is the wrong thing to do. --certificate=file Use the client certificate stored in file. This is needed for servers that are configured to require certificates from the clients that connect to them. Normally a certificate is not required and this switch is optional. --certificate-type=type Specify the type of the client certificate. Legal values are PEM (assumed by default) and DER, also known as ASN1. --private-key=file Read the private key from file. This allows you to provide the private key in a file separate from the certificate. --private-key-type=type Specify the type of the private key. Accepted values are PEM (the default) and DER. --ca-certificate=file Use file as the file with the bundle of certificate authorities (\"CA\") to verify the peers. The certificates must be in PEM format. Without this option Wget looks for CA certificates at the system-specified locations, chosen at OpenSSL installation time. --ca-directory=directory Specifies directory containing CA certificates in PEM format. Each file contains one CA certificate, and the file name is based on a hash value derived from the certificate. This is achieved by processing a certificate directory with the \"c_rehash\" utility supplied with OpenSSL. Using --ca-directory is more efficient than --ca-certificate when many certificates are installed because it allows Wget to fetch certificates on demand. Without this option Wget looks for CA certificates at the system-specified locations, chosen at OpenSSL installation time. --crl-file=file Specifies a CRL file in file. This is needed for certificates that have been revocated by the CAs. --pinnedpubkey=file/hashes Tells wget to use the specified public key file (or hashes) to verify the peer. This can be a path to a file which contains a single public key in PEM or DER format, or any number of base64 encoded sha256 hashes preceded by \"sha256//\" and separated by \";\" When negotiating a TLS or SSL connection, the server sends a certificate indicating its identity. A public key is extracted from this certificate and if it does not exactly match the public key(s) provided to this option, wget will abort the connection before sending or receiving any data. --random-file=file [OpenSSL and LibreSSL only] Use file as the source of random data for seeding the pseudo-random number generator on systems without /dev/urandom. On such systems the SSL library needs an external source of randomness to initialize. Randomness may be provided by EGD (see --egd-file below) or read from an external source specified by the user. If this option is not specified, Wget looks for random data in $RANDFILE or, if that is unset, in $HOME/.rnd. If you're getting the \"Could not seed OpenSSL PRNG; disabling SSL.\" error, you should provide random data using some of the methods described above. --egd-file=file [OpenSSL only] Use file as the EGD socket. EGD stands for Entropy Gathering Daemon, a user-space program that collects data from various unpredictable system sources and makes it available to other programs that might need it. Encryption software, such as the SSL library, needs sources of non- repeating randomness to seed the random number generator used to produce cryptographically strong keys. OpenSSL allows the user to specify his own source of entropy using the \"RAND_FILE\" environment variable. If this variable is unset, or if the specified file does not produce enough randomness, OpenSSL will read random data from EGD socket specified using this option. If this option is not specified (and the equivalent startup command is not used), EGD is never contacted. EGD is not needed on modern Unix systems that support /dev/urandom. --no-hsts Wget supports HSTS (HTTP Strict Transport Security, RFC 6797) by default. Use --no-hsts to make Wget act as a non-HSTS- compliant UA. As a consequence, Wget would ignore all the \"Strict-Transport-Security\" headers, and would not enforce any existing HSTS policy. --hsts-file=file By default, Wget stores its HSTS database in ~/.wget-hsts. You can use --hsts-file to override this. Wget will use the supplied file as the HSTS database. Such file must conform to the correct HSTS database format used by Wget. If Wget cannot parse the provided file, the behaviour is unspecified. The Wget's HSTS database is a plain text file. Each line contains an HSTS entry (ie. a site that has issued a \"Strict-Transport-Security\" header and that therefore has specified a concrete HSTS policy to be applied). Lines starting with a dash (\"#\") are ignored by Wget. Please note that in spite of this convenient human-readability hand- hacking the HSTS database is generally not a good idea. An HSTS entry line consists of several fields separated by one or more whitespace: \"<hostname> SP [<port>] SP <include subdomains> SP <created> SP <max-age>\" The hostname and port fields indicate the hostname and port to which the given HSTS policy applies. The port field may be zero, and it will, in most of the cases. That means that the port number will not be taken into account when deciding whether such HSTS policy should be applied on a given request (only the hostname will be evaluated). When port is different to zero, both the target hostname and the port will be evaluated and the HSTS policy will only be applied if both of them match. This feature has been included for testing/development purposes only. The Wget testsuite (in testenv/) creates HSTS databases with explicit ports with the purpose of ensuring Wget's correct behaviour. Applying HSTS policies to ports other than the default ones is discouraged by RFC 6797 (see Appendix B \"Differences between HSTS Policy and Same-Origin Policy\"). Thus, this functionality should not be used in production environments and port will typically be zero. The last three fields do what they are expected to. The field include_subdomains can either be 1 or 0 and it signals whether the subdomains of the target domain should be part of the given HSTS policy as well. The created and max-age fields hold the timestamp values of when such entry was created (first seen by Wget) and the HSTS-defined value 'max-age', which states how long should that HSTS policy remain active, measured in seconds elapsed since the timestamp stored in created. Once that time has passed, that HSTS policy will no longer be valid and will eventually be removed from the database. If you supply your own HSTS database via --hsts-file, be aware that Wget may modify the provided file if any change occurs between the HSTS policies requested by the remote servers and those in the file. When Wget exits, it effectively updates the HSTS database by rewriting the database file with the new entries. If the supplied file does not exist, Wget will create one. This file will contain the new HSTS entries. If no HSTS entries were generated (no \"Strict-Transport-Security\" headers were sent by any of the servers) then no file will be created, not even an empty one. This behaviour applies to the default database file (~/.wget-hsts) as well: it will not be created until some server enforces an HSTS policy. Care is taken not to override possible changes made by other Wget processes at the same time over the HSTS database. Before dumping the updated HSTS entries on the file, Wget will re-read it and merge the changes. Using a custom HSTS database and/or modifying an existing one is discouraged. For more information about the potential security threats arose from such practice, see section 14 \"Security Considerations\" of RFC 6797, specially section 14.9 \"Creative Manipulation of HSTS Policy Store\". --warc-file=file Use file as the destination WARC file. --warc-header=string Use string into as the warcinfo record. --warc-max-size=size Set the maximum size of the WARC files to size. --warc-cdx Write CDX index files. --warc-dedup=file Do not store records listed in this CDX file. --no-warc-compression Do not compress WARC files with GZIP. --no-warc-digests Do not calculate SHA1 digests. --no-warc-keep-log Do not store the log file in a WARC record. --warc-tempdir=dir Specify the location for temporary files created by the WARC writer. FTP Options --ftp-user=user --ftp-password=password Specify the username user and password password on an FTP server. Without this, or the corresponding startup option, the password defaults to -wget@, normally used for anonymous FTP. Another way to specify username and password is in the URL itself. Either method reveals your password to anyone who bothers to run \"ps\". To prevent the passwords from being seen, store them in .wgetrc or .netrc, and make sure to protect those files from other users with \"chmod\". If the passwords are really important, do not leave them lying in those files either---edit the files and delete them after Wget has started the download. --no-remove-listing Don't remove the temporary .listing files generated by FTP retrievals. Normally, these files contain the raw directory listings received from FTP servers. Not removing them can be useful for debugging purposes, or when you want to be able to easily check on the contents of remote server directories (e.g. to verify that a mirror you're running is complete). Note that even though Wget writes to a known filename for this file, this is not a security hole in the scenario of a user making .listing a symbolic link to /etc/passwd or something and asking \"root\" to run Wget in his or her directory. Depending on the options used, either Wget will refuse to write to .listing, making the globbing/recursion/time-stamping operation fail, or the symbolic link will be deleted and replaced with the actual .listing file, or the listing will be written to a .listing.number file. Even though this situation isn't a problem, though, \"root\" should never run Wget in a non-trusted user's directory. A user could do something as simple as linking index.html to /etc/passwd and asking \"root\" to run Wget with -N or -r so the file will be overwritten. --no-glob Turn off FTP globbing. Globbing refers to the use of shell- like special characters (wildcards), like *, ?, [ and ] to retrieve more than one file from the same directory at once, like: wget ftp://gnjilux.srk.fer.hr/*.msg By default, globbing will be turned on if the URL contains a globbing character. This option may be used to turn globbing on or off permanently. You may have to quote the URL to protect it from being expanded by your shell. Globbing makes Wget look for a directory listing, which is system-specific. This is why it currently works only with Unix FTP servers (and the ones emulating Unix \"ls\" output). --no-passive-ftp Disable the use of the passive FTP transfer mode. Passive FTP mandates that the client connect to the server to establish the data connection rather than the other way around. If the machine is connected to the Internet directly, both passive and active FTP should work equally well. Behind most firewall and NAT configurations passive FTP has a better chance of working. However, in some rare firewall configurations, active FTP actually works when passive FTP doesn't. If you suspect this to be the case, use this option, or set \"passive_ftp=off\" in your init file. --preserve-permissions Preserve remote file permissions instead of permissions set by umask. --retr-symlinks By default, when retrieving FTP directories recursively and a symbolic link is encountered, the symbolic link is traversed and the pointed-to files are retrieved. Currently, Wget does not traverse symbolic links to directories to download them recursively, though this feature may be added in the future. When --retr-symlinks=no is specified, the linked-to file is not downloaded. Instead, a matching symbolic link is created on the local file system. The pointed-to file will not be retrieved unless this recursive retrieval would have encountered it separately and downloaded it anyway. This option poses a security risk where a malicious FTP Server may cause Wget to write to files outside of the intended directories through a specially crafted .LISTING file. Note that when retrieving a file (not a directory) because it was specified on the command-line, rather than because it was recursed to, this option has no effect. Symbolic links are always traversed in this case. FTPS Options --ftps-implicit This option tells Wget to use FTPS implicitly. Implicit FTPS consists of initializing SSL/TLS from the very beginning of the control connection. This option does not send an \"AUTH TLS\" command: it assumes the server speaks FTPS and directly starts an SSL/TLS connection. If the attempt is successful, the session continues just like regular FTPS (\"PBSZ\" and \"PROT\" are sent, etc.). Implicit FTPS is no longer a requirement for FTPS implementations, and thus many servers may not support it. If --ftps-implicit is passed and no explicit port number specified, the default port for implicit FTPS, 990, will be used, instead of the default port for the \"normal\" (explicit) FTPS which is the same as that of FTP, 21. --no-ftps-resume-ssl Do not resume the SSL/TLS session in the data channel. When starting a data connection, Wget tries to resume the SSL/TLS session previously started in the control connection. SSL/TLS session resumption avoids performing an entirely new handshake by reusing the SSL/TLS parameters of a previous session. Typically, the FTPS servers want it that way, so Wget does this by default. Under rare circumstances however, one might want to start an entirely new SSL/TLS session in every data connection. This is what --no-ftps-resume-ssl is for. --ftps-clear-data-connection All the data connections will be in plain text. Only the control connection will be under SSL/TLS. Wget will send a \"PROT C\" command to achieve this, which must be approved by the server. --ftps-fallback-to-ftp Fall back to FTP if FTPS is not supported by the target server. For security reasons, this option is not asserted by default. The default behaviour is to exit with an error. If a server does not successfully reply to the initial \"AUTH TLS\" command, or in the case of implicit FTPS, if the initial SSL/TLS connection attempt is rejected, it is considered that such server does not support FTPS. Recursive Retrieval Options -r --recursive Turn on recursive retrieving. The default maximum depth is 5. -l depth --level=depth Set the maximum number of subdirectories that Wget will recurse into to depth. In order to prevent one from accidentally downloading very large websites when using recursion this is limited to a depth of 5 by default, i.e., it will traverse at most 5 directories deep starting from the provided URL. Set -l 0 or -l inf for infinite recursion depth. wget -r -l 0 http://<site>/1.html Ideally, one would expect this to download just 1.html. but unfortunately this is not the case, because -l 0 is equivalent to -l inf---that is, infinite recursion. To download a single HTML page (or a handful of them), specify them all on the command line and leave away -r and -l. To download the essential items to view a single HTML page, see page requisites. --delete-after This option tells Wget to delete every single file it downloads, after having done so. It is useful for pre- fetching popular pages through a proxy, e.g.: wget -r -nd --delete-after http://whatever.com/~popular/page/ The -r option is to retrieve recursively, and -nd to not create directories. Note that --delete-after deletes files on the local machine. It does not issue the DELE command to remote FTP sites, for instance. Also note that when --delete-after is specified, --convert-links is ignored, so .orig files are simply not created in the first place. -k --convert-links After the download is complete, convert the links in the document to make them suitable for local viewing. This affects not only the visible hyperlinks, but any part of the document that links to external content, such as embedded images, links to style sheets, hyperlinks to non-HTML content, etc. Each link will be changed in one of the two ways: \u2022 The links to files that have been downloaded by Wget will be changed to refer to the file they point to as a relative link. Example: if the downloaded file /foo/doc.html links to /bar/img.gif, also downloaded, then the link in doc.html will be modified to point to ../bar/img.gif. This kind of transformation works reliably for arbitrary combinations of directories. \u2022 The links to files that have not been downloaded by Wget will be changed to include host name and absolute path of the location they point to. Example: if the downloaded file /foo/doc.html links to /bar/img.gif (or to ../bar/img.gif), then the link in doc.html will be modified to point to http://hostname/bar/img.gif . Because of this, local browsing works reliably: if a linked file was downloaded, the link will refer to its local name; if it was not downloaded, the link will refer to its full Internet address rather than presenting a broken link. The fact that the former links are converted to relative links ensures that you can move the downloaded hierarchy to another directory. Note that only at the end of the download can Wget know which links have been downloaded. Because of that, the work done by -k will be performed at the end of all the downloads. --convert-file-only This option converts only the filename part of the URLs, leaving the rest of the URLs untouched. This filename part is sometimes referred to as the \"basename\", although we avoid that term here in order not to cause confusion. It works particularly well in conjunction with --adjust-extension, although this coupling is not enforced. It proves useful to populate Internet caches with files downloaded from different hosts. Example: if some link points to //foo.com/bar.cgi?xyz with --adjust-extension asserted and its local destination is intended to be ./foo.com/bar.cgi?xyz.css, then the link would be converted to //foo.com/bar.cgi?xyz.css. Note that only the filename part has been modified. The rest of the URL has been left untouched, including the net path (\"//\") which would otherwise be processed by Wget and converted to the effective scheme (ie. \"http://\"). -K --backup-converted When converting a file, back up the original version with a .orig suffix. Affects the behavior of -N. -m --mirror Turn on options suitable for mirroring. This option turns on recursion and time-stamping, sets infinite recursion depth and keeps FTP directory listings. It is currently equivalent to -r -N -l inf --no-remove-listing. -p --page-requisites This option causes Wget to download all the files that are necessary to properly display a given HTML page. This includes such things as inlined images, sounds, and referenced stylesheets. Ordinarily, when downloading a single HTML page, any requisite documents that may be needed to display it properly are not downloaded. Using -r together with -l can help, but since Wget does not ordinarily distinguish between external and inlined documents, one is generally left with \"leaf documents\" that are missing their requisites. For instance, say document 1.html contains an \"<IMG>\" tag referencing 1.gif and an \"<A>\" tag pointing to external document 2.html. Say that 2.html is similar but that its image is 2.gif and it links to 3.html. Say this continues up to some arbitrarily high number. If one executes the command: wget -r -l 2 http://<site>/1.html then 1.html, 1.gif, 2.html, 2.gif, and 3.html will be downloaded. As you can see, 3.html is without its requisite 3.gif because Wget is simply counting the number of hops (up to 2) away from 1.html in order to determine where to stop the recursion. However, with this command: wget -r -l 2 -p http://<site>/1.html all the above files and 3.html's requisite 3.gif will be downloaded. Similarly, wget -r -l 1 -p http://<site>/1.html will cause 1.html, 1.gif, 2.html, and 2.gif to be downloaded. One might think that: wget -r -l 0 -p http://<site>/1.html would download just 1.html and 1.gif, but unfortunately this is not the case, because -l 0 is equivalent to -l inf---that is, infinite recursion. To download a single HTML page (or a handful of them, all specified on the command-line or in a -i URL input file) and its (or their) requisites, simply leave off -r and -l: wget -p http://<site>/1.html Note that Wget will behave as if -r had been specified, but only that single page and its requisites will be downloaded. Links from that page to external documents will not be followed. Actually, to download a single page and all its requisites (even if they exist on separate websites), and make sure the lot displays properly locally, this author likes to use a few options in addition to -p: wget -E -H -k -K -p http://<site>/<document> To finish off this topic, it's worth knowing that Wget's idea of an external document link is any URL specified in an \"<A>\" tag, an \"<AREA>\" tag, or a \"<LINK>\" tag other than \"<LINK REL=\"stylesheet\">\". --strict-comments Turn on strict parsing of HTML comments. The default is to terminate comments at the first occurrence of -->. According to specifications, HTML comments are expressed as SGML declarations. Declaration is special markup that begins with <! and ends with >, such as <!DOCTYPE ...>, that may contain comments between a pair of -- delimiters. HTML comments are \"empty declarations\", SGML declarations without any non-comment text. Therefore, <!--foo--> is a valid comment, and so is <!--one-- --two-->, but <!--1--2--> is not. On the other hand, most HTML writers don't perceive comments as anything other than text delimited with <!-- and -->, which is not quite the same. For example, something like <!------------> works as a valid comment as long as the number of dashes is a multiple of four (!). If not, the comment technically lasts until the next --, which may be at the other end of the document. Because of this, many popular browsers completely ignore the specification and implement what users have come to expect: comments delimited with <!-- and -->. Until version 1.9, Wget interpreted comments strictly, which resulted in missing links in many web pages that displayed fine in browsers, but had the misfortune of containing non- compliant comments. Beginning with version 1.9, Wget has joined the ranks of clients that implements \"naive\" comments, terminating each comment at the first occurrence of -->. If, for whatever reason, you want strict comment parsing, use this option to turn it on. Recursive Accept/Reject Options -A acclist --accept acclist -R rejlist --reject rejlist Specify comma-separated lists of file name suffixes or patterns to accept or reject. Note that if any of the wildcard characters, *, ?, [ or ], appear in an element of acclist or rejlist, it will be treated as a pattern, rather than a suffix. In this case, you have to enclose the pattern into quotes to prevent your shell from expanding it, like in -A \"*.mp3\" or -A '*.mp3'. --accept-regex urlregex --reject-regex urlregex Specify a regular expression to accept or reject the complete URL. --regex-type regextype Specify the regular expression type. Possible types are posix or pcre. Note that to be able to use pcre type, wget has to be compiled with libpcre support. -D domain-list --domains=domain-list Set domains to be followed. domain-list is a comma-separated list of domains. Note that it does not turn on -H. --exclude-domains domain-list Specify the domains that are not to be followed. --follow-ftp Follow FTP links from HTML documents. Without this option, Wget will ignore all the FTP links. --follow-tags=list Wget has an internal table of HTML tag / attribute pairs that it considers when looking for linked documents during a recursive retrieval. If a user wants only a subset of those tags to be considered, however, he or she should be specify such tags in a comma-separated list with this option. --ignore-tags=list This is the opposite of the --follow-tags option. To skip certain HTML tags when recursively looking for documents to download, specify them in a comma-separated list. In the past, this option was the best bet for downloading a single page and its requisites, using a command-line like: wget --ignore-tags=a,area -H -k -K -r http://<site>/<document> However, the author of this option came across a page with tags like \"<LINK REL=\"home\" HREF=\"/\">\" and came to the realization that specifying tags to ignore was not enough. One can't just tell Wget to ignore \"<LINK>\", because then stylesheets will not be downloaded. Now the best bet for downloading a single page and its requisites is the dedicated --page-requisites option. --ignore-case Ignore case when matching files and directories. This influences the behavior of -R, -A, -I, and -X options, as well as globbing implemented when downloading from FTP sites. For example, with this option, -A \"*.txt\" will match file1.txt, but also file2.TXT, file3.TxT, and so on. The quotes in the example are to prevent the shell from expanding the pattern. -H --span-hosts Enable spanning across hosts when doing recursive retrieving. -L --relative Follow relative links only. Useful for retrieving a specific home page without any distractions, not even those from the same hosts. -I list --include-directories=list Specify a comma-separated list of directories you wish to follow when downloading. Elements of list may contain wildcards. -X list --exclude-directories=list Specify a comma-separated list of directories you wish to exclude from download. Elements of list may contain wildcards. -np --no-parent Do not ever ascend to the parent directory when retrieving recursively. This is a useful option, since it guarantees that only the files below a certain hierarchy will be downloaded. "
  },
  {
    "command": "systemd-mount",
    "description": " systemd-mount may be used to create and start a transient .mount or .automount unit of the file system WHAT on the mount point WHERE. In many ways, systemd-mount is similar to the lower-level mount(8) command, however instead of executing the mount operation directly and immediately, systemd-mount schedules it through the service manager job queue, so that it may pull in further dependencies (such as parent mounts, or a file system checker to execute a priori), and may make use of the auto-mounting logic. The command takes either one or two arguments. If only one argument is specified it should refer to a block device or regular file containing a file system (e.g. \"/dev/sdb1\" or \"/path/to/disk.img\"). The block device or image file is then probed for a file system label and other metadata, and is mounted to a directory below /run/media/system/ whose name is generated from the file system label. In this mode the block device or image file must exist at the time of invocation of the command, so that it may be probed. If the device is found to be a removable block device (e.g. a USB stick), an automount point is created instead of a regular mount point (i.e. the --automount= option is implied, see below). If two arguments are specified, the first indicates the mount source (the WHAT) and the second indicates the path to mount it on (the WHERE). In this mode no probing of the source is attempted, and a backing device node doesn't have to exist. However, if this mode is combined with --discover, device node probing for additional metadata is enabled, and \u2013 much like in the single-argument case discussed above \u2013 the specified device has to exist at the time of invocation of the command. Use the --list command to show a terse table of all local, known block devices with file systems that may be mounted with this command. systemd-umount can be used to unmount a mount or automount point. It is the same as systemd-mount --umount. The following options are understood: --no-block Do not synchronously wait for the requested operation to finish. If this is not specified, the job will be verified, enqueued and systemd-mount will wait until the mount or automount unit's start-up is completed. By passing this argument, it is only verified and enqueued. -l, --full Do not ellipsize the output when --list is specified. --no-pager Do not pipe output into a pager. --no-legend Do not print the legend, i.e. column headers and the footer with hints. --no-ask-password Do not query the user for authentication for privileged operations. --quiet, -q Suppresses additional informational output while running. --discover Enable probing of the mount source. This switch is implied if a single argument is specified on the command line. If passed, additional metadata is read from the device to enhance the unit to create. For example, a descriptive string for the transient units is generated from the file system label and device model. Moreover if a removable block device (e.g. USB stick) is detected an automount unit instead of a regular mount unit is created, with a short idle timeout, in order to ensure the file-system is placed in a clean state quickly after each access. --type=, -t Specifies the file system type to mount (e.g. \"vfat\" or \"ext4\"). If omitted or set to \"auto\", the file system type is determined automatically. --options=, -o Additional mount options for the mount point. --owner=USER Let the specified user USER own the mounted file system. This is done by appending uid= and gid= options to the list of mount options. Only certain file systems support this option. --fsck= Takes a boolean argument, defaults to on. Controls whether to run a file system check immediately before the mount operation. In the automount case (see --automount= below) the check will be run the moment the first access to the device is made, which might slightly delay the access. --description= Provide a description for the mount or automount unit. See Description= in systemd.unit(5). --property=, -p Sets a unit property for the mount unit that is created. This takes an assignment in the same format as systemctl(1)'s set-property command. --automount= Takes a boolean argument. Controls whether to create an automount point or a regular mount point. If true an automount point is created that is backed by the actual file system at the time of first access. If false a plain mount point is created that is backed by the actual file system immediately. Automount points have the benefit that the file system stays unmounted and hence in clean state until it is first accessed. In automount mode the --timeout-idle-sec= switch (see below) may be used to ensure the mount point is unmounted automatically after the last access and an idle period passed. If this switch is not specified it defaults to false. If not specified and --discover is used (or only a single argument passed, which implies --discover, see above), and the file system block device is detected to be removable, it is set to true, in order to increase the chance that the file system is in a fully clean state if the device is unplugged abruptly. -A Equivalent to --automount=yes. --timeout-idle-sec= Takes a time value that controls the idle timeout in automount mode. If set to \"infinity\" (the default) no automatic unmounts are done. Otherwise the file system backing the automount point is detached after the last access and the idle timeout passed. See systemd.time(7) for details on the time syntax supported. This option has no effect if only a regular mount is established, and automounting is not used. Note that if --discover is used (or only a single argument passed, which implies --discover, see above), and the file system block device is detected to be removable, --timeout-idle-sec=1s is implied. --automount-property= Similar to --property=, but applies additional properties to the automount unit created, instead of the mount unit. --bind-device This option only has an effect in automount mode, and controls whether the automount unit shall be bound to the backing device's lifetime. If set, the automount unit will be stopped automatically when the backing device vanishes. By default the automount unit stays around, and subsequent accesses will block until backing device is replugged. This option has no effect in case of non-device mounts, such as network or virtual file system mounts. Note that if --discover is used (or only a single argument passed, which implies --discover, see above), and the file system block device is detected to be removable, this option is implied. --list Instead of establishing a mount or automount point, print a terse list of block devices containing file systems that may be mounted with \"systemd-mount\", along with useful metadata such as labels, etc. -u, --umount Stop the mount and automount units corresponding to the specified mount points WHERE or the devices WHAT. systemd-mount with this option or systemd-umount can take multiple arguments which can be mount points, devices, /etc/fstab style node names, or backing files corresponding to loop devices, like systemd-mount --umount /path/to/umount /dev/sda1 UUID=xxxxxx-xxxx LABEL=xxxxx /path/to/disk.img. Note that when -H or -M is specified, only absolute paths to mount points are supported. -G, --collect Unload the transient unit after it completed, even if it failed. Normally, without this option, all mount units that mount and failed are kept in memory until the user explicitly resets their failure state with systemctl reset-failed or an equivalent command. On the other hand, units that stopped successfully are unloaded immediately. If this option is turned on the \"garbage collection\" of units is more aggressive, and unloads units regardless if they exited successfully or failed. This option is a shortcut for --property=CollectMode=inactive-or-failed, see the explanation for CollectMode= in systemd.unit(5) for further information. --user Talk to the service manager of the calling user, rather than the service manager of the system. --system Talk to the service manager of the system. This is the implied default. -H, --host= Execute the operation remotely. Specify a hostname, or a username and hostname separated by \"@\", to connect to. The hostname may optionally be suffixed by a port ssh is listening on, separated by \":\", and then a container name, separated by \"/\", which connects directly to a specific container on the specified host. This will use SSH to talk to the remote machine manager instance. Container names may be enumerated with machinectl -H HOST. Put IPv6 addresses in brackets. -M, --machine= Execute operation on a local container. Specify a container name to connect to, optionally prefixed by a user name to connect as and a separating \"@\" character. If the special string \".host\" is used in place of the container name, a connection to the local system is made (which is useful to connect to a specific user's user bus: \"--user --machine=lennart@.host\"). If the \"@\" syntax is not used, the connection is made as root user. If the \"@\" syntax is used either the left hand side or the right hand side may be omitted (but not both) in which case the local user name and \".host\" are implied. -h, --help Print a short help text and exit. --version Print a short version string and exit. "
  },
  {
    "command": "date",
    "description": " The date utility shall write the date and time to standard output or attempt to set the system date and time. By default, the current date and time shall be written. If an operand beginning with '+' is specified, the output format of date shall be controlled by the conversion specifications and other text in the operand. The date utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following option shall be supported: -u Perform operations as if the TZ environment variable was set to the string \"UTC0\", or its equivalent historical value of \"GMT0\". Otherwise, date shall use the timezone indicated by the TZ environment variable or the system default if that variable is unset or null. "
  },
  {
    "command": "mcookie",
    "description": " mcookie generates a 128-bit random hexadecimal number for use with the X authority system. Typical usage: xauth add :0 . mcookie The \"random\" number generated is actually the MD5 message digest of random information coming from one of the sources getrandom(2) system call, /dev/urandom, /dev/random, or the libc pseudo-random functions, in this preference order. See also the option --file. -f, --file file Use this file as an additional source of randomness (for example /dev/urandom). When file is '-', characters are read from standard input. -m, --max-size number Read from file only this number of bytes. This option is meant to be used when reading additional randomness from a file or device. The number argument may be followed by the multiplicative suffixes KiB=1024, MiB=1024*1024, and so on for GiB, TiB, PiB, EiB, ZiB and YiB (the \"iB\" is optional, e.g., \"K\" has the same meaning as \"KiB\") or the suffixes KB=1000, MB=1000*1000, and so on for GB, TB, PB, EB, ZB and YB. -v, --verbose Inform where randomness originated, with amount of entropy read from each source. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "scriptreplay",
    "description": " This program replays a typescript, using timing information to ensure that output happens in the same rhythm as it originally appeared when the script was recorded. The replay simply displays the information again; the programs that were run when the typescript was being recorded are not run again. Since the same information is simply being displayed, scriptreplay is only guaranteed to work properly if run on the same type of terminal the typescript was recorded on. Otherwise, any escape characters in the typescript may be interpreted differently by the terminal to which scriptreplay is sending its output. The timing information is what script(1) outputs to file specified by --log-timing. By default, the typescript to display is assumed to be named typescript, but other filenames may be specified, as the second parameter or with option --log-out. If the third parameter or --divisor is specified, it is used as a speed-up multiplier. For example, a speed-up of 2 makes scriptreplay go twice as fast, and a speed-down of 0.1 makes it go ten times slower than the original session. -I, --log-in file File containing script's terminal input. -O, --log-out file File containing script's terminal output. -B, --log-io file File containing script's terminal output and input. -t, --timing file File containing script's timing output. This option overrides old-style arguments. -T, --log-timing file This is an alias for -t, maintained for compatibility with script(1) command-line options. -s, --typescript file File containing script's terminal output. Deprecated alias to --log-out. This option overrides old-style arguments. -c, --cr-mode mode Specifies how to use the CR (0x0D, carriage return) character from log files. The default mode is auto, in this case CR is replaced with line break for stdin log, because otherwise scriptreplay would overwrite the same line. The other modes are never and always. -d, --divisor number Speed up the replay displaying this number of times. The argument is a floating-point number. It\u2019s called divisor because it divides the timings by this factor. This option overrides old-style arguments. -m, --maxdelay number Set the maximum delay between updates to number of seconds. The argument is a floating-point number. This can be used to avoid long pauses in the typescript replay. --summary Display details about the session recorded in the specified timing file and exit. The session has to be recorded using advanced format (see script(1) option --logging-format for more details). -x, --stream type Forces scriptreplay to print only the specified stream. The supported stream types are in, out, signal, or info. This option is recommended for multi-stream logs (e.g., --log-io) in order to print only specified data. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "git-repack",
    "description": " This command is used to combine all objects that do not currently reside in a \"pack\", into a pack. It can also be used to re-organize existing packs into a single, more efficient pack. A pack is a collection of objects, individually compressed, with delta compression applied, stored in a single file, with an associated index file. Packs are used to reduce the load on mirror systems, backup engines, disk storage, etc. -a Instead of incrementally packing the unpacked objects, pack everything referenced into a single pack. Especially useful when packing a repository that is used for private development. Use with -d. This will clean up the objects that git prune leaves behind, but git fsck --full --dangling shows as dangling. Note that users fetching over dumb protocols will have to fetch the whole new pack in order to get any contained object, no matter how many other objects in that pack they already have locally. Promisor packfiles are repacked separately: if there are packfiles that have an associated \".promisor\" file, these packfiles will be repacked into another separate pack, and an empty \".promisor\" file corresponding to the new separate pack will be written. -A Same as -a, unless -d is used. Then any unreachable objects in a previous pack become loose, unpacked objects, instead of being left in the old pack. Unreachable objects are never intentionally added to a pack, even when repacking. This option prevents unreachable objects from being immediately deleted by way of being left in the old pack and then removed. Instead, the loose unreachable objects will be pruned according to normal expiry rules with the next git gc invocation. See git-gc(1). -d After packing, if the newly created packs make some existing packs redundant, remove the redundant packs. Also run git prune-packed to remove redundant loose object files. --cruft Same as -a, unless -d is used. Then any unreachable objects are packed into a separate cruft pack. Unreachable objects can be pruned using the normal expiry rules with the next git gc invocation (see git-gc(1)). Incompatible with -k. --cruft-expiration=<approxidate> Expire unreachable objects older than <approxidate> immediately instead of waiting for the next git gc invocation. Only useful with --cruft -d. --expire-to=<dir> Write a cruft pack containing pruned objects (if any) to the directory <dir>. This option is useful for keeping a copy of any pruned objects in a separate directory as a backup. Only useful with --cruft -d. -l Pass the --local option to git pack-objects. See git-pack-objects(1). -f Pass the --no-reuse-delta option to git-pack-objects, see git-pack-objects(1). -F Pass the --no-reuse-object option to git-pack-objects, see git-pack-objects(1). -q, --quiet Show no progress over the standard error stream and pass the -q option to git pack-objects. See git-pack-objects(1). -n Do not update the server information with git update-server-info. This option skips updating local catalog files needed to publish this repository (or a direct copy of it) over HTTP or FTP. See git-update-server-info(1). --window=<n>, --depth=<n> These two options affect how the objects contained in the pack are stored using delta compression. The objects are first internally sorted by type, size and optionally names and compared against the other objects within --window to see if using delta compression saves space. --depth limits the maximum delta depth; making it too deep affects the performance on the unpacker side, because delta data needs to be applied that many times to get to the necessary object. The default value for --window is 10 and --depth is 50. The maximum depth is 4095. --threads=<n> This option is passed through to git pack-objects. --window-memory=<n> This option provides an additional limit on top of --window; the window size will dynamically scale down so as to not take up more than <n> bytes in memory. This is useful in repositories with a mix of large and small objects to not run out of memory with a large window, but still be able to take advantage of the large window for the smaller objects. The size can be suffixed with \"k\", \"m\", or \"g\". --window-memory=0 makes memory usage unlimited. The default is taken from the pack.windowMemory configuration variable. Note that the actual memory usage will be the limit multiplied by the number of threads used by git-pack-objects(1). --max-pack-size=<n> Maximum size of each output pack file. The size can be suffixed with \"k\", \"m\", or \"g\". The minimum size allowed is limited to 1 MiB. If specified, multiple packfiles may be created, which also prevents the creation of a bitmap index. The default is unlimited, unless the config variable pack.packSizeLimit is set. Note that this option may result in a larger and slower repository; see the discussion in pack.packSizeLimit. -b, --write-bitmap-index Write a reachability bitmap index as part of the repack. This only makes sense when used with -a, -A or -m, as the bitmaps must be able to refer to all reachable objects. This option overrides the setting of repack.writeBitmaps. This option has no effect if multiple packfiles are created, unless writing a MIDX (in which case a multi-pack bitmap is created). --pack-kept-objects Include objects in .keep files when repacking. Note that we still do not delete .keep packs after pack-objects finishes. This means that we may duplicate objects, but this makes the option safe to use when there are concurrent pushes or fetches. This option is generally only useful if you are writing bitmaps with -b or repack.writeBitmaps, as it ensures that the bitmapped packfile has the necessary objects. --keep-pack=<pack-name> Exclude the given pack from repacking. This is the equivalent of having .keep file on the pack. <pack-name> is the pack file name without leading directory (e.g. pack-123.pack). The option could be specified multiple times to keep multiple packs. --unpack-unreachable=<when> When loosening unreachable objects, do not bother loosening any objects older than <when>. This can be used to optimize out the write of any objects that would be immediately pruned by a follow-up git prune. -k, --keep-unreachable When used with -ad, any unreachable objects from existing packs will be appended to the end of the packfile instead of being removed. In addition, any unreachable loose objects will be packed (and their loose counterparts removed). -i, --delta-islands Pass the --delta-islands option to git-pack-objects, see git-pack-objects(1). -g=<factor>, --geometric=<factor> Arrange resulting pack structure so that each successive pack contains at least <factor> times the number of objects as the next-largest pack. git repack ensures this by determining a \"cut\" of packfiles that need to be repacked into one in order to ensure a geometric progression. It picks the smallest set of packfiles such that as many of the larger packfiles (by count of objects contained in that pack) may be left intact. Unlike other repack modes, the set of objects to pack is determined uniquely by the set of packs being \"rolled-up\"; in other words, the packs determined to need to be combined in order to restore a geometric progression. When --unpacked is specified, loose objects are implicitly included in this \"roll-up\", without respect to their reachability. This is subject to change in the future. This option (implying a drastically different repack mode) is not guaranteed to work with all other combinations of option to git repack. When writing a multi-pack bitmap, git repack selects the largest resulting pack as the preferred pack for object selection by the MIDX (see git-multi-pack-index(1)). -m, --write-midx Write a multi-pack index (see git-multi-pack-index(1)) containing the non-redundant packs. "
  },
  {
    "command": "rev",
    "description": " The rev utility copies the specified files to standard output, reversing the order of characters in every line. If no files are specified, standard input is read. This utility is a line-oriented tool and it uses in-memory allocated buffer for a whole wide-char line. If the input file is huge and without line breaks then allocating the memory for the file may be unsuccessful. -h, --help Display help text and exit. -V, --version Print version and exit. -0, --zero Zero termination. Use the byte '\\0' as line separator. "
  },
  {
    "command": "logname",
    "description": " The logname utility shall write the user's login name to standard output. The login name shall be the string that would be returned by the getlogin() function defined in the System Interfaces volume of POSIX.1\u20102017. Under the conditions where the getlogin() function would fail, the logname utility shall write a diagnostic message to standard error and exit with a non-zero exit status. None. "
  },
  {
    "command": "true",
    "description": " Exit with a status code indicating success. --help display this help and exit --version output version information and exit NOTE: your shell may have its own version of true, which usually supersedes the version described here. Please refer to your shell's documentation for details about the options it supports. "
  },
  {
    "command": "sed",
    "description": " The sed utility is a stream editor that shall read one or more text files, make editing changes according to a script of editing commands, and write the results to standard output. The script shall be obtained from either the script operand string or a combination of the option-arguments from the -e script and -f script_file options. The sed utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except that the order of presentation of the -e and -f options is significant. The following options shall be supported: -e script Add the editing commands specified by the script option-argument to the end of the script of editing commands. -f script_file Add the editing commands in the file script_file to the end of the script of editing commands. -n Suppress the default output (in which each line, after it is examined for editing, is written to standard output). Only lines explicitly selected for output are written. If any -e or -f options are specified, the script of editing commands shall initially be empty. The commands specified by each -e or -f option shall be added to the script in the order specified. When each addition is made, if the previous addition (if any) was from a -e option, a <newline> shall be inserted before the new addition. The resulting script shall have the same properties as the script operand, described in the OPERANDS section. "
  },
  {
    "command": "lsattr",
    "description": " lsattr lists the file attributes on a second extended file system. See chattr(1) for a description of the attributes and what they mean. -R Recursively list attributes of directories and their contents. -V Display the program version. -a List all files in directories, including files that start with `.'. -d List directories like other files, rather than listing their contents. -l Print the options using long names instead of single character abbreviations. -p List the file's project number. -v List the file's version/generation number. "
  },
  {
    "command": "delta",
    "description": " The delta utility shall be used to permanently introduce into the named SCCS files changes that were made to the files retrieved by get (called the g-files, or generated files). The delta utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except that the -y option has an optional option-argument. This optional option-argument shall not be presented as a separate argument. The following options shall be supported: -r SID Uniquely identify which delta is to be made to the SCCS file. The use of this option shall be necessary only if two or more outstanding get commands for editing (get -e) on the same SCCS file were done by the same person (login name). The SID value specified with the -r option can be either the SID specified on the get command line or the SID to be made as reported by the get utility; see get(1p). -s Suppress the report to standard output of the activity associated with each file. See the STDOUT section. -n Specify retention of the edited g-file (normally removed at completion of delta processing). -g list Specify a list (see get(1p) for the definition of list) of deltas that shall be ignored when the file is accessed at the change level (SID) created by this delta. -m mrlist Specify a modification request (MR) number that the application shall supply as the reason for creating the new delta. This shall be used if the SCCS file has the v flag set; see admin(1p). If -m is not used and '-' is not specified as a file argument, and the standard input is a terminal, the prompt described in the STDOUT section shall be written to standard output before the standard input is read; if the standard input is not a terminal, no prompt shall be issued. MRs in a list shall be separated by <blank> characters or escaped <newline> characters. An unescaped <newline> shall terminate the MR list. The escape character is <backslash>. If the v flag has a value, it shall be taken to be the name of a program which validates the correctness of the MR numbers. If a non-zero exit status is returned from the MR number validation program, the delta utility shall terminate. (It is assumed that the MR numbers were not all valid.) -y[comment] Describe the reason for making the delta. The comment shall be an arbitrary group of lines that would meet the definition of a text file. Implementations shall support comments from zero to 512 bytes and may support longer values. A null string (specified as either -y, -y\"\", or in response to a prompt for a comment) shall be considered a valid comment. If -y is not specified and '-' is not specified as a file argument, and the standard input is a terminal, the prompt described in the STDOUT section shall be written to standard output before the standard input is read; if the standard input is not a terminal, no prompt shall be issued. An unescaped <newline> shall terminate the comment text. The escape character is <backslash>. The -y option shall be required if the file operand is specified as '-'. -p Write (to standard output) the SCCS file differences before and after the delta is applied in diff format; see diff(1p). "
  },
  {
    "command": "git-submodule",
    "description": " Inspects, updates and manages submodules. For more information about submodules, see gitsubmodules(7). -q, --quiet Only print error messages. --progress This option is only valid for add and update commands. Progress status is reported on the standard error stream by default when it is attached to a terminal, unless -q is specified. This flag forces progress status even if the standard error stream is not directed to a terminal. --all This option is only valid for the deinit command. Unregister all submodules in the working tree. -b <branch>, --branch <branch> Branch of repository to add as submodule. The name of the branch is recorded as submodule.<name>.branch in .gitmodules for update --remote. A special value of . is used to indicate that the name of the branch in the submodule should be the same name as the current branch in the current repository. If the option is not specified, it defaults to the remote HEAD. -f, --force This option is only valid for add, deinit and update commands. When running add, allow adding an otherwise ignored submodule path. When running deinit the submodule working trees will be removed even if they contain local changes. When running update (only effective with the checkout procedure), throw away local changes in submodules when switching to a different commit; and always run a checkout operation in the submodule, even if the commit listed in the index of the containing repository matches the commit checked out in the submodule. --cached This option is only valid for status and summary commands. These commands typically use the commit found in the submodule HEAD, but with this option, the commit stored in the index is used instead. --files This option is only valid for the summary command. This command compares the commit in the index with that in the submodule HEAD when this option is used. -n, --summary-limit This option is only valid for the summary command. Limit the summary size (number of commits shown in total). Giving 0 will disable the summary; a negative number means unlimited (the default). This limit only applies to modified submodules. The size is always limited to 1 for added/deleted/typechanged submodules. --remote This option is only valid for the update command. Instead of using the superproject\u2019s recorded SHA-1 to update the submodule, use the status of the submodule\u2019s remote-tracking branch. The remote used is branch\u2019s remote (branch.<name>.remote), defaulting to origin. The remote branch used defaults to the remote HEAD, but the branch name may be overridden by setting the submodule.<name>.branch option in either .gitmodules or .git/config (with .git/config taking precedence). This works for any of the supported update procedures (--checkout, --rebase, etc.). The only change is the source of the target SHA-1. For example, submodule update --remote --merge will merge upstream submodule changes into the submodules, while submodule update --merge will merge superproject gitlink changes into the submodules. In order to ensure a current tracking branch state, update --remote fetches the submodule\u2019s remote repository before calculating the SHA-1. If you don\u2019t want to fetch, you should use submodule update --remote --no-fetch. Use this option to integrate changes from the upstream subproject with your submodule\u2019s current HEAD. Alternatively, you can run git pull from the submodule, which is equivalent except for the remote branch name: update --remote uses the default upstream repository and submodule.<name>.branch, while git pull uses the submodule\u2019s branch.<name>.merge. Prefer submodule.<name>.branch if you want to distribute the default upstream branch with the superproject and branch.<name>.merge if you want a more native feel while working in the submodule itself. -N, --no-fetch This option is only valid for the update command. Don\u2019t fetch new objects from the remote site. --checkout This option is only valid for the update command. Checkout the commit recorded in the superproject on a detached HEAD in the submodule. This is the default behavior, the main use of this option is to override submodule.$name.update when set to a value other than checkout. If the key submodule.$name.update is either not explicitly set or set to checkout, this option is implicit. --merge This option is only valid for the update command. Merge the commit recorded in the superproject into the current branch of the submodule. If this option is given, the submodule\u2019s HEAD will not be detached. If a merge failure prevents this process, you will have to resolve the resulting conflicts within the submodule with the usual conflict resolution tools. If the key submodule.$name.update is set to merge, this option is implicit. --rebase This option is only valid for the update command. Rebase the current branch onto the commit recorded in the superproject. If this option is given, the submodule\u2019s HEAD will not be detached. If a merge failure prevents this process, you will have to resolve these failures with git-rebase(1). If the key submodule.$name.update is set to rebase, this option is implicit. --init This option is only valid for the update command. Initialize all submodules for which \"git submodule init\" has not been called so far before updating. --name This option is only valid for the add command. It sets the submodule\u2019s name to the given string instead of defaulting to its path. The name must be valid as a directory name and may not end with a /. --reference <repository> This option is only valid for add and update commands. These commands sometimes need to clone a remote repository. In this case, this option will be passed to the git-clone(1) command. NOTE: Do not use this option unless you have read the note for git-clone(1)'s --reference, --shared, and --dissociate options carefully. --dissociate This option is only valid for add and update commands. These commands sometimes need to clone a remote repository. In this case, this option will be passed to the git-clone(1) command. NOTE: see the NOTE for the --reference option. --recursive This option is only valid for foreach, update, status and sync commands. Traverse submodules recursively. The operation is performed not only in the submodules of the current repo, but also in any nested submodules inside those submodules (and so on). --depth This option is valid for add and update commands. Create a shallow clone with a history truncated to the specified number of revisions. See git-clone(1) --[no-]recommend-shallow This option is only valid for the update command. The initial clone of a submodule will use the recommended submodule.<name>.shallow as provided by the .gitmodules file by default. To ignore the suggestions use --no-recommend-shallow. -j <n>, --jobs <n> This option is only valid for the update command. Clone new submodules in parallel with as many jobs. Defaults to the submodule.fetchJobs option. --[no-]single-branch This option is only valid for the update command. Clone only one branch during update: HEAD or one specified by --branch. <path>... Paths to submodule(s). When specified this will restrict the command to only operate on the submodules found at the specified paths. (This argument is required with add). "
  },
  {
    "command": "git-send-email",
    "description": " Takes the patches given on the command line and emails them out. Patches can be specified as files, directories (which will send all files in the directory), or directly as a revision list. In the last case, any format accepted by git-format-patch(1) can be passed to git send-email, as well as options understood by git-format-patch(1). The header of the email is configurable via command-line options. If not specified on the command line, the user will be prompted with a ReadLine enabled interface to provide the necessary information. There are two formats accepted for patch files: 1. mbox format files This is what git-format-patch(1) generates. Most headers and MIME formatting are ignored. 2. The original format used by Greg Kroah-Hartman\u2019s send_lots_of_email.pl script This format expects the first line of the file to contain the \"Cc:\" value and the \"Subject:\" of the message as the second line. Composing --annotate Review and edit each patch you\u2019re about to send. Default is the value of sendemail.annotate. See the CONFIGURATION section for sendemail.multiEdit. --bcc=<address>,... Specify a \"Bcc:\" value for each email. Default is the value of sendemail.bcc. This option may be specified multiple times. --cc=<address>,... Specify a starting \"Cc:\" value for each email. Default is the value of sendemail.cc. This option may be specified multiple times. --compose Invoke a text editor (see GIT_EDITOR in git-var(1)) to edit an introductory message for the patch series. When --compose is used, git send-email will use the From, Subject, and In-Reply-To headers specified in the message. If the body of the message (what you type after the headers and a blank line) only contains blank (or Git: prefixed) lines, the summary won\u2019t be sent, but From, Subject, and In-Reply-To headers will be used unless they are removed. Missing From or In-Reply-To headers will be prompted for. See the CONFIGURATION section for sendemail.multiEdit. --from=<address> Specify the sender of the emails. If not specified on the command line, the value of the sendemail.from configuration option is used. If neither the command-line option nor sendemail.from are set, then the user will be prompted for the value. The default for the prompt will be the value of GIT_AUTHOR_IDENT, or GIT_COMMITTER_IDENT if that is not set, as returned by \"git var -l\". --reply-to=<address> Specify the address where replies from recipients should go to. Use this if replies to messages should go to another address than what is specified with the --from parameter. --in-reply-to=<identifier> Make the first mail (or all the mails with --no-thread) appear as a reply to the given Message-ID, which avoids breaking threads to provide a new patch series. The second and subsequent emails will be sent as replies according to the --[no-]chain-reply-to setting. So for example when --thread and --no-chain-reply-to are specified, the second and subsequent patches will be replies to the first one like in the illustration below where [PATCH v2 0/3] is in reply to [PATCH 0/2]: [PATCH 0/2] Here is what I did... [PATCH 1/2] Clean up and tests [PATCH 2/2] Implementation [PATCH v2 0/3] Here is a reroll [PATCH v2 1/3] Clean up [PATCH v2 2/3] New tests [PATCH v2 3/3] Implementation Only necessary if --compose is also set. If --compose is not set, this will be prompted for. --subject=<string> Specify the initial subject of the email thread. Only necessary if --compose is also set. If --compose is not set, this will be prompted for. --to=<address>,... Specify the primary recipient of the emails generated. Generally, this will be the upstream maintainer of the project involved. Default is the value of the sendemail.to configuration value; if that is unspecified, and --to-cmd is not specified, this will be prompted for. This option may be specified multiple times. --8bit-encoding=<encoding> When encountering a non-ASCII message or subject that does not declare its encoding, add headers/quoting to indicate it is encoded in <encoding>. Default is the value of the sendemail.assume8bitEncoding; if that is unspecified, this will be prompted for if any non-ASCII files are encountered. Note that no attempts whatsoever are made to validate the encoding. --compose-encoding=<encoding> Specify encoding of compose message. Default is the value of the sendemail.composeencoding; if that is unspecified, UTF-8 is assumed. --transfer-encoding=(7bit|8bit|quoted-printable|base64|auto) Specify the transfer encoding to be used to send the message over SMTP. 7bit will fail upon encountering a non-ASCII message. quoted-printable can be useful when the repository contains files that contain carriage returns, but makes the raw patch email file (as saved from a MUA) much harder to inspect manually. base64 is even more fool proof, but also even more opaque. auto will use 8bit when possible, and quoted-printable otherwise. Default is the value of the sendemail.transferEncoding configuration value; if that is unspecified, default to auto. --xmailer, --no-xmailer Add (or prevent adding) the \"X-Mailer:\" header. By default, the header is added, but it can be turned off by setting the sendemail.xmailer configuration variable to false. Sending --envelope-sender=<address> Specify the envelope sender used to send the emails. This is useful if your default address is not the address that is subscribed to a list. In order to use the From address, set the value to \"auto\". If you use the sendmail binary, you must have suitable privileges for the -f parameter. Default is the value of the sendemail.envelopeSender configuration variable; if that is unspecified, choosing the envelope sender is left to your MTA. --sendmail-cmd=<command> Specify a command to run to send the email. The command should be sendmail-like; specifically, it must support the -i option. The command will be executed in the shell if necessary. Default is the value of sendemail.sendmailcmd. If unspecified, and if --smtp-server is also unspecified, git-send-email will search for sendmail in /usr/sbin, /usr/lib and $PATH. --smtp-encryption=<encryption> Specify in what way encrypting begins for the SMTP connection. Valid values are ssl and tls. Any other value reverts to plain (unencrypted) SMTP, which defaults to port 25. Despite the names, both values will use the same newer version of TLS, but for historic reasons have these names. ssl refers to \"implicit\" encryption (sometimes called SMTPS), that uses port 465 by default. tls refers to \"explicit\" encryption (often known as STARTTLS), that uses port 25 by default. Other ports might be used by the SMTP server, which are not the default. Commonly found alternative port for tls and unencrypted is 587. You need to check your provider\u2019s documentation or your server configuration to make sure for your own case. Default is the value of sendemail.smtpEncryption. --smtp-domain=<FQDN> Specifies the Fully Qualified Domain Name (FQDN) used in the HELO/EHLO command to the SMTP server. Some servers require the FQDN to match your IP address. If not set, git send-email attempts to determine your FQDN automatically. Default is the value of sendemail.smtpDomain. --smtp-auth=<mechanisms> Whitespace-separated list of allowed SMTP-AUTH mechanisms. This setting forces using only the listed mechanisms. Example: $ git send-email --smtp-auth=\"PLAIN LOGIN GSSAPI\" ... If at least one of the specified mechanisms matches the ones advertised by the SMTP server and if it is supported by the utilized SASL library, the mechanism is used for authentication. If neither sendemail.smtpAuth nor --smtp-auth is specified, all mechanisms supported by the SASL library can be used. The special value none maybe specified to completely disable authentication independently of --smtp-user --smtp-pass[=<password>] Password for SMTP-AUTH. The argument is optional: If no argument is specified, then the empty string is used as the password. Default is the value of sendemail.smtpPass, however --smtp-pass always overrides this value. Furthermore, passwords need not be specified in configuration files or on the command line. If a username has been specified (with --smtp-user or a sendemail.smtpUser), but no password has been specified (with --smtp-pass or sendemail.smtpPass), then a password is obtained using git-credential. --no-smtp-auth Disable SMTP authentication. Short hand for --smtp-auth=none --smtp-server=<host> If set, specifies the outgoing SMTP server to use (e.g. smtp.example.com or a raw IP address). If unspecified, and if --sendmail-cmd is also unspecified, the default is to search for sendmail in /usr/sbin, /usr/lib and $PATH if such a program is available, falling back to localhost otherwise. For backward compatibility, this option can also specify a full pathname of a sendmail-like program instead; the program must support the -i option. This method does not support passing arguments or using plain command names. For those use cases, consider using --sendmail-cmd instead. --smtp-server-port=<port> Specifies a port different from the default port (SMTP servers typically listen to smtp port 25, but may also listen to submission port 587, or the common SSL smtp port 465); symbolic port names (e.g. \"submission\" instead of 587) are also accepted. The port can also be set with the sendemail.smtpServerPort configuration variable. --smtp-server-option=<option> If set, specifies the outgoing SMTP server option to use. Default value can be specified by the sendemail.smtpServerOption configuration option. The --smtp-server-option option must be repeated for each option you want to pass to the server. Likewise, different lines in the configuration files must be used for each option. --smtp-ssl Legacy alias for --smtp-encryption ssl. --smtp-ssl-cert-path Path to a store of trusted CA certificates for SMTP SSL/TLS certificate validation (either a directory that has been processed by c_rehash, or a single file containing one or more PEM format certificates concatenated together: see verify(1) -CAfile and -CApath for more information on these). Set it to an empty string to disable certificate verification. Defaults to the value of the sendemail.smtpsslcertpath configuration variable, if set, or the backing SSL library\u2019s compiled-in default otherwise (which should be the best choice on most platforms). --smtp-user=<user> Username for SMTP-AUTH. Default is the value of sendemail.smtpUser; if a username is not specified (with --smtp-user or sendemail.smtpUser), then authentication is not attempted. --smtp-debug=0|1 Enable (1) or disable (0) debug output. If enabled, SMTP commands and replies will be printed. Useful to debug TLS connection and authentication problems. --batch-size=<num> Some email servers (e.g. smtp.163.com) limit the number emails to be sent per session (connection) and this will lead to a failure when sending many messages. With this option, send-email will disconnect after sending $<num> messages and wait for a few seconds (see --relogin-delay) and reconnect, to work around such a limit. You may want to use some form of credential helper to avoid having to retype your password every time this happens. Defaults to the sendemail.smtpBatchSize configuration variable. --relogin-delay=<int> Waiting $<int> seconds before reconnecting to SMTP server. Used together with --batch-size option. Defaults to the sendemail.smtpReloginDelay configuration variable. Automating --no-[to|cc|bcc] Clears any list of \"To:\", \"Cc:\", \"Bcc:\" addresses previously set via config. --no-identity Clears the previously read value of sendemail.identity set via config, if any. --to-cmd=<command> Specify a command to execute once per patch file which should generate patch file specific \"To:\" entries. Output of this command must be single email address per line. Default is the value of sendemail.tocmd configuration value. --cc-cmd=<command> Specify a command to execute once per patch file which should generate patch file specific \"Cc:\" entries. Output of this command must be single email address per line. Default is the value of sendemail.ccCmd configuration value. --header-cmd=<command> Specify a command that is executed once per outgoing message and output RFC 2822 style header lines to be inserted into them. When the sendemail.headerCmd configuration variable is set, its value is always used. When --header-cmd is provided at the command line, its value takes precedence over the sendemail.headerCmd configuration variable. --no-header-cmd Disable any header command in use. --[no-]chain-reply-to If this is set, each email will be sent as a reply to the previous email sent. If disabled with \"--no-chain-reply-to\", all emails after the first will be sent as replies to the first email sent. When using this, it is recommended that the first file given be an overview of the entire patch series. Disabled by default, but the sendemail.chainReplyTo configuration variable can be used to enable it. --identity=<identity> A configuration identity. When given, causes values in the sendemail.<identity> subsection to take precedence over values in the sendemail section. The default identity is the value of sendemail.identity. --[no-]signed-off-by-cc If this is set, add emails found in the Signed-off-by trailer or Cc: lines to the cc list. Default is the value of sendemail.signedoffbycc configuration value; if that is unspecified, default to --signed-off-by-cc. --[no-]cc-cover If this is set, emails found in Cc: headers in the first patch of the series (typically the cover letter) are added to the cc list for each email set. Default is the value of sendemail.cccover configuration value; if that is unspecified, default to --no-cc-cover. --[no-]to-cover If this is set, emails found in To: headers in the first patch of the series (typically the cover letter) are added to the to list for each email set. Default is the value of sendemail.tocover configuration value; if that is unspecified, default to --no-to-cover. --suppress-cc=<category> Specify an additional category of recipients to suppress the auto-cc of: \u2022 author will avoid including the patch author. \u2022 self will avoid including the sender. \u2022 cc will avoid including anyone mentioned in Cc lines in the patch header except for self (use self for that). \u2022 bodycc will avoid including anyone mentioned in Cc lines in the patch body (commit message) except for self (use self for that). \u2022 sob will avoid including anyone mentioned in the Signed-off-by trailers except for self (use self for that). \u2022 misc-by will avoid including anyone mentioned in Acked-by, Reviewed-by, Tested-by and other \"-by\" lines in the patch body, except Signed-off-by (use sob for that). \u2022 cccmd will avoid running the --cc-cmd. \u2022 body is equivalent to sob + bodycc + misc-by. \u2022 all will suppress all auto cc values. Default is the value of sendemail.suppresscc configuration value; if that is unspecified, default to self if --suppress-from is specified, as well as body if --no-signed-off-cc is specified. --[no-]suppress-from If this is set, do not add the From: address to the cc: list. Default is the value of sendemail.suppressFrom configuration value; if that is unspecified, default to --no-suppress-from. --[no-]thread If this is set, the In-Reply-To and References headers will be added to each email sent. Whether each mail refers to the previous email (deep threading per git format-patch wording) or to the first email (shallow threading) is governed by \"--[no-]chain-reply-to\". If disabled with \"--no-thread\", those headers will not be added (unless specified with --in-reply-to). Default is the value of the sendemail.thread configuration value; if that is unspecified, default to --thread. It is up to the user to ensure that no In-Reply-To header already exists when git send-email is asked to add it (especially note that git format-patch can be configured to do the threading itself). Failure to do so may not produce the expected result in the recipient\u2019s MUA. Administering --confirm=<mode> Confirm just before sending: \u2022 always will always confirm before sending \u2022 never will never confirm before sending \u2022 cc will confirm before sending when send-email has automatically added addresses from the patch to the Cc list \u2022 compose will confirm before sending the first message when using --compose. \u2022 auto is equivalent to cc + compose Default is the value of sendemail.confirm configuration value; if that is unspecified, default to auto unless any of the suppress options have been specified, in which case default to compose. --dry-run Do everything except actually send the emails. --[no-]format-patch When an argument may be understood either as a reference or as a file name, choose to understand it as a format-patch argument (--format-patch) or as a file name (--no-format-patch). By default, when such a conflict occurs, git send-email will fail. --quiet Make git-send-email less verbose. One line per email should be all that is output. --[no-]validate Perform sanity checks on patches. Currently, validation means the following: \u2022 Invoke the sendemail-validate hook if present (see githooks(5)). \u2022 Warn of patches that contain lines longer than 998 characters unless a suitable transfer encoding (auto, base64, or quoted-printable) is used; this is due to SMTP limits as described by http://www.ietf.org/rfc/rfc5322.txt . Default is the value of sendemail.validate; if this is not set, default to --validate. --force Send emails even if safety checks would prevent it. Information --dump-aliases Instead of the normal operation, dump the shorthand alias names from the configured alias file(s), one per line in alphabetical order. Note, this only includes the alias name and not its expanded email addresses. See sendemail.aliasesfile for more information about aliases. "
  },
  {
    "command": "git-checkout",
    "description": " Updates files in the working tree to match the version in the index or the specified tree. If no pathspec was given, git checkout will also update HEAD to set the specified branch as the current branch. git checkout [<branch>] To prepare for working on <branch>, switch to it by updating the index and the files in the working tree, and by pointing HEAD at the branch. Local modifications to the files in the working tree are kept, so that they can be committed to the <branch>. If <branch> is not found but there does exist a tracking branch in exactly one remote (call it <remote>) with a matching name and --no-guess is not specified, treat as equivalent to $ git checkout -b <branch> --track <remote>/<branch> You could omit <branch>, in which case the command degenerates to \"check out the current branch\", which is a glorified no-op with rather expensive side-effects to show only the tracking information, if exists, for the current branch. git checkout -b|-B <new-branch> [<start-point>] Specifying -b causes a new branch to be created as if git-branch(1) were called and then checked out. In this case you can use the --track or --no-track options, which will be passed to git branch. As a convenience, --track without -b implies branch creation; see the description of --track below. If -B is given, <new-branch> is created if it doesn\u2019t exist; otherwise, it is reset. This is the transactional equivalent of $ git branch -f <branch> [<start-point>] $ git checkout <branch> that is to say, the branch is not reset/created unless \"git checkout\" is successful. git checkout --detach [<branch>], git checkout [--detach] <commit> Prepare to work on top of <commit>, by detaching HEAD at it (see \"DETACHED HEAD\" section), and updating the index and the files in the working tree. Local modifications to the files in the working tree are kept, so that the resulting working tree will be the state recorded in the commit plus the local modifications. When the <commit> argument is a branch name, the --detach option can be used to detach HEAD at the tip of the branch (git checkout <branch> would check out that branch without detaching HEAD). Omitting <branch> detaches HEAD at the tip of the current branch. git checkout [-f|--ours|--theirs|-m|--conflict=<style>] [<tree-ish>] [--] <pathspec>..., git checkout [-f|--ours|--theirs|-m|--conflict=<style>] [<tree-ish>] --pathspec-from-file=<file> [--pathspec-file-nul] Overwrite the contents of the files that match the pathspec. When the <tree-ish> (most often a commit) is not given, overwrite working tree with the contents in the index. When the <tree-ish> is given, overwrite both the index and the working tree with the contents at the <tree-ish>. The index may contain unmerged entries because of a previous failed merge. By default, if you try to check out such an entry from the index, the checkout operation will fail and nothing will be checked out. Using -f will ignore these unmerged entries. The contents from a specific side of the merge can be checked out of the index by using --ours or --theirs. With -m, changes made to the working tree file can be discarded to re-create the original conflicted merge result. git checkout (-p|--patch) [<tree-ish>] [--] [<pathspec>...] This is similar to the previous mode, but lets you use the interactive interface to show the \"diff\" output and choose which hunks to use in the result. See below for the description of --patch option. -q, --quiet Quiet, suppress feedback messages. --progress, --no-progress Progress status is reported on the standard error stream by default when it is attached to a terminal, unless --quiet is specified. This flag enables progress reporting even if not attached to a terminal, regardless of --quiet. -f, --force When switching branches, proceed even if the index or the working tree differs from HEAD, and even if there are untracked files in the way. This is used to throw away local changes and any untracked files or directories that are in the way. When checking out paths from the index, do not fail upon unmerged entries; instead, unmerged entries are ignored. --ours, --theirs When checking out paths from the index, check out stage #2 (ours) or #3 (theirs) for unmerged paths. Note that during git rebase and git pull --rebase, ours and theirs may appear swapped; --ours gives the version from the branch the changes are rebased onto, while --theirs gives the version from the branch that holds your work that is being rebased. This is because rebase is used in a workflow that treats the history at the remote as the shared canonical one, and treats the work done on the branch you are rebasing as the third-party work to be integrated, and you are temporarily assuming the role of the keeper of the canonical history during the rebase. As the keeper of the canonical history, you need to view the history from the remote as ours (i.e. \"our shared canonical history\"), while what you did on your side branch as theirs (i.e. \"one contributor\u2019s work on top of it\"). -b <new-branch> Create a new branch named <new-branch>, start it at <start-point>, and check the resulting branch out; see git-branch(1) for details. -B <new-branch> Creates the branch <new-branch>, start it at <start-point>; if it already exists, then reset it to <start-point>. And then check the resulting branch out. This is equivalent to running \"git branch\" with \"-f\" followed by \"git checkout\" of that branch; see git-branch(1) for details. -t, --track[=(direct|inherit)] When creating a new branch, set up \"upstream\" configuration. See \"--track\" in git-branch(1) for details. If no -b option is given, the name of the new branch will be derived from the remote-tracking branch, by looking at the local part of the refspec configured for the corresponding remote, and then stripping the initial part up to the \"*\". This would tell us to use hack as the local branch when branching off of origin/hack (or remotes/origin/hack, or even refs/remotes/origin/hack). If the given name has no slash, or the above guessing results in an empty name, the guessing is aborted. You can explicitly give a name with -b in such a case. --no-track Do not set up \"upstream\" configuration, even if the branch.autoSetupMerge configuration variable is true. --guess, --no-guess If <branch> is not found but there does exist a tracking branch in exactly one remote (call it <remote>) with a matching name, treat as equivalent to $ git checkout -b <branch> --track <remote>/<branch> If the branch exists in multiple remotes and one of them is named by the checkout.defaultRemote configuration variable, we\u2019ll use that one for the purposes of disambiguation, even if the <branch> isn\u2019t unique across all remotes. Set it to e.g. checkout.defaultRemote=origin to always checkout remote branches from there if <branch> is ambiguous but exists on the origin remote. See also checkout.defaultRemote in git-config(1). --guess is the default behavior. Use --no-guess to disable it. The default behavior can be set via the checkout.guess configuration variable. -l Create the new branch\u2019s reflog; see git-branch(1) for details. -d, --detach Rather than checking out a branch to work on it, check out a commit for inspection and discardable experiments. This is the default behavior of git checkout <commit> when <commit> is not a branch name. See the \"DETACHED HEAD\" section below for details. --orphan <new-branch> Create a new orphan branch, named <new-branch>, started from <start-point> and switch to it. The first commit made on this new branch will have no parents and it will be the root of a new history totally disconnected from all the other branches and commits. The index and the working tree are adjusted as if you had previously run git checkout <start-point>. This allows you to start a new history that records a set of paths similar to <start-point> by easily running git commit -a to make the root commit. This can be useful when you want to publish the tree from a commit without exposing its full history. You might want to do this to publish an open source branch of a project whose current tree is \"clean\", but whose full history contains proprietary or otherwise encumbered bits of code. If you want to start a disconnected history that records a set of paths that is totally different from the one of <start-point>, then you should clear the index and the working tree right after creating the orphan branch by running git rm -rf . from the top level of the working tree. Afterwards you will be ready to prepare your new files, repopulating the working tree, by copying them from elsewhere, extracting a tarball, etc. --ignore-skip-worktree-bits In sparse checkout mode, git checkout -- <paths> would update only entries matched by <paths> and sparse patterns in $GIT_DIR/info/sparse-checkout. This option ignores the sparse patterns and adds back any files in <paths>. -m, --merge When switching branches, if you have local modifications to one or more files that are different between the current branch and the branch to which you are switching, the command refuses to switch branches in order to preserve your modifications in context. However, with this option, a three-way merge between the current branch, your working tree contents, and the new branch is done, and you will be on the new branch. When a merge conflict happens, the index entries for conflicting paths are left unmerged, and you need to resolve the conflicts and mark the resolved paths with git add (or git rm if the merge should result in deletion of the path). When checking out paths from the index, this option lets you recreate the conflicted merge in the specified paths. When switching branches with --merge, staged changes may be lost. --conflict=<style> The same as --merge option above, but changes the way the conflicting hunks are presented, overriding the merge.conflictStyle configuration variable. Possible values are \"merge\" (default), \"diff3\", and \"zdiff3\". -p, --patch Interactively select hunks in the difference between the <tree-ish> (or the index, if unspecified) and the working tree. The chosen hunks are then applied in reverse to the working tree (and if a <tree-ish> was specified, the index). This means that you can use git checkout -p to selectively discard edits from your current working tree. See the \u201cInteractive Mode\u201d section of git-add(1) to learn how to operate the --patch mode. Note that this option uses the no overlay mode by default (see also --overlay), and currently doesn\u2019t support overlay mode. --ignore-other-worktrees git checkout refuses when the wanted ref is already checked out by another worktree. This option makes it check the ref out anyway. In other words, the ref can be held by more than one worktree. --overwrite-ignore, --no-overwrite-ignore Silently overwrite ignored files when switching branches. This is the default behavior. Use --no-overwrite-ignore to abort the operation when the new branch contains ignored files. --recurse-submodules, --no-recurse-submodules Using --recurse-submodules will update the content of all active submodules according to the commit recorded in the superproject. If local modifications in a submodule would be overwritten the checkout will fail unless -f is used. If nothing (or --no-recurse-submodules) is used, submodules working trees will not be updated. Just like git-submodule(1), this will detach HEAD of the submodule. --overlay, --no-overlay In the default overlay mode, git checkout never removes files from the index or the working tree. When specifying --no-overlay, files that appear in the index and working tree, but not in <tree-ish> are removed, to make them match <tree-ish> exactly. --pathspec-from-file=<file> Pathspec is passed in <file> instead of commandline args. If <file> is exactly - then standard input is used. Pathspec elements are separated by LF or CR/LF. Pathspec elements can be quoted as explained for the configuration variable core.quotePath (see git-config(1)). See also --pathspec-file-nul and global --literal-pathspecs. --pathspec-file-nul Only meaningful with --pathspec-from-file. Pathspec elements are separated with NUL character and all other characters are taken literally (including newlines and quotes). <branch> Branch to checkout; if it refers to a branch (i.e., a name that, when prepended with \"refs/heads/\", is a valid ref), then that branch is checked out. Otherwise, if it refers to a valid commit, your HEAD becomes \"detached\" and you are no longer on any branch (see below for details). You can use the @{-N} syntax to refer to the N-th last branch/commit checked out using \"git checkout\" operation. You may also specify - which is synonymous to @{-1}. As a special case, you may use A...B as a shortcut for the merge base of A and B if there is exactly one merge base. You can leave out at most one of A and B, in which case it defaults to HEAD. <new-branch> Name for the new branch. <start-point> The name of a commit at which to start the new branch; see git-branch(1) for details. Defaults to HEAD. As a special case, you may use \"A...B\" as a shortcut for the merge base of A and B if there is exactly one merge base. You can leave out at most one of A and B, in which case it defaults to HEAD. <tree-ish> Tree to checkout from (when paths are given). If not specified, the index will be used. As a special case, you may use \"A...B\" as a shortcut for the merge base of A and B if there is exactly one merge base. You can leave out at most one of A and B, in which case it defaults to HEAD. -- Do not interpret any more arguments as options. <pathspec>... Limits the paths affected by the operation. For more details, see the pathspec entry in gitglossary(7). "
  },
  {
    "command": "git-show-ref",
    "description": " Displays references available in a local repository along with the associated commit IDs. Results can be filtered using a pattern and tags can be dereferenced into object IDs. Additionally, it can be used to test whether a particular ref exists. By default, shows the tags, heads, and remote refs. The --exclude-existing form is a filter that does the inverse. It reads refs from stdin, one ref per line, and shows those that don\u2019t exist in the local repository. Use of this utility is encouraged in favor of directly accessing files under the .git directory. --head Show the HEAD reference, even if it would normally be filtered out. --heads, --tags Limit to \"refs/heads\" and \"refs/tags\", respectively. These options are not mutually exclusive; when given both, references stored in \"refs/heads\" and \"refs/tags\" are displayed. -d, --dereference Dereference tags into object IDs as well. They will be shown with {caret}{} appended. -s, --hash[=<n>] Only show the OID, not the reference name. When combined with --dereference, the dereferenced tag will still be shown after the OID. --verify Enable stricter reference checking by requiring an exact ref path. Aside from returning an error code of 1, it will also print an error message if --quiet was not specified. --abbrev[=<n>] Abbreviate the object name. When using --hash, you do not have to say --hash --abbrev; --hash=n would do. -q, --quiet Do not print any results to stdout. When combined with --verify, this can be used to silently check if a reference exists. --exclude-existing[=<pattern>] Make git show-ref act as a filter that reads refs from stdin of the form ^(?:<anything>\\s)?<refname>(?:\\^{})?$ and performs the following actions on each: (1) strip {caret}{} at the end of line if any; (2) ignore if pattern is provided and does not head-match refname; (3) warn if refname is not a well-formed refname and skip; (4) ignore if refname is a ref that exists in the local repository; (5) otherwise output the line. <pattern>... Show references matching one or more patterns. Patterns are matched from the end of the full name, and only complete parts are matched, e.g. master matches refs/heads/master, refs/remotes/origin/master, refs/tags/jedi/master but not refs/heads/mymaster or refs/remotes/master/jedi. "
  },
  {
    "command": "tbl",
    "description": " The GNU implementation of tbl is part of the groff(1) document formatting system. tbl is a troff(1) preprocessor that translates descriptions of tables embedded in roff(7) input files into the language understood by troff. It copies the contents of each file to the standard output stream, except that lines between .TS and .TE are interpreted as table descriptions. While GNU tbl's input syntax is highly compatible with AT&T tbl, the output GNU tbl produces cannot be processed by AT&T troff; GNU troff (or a troff implementing any GNU extensions employed) must be used. Normally, tbl is not executed directly by the user, but invoked by specifying the -t option to groff(1). If no file operands are given on the command line, or if file is \u201c-\u201d, tbl reads the standard input stream. Overview tbl expects to find table descriptions between input lines that begin with .TS (table start) and .TE (table end). Each such table region encloses one or more table descriptions. Within a table region, table descriptions beyond the first must each be preceded by an input line beginning with .T&. This mechanism does not start a new table region; all table descriptions are treated as part of their .TS/.TE enclosure, even if they are boxed or have column headings that repeat on subsequent pages (see below). (Experienced roff users should observe that tbl is not a roff language interpreter: the default control character must be used, and no spaces or tabs are permitted between the control character and the macro name. These tbl input tokens remain as-is in the output, where they become ordinary macro calls. Macro packages often define TS, T&, and TE macros to handle issues of table placement on the page. tbl produces groff code to define these macros as empty if their definitions do not exist when the formatter encounters a table region.) Each table region may begin with region options, and must contain one or more table definitions; each table definition contains a format specification followed by one or more input lines (rows) of entries. These entries comprise the table data. Region options The line immediately following the .TS token may specify region options, keywords that influence the interpretation or rendering of the region as a whole or all table entries within it indiscriminately. They must be separated by commas, spaces, or tabs. Those that require a parenthesized argument permit spaces and tabs between the option's name and the opening parenthesis. Options accumulate and cannot be unset within a region once declared; if an option that takes a parameter is repeated, the last occurrence controls. If present, the set of region options must be terminated with a semicolon (;). Any of the allbox, box, doublebox, frame, and doubleframe region options makes a table \u201cboxed\u201d for the purpose of later discussion. allbox Enclose each table entry in a box; implies box. box Enclose the entire table region in a box. As a GNU extension, the alternative option name frame is also recognized. center Center the table region with respect to the current indentation and line length; the default is to left-align it. As a GNU extension, the alternative option name centre is also recognized. decimalpoint(c) Recognize character c as the decimal separator in columns using the N (numeric) classifier (see subsection \u201cColumn classifiers\u201d below). This is a GNU extension. delim(xy) Recognize characters x and y as start and end delimiters, respectively, for eqn(1) input, and ignore input between them. x and y need not be distinct. doublebox Enclose the entire table region in a double box; implies box. As a GNU extension, the alternative option name doubleframe is also recognized. expand Spread the table horizontally to fill the available space (line length minus indentation) by increasing column separation. Ordinarily, a table is made only as wide as necessary to accommodate the widths of its entries and its column separations (whether specified or default). When expand applies to a table that exceeds the available horizontal space, column separation is reduced as far as necessary (even to zero). tbl produces groff input that issues a diagnostic if such compression occurs. The column modifier x (see below) overrides this option. linesize(n) Draw lines or rules (e.g., from box) with a thickness of n points. The default is the current type size when the region begins. This option is ignored on terminal devices. nokeep Don't use roff diversions to manage page breaks. Normally, tbl employs them to avoid breaking a page within a table row. This usage can sometimes interact badly with macro packages' own use of diversions\u2014when footnotes, for example, are employed. This is a GNU extension. nospaces Ignore leading and trailing spaces in table entries. This is a GNU extension. nowarn Suppress diagnostic messages produced at document formatting time when the line or page lengths are inadequate to contain a table row. This is a GNU extension. tab(c) Use the character c instead of a tab to separate entries in a row of table data. Table format specification The table format specification is mandatory: it determines the number of columns in the table and directs how the entries within it are to be typeset. The format specification is a series of column descriptors. Each descriptor encodes a classifier followed by zero or more modifiers. Classifiers are letters (recognized case-insensitively) or punctuation symbols; modifiers consist of or begin with letters or numerals. Spaces, tabs, newlines, and commas separate descriptors. Newlines and commas are special; they apply the descriptors following them to a subsequent row of the table. (This enables column headings to be centered or emboldened while the table entries for the data are not, for instance.) We term the resulting group of column descriptors a row definition. Within a row definition, separation between column descriptors (by spaces or tabs) is often optional; only some modifiers, described below, make separation necessary. Each column descriptor begins with a mandatory classifier, a character that selects from one of several arrangements. Some determine the positioning of table entries within a rectangular cell: centered, left-aligned, numeric (aligned to a configurable decimal separator), and so on. Others perform special operations like drawing lines or spanning entries from adjacent cells in the table. Except for \u201c|\u201d, any classifier can be followed by one or more modifiers; some of these accept an argument, which in GNU tbl can be parenthesized. Modifiers select fonts, set the type size, and perform other tasks described below. The format specification can occupy multiple input lines, but must conclude with a dot \u201c.\u201d followed by a newline. Each row definition is applied in turn to one row of the table. The last row definition is applied to rows of table data in excess of the row definitions. For clarity in this document's examples, we shall write classifiers in uppercase and modifiers in lowercase. Thus, \u201cCbCb,LR.\u201d defines two rows of two columns. The first row's entries are centered and boldfaced; the second and any further rows' first and second columns are left- and right-aligned, respectively. The row definition with the most column descriptors determines the number of columns in the table; any row definition with fewer is implicitly extended on the right-hand side with L classifiers as many times as necessary to make the table rectangular. Column classifiers The L, R, and C classifiers are the easiest to understand and use. A, a Center longest entry in this column, left-align remaining entries in the column with respect to the centered entry, then indent all entries by one en. Such \u201calphabetic\u201d entries (hence the name of the classifier) can be used in the same column as L-classified entries, as in \u201cLL,AR.\u201d. The A entries are often termed \u201csub-columns\u201d due to their indentation. C, c Center entry within the column. L, l Left-align entry within the column. N, n Numerically align entry in the column. tbl aligns columns of numbers vertically at the units place. If multiple decimal separators are adjacent to a digit, it uses the rightmost one for vertical alignment. If there is no decimal separator, the rightmost digit is used for vertical alignment; otherwise, tbl centers the entry within the column. The roff dummy character \\& in an entry marks the glyph preceding it (if any) as the units place; if multiple instances occur in the data, the leftmost is used for alignment. If N-classified entries share a column with L or R entries, tbl centers the widest N entry with respect to the widest L or R entry, preserving the alignment of N entries with respect to each other. The appearance of eqn equations within N-classified columns can be troublesome due to the foregoing textual scan for a decimal separator. Use the delim region option to make tbl ignore the data within eqn delimiters for that purpose. R, r Right-align entry within the column. S, s Span previous entry on the left into this column. ^ Span entry in the same column from the previous row into this row. _, - Replace table entry with a horizontal rule. An empty table entry is expected to correspond to this classifier; if data are found there, tbl issues a diagnostic message. = Replace table entry with a double horizontal rule. An empty table entry is expected to correspond to this classifier; if data are found there, tbl issues a diagnostic message. | Place a vertical rule (line) on the corresponding row of the table (if two of these are adjacent, a double vertical rule). This classifier does not contribute to the column count and no table entries correspond to it. A | to the left of the first column descriptor or to the right of the last one produces a vertical rule at the edge of the table; these are redundant (and ignored) in boxed tables. To change the table format within a tbl region, use the .T& token at the start of a line. It is followed by a format specification and table data, but not region options. The quantity of columns in a new table format thus introduced cannot increase relative to the previous table format; in that case, you must end the table region and start another. If that will not serve because the region uses box options or the columns align in an undesirable manner, you must design the initial table format specification to include the maximum quantity of columns required, and use the S horizontal spanning classifier where necessary to achieve the desired columnar alignment. Attempting to horizontally span in the first column or vertically span on the first row is an error. Non-rectangular span areas are also not supported. Column modifiers Any number of modifiers can follow a column classifier. Arguments to modifiers, where accepted, are case-sensitive. If the same modifier is applied to a column specifier more than once, or if conflicting modifiers are applied, only the last occurrence has effect. The modifier x is mutually exclusive with e and w, but e is not mutually exclusive with w; if these are used in combination, x unsets both e and w, while either e or w overrides x. b, B Typeset entry in boldface, abbreviating f(B). d, D Align a vertically spanned table entry to the bottom (\u201cdown\u201d), instead of the center, of its range. This is a GNU extension. e, E Equalize the widths of columns with this modifier. The column with the largest width controls. This modifier sets the default line length used in a text block. f, F Select the typeface for the table entry. This modifier must be followed by a font or style name (one or two characters not starting with a digit), font mounting position (a single digit), or a name or mounting position of any length in parentheses. The last form is a GNU extension. (The parameter corresponds to that accepted by the troff ft request.) A one-character argument not in parentheses must be separated by one or more spaces or tabs from what follows. i, I Typeset entry in an oblique or italic face, abbreviating f(I). m, M Call a groff macro before typesetting a text block (see subsection \u201cText blocks\u201d below). This is a GNU extension. This modifier must be followed by a macro name of one or two characters or a name of any length in parentheses. A one-character macro name not in parentheses must be separated by one or more spaces or tabs from what follows. The named macro must be defined before the table region containing this column modifier is encountered. The macro should contain only simple groff requests to change text formatting, like adjustment or hyphenation. The macro is called after the column modifiers b, f, i, p, and v take effect; it can thus override other column modifiers. p, P Set the type size for the table entry. This modifier must be followed by an integer n with an optional leading sign. If unsigned, the type size is set to n scaled points. Otherwise, the type size is incremented or decremented per the sign by n scaled points. The use of a signed multi- digit number is a GNU extension. (The parameter corresponds to that accepted by the troff ps request.) If a type size modifier is followed by a column separation modifier (see below), they must be separated by at least one space or tab. t, T Align a vertically spanned table entry to the top, instead of the center, of its range. u, U Move the column up one half-line, \u201cstaggering\u201d the rows. This is a GNU extension. v, V Set the vertical spacing to be used in a text block. This modifier must be followed by an integer n with an optional leading sign. If unsigned, the vertical spacing is set to n points. Otherwise, the vertical spacing is incremented or decremented per the sign by n points. The use of a signed multi-digit number is a GNU extension. (This parameter corresponds to that accepted by the troff vs request.) If a vertical spacing modifier is followed by a column separation modifier (see below), they must be separated by at least one space or tab. w, W Set the column's minimum width. This modifier must be followed by a number, which is either a unitless integer, or a roff horizontal measurement in parentheses. Parentheses are required if the width is to be followed immediately by an explicit column separation (alternatively, follow the width with one or more spaces or tabs). If no unit is specified, ens are assumed. This modifier sets the default line length used in a text block. x, X Expand the column. After computing the column widths, distribute any remaining line length evenly over all columns bearing this modifier. Applying the x modifier to more than one column is a GNU extension. This modifier sets the default line length used in a text block. z, Z Ignore the table entries corresponding to this column for width calculation purposes; that is, compute the column's width using only the information in its descriptor. n A numeric suffix on a column descriptor sets the separation distance (in ens) from the succeeding column; the default separation is 3n. This separation is proportionally multiplied if the expand region option is in effect; in the case of tables wider than the output line length, this separation might be zero. A negative separation cannot be specified. A separation amount after the last column in a row is nonsensical and provokes a diagnostic from tbl. Table data The table data come after the format specification. Each input line corresponds to a table row, except that a backslash at the end of a line of table data continues an entry on the next input line. (Text blocks, discussed below, also spread table entries across multiple input lines.) Table entries within a row are separated in the input by a tab character by default; see the tab region option above. Excess entries in a row of table data (those that have no corresponding column descriptor, not even an implicit one arising from rectangularization of the table) are discarded with a diagnostic message. roff control lines are accepted between rows of table data and within text blocks. If you wish to visibly mark an empty table entry in the document source, populate it with the \\& roff dummy character. The table data are interrupted by a line consisting of the .T& input token, and conclude with the line .TE. Ordinarily, a table entry is typeset rigidly. It is not filled, broken, hyphenated, adjusted, or populated with additional inter- sentence space. tbl instructs the formatter to measure each table entry as it occurs in the input, updating the width required by its corresponding column. If the z modifier applies to the column, this measurement is ignored; if w applies and its argument is larger than this width, that argument is used instead. In contrast to conventional roff input (within a paragraph, say), changes to text formatting, such as font selection or vertical spacing, do not persist between entries. Several forms of table entry are interpreted specially. \u2022 If a table row contains only an underscore or equals sign (_ or =), a single or double horizontal rule (line), respectively, is drawn across the table at that point. \u2022 A table entry containing only _ or = on an otherwise populated row is replaced by a single or double horizontal rule, respectively, joining its neighbors. \u2022 Prefixing a lone underscore or equals sign with a backslash also has meaning. If a table entry consists only of \\_ or \\= on an otherwise populated row, it is replaced by a single or double horizontal rule, respectively, that does not (quite) join its neighbors. \u2022 A table entry consisting of \\Rx, where x is any roff ordinary or special character, is replaced by enough repetitions of the glyph corresponding to x to fill the column, albeit without joining its neighbors. \u2022 On any row but the first, a table entry of \\^ causes the entry above it to span down into the current one. On occasion, these special tokens may be required as literal table data. To use either _ or = literally and alone in an entry, prefix or suffix it with the roff dummy character \\&. To express \\_, \\=, or \\R, use a roff escape sequence to interpolate the backslash (\\e or \\[rs]). A reliable way to emplace the \\^ glyph sequence within a table entry is to use a pair of groff special character escape sequences (\\[rs]\\[ha]). Rows of table entries can be interleaved with groff control lines; these do not count as table data. On such lines the default control character (.) must be used (and not changed); the no-break control character is not recognized. To start the first table entry in a row with a dot, precede it with the roff dummy character \\&. Text blocks An ordinary table entry's contents can make a column, and therefore the table, excessively wide; the table then exceeds the line length of the page, and becomes ugly or is exposed to truncation by the output device. When a table entry requires more conventional typesetting, breaking across more than one output line (and thereby increasing the height of its row), it can be placed within a text block. tbl interprets a table entry beginning with \u201cT{\u201d at the end of an input line not as table data, but as a token starting a text block. Similarly, \u201cT}\u201d at the start of an input line ends a text block; it must also end the table entry. Text block tokens can share an input line with other table data (preceding T{ and following T}). Input lines between these tokens are formatted in a diversion by troff. Text blocks cannot be nested. Multiple text blocks can occur in a table row. Text blocks are formatted as was the text prior to the table, modified by applicable column descriptors. Specifically, the classifiers A, C, L, N, R, and S determine a text block's alignment within its cell, but not its adjustment. Add na or ad requests to the beginning of a text block to alter its adjustment distinctly from other text in the document. As with other table entries, when a text block ends, any alterations to formatting parameters are discarded. They do not affect subsequent table entries, not even other text blocks. If w or x modifiers are not specified for all columns of a text block's span, the default length of the text block (more precisely, the line length used to process the text block diversion) is computed as L\u00d7C/(N+1), where L is the current line length, C the number of columns spanned by the text block, and N the number of columns in the table. If necessary, you can also control a text block's width by including an ll (line length) request in it prior to any text to be formatted. Because a diversion is used to format the text block, its height and width are subsequently available in the registers dn and dl, respectively. roff interface The register TW stores the width of the table region in basic units; it can't be used within the region itself, but is defined before the .TE token is output so that a groff macro named TE can make use of it. T. is a Boolean-valued register indicating whether the bottom of the table is being processed. The #T register marks the top of the table. Avoid using these names for any other purpose. tbl also defines a macro T# to produce the bottom and side lines of a boxed table. While tbl itself arranges for the output to include a call of this macro at the end of such a table, it can also be used by macro packages to create boxes for multi-page tables by calling it from a page footer macro that is itself called by a trap planted near the bottom of the page. See section \u201cLimitations\u201d below for more on multi-page tables. GNU tbl internally employs register, string, macro, and diversion names beginning with the numeral 3. A document to be preprocessed with GNU tbl should not use any such identifiers. Interaction with eqn tbl should always be called before eqn(1). (groff(1) automatically arranges preprocessors in the correct order.) Don't call the EQ and EN macros within tables; instead, set up delimiters in your eqn input and use the delim region option so that tbl will recognize them. GNU tbl enhancements In addition to extensions noted above, GNU tbl removes constraints endured by users of AT&T tbl. \u2022 Region options can be specified in any lettercase. \u2022 There is no limit on the number of columns in a table, regardless of their classification, nor any limit on the number of text blocks. \u2022 All table rows are considered when deciding column widths, not just those occurring in the first 200 input lines of a region. Similarly, table continuation (.T&) tokens are recognized outside a region's first 200 input lines. \u2022 Numeric and alphabetic entries may appear in the same column. \u2022 Numeric and alphabetic entries may span horizontally. Using GNU tbl within macros You can embed a table region inside a macro definition. However, since tbl writes its own macro definitions at the beginning of each table region, it is necessary to call end macros instead of ending macro definitions with \u201c..\u201d. Additionally, the escape character must be disabled. Not all tbl features can be exercised from such macros because tbl is a roff preprocessor: it sees the input earlier than troff does. For example, vertically aligning decimal separators fails if the numbers containing them occur as macro or string parameters; the alignment is performed by tbl itself, which sees only \\$1, \\$2, and so on, and therefore can't recognize a decimal separator that only appears later when troff interpolates a macro or string definition. Using tbl macros within conditional input (that is, contingent upon an if, ie, el, or while request) can result in misleading line numbers in subsequent diagnostics. tbl unconditionally injects its output into the source document, but the conditional branch containing it may not be taken, and if it is not, the lf requests that tbl injects to restore the source line number cannot take effect. Consider copying the input line counter register c. and restoring its value at a convenient location after applicable arithmetic. --help displays a usage message, while -v and --version show version information; all exit afterward. -C Enable AT&T compatibility mode: recognize .TS and .TE even when followed by a character other than space or newline. Furthermore, interpret the uninterpreted leader escape sequence \\a. "
  },
  {
    "command": "fg",
    "description": " If job control is enabled (see the description of set -m), the fg utility shall move a background job from the current environment (see Section 2.12, Shell Execution Environment) into the foreground. Using fg to place a job into the foreground shall remove its process ID from the list of those ``known in the current shell execution environment''; see Section 2.9.3.1, Examples. None. "
  },
  {
    "command": "kill",
    "description": " The default signal for kill is TERM. Use -l or -L to list available signals. Particularly useful signals include HUP, INT, KILL, STOP, CONT, and 0. Alternate signals may be specified in three ways: -9, -SIGKILL or -KILL. Negative PID values may be used to choose whole process groups; see the PGID column in ps command output. A PID of -1 is special; it indicates all processes except the kill process itself and init. <pid> [...] Send signal to every <pid> listed. -<signal> -s <signal> --signal <signal> Specify the signal to be sent. The signal can be specified by using name or number. The behavior of signals is explained in signal(7) manual page. -q, --queue value Use sigqueue(3) rather than kill(2) and the value argument is used to specify an integer to be sent with the signal. If the receiving process has installed a handler for this signal using the SA_SIGINFO flag to sigaction(2), then it can obtain this data via the si_value field of the siginfo_t structure. -l, --list [signal] List signal names. This option has optional argument, which will convert signal number to signal name, or other way round. -L, --table List signal names in a nice table. "
  },
  {
    "command": "git-credential",
    "description": " Git has an internal interface for storing and retrieving credentials from system-specific helpers, as well as prompting the user for usernames and passwords. The git-credential command exposes this interface to scripts which may want to retrieve, store, or prompt for credentials in the same manner as Git. The design of this scriptable interface models the internal C API; see credential.h for more background on the concepts. git-credential takes an \"action\" option on the command-line (one of fill, approve, or reject) and reads a credential description on stdin (see INPUT/OUTPUT FORMAT). If the action is fill, git-credential will attempt to add \"username\" and \"password\" attributes to the description by reading config files, by contacting any configured credential helpers, or by prompting the user. The username and password attributes of the credential description are then printed to stdout together with the attributes already provided. If the action is approve, git-credential will send the description to any configured credential helpers, which may store the credential for later use. If the action is reject, git-credential will send the description to any configured credential helpers, which may erase any stored credential matching the description. If the action is approve or reject, no output should be emitted. "
  },
  {
    "command": "git-stripspace",
    "description": " Read text, such as commit messages, notes, tags and branch descriptions, from the standard input and clean it in the manner used by Git. With no arguments, this will: \u2022 remove trailing whitespace from all lines \u2022 collapse multiple consecutive empty lines into one empty line \u2022 remove empty lines from the beginning and end of the input \u2022 add a missing \\n to the last line if necessary. In the case where the input consists entirely of whitespace characters, no output will be produced. NOTE: This is intended for cleaning metadata, prefer the --whitespace=fix mode of git-apply(1) for correcting whitespace of patches or files in the repository. -s, --strip-comments Skip and remove all lines starting with comment character (default #). -c, --comment-lines Prepend comment character and blank to each line. Lines will automatically be terminated with a newline. On empty lines, only the comment character will be prepended. "
  },
  {
    "command": "hostname",
    "description": " Print or set the hostname of the current system. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "fuser",
    "description": " fuser displays the PIDs of processes using the specified files or file systems. In the default display mode, each file name is followed by a letter denoting the type of access: c current directory. e executable being run. f open file. f is omitted in default display mode. F open file for writing. F is omitted in default display mode. r root directory. m mmap'ed file or shared library. . Placeholder, omitted in default display mode. fuser returns a non-zero return code if none of the specified files is accessed or in case of a fatal error. If at least one access has been found, fuser returns zero. In order to look up processes using TCP and UDP sockets, the corresponding name space has to be selected with the -n option. By default fuser will look in both IPv6 and IPv4 sockets. To change the default behavior, use the -4 and -6 options. The socket(s) can be specified by the local and remote port, and the remote address. All fields are optional, but commas in front of missing fields must be present: [lcl_port][,[rmt_host][,[rmt_port]]] Either symbolic or numeric values can be used for IP addresses and port numbers. fuser outputs only the PIDs to stdout, everything else is sent to stderr. -a, --all Show all files specified on the command line. By default, only files that are accessed by at least one process are shown. -c Same as -m option, used for POSIX compatibility. -f Silently ignored, used for POSIX compatibility. -k, --kill Kill processes accessing the file. Unless changed with -SIGNAL, SIGKILL is sent. An fuser process never kills itself, but may kill other fuser processes. The effective user ID of the process executing fuser is set to its real user ID before attempting to kill. -i, --interactive Ask the user for confirmation before killing a process. This option is silently ignored if -k is not present too. -I, --inode For the name space file let all comparisons be based on the inodes of the specified file(s) and never on the file names even on network based file systems. -l, --list-signals List all known signal names. -m NAME, --mount NAME NAME specifies a file on a mounted file system or a block device that is mounted. All processes accessing files on that file system are listed. If a directory is specified, it is automatically changed to NAME/ to use any file system that might be mounted on that directory. -M, --ismountpoint Request will be fulfilled only if NAME specifies a mountpoint. This is an invaluable seat belt which prevents you from killing the machine if NAME happens to not be a filesystem. -w Kill only processes which have write access. This option is silently ignored if -k is not present too. -n NAMESPACE, --namespace NAMESPACE Select a different name space. The name spaces file (file names, the default), udp (local UDP ports), and tcp (local TCP ports) are supported. For ports, either the port number or the symbolic name can be specified. If there is no ambiguity, the shortcut notation name/space (e.g., 80/tcp) can be used. -s, --silent Silent operation. -u and -v are ignored in this mode. -a must not be used with -s. -SIGNAL Use the specified signal instead of SIGKILL when killing processes. Signals can be specified either by name (e.g., -HUP) or by number (e.g., -1). This option is silently ignored if the -k option is not used. -u, --user Append the user name of the process owner to each PID. -v, --verbose Verbose mode. Processes are shown in a ps-like style. The fields PID, USER and COMMAND are similar to ps. ACCESS shows how the process accesses the file. Verbose mode will also show when a particular file is being accessed as a mount point, knfs export or swap file. In this case kernel is shown instead of the PID. -V, --version Display version information. -4, --ipv4 Search only for IPv4 sockets. This option must not be used with the -6 option and only has an effect with the tcp and udp namespaces. -6, --ipv6 Search only for IPv6 sockets. This option must not be used with the -4 option and only has an effect with the tcp and udp namespaces. "
  },
  {
    "command": "git-mergetool",
    "description": " Use git mergetool to run one of several merge utilities to resolve merge conflicts. It is typically run after git merge. If one or more <file> parameters are given, the merge tool program will be run to resolve differences on each file (skipping those without conflicts). Specifying a directory will include all unresolved files in that path. If no <file> names are specified, git mergetool will run the merge tool program on every file with merge conflicts. -t <tool>, --tool=<tool> Use the merge resolution program specified by <tool>. Valid values include emerge, gvimdiff, kdiff3, meld, vimdiff, and tortoisemerge. Run git mergetool --tool-help for the list of valid <tool> settings. If a merge resolution program is not specified, git mergetool will use the configuration variable merge.tool. If the configuration variable merge.tool is not set, git mergetool will pick a suitable default. You can explicitly provide a full path to the tool by setting the configuration variable mergetool.<tool>.path. For example, you can configure the absolute path to kdiff3 by setting mergetool.kdiff3.path. Otherwise, git mergetool assumes the tool is available in PATH. Instead of running one of the known merge tool programs, git mergetool can be customized to run an alternative program by specifying the command line to invoke in a configuration variable mergetool.<tool>.cmd. When git mergetool is invoked with this tool (either through the -t or --tool option or the merge.tool configuration variable) the configured command line will be invoked with $BASE set to the name of a temporary file containing the common base for the merge, if available; $LOCAL set to the name of a temporary file containing the contents of the file on the current branch; $REMOTE set to the name of a temporary file containing the contents of the file to be merged, and $MERGED set to the name of the file to which the merge tool should write the result of the merge resolution. If the custom merge tool correctly indicates the success of a merge resolution with its exit code, then the configuration variable mergetool.<tool>.trustExitCode can be set to true. Otherwise, git mergetool will prompt the user to indicate the success of the resolution after the custom tool has exited. --tool-help Print a list of merge tools that may be used with --tool. -y, --no-prompt Don\u2019t prompt before each invocation of the merge resolution program. This is the default if the merge resolution program is explicitly specified with the --tool option or with the merge.tool configuration variable. --prompt Prompt before each invocation of the merge resolution program to give the user a chance to skip the path. -g, --gui When git-mergetool is invoked with the -g or --gui option the default merge tool will be read from the configured merge.guitool variable instead of merge.tool. If merge.guitool is not set, we will fallback to the tool configured under merge.tool. This may be autoselected using the configuration variable mergetool.guiDefault. --no-gui This overrides a previous -g or --gui setting or mergetool.guiDefault configuration and reads the default merge tool from the configured merge.tool variable. -O<orderfile> Process files in the order specified in the <orderfile>, which has one shell glob pattern per line. This overrides the diff.orderFile configuration variable (see git-config(1)). To cancel diff.orderFile, use -O/dev/null. "
  },
  {
    "command": "su",
    "description": " su allows commands to be run with a substitute user and group ID. When called with no user specified, su defaults to running an interactive shell as root. When user is specified, additional arguments can be supplied, in which case they are passed to the shell. For backward compatibility, su defaults to not change the current directory and to only set the environment variables HOME and SHELL (plus USER and LOGNAME if the target user is not root). It is recommended to always use the --login option (instead of its shortcut -) to avoid side effects caused by mixing environments. This version of su uses PAM for authentication, account and session management. Some configuration options found in other su implementations, such as support for a wheel group, have to be configured via PAM. su is mostly designed for unprivileged users, the recommended solution for privileged users (e.g., scripts executed by root) is to use non-set-user-ID command runuser(1) that does not require authentication and provides separate PAM configuration. If the PAM session is not required at all then the recommended solution is to use command setpriv(1). Note that su in all cases uses PAM (pam_getenvlist(3)) to do the final environment modification. Command-line options such as --login and --preserve-environment affect the environment before it is modified by PAM. Since version 2.38 su resets process resource limits RLIMIT_NICE, RLIMIT_RTPRIO, RLIMIT_FSIZE, RLIMIT_AS and RLIMIT_NOFILE. -c, --command=command Pass command to the shell with the -c option. -f, --fast Pass -f to the shell, which may or may not be useful, depending on the shell. -g, --group=group Specify the primary group. This option is available to the root user only. -G, --supp-group=group Specify a supplementary group. This option is available to the root user only. The first specified supplementary group is also used as a primary group if the option --group is not specified. -, -l, --login Start the shell as a login shell with an environment similar to a real login: \u2022 clears all the environment variables except TERM and variables specified by --whitelist-environment \u2022 initializes the environment variables HOME, SHELL, USER, LOGNAME, and PATH \u2022 changes to the target user\u2019s home directory \u2022 sets argv[0] of the shell to '-' in order to make the shell a login shell -m, -p, --preserve-environment Preserve the entire environment, i.e., do not set HOME, SHELL, USER or LOGNAME. This option is ignored if the option --login is specified. -P, --pty Create a pseudo-terminal for the session. The independent terminal provides better security as the user does not share a terminal with the original session. This can be used to avoid TIOCSTI ioctl terminal injection and other security attacks against terminal file descriptors. The entire session can also be moved to the background (e.g., su --pty - username -c application &). If the pseudo-terminal is enabled, then su works as a proxy between the sessions (sync stdin and stdout). This feature is mostly designed for interactive sessions. If the standard input is not a terminal, but for example a pipe (e.g., echo \"date\" | su --pty), then the ECHO flag for the pseudo-terminal is disabled to avoid messy output. -s, --shell=shell Run the specified shell instead of the default. The shell to run is selected according to the following rules, in order: \u2022 the shell specified with --shell \u2022 the shell specified in the environment variable SHELL, if the --preserve-environment option is used \u2022 the shell listed in the passwd entry of the target user \u2022 /bin/sh If the target user has a restricted shell (i.e., not listed in /etc/shells), the --shell option and the SHELL environment variables are ignored unless the calling user is root. --session-command=command Same as -c, but do not create a new session. (Discouraged.) -w, --whitelist-environment=list Don\u2019t reset the environment variables specified in the comma-separated list when clearing the environment for --login. The whitelist is ignored for the environment variables HOME, SHELL, USER, LOGNAME, and PATH. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "git-request-pull",
    "description": " Generate a request asking your upstream project to pull changes into their tree. The request, printed to the standard output, begins with the branch description, summarizes the changes and indicates from where they can be pulled. The upstream project is expected to have the commit named by <start> and the output asks it to integrate the changes you made since that commit, up to the commit named by <end>, by visiting the repository named by <URL>. -p Include patch text in the output. <start> Commit to start at. This names a commit that is already in the upstream history. <URL> The repository URL to be pulled from. <end> Commit to end at (defaults to HEAD). This names the commit at the tip of the history you are asking to be pulled. When the repository named by <URL> has the commit at a tip of a ref that is different from the ref you have locally, you can use the <local>:<remote> syntax, to have its local name, a colon :, and its remote name. "
  },
  {
    "command": "perf",
    "description": " Performance counters for Linux are a new kernel-based subsystem that provide a framework for all things performance analysis. It covers hardware level (CPU/PMU, Performance Monitoring Unit) features and software features (software counters, tracepoints) as well. -h, --help Run perf help command. -v, --version Display perf version. -vv Print the compiled-in status of libraries. --exec-path Display or set exec path. --html-path Display html documentation path. -p, --paginate Set up pager. --no-pager Do not set pager. --buildid-dir Setup buildid cache directory. It has higher priority than buildid.dir config file option. --list-cmds List the most commonly used perf commands. --list-opts List available perf options. --debugfs-dir Set debugfs directory or set environment variable PERF_DEBUGFS_DIR. --debug Setup debug variable (see list below) in value range (0, 10). Use like: --debug verbose # sets verbose = 1 --debug verbose=2 # sets verbose = 2 List of debug variables allowed to set: verbose - general debug messages ordered-events - ordered events object debug messages data-convert - data convert command debug messages stderr - write debug output (option -v) to stderr in browser mode perf-event-open - Print perf_event_open() arguments and return value "
  },
  {
    "command": "chrt",
    "description": " chrt sets or retrieves the real-time scheduling attributes of an existing PID, or runs command with the given attributes. -a, --all-tasks Set or retrieve the scheduling attributes of all the tasks (threads) for a given PID. -m, --max Show minimum and maximum valid priorities, then exit. -p, --pid Operate on an existing PID and do not launch a new task. -v, --verbose Show status information. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "git-describe",
    "description": " The command finds the most recent tag that is reachable from a commit. If the tag points to the commit, then only the tag is shown. Otherwise, it suffixes the tag name with the number of additional commits on top of the tagged object and the abbreviated object name of the most recent commit. The result is a \"human-readable\" object name which can also be used to identify the commit to other git commands. By default (without --all or --tags) git describe only shows annotated tags. For more information about creating annotated tags see the -a and -s options to git-tag(1). If the given object refers to a blob, it will be described as <commit-ish>:<path>, such that the blob can be found at <path> in the <commit-ish>, which itself describes the first commit in which this blob occurs in a reverse revision walk from HEAD. <commit-ish>... Commit-ish object names to describe. Defaults to HEAD if omitted. --dirty[=<mark>], --broken[=<mark>] Describe the state of the working tree. When the working tree matches HEAD, the output is the same as \"git describe HEAD\". If the working tree has local modification \"-dirty\" is appended to it. If a repository is corrupt and Git cannot determine if there is local modification, Git will error out, unless \u2018--broken\u2019 is given, which appends the suffix \"-broken\" instead. --all Instead of using only the annotated tags, use any ref found in refs/ namespace. This option enables matching any known branch, remote-tracking branch, or lightweight tag. --tags Instead of using only the annotated tags, use any tag found in refs/tags namespace. This option enables matching a lightweight (non-annotated) tag. --contains Instead of finding the tag that predates the commit, find the tag that comes after the commit, and thus contains it. Automatically implies --tags. --abbrev=<n> Instead of using the default number of hexadecimal digits (which will vary according to the number of objects in the repository with a default of 7) of the abbreviated object name, use <n> digits, or as many digits as needed to form a unique object name. An <n> of 0 will suppress long format, only showing the closest tag. --candidates=<n> Instead of considering only the 10 most recent tags as candidates to describe the input commit-ish consider up to <n> candidates. Increasing <n> above 10 will take slightly longer but may produce a more accurate result. An <n> of 0 will cause only exact matches to be output. --exact-match Only output exact matches (a tag directly references the supplied commit). This is a synonym for --candidates=0. --debug Verbosely display information about the searching strategy being employed to standard error. The tag name will still be printed to standard out. --long Always output the long format (the tag, the number of commits and the abbreviated commit name) even when it matches a tag. This is useful when you want to see parts of the commit object name in \"describe\" output, even when the commit in question happens to be a tagged version. Instead of just emitting the tag name, it will describe such a commit as v1.2-0-gdeadbee (0th commit since tag v1.2 that points at object deadbee....). --match <pattern> Only consider tags matching the given glob(7) pattern, excluding the \"refs/tags/\" prefix. If used with --all, it also considers local branches and remote-tracking references matching the pattern, excluding respectively \"refs/heads/\" and \"refs/remotes/\" prefix; references of other types are never considered. If given multiple times, a list of patterns will be accumulated, and tags matching any of the patterns will be considered. Use --no-match to clear and reset the list of patterns. --exclude <pattern> Do not consider tags matching the given glob(7) pattern, excluding the \"refs/tags/\" prefix. If used with --all, it also does not consider local branches and remote-tracking references matching the pattern, excluding respectively \"refs/heads/\" and \"refs/remotes/\" prefix; references of other types are never considered. If given multiple times, a list of patterns will be accumulated and tags matching any of the patterns will be excluded. When combined with --match a tag will be considered when it matches at least one --match pattern and does not match any of the --exclude patterns. Use --no-exclude to clear and reset the list of patterns. --always Show uniquely abbreviated commit object as fallback. --first-parent Follow only the first parent commit upon seeing a merge commit. This is useful when you wish to not match tags on branches merged in the history of the target commit. "
  },
  {
    "command": "tail",
    "description": " The tail utility shall copy its input file to the standard output beginning at a designated place. Copying shall begin at the point in the file indicated by the -c number or -n number options. The option-argument number shall be counted in units of lines or bytes, according to the options -n and -c. Both line and byte counts start from 1. Tails relative to the end of the file may be saved in an internal buffer, and thus may be limited in length. Such a buffer, if any, shall be no smaller than {LINE_MAX}*10 bytes. The tail utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except that '+' may be recognized as an option delimiter as well as '-'. The following options shall be supported: -c number The application shall ensure that the number option- argument is a decimal integer, optionally including a sign. The sign shall affect the location in the file, measured in bytes, to begin the copying: \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502Sign \u2502 Copying Starts \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 + \u2502 Relative to the beginning of the file. \u2502 \u2502 - \u2502 Relative to the end of the file. \u2502 \u2502none \u2502 Relative to the end of the file. \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 The application shall ensure that if the sign of the number option-argument is '+', the number option- argument is a non-zero decimal integer. The origin for counting shall be 1; that is, -c +1 represents the first byte of the file, -c -1 the last. -f If the input file is a regular file or if the file operand specifies a FIFO, do not terminate after the last line of the input file has been copied, but read and copy further bytes from the input file when they become available. If no file operand is specified and standard input is a pipe or FIFO, the -f option shall be ignored. If the input file is not a FIFO, pipe, or regular file, it is unspecified whether or not the -f option shall be ignored. -n number This option shall be equivalent to -c number, except the starting location in the file shall be measured in lines instead of bytes. The origin for counting shall be 1; that is, -n +1 represents the first line of the file, -n -1 the last. If neither -c nor -n is specified, -n 10 shall be assumed. "
  },
  {
    "command": "truncate",
    "description": " Shrink or extend the size of each FILE to the specified size A FILE argument that does not exist is created. If a FILE is larger than the specified size, the extra data is lost. If a FILE is shorter, it is extended and the sparse extended part (hole) reads as zero bytes. Mandatory arguments to long options are mandatory for short options too. -c, --no-create do not create any files -o, --io-blocks treat SIZE as number of IO blocks instead of bytes -r, --reference=RFILE base size on RFILE -s, --size=SIZE set or adjust the file size by SIZE bytes --help display this help and exit --version output version information and exit The SIZE argument is an integer and optional unit (example: 10K is 10*1024). Units are K,M,G,T,P,E,Z,Y,R,Q (powers of 1024) or KB,MB,... (powers of 1000). Binary prefixes can be used, too: KiB=K, MiB=M, and so on. SIZE may also be prefixed by one of the following modifying characters: '+' extend by, '-' reduce by, '<' at most, '>' at least, '/' round down to multiple of, '%' round up to multiple of. "
  },
  {
    "command": "git-check-attr",
    "description": " For every pathname, this command will list if each attribute is unspecified, set, or unset as a gitattribute on that pathname. -a, --all List all attributes that are associated with the specified paths. If this option is used, then unspecified attributes will not be included in the output. --cached Consider .gitattributes in the index only, ignoring the working tree. --stdin Read pathnames from the standard input, one per line, instead of from the command-line. -z The output format is modified to be machine-parsable. If --stdin is also given, input paths are separated with a NUL character instead of a linefeed character. --source=<tree-ish> Check attributes against the specified tree-ish. It is common to specify the source tree by naming a commit, branch or tag associated with it. -- Interpret all preceding arguments as attributes and all following arguments as path names. If none of --stdin, --all, or -- is used, the first argument will be treated as an attribute and the rest of the arguments as pathnames. "
  },
  {
    "command": "tr",
    "description": " The tr utility shall copy the standard input to the standard output with substitution or deletion of selected characters. The options specified and the string1 and string2 operands shall control translations that occur while copying characters and single-character collating elements. The tr utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -c Complement the set of values specified by string1. See the EXTENDED DESCRIPTION section. -C Complement the set of characters specified by string1. See the EXTENDED DESCRIPTION section. -d Delete all occurrences of input characters that are specified by string1. -s Replace instances of repeated characters with a single character, as described in the EXTENDED DESCRIPTION section. "
  },
  {
    "command": "cp",
    "description": " Copy SOURCE to DEST, or multiple SOURCE(s) to DIRECTORY. Mandatory arguments to long options are mandatory for short options too. -a, --archive same as -dR --preserve=all --attributes-only don't copy the file data, just the attributes --backup[=CONTROL] make a backup of each existing destination file -b like --backup but does not accept an argument --copy-contents copy contents of special files when recursive -d same as --no-dereference --preserve=links --debug explain how a file is copied. Implies -v -f, --force if an existing destination file cannot be opened, remove it and try again (this option is ignored when the -n option is also used) -i, --interactive prompt before overwrite (overrides a previous -n option) -H follow command-line symbolic links in SOURCE -l, --link hard link files instead of copying -L, --dereference always follow symbolic links in SOURCE -n, --no-clobber do not overwrite an existing file (overrides a -u or previous -i option). See also --update -P, --no-dereference never follow symbolic links in SOURCE -p same as --preserve=mode,ownership,timestamps --preserve[=ATTR_LIST] preserve the specified attributes --no-preserve=ATTR_LIST don't preserve the specified attributes --parents use full source file name under DIRECTORY -R, -r, --recursive copy directories recursively --reflink[=WHEN] control clone/CoW copies. See below --remove-destination remove each existing destination file before attempting to open it (contrast with --force) --sparse=WHEN control creation of sparse files. See below --strip-trailing-slashes remove any trailing slashes from each SOURCE argument -s, --symbolic-link make symbolic links instead of copying -S, --suffix=SUFFIX override the usual backup suffix -t, --target-directory=DIRECTORY copy all SOURCE arguments into DIRECTORY -T, --no-target-directory treat DEST as a normal file --update[=UPDATE] control which existing files are updated; UPDATE={all,none,older(default)}. See below -u equivalent to --update[=older] -v, --verbose explain what is being done -x, --one-file-system stay on this file system -Z set SELinux security context of destination file to default type --context[=CTX] like -Z, or if CTX is specified then set the SELinux or SMACK security context to CTX --help display this help and exit --version output version information and exit ATTR_LIST is a comma-separated list of attributes. Attributes are 'mode' for permissions (including any ACL and xattr permissions), 'ownership' for user and group, 'timestamps' for file timestamps, 'links' for hard links, 'context' for security context, 'xattr' for extended attributes, and 'all' for all attributes. By default, sparse SOURCE files are detected by a crude heuristic and the corresponding DEST file is made sparse as well. That is the behavior selected by --sparse=auto. Specify --sparse=always to create a sparse DEST file whenever the SOURCE file contains a long enough sequence of zero bytes. Use --sparse=never to inhibit creation of sparse files. UPDATE controls which existing files in the destination are replaced. 'all' is the default operation when an --update option is not specified, and results in all existing files in the destination being replaced. 'none' is similar to the --no-clobber option, in that no files in the destination are replaced, but also skipped files do not induce a failure. 'older' is the default operation when --update is specified, and results in files being replaced if they're older than the corresponding source file. When --reflink[=always] is specified, perform a lightweight copy, where the data blocks are copied only when modified. If this is not possible the copy fails, or if --reflink=auto is specified, fall back to a standard copy. Use --reflink=never to ensure a standard copy is performed. The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX. The version control method may be selected via the --backup option or through the VERSION_CONTROL environment variable. Here are the values: none, off never make backups (even if --backup is given) numbered, t make numbered backups existing, nil numbered if numbered backups exist, simple otherwise simple, never always make simple backups As a special case, cp makes a backup of SOURCE when the force and backup options are given and SOURCE and DEST are the same name for an existing, regular file. "
  },
  {
    "command": "git-push",
    "description": " Updates remote refs using local refs, while sending objects necessary to complete the given refs. You can make interesting things happen to a repository every time you push into it, by setting up hooks there. See documentation for git-receive-pack(1). When the command line does not specify where to push with the <repository> argument, branch.*.remote configuration for the current branch is consulted to determine where to push. If the configuration is missing, it defaults to origin. When the command line does not specify what to push with <refspec>... arguments or --all, --mirror, --tags options, the command finds the default <refspec> by consulting remote.*.push configuration, and if it is not found, honors push.default configuration to decide what to push (See git-config(1) for the meaning of push.default). When neither the command-line nor the configuration specify what to push, the default behavior is used, which corresponds to the simple value for push.default: the current branch is pushed to the corresponding upstream branch, but as a safety measure, the push is aborted if the upstream branch does not have the same name as the local one. <repository> The \"remote\" repository that is destination of a push operation. This parameter can be either a URL (see the section GIT URLS below) or the name of a remote (see the section REMOTES below). <refspec>... Specify what destination ref to update with what source object. The format of a <refspec> parameter is an optional plus +, followed by the source object <src>, followed by a colon :, followed by the destination ref <dst>. The <src> is often the name of the branch you would want to push, but it can be any arbitrary \"SHA-1 expression\", such as master~4 or HEAD (see gitrevisions(7)). The <dst> tells which ref on the remote side is updated with this push. Arbitrary expressions cannot be used here, an actual ref must be named. If git push [<repository>] without any <refspec> argument is set to update some ref at the destination with <src> with remote.<repository>.push configuration variable, :<dst> part can be omitted\u2014such a push will update a ref that <src> normally updates without any <refspec> on the command line. Otherwise, missing :<dst> means to update the same ref as the <src>. If <dst> doesn\u2019t start with refs/ (e.g. refs/heads/master) we will try to infer where in refs/* on the destination <repository> it belongs based on the type of <src> being pushed and whether <dst> is ambiguous. \u2022 If <dst> unambiguously refers to a ref on the <repository> remote, then push to that ref. \u2022 If <src> resolves to a ref starting with refs/heads/ or refs/tags/, then prepend that to <dst>. \u2022 Other ambiguity resolutions might be added in the future, but for now any other cases will error out with an error indicating what we tried, and depending on the advice.pushUnqualifiedRefname configuration (see git-config(1)) suggest what refs/ namespace you may have wanted to push to. The object referenced by <src> is used to update the <dst> reference on the remote side. Whether this is allowed depends on where in refs/* the <dst> reference lives as described in detail below, in those sections \"update\" means any modifications except deletes, which as noted after the next few sections are treated differently. The refs/heads/* namespace will only accept commit objects, and updates only if they can be fast-forwarded. The refs/tags/* namespace will accept any kind of object (as commits, trees and blobs can be tagged), and any updates to them will be rejected. It\u2019s possible to push any type of object to any namespace outside of refs/{tags,heads}/*. In the case of tags and commits, these will be treated as if they were the commits inside refs/heads/* for the purposes of whether the update is allowed. I.e. a fast-forward of commits and tags outside refs/{tags,heads}/* is allowed, even in cases where what\u2019s being fast-forwarded is not a commit, but a tag object which happens to point to a new commit which is a fast-forward of the commit the last tag (or commit) it\u2019s replacing. Replacing a tag with an entirely different tag is also allowed, if it points to the same commit, as well as pushing a peeled tag, i.e. pushing the commit that existing tag object points to, or a new tag object which an existing commit points to. Tree and blob objects outside of refs/{tags,heads}/* will be treated the same way as if they were inside refs/tags/*, any update of them will be rejected. All of the rules described above about what\u2019s not allowed as an update can be overridden by adding an the optional leading + to a refspec (or using --force command line option). The only exception to this is that no amount of forcing will make the refs/heads/* namespace accept a non-commit object. Hooks and configuration can also override or amend these rules, see e.g. receive.denyNonFastForwards in git-config(1) and pre-receive and update in githooks(5). Pushing an empty <src> allows you to delete the <dst> ref from the remote repository. Deletions are always accepted without a leading + in the refspec (or --force), except when forbidden by configuration or hooks. See receive.denyDeletes in git-config(1) and pre-receive and update in githooks(5). The special refspec : (or +: to allow non-fast-forward updates) directs Git to push \"matching\" branches: for every branch that exists on the local side, the remote side is updated if a branch of the same name already exists on the remote side. tag <tag> means the same as refs/tags/<tag>:refs/tags/<tag>. --all, --branches Push all branches (i.e. refs under refs/heads/); cannot be used with other <refspec>. --prune Remove remote branches that don\u2019t have a local counterpart. For example a remote branch tmp will be removed if a local branch with the same name doesn\u2019t exist any more. This also respects refspecs, e.g. git push --prune remote refs/heads/*:refs/tmp/* would make sure that remote refs/tmp/foo will be removed if refs/heads/foo doesn\u2019t exist. --mirror Instead of naming each ref to push, specifies that all refs under refs/ (which includes but is not limited to refs/heads/, refs/remotes/, and refs/tags/) be mirrored to the remote repository. Newly created local refs will be pushed to the remote end, locally updated refs will be force updated on the remote end, and deleted refs will be removed from the remote end. This is the default if the configuration option remote.<remote>.mirror is set. -n, --dry-run Do everything except actually send the updates. --porcelain Produce machine-readable output. The output status line for each ref will be tab-separated and sent to stdout instead of stderr. The full symbolic names of the refs will be given. -d, --delete All listed refs are deleted from the remote repository. This is the same as prefixing all refs with a colon. --tags All refs under refs/tags are pushed, in addition to refspecs explicitly listed on the command line. --follow-tags Push all the refs that would be pushed without this option, and also push annotated tags in refs/tags that are missing from the remote but are pointing at commit-ish that are reachable from the refs being pushed. This can also be specified with configuration variable push.followTags. For more information, see push.followTags in git-config(1). --[no-]signed, --signed=(true|false|if-asked) GPG-sign the push request to update refs on the receiving side, to allow it to be checked by the hooks and/or be logged. If false or --no-signed, no signing will be attempted. If true or --signed, the push will fail if the server does not support signed pushes. If set to if-asked, sign if and only if the server supports signed pushes. The push will also fail if the actual call to gpg --sign fails. See git-receive-pack(1) for the details on the receiving end. --[no-]atomic Use an atomic transaction on the remote side if available. Either all refs are updated, or on error, no refs are updated. If the server does not support atomic pushes the push will fail. -o <option>, --push-option=<option> Transmit the given string to the server, which passes them to the pre-receive as well as the post-receive hook. The given string must not contain a NUL or LF character. When multiple --push-option=<option> are given, they are all sent to the other side in the order listed on the command line. When no --push-option=<option> is given from the command line, the values of configuration variable push.pushOption are used instead. --receive-pack=<git-receive-pack>, --exec=<git-receive-pack> Path to the git-receive-pack program on the remote end. Sometimes useful when pushing to a remote repository over ssh, and you do not have the program in a directory on the default $PATH. --[no-]force-with-lease, --force-with-lease=<refname>, --force-with-lease=<refname>:<expect> Usually, \"git push\" refuses to update a remote ref that is not an ancestor of the local ref used to overwrite it. This option overrides this restriction if the current value of the remote ref is the expected value. \"git push\" fails otherwise. Imagine that you have to rebase what you have already published. You will have to bypass the \"must fast-forward\" rule in order to replace the history you originally published with the rebased history. If somebody else built on top of your original history while you are rebasing, the tip of the branch at the remote may advance with their commit, and blindly pushing with --force will lose their work. This option allows you to say that you expect the history you are updating is what you rebased and want to replace. If the remote ref still points at the commit you specified, you can be sure that no other people did anything to the ref. It is like taking a \"lease\" on the ref without explicitly locking it, and the remote ref is updated only if the \"lease\" is still valid. --force-with-lease alone, without specifying the details, will protect all remote refs that are going to be updated by requiring their current value to be the same as the remote-tracking branch we have for them. --force-with-lease=<refname>, without specifying the expected value, will protect the named ref (alone), if it is going to be updated, by requiring its current value to be the same as the remote-tracking branch we have for it. --force-with-lease=<refname>:<expect> will protect the named ref (alone), if it is going to be updated, by requiring its current value to be the same as the specified value <expect> (which is allowed to be different from the remote-tracking branch we have for the refname, or we do not even have to have such a remote-tracking branch when this form is used). If <expect> is the empty string, then the named ref must not already exist. Note that all forms other than --force-with-lease=<refname>:<expect> that specifies the expected current value of the ref explicitly are still experimental and their semantics may change as we gain experience with this feature. \"--no-force-with-lease\" will cancel all the previous --force-with-lease on the command line. A general note on safety: supplying this option without an expected value, i.e. as --force-with-lease or --force-with-lease=<refname> interacts very badly with anything that implicitly runs git fetch on the remote to be pushed to in the background, e.g. git fetch origin on your repository in a cronjob. The protection it offers over --force is ensuring that subsequent changes your work wasn\u2019t based on aren\u2019t clobbered, but this is trivially defeated if some background process is updating refs in the background. We don\u2019t have anything except the remote tracking info to go by as a heuristic for refs you\u2019re expected to have seen & are willing to clobber. If your editor or some other system is running git fetch in the background for you a way to mitigate this is to simply set up another remote: git remote add origin-push $(git config remote.origin.url) git fetch origin-push Now when the background process runs git fetch origin the references on origin-push won\u2019t be updated, and thus commands like: git push --force-with-lease origin-push Will fail unless you manually run git fetch origin-push. This method is of course entirely defeated by something that runs git fetch --all, in that case you\u2019d need to either disable it or do something more tedious like: git fetch # update 'master' from remote git tag base master # mark our base point git rebase -i master # rewrite some commits git push --force-with-lease=master:base master:master I.e. create a base tag for versions of the upstream code that you\u2019ve seen and are willing to overwrite, then rewrite history, and finally force push changes to master if the remote version is still at base, regardless of what your local remotes/origin/master has been updated to in the background. Alternatively, specifying --force-if-includes as an ancillary option along with --force-with-lease[=<refname>] (i.e., without saying what exact commit the ref on the remote side must be pointing at, or which refs on the remote side are being protected) at the time of \"push\" will verify if updates from the remote-tracking refs that may have been implicitly updated in the background are integrated locally before allowing a forced update. -f, --force Usually, the command refuses to update a remote ref that is not an ancestor of the local ref used to overwrite it. Also, when --force-with-lease option is used, the command refuses to update a remote ref whose current value does not match what is expected. This flag disables these checks, and can cause the remote repository to lose commits; use it with care. Note that --force applies to all the refs that are pushed, hence using it with push.default set to matching or with multiple push destinations configured with remote.*.push may overwrite refs other than the current branch (including local refs that are strictly behind their remote counterpart). To force a push to only one branch, use a + in front of the refspec to push (e.g git push origin +master to force a push to the master branch). See the <refspec>... section above for details. --[no-]force-if-includes Force an update only if the tip of the remote-tracking ref has been integrated locally. This option enables a check that verifies if the tip of the remote-tracking ref is reachable from one of the \"reflog\" entries of the local branch based in it for a rewrite. The check ensures that any updates from the remote have been incorporated locally by rejecting the forced update if that is not the case. If the option is passed without specifying --force-with-lease, or specified along with --force-with-lease=<refname>:<expect>, it is a \"no-op\". Specifying --no-force-if-includes disables this behavior. --repo=<repository> This option is equivalent to the <repository> argument. If both are specified, the command-line argument takes precedence. -u, --set-upstream For every branch that is up to date or successfully pushed, add upstream (tracking) reference, used by argument-less git-pull(1) and other commands. For more information, see branch.<name>.merge in git-config(1). --[no-]thin These options are passed to git-send-pack(1). A thin transfer significantly reduces the amount of sent data when the sender and receiver share many of the same objects in common. The default is --thin. -q, --quiet Suppress all output, including the listing of updated refs, unless an error occurs. Progress is not reported to the standard error stream. -v, --verbose Run verbosely. --progress Progress status is reported on the standard error stream by default when it is attached to a terminal, unless -q is specified. This flag forces progress status even if the standard error stream is not directed to a terminal. --no-recurse-submodules, --recurse-submodules=check|on-demand|only|no May be used to make sure all submodule commits used by the revisions to be pushed are available on a remote-tracking branch. If check is used Git will verify that all submodule commits that changed in the revisions to be pushed are available on at least one remote of the submodule. If any commits are missing the push will be aborted and exit with non-zero status. If on-demand is used all submodules that changed in the revisions to be pushed will be pushed. If on-demand was not able to push all necessary revisions it will also be aborted and exit with non-zero status. If only is used all submodules will be pushed while the superproject is left unpushed. A value of no or using --no-recurse-submodules can be used to override the push.recurseSubmodules configuration variable when no submodule recursion is required. When using on-demand or only, if a submodule has a \"push.recurseSubmodules={on-demand,only}\" or \"submodule.recurse\" configuration, further recursion will occur. In this case, \"only\" is treated as \"on-demand\". --[no-]verify Toggle the pre-push hook (see githooks(5)). The default is --verify, giving the hook a chance to prevent the push. With --no-verify, the hook is bypassed completely. -4, --ipv4 Use IPv4 addresses only, ignoring IPv6 addresses. -6, --ipv6 Use IPv6 addresses only, ignoring IPv4 addresses. "
  },
  {
    "command": "lpstat",
    "description": " lpstat displays status information about the current classes, jobs, and printers. When run with no arguments, lpstat will list active jobs queued by the current user. The lpstat command supports the following options: -E Forces encryption when connecting to the server. -H Shows the server hostname and port. -R Shows the ranking of print jobs. -U username Specifies an alternate username. -W which-jobs Specifies which jobs to show, \"completed\" or \"not-completed\" (the default). This option must appear before the -o option and/or any printer names, otherwise the default (\"not- completed\") value will be used in the request to the scheduler. -a [printer(s)] Shows the accepting state of printer queues. If no printers are specified then all printers are listed. -c [class(es)] Shows the printer classes and the printers that belong to them. If no classes are specified then all classes are listed. -d Shows the current default destination. -e Shows all available destinations on the local network. -h server[:port] Specifies an alternate server. -l Shows a long listing of printers, classes, or jobs. -o [destination(s)] Shows the jobs queued on the specified destinations. If no destinations are specified all jobs are shown. -p [printer(s)] Shows the printers and whether they are enabled for printing. If no printers are specified then all printers are listed. -r Shows whether the CUPS server is running. -s Shows a status summary, including the default destination, a list of classes and their member printers, and a list of printers and their associated devices. This is equivalent to using the -d, -c, and -v options. -t Shows all status information. This is equivalent to using the -r, -d, -c, -v, -a, -p, and -o options. -u [user(s)] Shows a list of print jobs queued by the specified users. If no users are specified, lists the jobs queued by the current user. -v [printer(s)] Shows the printers and what device they are attached to. If no printers are specified then all printers are listed. "
  },
  {
    "command": "find",
    "description": " This manual page documents the GNU version of find. GNU find searches the directory tree rooted at each given starting-point by evaluating the given expression from left to right, according to the rules of precedence (see section OPERATORS), until the outcome is known (the left hand side is false for and operations, true for or), at which point find moves on to the next file name. If no starting-point is specified, `.' is assumed. If you are using find in an environment where security is important (for example if you are using it to search directories that are writable by other users), you should read the `Security Considerations' chapter of the findutils documentation, which is called Finding Files and comes with findutils. That document also includes a lot more detail and discussion than this manual page, so you may find it a more useful source of information. The -H, -L and -P options control the treatment of symbolic links. Command-line arguments following these are taken to be names of files or directories to be examined, up to the first argument that begins with `-', or the argument `(' or `!'. That argument and any following arguments are taken to be the expression describing what is to be searched for. If no paths are given, the current directory is used. If no expression is given, the expression -print is used (but you should probably consider using -print0 instead, anyway). This manual page talks about `options' within the expression list. These options control the behaviour of find but are specified immediately after the last path name. The five `real' options -H, -L, -P, -D and -O must appear before the first path name, if at all. A double dash -- could theoretically be used to signal that any remaining arguments are not options, but this does not really work due to the way find determines the end of the following path arguments: it does that by reading until an expression argument comes (which also starts with a `-'). Now, if a path argument would start with a `-', then find would treat it as expression argument instead. Thus, to ensure that all start points are taken as such, and especially to prevent that wildcard patterns expanded by the calling shell are not mistakenly treated as expression arguments, it is generally safer to prefix wildcards or dubious path names with either `./' or to use absolute path names starting with '/'. Alternatively, it is generally safe though non-portable to use the GNU option -files0-from to pass arbitrary starting points to find. -P Never follow symbolic links. This is the default behaviour. When find examines or prints information about files, and the file is a symbolic link, the information used shall be taken from the properties of the symbolic link itself. -L Follow symbolic links. When find examines or prints information about files, the information used shall be taken from the properties of the file to which the link points, not from the link itself (unless it is a broken symbolic link or find is unable to examine the file to which the link points). Use of this option implies -noleaf. If you later use the -P option, -noleaf will still be in effect. If -L is in effect and find discovers a symbolic link to a subdirectory during its search, the subdirectory pointed to by the symbolic link will be searched. When the -L option is in effect, the -type predicate will always match against the type of the file that a symbolic link points to rather than the link itself (unless the symbolic link is broken). Actions that can cause symbolic links to become broken while find is executing (for example -delete) can give rise to confusing behaviour. Using -L causes the -lname and -ilname predicates always to return false. -H Do not follow symbolic links, except while processing the command line arguments. When find examines or prints information about files, the information used shall be taken from the properties of the symbolic link itself. The only exception to this behaviour is when a file specified on the command line is a symbolic link, and the link can be resolved. For that situation, the information used is taken from whatever the link points to (that is, the link is followed). The information about the link itself is used as a fallback if the file pointed to by the symbolic link cannot be examined. If -H is in effect and one of the paths specified on the command line is a symbolic link to a directory, the contents of that directory will be examined (though of course -maxdepth 0 would prevent this). If more than one of -H, -L and -P is specified, each overrides the others; the last one appearing on the command line takes effect. Since it is the default, the -P option should be considered to be in effect unless either -H or -L is specified. GNU find frequently stats files during the processing of the command line itself, before any searching has begun. These options also affect how those arguments are processed. Specifically, there are a number of tests that compare files listed on the command line against a file we are currently considering. In each case, the file specified on the command line will have been examined and some of its properties will have been saved. If the named file is in fact a symbolic link, and the -P option is in effect (or if neither -H nor -L were specified), the information used for the comparison will be taken from the properties of the symbolic link. Otherwise, it will be taken from the properties of the file the link points to. If find cannot follow the link (for example because it has insufficient privileges or the link points to a nonexistent file) the properties of the link itself will be used. When the -H or -L options are in effect, any symbolic links listed as the argument of -newer will be dereferenced, and the timestamp will be taken from the file to which the symbolic link points. The same consideration applies to -newerXY, -anewer and -cnewer. The -follow option has a similar effect to -L, though it takes effect at the point where it appears (that is, if -L is not used but -follow is, any symbolic links appearing after -follow on the command line will be dereferenced, and those before it will not). -D debugopts Print diagnostic information; this can be helpful to diagnose problems with why find is not doing what you want. The list of debug options should be comma separated. Compatibility of the debug options is not guaranteed between releases of findutils. For a complete list of valid debug options, see the output of find -D help. Valid debug options include exec Show diagnostic information relating to -exec, -execdir, -ok and -okdir opt Prints diagnostic information relating to the optimisation of the expression tree; see the -O option. rates Prints a summary indicating how often each predicate succeeded or failed. search Navigate the directory tree verbosely. stat Print messages as files are examined with the stat and lstat system calls. The find program tries to minimise such calls. tree Show the expression tree in its original and optimised form. all Enable all of the other debug options (but help). help Explain the debugging options. -Olevel Enables query optimisation. The find program reorders tests to speed up execution while preserving the overall effect; that is, predicates with side effects are not reordered relative to each other. The optimisations performed at each optimisation level are as follows. 0 Equivalent to optimisation level 1. 1 This is the default optimisation level and corresponds to the traditional behaviour. Expressions are reordered so that tests based only on the names of files (for example -name and -regex) are performed first. 2 Any -type or -xtype tests are performed after any tests based only on the names of files, but before any tests that require information from the inode. On many modern versions of Unix, file types are returned by readdir() and so these predicates are faster to evaluate than predicates which need to stat the file first. If you use the -fstype FOO predicate and specify a filesystem type FOO which is not known (that is, present in `/etc/mtab') at the time find starts, that predicate is equivalent to -false. 3 At this optimisation level, the full cost-based query optimiser is enabled. The order of tests is modified so that cheap (i.e. fast) tests are performed first and more expensive ones are performed later, if necessary. Within each cost band, predicates are evaluated earlier or later according to whether they are likely to succeed or not. For -o, predicates which are likely to succeed are evaluated earlier, and for -a, predicates which are likely to fail are evaluated earlier. The cost-based optimiser has a fixed idea of how likely any given test is to succeed. In some cases the probability takes account of the specific nature of the test (for example, -type f is assumed to be more likely to succeed than -type c). The cost-based optimiser is currently being evaluated. If it does not actually improve the performance of find, it will be removed again. Conversely, optimisations that prove to be reliable, robust and effective may be enabled at lower optimisation levels over time. However, the default behaviour (i.e. optimisation level 1) will not be changed in the 4.3.x release series. The findutils test suite runs all the tests on find at each optimisation level and ensures that the result is the same. "
  },
  {
    "command": "flock",
    "description": " This utility manages flock(2) locks from within shell scripts or from the command line. The first and second of the above forms wrap the lock around the execution of a command, in a manner similar to su(1) or newgrp(1). They lock a specified file or directory, which is created (assuming appropriate permissions) if it does not already exist. By default, if the lock cannot be immediately acquired, flock waits until the lock is available. The third form uses an open file by its file descriptor number. See the examples below for how that can be used. -c, --command command Pass a single command, without arguments, to the shell with -c. -E, --conflict-exit-code number The exit status used when the -n option is in use, and the conflicting lock exists, or the -w option is in use, and the timeout is reached. The default value is 1. The number has to be in the range of 0 to 255. -F, --no-fork Do not fork before executing command. Upon execution the flock process is replaced by command which continues to hold the lock. This option is incompatible with --close as there would otherwise be nothing left to hold the lock. -e, -x, --exclusive Obtain an exclusive lock, sometimes called a write lock. This is the default. -n, --nb, --nonblock Fail rather than wait if the lock cannot be immediately acquired. See the -E option for the exit status used. -o, --close Close the file descriptor on which the lock is held before executing command. This is useful if command spawns a child process which should not be holding the lock. -s, --shared Obtain a shared lock, sometimes called a read lock. -u, --unlock Drop a lock. This is usually not required, since a lock is automatically dropped when the file is closed. However, it may be required in special cases, for example if the enclosed command group may have forked a background process which should not be holding the lock. -w, --wait, --timeout seconds Fail if the lock cannot be acquired within seconds. Decimal fractional values are allowed. See the -E option for the exit status used. The zero number of seconds is interpreted as --nonblock. --verbose Report how long it took to acquire the lock, or why the lock could not be obtained. -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "ssh-add",
    "description": " ssh-add adds private key identities to the authentication agent, ssh-agent(1). When run without arguments, it adds the files ~/.ssh/id_rsa, ~/.ssh/id_ecdsa, ~/.ssh/id_ecdsa_sk, ~/.ssh/id_ed25519, ~/.ssh/id_ed25519_sk, and ~/.ssh/id_dsa. After loading a private key, ssh-add will try to load corresponding certificate information from the filename obtained by appending -cert.pub to the name of the private key file. Alternative file names can be given on the command line. If any file requires a passphrase, ssh-add asks for the passphrase from the user. The passphrase is read from the user's tty. ssh-add retries the last passphrase if multiple identity files are given. The authentication agent must be running and the SSH_AUTH_SOCK environment variable must contain the name of its socket for ssh-add to work. The options are as follows: -c Indicates that added identities should be subject to confirmation before being used for authentication. Confirmation is performed by ssh-askpass(1). Successful confirmation is signaled by a zero exit status from ssh-askpass(1), rather than text entered into the requester. -D Deletes all identities from the agent. -d Instead of adding identities, removes identities from the agent. If ssh-add has been run without arguments, the keys for the default identities and their corresponding certificates will be removed. Otherwise, the argument list will be interpreted as a list of paths to public key files to specify keys and certificates to be removed from the agent. If no public key is found at a given path, ssh-add will append .pub and retry. If the argument list consists of \u201c-\u201d then ssh-add will read public keys to be removed from standard input. -E fingerprint_hash Specifies the hash algorithm used when displaying key fingerprints. Valid options are: \u201cmd5\u201d and \u201csha256\u201d. The default is \u201csha256\u201d. -e pkcs11 Remove keys provided by the PKCS#11 shared library pkcs11. -H hostkey_file Specifies a known hosts file to look up hostkeys when using destination-constrained keys via the -h flag. This option may be specified multiple times to allow multiple files to be searched. If no files are specified, ssh-add will use the default ssh_config(5) known hosts files: ~/.ssh/known_hosts, ~/.ssh/known_hosts2, /etc/ssh/ssh_known_hosts, and /etc/ssh/ssh_known_hosts2. -h destination_constraint When adding keys, constrain them to be usable only through specific hosts or to specific destinations. Destination constraints of the form \u2018[user@]dest-hostname\u2019 permit use of the key only from the origin host (the one running ssh-agent(1)) to the listed destination host, with optional user name. Constraints of the form \u2018src-hostname>[user@]dst-hostname\u2019 allow a key available on a forwarded ssh-agent(1) to be used through a particular host (as specified by \u2018src-hostname\u2019) to authenticate to a further host, specified by \u2018dst-hostname\u2019. Multiple destination constraints may be added when loading keys. When attempting authentication with a key that has destination constraints, the whole connection path, including ssh-agent(1) forwarding, is tested against those constraints and each hop must be permitted for the attempt to succeed. For example, if key is forwarded to a remote host, \u2018host-b\u2019, and is attempting authentication to another host, \u2018host-c\u2019, then the operation will be successful only if \u2018host-b\u2019 was permitted from the origin host and the subsequent \u2018host-b>host-c\u2019 hop is also permitted by destination constraints. Hosts are identified by their host keys, and are looked up from known hosts files by ssh-add. Wildcards patterns may be used for hostnames and certificate host keys are supported. By default, keys added by ssh-add are not destination constrained. Destination constraints were added in OpenSSH release 8.9. Support in both the remote SSH client and server is required when using destination-constrained keys over a forwarded ssh-agent(1) channel. It is also important to note that destination constraints can only be enforced by ssh-agent(1) when a key is used, or when it is forwarded by a cooperating ssh(1). Specifically, it does not prevent an attacker with access to a remote SSH_AUTH_SOCK from forwarding it again and using it on a different host (but only to a permitted destination). -K Load resident keys from a FIDO authenticator. -k When loading keys into or deleting keys from the agent, process plain private keys only and skip certificates. -L Lists public key parameters of all identities currently represented by the agent. -l Lists fingerprints of all identities currently represented by the agent. -q Be quiet after a successful operation. -S provider Specifies a path to a library that will be used when adding FIDO authenticator-hosted keys, overriding the default of using the internal USB HID support. -s pkcs11 Add keys provided by the PKCS#11 shared library pkcs11. -T pubkey ... Tests whether the private keys that correspond to the specified pubkey files are usable by performing sign and verify operations on each. -t life Set a maximum lifetime when adding identities to an agent. The lifetime may be specified in seconds or in a time format specified in sshd_config(5). -v Verbose mode. Causes ssh-add to print debugging messages about its progress. This is helpful in debugging problems. Multiple -v options increase the verbosity. The maximum is 3. -X Unlock the agent. -x Lock the agent with a password. "
  },
  {
    "command": "git-show-branch",
    "description": " Shows the commit ancestry graph starting from the commits named with <rev>s or <glob>s (or all refs under refs/heads and/or refs/tags) semi-visually. It cannot show more than 29 branches and commits at a time. It uses showbranch.default multi-valued configuration items if no <rev> or <glob> is given on the command line. <rev> Arbitrary extended SHA-1 expression (see gitrevisions(7)) that typically names a branch head or a tag. <glob> A glob pattern that matches branch or tag names under refs/. For example, if you have many topic branches under refs/heads/topic, giving topic/* would show all of them. -r, --remotes Show the remote-tracking branches. -a, --all Show both remote-tracking branches and local branches. --current With this option, the command includes the current branch to the list of revs to be shown when it is not given on the command line. --topo-order By default, the branches and their commits are shown in reverse chronological order. This option makes them appear in topological order (i.e., descendant commits are shown before their parents). --date-order This option is similar to --topo-order in the sense that no parent comes before all of its children, but otherwise commits are ordered according to their commit date. --sparse By default, the output omits merges that are reachable from only one tip being shown. This option makes them visible. --more=<n> Usually the command stops output upon showing the commit that is the common ancestor of all the branches. This flag tells the command to go <n> more common commits beyond that. When <n> is negative, display only the <ref>s given, without showing the commit ancestry tree. --list Synonym to --more=-1 --merge-base Instead of showing the commit list, determine possible merge bases for the specified commits. All merge bases will be contained in all specified commits. This is different from how git-merge-base(1) handles the case of three or more commits. --independent Among the <ref>s given, display only the ones that cannot be reached from any other <ref>. --no-name Do not show naming strings for each commit. --sha1-name Instead of naming the commits using the path to reach them from heads (e.g. \"master~2\" to mean the grandparent of \"master\"), name them with the unique prefix of their object names. --topics Shows only commits that are NOT on the first branch given. This helps track topic branches by hiding any commit that is already in the main line of development. When given \"git show-branch --topics master topic1 topic2\", this will show the revisions given by \"git rev-list ^master topic1 topic2\" -g, --reflog[=<n>[,<base>]] [<ref>] Shows <n> most recent ref-log entries for the given ref. If <base> is given, <n> entries going back from that entry. <base> can be specified as count or date. When no explicit <ref> parameter is given, it defaults to the current branch (or HEAD if it is detached). --color[=<when>] Color the status sign (one of these: * ! + -) of each commit corresponding to the branch it\u2019s in. The value must be always (the default), never, or auto. --no-color Turn off colored output, even when the configuration file gives the default to color output. Same as --color=never. Note that --more, --list, --independent and --merge-base options are mutually exclusive. "
  },
  {
    "command": "gawk",
    "description": " Gawk is the GNU Project's implementation of the AWK programming language. It conforms to the definition of the language in the POSIX 1003.1 standard. This version in turn is based on the description in The AWK Programming Language, by Aho, Kernighan, and Weinberger. Gawk provides the additional features found in the current version of Brian Kernighan's awk and numerous GNU- specific extensions. The command line consists of options to gawk itself, the AWK program text (if not supplied via the -f or --include options), and values to be made available in the ARGC and ARGV pre-defined AWK variables. Gawk accepts the following options. Standard options are listed first, followed by options for gawk extensions, listed alphabetically by short option. -f program-file, --file program-file Read the AWK program source from the file program-file, instead of from the first command line argument. Multiple -f options may be used. Files read with -f are treated as if they begin with an implicit @namespace \"awk\" statement. -F fs, --field-separator fs Use fs for the input field separator (the value of the FS predefined variable). -v var=val, --assign var=val Assign the value val to the variable var, before execution of the program begins. Such variable values are available to the BEGIN rule of an AWK program. -b, --characters-as-bytes Treat all input data as single-byte characters. The --posix option overrides this one. -c, --traditional Run in compatibility mode. In compatibility mode, gawk behaves identically to Brian Kernighan's awk; none of the GNU-specific extensions are recognized. -C, --copyright Print the short version of the GNU copyright information message on the standard output and exit successfully. -d[file], --dump-variables[=file] Print a sorted list of global variables, their types and final values to file. The default file is awkvars.out in the current directory. -D[file], --debug[=file] Enable debugging of AWK programs. By default, the debugger reads commands interactively from the keyboard (standard input). The optional file argument specifies a file with a list of commands for the debugger to execute non-interactively. In this mode of execution, gawk loads the AWK source code and then prompts for debugging commands. Gawk can only debug AWK program source provided with the -f and --include options. The debugger is documented in GAWK: Effective AWK Programming; see https://www.gnu.org/software/gawk/manual/html_node/Debugger.html#Debugger . -e program-text, --source program-text Use program-text as AWK program source code. Each argument supplied via -e is treated as if it begins with an implicit @namespace \"awk\" statement. -E file, --exec file Similar to -f, however, this option is the last one processed. This should be used with #! scripts, particularly for CGI applications, to avoid passing in options or source code (!) on the command line from a URL. This option disables command-line variable assignments. -g, --gen-pot Scan and parse the AWK program, and generate a GNU .pot (Portable Object Template) format file on standard output with entries for all localizable strings in the program. The program itself is not executed. -h, --help Print a relatively short summary of the available options on the standard output. Per the GNU Coding Standards, these options cause an immediate, successful exit. -i include-file, --include include-file Load an awk source library. This searches for the library using the AWKPATH environment variable. If the initial search fails, another attempt will be made after appending the .awk suffix. The file will be loaded only once (i.e., duplicates are eliminated), and the code does not constitute the main program source. Files read with --include are treated as if they begin with an implicit @namespace \"awk\" statement. -I, --trace Print the internal byte code names as they are executed when running the program. The trace is printed to standard error. Each ``op code'' is preceded by a + sign in the output. -k, --csv Enable CSV special processing. See the manual for details. FIXME: eventually provide a URL here. -l lib, --load lib Load a gawk extension from the shared library lib. This searches for the library using the AWKLIBPATH environment variable. If the initial search fails, another attempt will be made after appending the default shared library suffix for the platform. The library initialization routine is expected to be named dl_load(). -L [value], --lint[=value] Provide warnings about constructs that are dubious or non- portable to other AWK implementations. See https://www.gnu.org/software/gawk/manual/html_node/Options.html#Options for the list of possible values for value. -M, --bignum Force arbitrary precision arithmetic on numbers. This option has no effect if gawk is not compiled to use the GNU MPFR and GMP libraries. (In such a case, gawk issues a warning.) NOTE: This feature is on parole. The primary gawk maintainer is no longer supporting it, although there is a member of the development team who is. If this situation changes, the feature will be removed from gawk. -n, --non-decimal-data Recognize octal and hexadecimal values in input data. Use this option with great caution! -N, --use-lc-numeric Force gawk to use the locale's decimal point character when parsing input data. -o[file], --pretty-print[=file] Output a pretty printed version of the program to file. The default file is awkprof.out in the current directory. This option implies --no-optimize. -O, --optimize Enable gawk's default optimizations upon the internal representation of the program. This option is on by default. -p[prof-file], --profile[=prof-file] Start a profiling session, and send the profiling data to prof-file. The default is awkprof.out in the current directory. The profile contains execution counts of each statement in the program in the left margin and function call counts for each user-defined function. Gawk runs more slowly in this mode. This option implies --no-optimize. -P, --posix This turns on compatibility mode, and disables a number of common extensions. -r, --re-interval Enable the use of interval expressions in regular expression matching. Interval expressions are enabled by default, but this option remains for backwards compatibility. -s, --no-optimize Disable gawk's default optimizations upon the internal representation of the program. -S, --sandbox Run gawk in sandbox mode, disabling the system() function, input redirection with getline, output redirection with print and printf, and loading dynamic extensions. Command execution (through pipelines) is also disabled. -t, --lint-old Provide warnings about constructs that are not portable to the original version of UNIX awk. -V, --version Print version information for this particular copy of gawk on the standard output. This is useful when reporting bugs. Per the GNU Coding Standards, these options cause an immediate, successful exit. -- Signal the end of options. This is useful to allow further arguments to the AWK program itself to start with a \u201c-\u201d. In compatibility mode, any other options are flagged as invalid, but are otherwise ignored. In normal operation, as long as program text has been supplied, unknown options are passed on to the AWK program in the ARGV array for processing. For POSIX compatibility, the -W option may be used, followed by the name of a long option. "
  },
  {
    "command": "trap",
    "description": " If the first operand is an unsigned decimal integer, the shell shall treat all operands as conditions, and shall reset each condition to the default value. Otherwise, if there are operands, the first is treated as an action and the remaining as conditions. If action is '-', the shell shall reset each condition to the default value. If action is null (\"\"), the shell shall ignore each specified condition if it arises. Otherwise, the argument action shall be read and executed by the shell when one of the corresponding conditions arises. The action of trap shall override a previous action (either default action or one explicitly set). The value of \"$?\" after the trap action completes shall be the value it had before trap was invoked. The condition can be EXIT, 0 (equivalent to EXIT), or a signal specified using a symbolic name, without the SIG prefix, as listed in the tables of signal names in the <signal.h> header defined in the Base Definitions volume of POSIX.1\u20102017, Chapter 13, Headers; for example, HUP, INT, QUIT, TERM. Implementations may permit names with the SIG prefix or ignore case in signal names as an extension. Setting a trap for SIGKILL or SIGSTOP produces undefined results. The environment in which the shell executes a trap on EXIT shall be identical to the environment immediately after the last command executed before the trap on EXIT was taken. Each time trap is invoked, the action argument shall be processed in a manner equivalent to: eval action Signals that were ignored on entry to a non-interactive shell cannot be trapped or reset, although no error need be reported when attempting to do so. An interactive shell may reset or catch signals ignored on entry. Traps shall remain in place for a given shell until explicitly changed with another trap command. When a subshell is entered, traps that are not being ignored shall be set to the default actions, except in the case of a command substitution containing only a single trap command, when the traps need not be altered. Implementations may check for this case using only lexical analysis; for example, if `trap` and $( trap -- ) do not alter the traps in the subshell, cases such as assigning var=trap and then using $($var) may still alter them. This does not imply that the trap command cannot be used within the subshell to set new traps. The trap command with no operands shall write to standard output a list of commands associated with each condition. If the command is executed in a subshell, the implementation does not perform the optional check described above for a command substitution containing only a single trap command, and no trap commands with operands have been executed since entry to the subshell, the list shall contain the commands that were associated with each condition immediately before the subshell environment was entered. Otherwise, the list shall contain the commands currently associated with each condition. The format shall be: \"trap -- %s %s ...\\n\", <action>, <condition> ... The shell shall format the output, including the proper use of quoting, so that it is suitable for reinput to the shell as commands that achieve the same trapping results. For example: save_traps=$(trap) ... eval \"$save_traps\" XSI-conformant systems also allow numeric signal numbers for the conditions corresponding to the following signal names: 1 SIGHUP 2 SIGINT 3 SIGQUIT 6 SIGABRT 9 SIGKILL 14 SIGALRM 15 SIGTERM The trap special built-in shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. None. "
  },
  {
    "command": "git-whatchanged",
    "description": " Shows commit logs and diff output each commit introduces. New users are encouraged to use git-log(1) instead. The whatchanged command is essentially the same as git-log(1) but defaults to show the raw format diff output and to skip merges. The command is kept primarily for historical reasons; fingers of many people who learned Git long before git log was invented by reading Linux kernel mailing list are trained to type it. "
  },
  {
    "command": "troff",
    "description": " GNU troff transforms groff(7) language input into the device- independent output format described in groff_out(5); troff is thus the heart of the GNU roff document formatting system. If no file operands are given on the command line, or if file is \u201c-\u201d, the standard input stream is read. GNU troff is functionally compatible with the AT&T troff typesetter and features numerous extensions. Many people prefer to use the groff(1) command, a front end which also runs preprocessors and output drivers in the appropriate order and with appropriate options. -h and --help display a usage message, while -v and --version show version information; all exit afterward. -a Generate a plain text approximation of the typeset output. The read-only register .A is set to 1. This option produces a sort of abstract preview of the formatted output. \u2022 Page breaks are marked by a phrase in angle brackets; for example, \u201c<beginning of page>\u201d. \u2022 Lines are broken where they would be in the formatted output. \u2022 A horizontal motion of any size is represented as one space. Adjacent horizontal motions are not combined. Inter-sentence space nodes (those arising from the second argument to the .ss request) are not represented. \u2022 Vertical motions are not represented. \u2022 Special characters are rendered in angle brackets; for example, the default soft hyphen character appears as \u201c<hy>\u201d. The above description should not be considered a specification; the details of -a output are subject to change. -b Write a backtrace reporting the state of troff's input parser to the standard error stream with each diagnostic message. The line numbers given in the backtrace might not always be correct, because troff's idea of line numbers can be confused by requests that append to macros. -c Start with color output disabled. -C Enable AT&T troff compatibility mode; implies -c. See groff_diff(7). -d ctext -d string=text Define roff string c or string as text. c must be one character; string can be of arbitrary length. Such string assignments happen before any macro file is loaded, including the startup file. Due to getopt_long(3) limitations, c cannot be, and string cannot contain, an equals sign, even though that is a valid character in a roff identifier. -E Inhibit troff error messages; implies -Ww. This option does not suppress messages sent to the standard error stream by documents or macro packages using tm or related requests. -f fam Use fam as the default font family. -F dir Search in directory dir for the selected output device's directory of device and font description files. See the description of GROFF_FONT_PATH in section \u201cEnvironment\u201d below for the default search locations and ordering. -i Read the standard input stream after all named input files have been processed. -I dir Search the directory dir for files (those named on the command line; in psbb, so, and soquiet requests; and in \u201c\\X'ps: import'\u201d, \u201c\\X'ps: file'\u201d, and \u201c\\X'pdf: pdfpic'\u201d device control escape sequences). -I may be specified more than once; each dir is searched in the given order. To search the current working directory before others, add \u201c-I .\u201d at the desired place; it is otherwise searched last. -I works similarly to, and is named for, the \u201cinclude\u201d option of Unix C compilers. -m name Process the file name.tmac prior to any input files. If not found, tmac.name is attempted. name (in both arrangements) is presumed to be a macro file; see the description of GROFF_TMAC_PATH in section \u201cEnvironment\u201d below for the default search locations and ordering. -M dir Search directory dir for macro files. See the description of GROFF_TMAC_PATH in section \u201cEnvironment\u201d below for the default search locations and ordering. -n num Begin numbering pages at num. The default is 1. -o list Output only pages in list, which is a comma-separated list of inclusive page ranges; n means page n, m-n means every page between m and n, -n means every page up to n, and n- means every page from n on. troff stops processing and exits after formatting the last page enumerated in list. -r cnumeric-expression -r register=numeric-expression Define roff register c or register as numeric-expression. c must be a one-character name; register can be of arbitrary length. Such register assignments happen before any macro file is loaded, including the startup file. Due to getopt_long(3) limitations, c cannot be, and register cannot contain, an equals sign, even though that is a valid character in a roff identifier. -R Don't load troffrc and troffrc-end. -T dev Prepare output for device dev. The default is ps; see groff(1). -U Operate in unsafe mode, enabling the open, opena, pi, pso, and sy requests, which are disabled by default because they allow an untrusted input document to write to arbitrary file names and run arbitrary commands. This option also adds the current directory to the macro package search path; see the -m and -M options above. -w name -W name Enable (-w) or inhibit (-W) warnings in category name. See section \u201cWarnings\u201d below. -z Suppress formatted output. "
  },
  {
    "command": "ar",
    "description": " The ar utility is part of the Software Development Utilities option. The ar utility can be used to create and maintain groups of files combined into an archive. Once an archive has been created, new files can be added, and existing files in an archive can be extracted, deleted, or replaced. When an archive consists entirely of valid object files, the implementation shall format the archive so that it is usable as a library for link editing (see c99 and fort77). When some of the archived files are not valid object files, the suitability of the archive for library use is undefined. If an archive consists entirely of printable files, the entire archive shall be printable. When ar creates an archive, it creates administrative information indicating whether a symbol table is present in the archive. When there is at least one object file that ar recognizes as such in the archive, an archive symbol table shall be created in the archive and maintained by ar; it is used by the link editor to search the archive. Whenever the ar utility is used to create or update the contents of such an archive, the symbol table shall be rebuilt. The -s option shall force the symbol table to be rebuilt. All file operands can be pathnames. However, files within archives shall be named by a filename, which is the last component of the pathname used when the file was entered into the archive. The comparison of file operands to the names of files in archives shall be performed by comparing the last component of the operand to the name of the file in the archive. It is unspecified whether multiple files in the archive may be identically named. In the case of such files, however, each file and posname operand shall match only the first file in the archive having a name that is the same as the last component of the operand. The ar utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for Guideline 9. The following options shall be supported: -a Position new files in the archive after the file named by the posname operand. -b Position new files in the archive before the file named by the posname operand. -c Suppress the diagnostic message that is written to standard error by default when the archive archive is created. -C Prevent extracted files from replacing like-named files in the file system. This option is useful when -T is also used, to prevent truncated filenames from replacing files with the same prefix. -d Delete one or more files from archive. -i Position new files in the archive before the file in the archive named by the posname operand (equivalent to -b). -m Move the named files in the archive. The -a, -b, or -i options with the posname operand indicate the position; otherwise, move the names files in the archive to the end of the archive. -p Write the contents of the files in the archive named by file operands from archive to the standard output. If no file operands are specified, the contents of all files in the archive shall be written in the order of the archive. -q Append the named files to the end of the archive. In this case ar does not check whether the added files are already in the archive. This is useful to bypass the searching otherwise done when creating a large archive piece by piece. -r Replace or add files to archive. If the archive named by archive does not exist, a new archive shall be created and a diagnostic message shall be written to standard error (unless the -c option is specified). If no files are specified and the archive exists, the results are undefined. Files that replace existing files in the archive shall not change the order of the archive. Files that do not replace existing files in the archive shall be appended to the archive unless a -a, -b, or -i option specifies another position. -s Force the regeneration of the archive symbol table even if ar is not invoked with an option that modifies the archive contents. This option is useful to restore the archive symbol table after it has been stripped; see strip. -t Write a table of contents of archive to the standard output. Only the files specified by the file operands shall be included in the written list. If no file operands are specified, all files in archive shall be included in the order of the archive. -T Allow filename truncation of extracted files whose archive names are longer than the file system can support. By default, extracting a file with a name that is too long shall be an error; a diagnostic message shall be written and the file shall not be extracted. -u Update older files in the archive. When used with the -r option, files in the archive shall be replaced only if the corresponding file has a modification time that is at least as new as the modification time of the file in the archive. -v Give verbose output. When used with the option characters -d, -r, or -x, write a detailed file-by-file description of the archive creation and maintenance activity, as described in the STDOUT section. When used with -p, write the name of the file in the archive to the standard output before writing the file in the archive itself to the standard output, as described in the STDOUT section. When used with -t, include a long listing of information about the files in the archive, as described in the STDOUT section. -x Extract the files in the archive named by the file operands from archive. The contents of the archive shall not be changed. If no file operands are given, all files in the archive shall be extracted. The modification time of each file extracted shall be set to the time the file is extracted from the archive. "
  },
  {
    "command": "hostnamectl",
    "description": " hostnamectl may be used to query and change the system hostname and related settings. systemd-hostnamed.service(8) and this tool distinguish three different hostnames: the high-level \"pretty\" hostname which might include all kinds of special characters (e.g. \"Lennart's Laptop\"), the \"static\" hostname which is the user-configured hostname (e.g. \"lennarts-laptop\"), and the transient hostname which is a fallback value received from network configuration (e.g. \"node12345678\"). If a static hostname is set to a valid value, then the transient hostname is not used. Note that the pretty hostname has little restrictions on the characters and length used, while the static and transient hostnames are limited to the usually accepted characters of Internet domain names, and 64 characters at maximum (the latter being a Linux limitation). Use systemd-firstboot(1) to initialize the system hostname for mounted (but not booted) system images. The following options are understood: --no-ask-password Do not query the user for authentication for privileged operations. --static, --transient, --pretty If status is invoked (or no explicit command is given) and one of these switches is specified, hostnamectl will print out just this selected hostname. If used with hostname, only the selected hostnames will be updated. When more than one of these switches are specified, all the specified hostnames will be updated. -H, --host= Execute the operation remotely. Specify a hostname, or a username and hostname separated by \"@\", to connect to. The hostname may optionally be suffixed by a port ssh is listening on, separated by \":\", and then a container name, separated by \"/\", which connects directly to a specific container on the specified host. This will use SSH to talk to the remote machine manager instance. Container names may be enumerated with machinectl -H HOST. Put IPv6 addresses in brackets. -M, --machine= Execute operation on a local container. Specify a container name to connect to, optionally prefixed by a user name to connect as and a separating \"@\" character. If the special string \".host\" is used in place of the container name, a connection to the local system is made (which is useful to connect to a specific user's user bus: \"--user --machine=lennart@.host\"). If the \"@\" syntax is not used, the connection is made as root user. If the \"@\" syntax is used either the left hand side or the right hand side may be omitted (but not both) in which case the local user name and \".host\" are implied. -h, --help Print a short help text and exit. --version Print a short version string and exit. --json=MODE Shows output formatted as JSON. Expects one of \"short\" (for the shortest possible output without any redundant whitespace or line breaks), \"pretty\" (for a pretty version of the same, with indentation and line breaks) or \"off\" (to turn off JSON output, the default). "
  },
  {
    "command": "split",
    "description": " The split utility shall read an input file and write zero or more output files. The default size of each output file shall be 1000 lines. The size of the output files can be modified by specification of the -b or -l options. Each output file shall be created with a unique suffix. The suffix shall consist of exactly suffix_length lowercase letters from the POSIX locale. The letters of the suffix shall be used as if they were a base-26 digit system, with the first suffix to be created consisting of all 'a' characters, the second with a 'b' replacing the last 'a', and so on, until a name of all 'z' characters is created. By default, the names of the output files shall be 'x', followed by a two-character suffix from the character set as described above, starting with \"aa\", \"ab\", \"ac\", and so on, and continuing until the suffix \"zz\", for a maximum of 676 files. If the number of files required exceeds the maximum allowed by the suffix length provided, such that the last allowable file would be larger than the requested size, the split utility shall fail after creating the last file with a valid suffix; split shall not delete the files it created with valid suffixes. If the file limit is not exceeded, the last file created shall contain the remainder of the input file, and may be smaller than the requested size. If the input is an empty file, no output file shall be created and this shall not be considered to be an error. The split utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -a suffix_length Use suffix_length letters to form the suffix portion of the filenames of the split file. If -a is not specified, the default suffix length shall be two. If the sum of the name operand and the suffix_length option-argument would create a filename exceeding {NAME_MAX} bytes, an error shall result; split shall exit with a diagnostic message and no files shall be created. -b n Split a file into pieces n bytes in size. -b nk Split a file into pieces n*1024 bytes in size. -b nm Split a file into pieces n*1048576 bytes in size. -l line_count Specify the number of lines in each resulting file piece. The line_count argument is an unsigned decimal integer. The default is 1000. If the input does not end with a <newline>, the partial line shall be included in the last output file. "
  },
  {
    "command": "sftp",
    "description": " sftp is a file transfer program, similar to ftp(1), which performs all operations over an encrypted ssh(1) transport. It may also use many features of ssh, such as public key authentication and compression. The destination may be specified either as [user@]host[:path] or as a URI in the form sftp://[user@]host[:port][/path]. If the destination includes a path and it is not a directory, sftp will retrieve files automatically if a non-interactive authentication method is used; otherwise it will do so after successful interactive authentication. If no path is specified, or if the path is a directory, sftp will log in to the specified host and enter interactive command mode, changing to the remote directory if one was specified. An optional trailing slash can be used to force the path to be interpreted as a directory. Since the destination formats use colon characters to delimit host names from path names or port numbers, IPv6 addresses must be enclosed in square brackets to avoid ambiguity. The options are as follows: -4 Forces sftp to use IPv4 addresses only. -6 Forces sftp to use IPv6 addresses only. -A Allows forwarding of ssh-agent(1) to the remote system. The default is not to forward an authentication agent. -a Attempt to continue interrupted transfers rather than overwriting existing partial or complete copies of files. If the partial contents differ from those being transferred, then the resultant file is likely to be corrupt. -B buffer_size Specify the size of the buffer that sftp uses when transferring files. Larger buffers require fewer round trips at the cost of higher memory consumption. The default is 32768 bytes. -b batchfile Batch mode reads a series of commands from an input batchfile instead of stdin. Since it lacks user interaction, it should be used in conjunction with non- interactive authentication to obviate the need to enter a password at connection time (see sshd(8) and ssh-keygen(1) for details). A batchfile of \u2018-\u2019 may be used to indicate standard input. sftp will abort if any of the following commands fail: get, put, reget, reput, rename, ln, rm, mkdir, chdir, ls, lchdir, copy, cp, chmod, chown, chgrp, lpwd, df, symlink, and lmkdir. Termination on error can be suppressed on a command by command basis by prefixing the command with a \u2018-\u2019 character (for example, -rm /tmp/blah*). Echo of the command may be suppressed by prefixing the command with a \u2018@\u2019 character. These two prefixes may be combined in any order, for example -@ls /bsd. -C Enables compression (via ssh's -C flag). -c cipher Selects the cipher to use for encrypting the data transfers. This option is directly passed to ssh(1). -D sftp_server_command Connect directly to a local sftp server (rather than via ssh(1)). A command and arguments may be specified, for example \"/path/sftp-server -el debug3\". This option may be useful in debugging the client and server. -F ssh_config Specifies an alternative per-user configuration file for ssh(1). This option is directly passed to ssh(1). -f Requests that files be flushed to disk immediately after transfer. When uploading files, this feature is only enabled if the server implements the \"fsync@openssh.com\" extension. -i identity_file Selects the file from which the identity (private key) for public key authentication is read. This option is directly passed to ssh(1). -J destination Connect to the target host by first making an sftp connection to the jump host described by destination and then establishing a TCP forwarding to the ultimate destination from there. Multiple jump hops may be specified separated by comma characters. This is a shortcut to specify a ProxyJump configuration directive. This option is directly passed to ssh(1). -l limit Limits the used bandwidth, specified in Kbit/s. -N Disables quiet mode, e.g. to override the implicit quiet mode set by the -b flag. -o ssh_option Can be used to pass options to ssh in the format used in ssh_config(5). This is useful for specifying options for which there is no separate sftp command-line flag. For example, to specify an alternate port use: sftp -oPort=24. For full details of the options listed below, and their possible values, see ssh_config(5). AddressFamily BatchMode BindAddress BindInterface CanonicalDomains CanonicalizeFallbackLocal CanonicalizeHostname CanonicalizeMaxDots CanonicalizePermittedCNAMEs CASignatureAlgorithms CertificateFile CheckHostIP Ciphers Compression ConnectionAttempts ConnectTimeout ControlMaster ControlPath ControlPersist GlobalKnownHostsFile GSSAPIAuthentication GSSAPIDelegateCredentials HashKnownHosts Host HostbasedAcceptedAlgorithms HostbasedAuthentication HostKeyAlgorithms HostKeyAlias Hostname IdentitiesOnly IdentityAgent IdentityFile IPQoS KbdInteractiveAuthentication KbdInteractiveDevices KexAlgorithms KnownHostsCommand LogLevel MACs NoHostAuthenticationForLocalhost NumberOfPasswordPrompts PasswordAuthentication PKCS11Provider Port PreferredAuthentications ProxyCommand ProxyJump PubkeyAcceptedAlgorithms PubkeyAuthentication RekeyLimit RequiredRSASize SendEnv ServerAliveInterval ServerAliveCountMax SetEnv StrictHostKeyChecking TCPKeepAlive UpdateHostKeys User UserKnownHostsFile VerifyHostKeyDNS -P port Specifies the port to connect to on the remote host. -p Preserves modification times, access times, and modes from the original files transferred. -q Quiet mode: disables the progress meter as well as warning and diagnostic messages from ssh(1). -R num_requests Specify how many requests may be outstanding at any one time. Increasing this may slightly improve file transfer speed but will increase memory usage. The default is 64 outstanding requests. -r Recursively copy entire directories when uploading and downloading. Note that sftp does not follow symbolic links encountered in the tree traversal. -S program Name of the program to use for the encrypted connection. The program must understand ssh(1) options. -s subsystem | sftp_server Specifies the SSH2 subsystem or the path for an sftp server on the remote host. A path is useful when the remote sshd(8) does not have an sftp subsystem configured. -v Raise logging level. This option is also passed to ssh. -X sftp_option Specify an option that controls aspects of SFTP protocol behaviour. The valid options are: nrequests=value Controls how many concurrent SFTP read or write requests may be in progress at any point in time during a download or upload. By default 64 requests may be active concurrently. buffer=value Controls the maximum buffer size for a single SFTP read/write operation used during download or upload. By default a 32KB buffer is used. "
  },
  {
    "command": "renice",
    "description": " The renice utility shall request that the nice values (see the Base Definitions volume of POSIX.1\u20102017, Section 3.244, Nice Value) of one or more running processes be changed. By default, the applicable processes are specified by their process IDs. When a process group is specified (see -g), the request shall apply to all processes in the process group. The nice value shall be bounded in an implementation-defined manner. If the requested increment would raise or lower the nice value of the executed utility beyond implementation-defined limits, then the limit whose value was exceeded shall be used. When a user is reniced, the request applies to all processes whose saved set-user-ID matches the user ID corresponding to the user. Regardless of which options are supplied or any other factor, renice shall not alter the nice values of any process unless the user requesting such a change has appropriate privileges to do so for the specified process. If the user lacks appropriate privileges to perform the requested action, the utility shall return an error status. The saved set-user-ID of the user's process shall be checked instead of its effective user ID when renice attempts to determine the user ID of the process in order to determine whether the user has appropriate privileges. The renice utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines, except for Guideline 9. The following options shall be supported: -g Interpret the following operands as unsigned decimal integer process group IDs. -n increment Specify how the nice value of the specified process or processes is to be adjusted. The increment option- argument is a positive or negative decimal integer that shall be used to modify the nice value of the specified process or processes. Positive increment values shall cause a lower nice value. Negative increment values may require appropriate privileges and shall cause a higher nice value. -p Interpret the following operands as unsigned decimal integer process IDs. The -p option is the default if no options are specified. -u Interpret the following operands as users. If a user exists with a user name equal to the operand, then the user ID of that user is used in further processing. Otherwise, if the operand represents an unsigned decimal integer, it shall be used as the numeric user ID of the user. "
  },
  {
    "command": "envsubst",
    "description": " Substitutes the values of environment variables. Operation mode: -v, --variables output the variables occurring in SHELL-FORMAT Informative output: -h, --help display this help and exit -V, --version output version information and exit In normal operation mode, standard input is copied to standard output, with references to environment variables of the form $VARIABLE or ${VARIABLE} being replaced with the corresponding values. If a SHELL-FORMAT is given, only those environment variables that are referenced in SHELL-FORMAT are substituted; otherwise all environment variables references occurring in standard input are substituted. When --variables is used, standard input is ignored, and the output consists of the environment variables that are referenced in SHELL-FORMAT, one per line. "
  },
  {
    "command": "comm",
    "description": " The comm utility shall read file1 and file2, which should be ordered in the current collating sequence, and produce three text columns as output: lines only in file1, lines only in file2, and lines in both files. If the lines in both files are not ordered according to the collating sequence of the current locale, the results are unspecified. If the collating sequence of the current locale does not have a total ordering of all characters (see the Base Definitions volume of POSIX.1\u20102017, Section 7.3.2, LC_COLLATE) and any lines from the input files collate equally but are not identical, comm should treat them as different lines but may treat them as being the same. If it treats them as different, comm should expect them to be ordered according to a further byte-by-byte comparison using the collating sequence for the POSIX locale and if they are not ordered in this way, the output of comm can identify such lines as being both unique to file1 and unique to file2 instead of being in both files. The comm utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -1 Suppress the output column of lines unique to file1. -2 Suppress the output column of lines unique to file2. -3 Suppress the output column of lines duplicated in file1 and file2. "
  },
  {
    "command": "gdb",
    "description": " The purpose of a debugger such as GDB is to allow you to see what is going on \"inside\" another program while it executes -- or what another program was doing at the moment it crashed. GDB can do four main kinds of things (plus other things in support of these) to help you catch bugs in the act: \u2022 Start your program, specifying anything that might affect its behavior. \u2022 Make your program stop on specified conditions. \u2022 Examine what has happened, when your program has stopped. \u2022 Change things in your program, so you can experiment with correcting the effects of one bug and go on to learn about another. You can use GDB to debug programs written in C, C++, Fortran and Modula-2. GDB is invoked with the shell command \"gdb\". Once started, it reads commands from the terminal until you tell it to exit with the GDB command \"quit\" or \"exit\". You can get online help from GDB itself by using the command \"help\". You can run \"gdb\" with no arguments or options; but the most usual way to start GDB is with one argument or two, specifying an executable program as the argument: gdb program You can also start with both an executable program and a core file specified: gdb program core You can, instead, specify a process ID as a second argument or use option \"-p\", if you want to debug a running process: gdb program 1234 gdb -p 1234 would attach GDB to process 1234. With option -p you can omit the program filename. Here are some of the most frequently needed GDB commands: break [file:][function|line] Set a breakpoint at function or line (in file). run [arglist] Start your program (with arglist, if specified). bt Backtrace: display the program stack. print expr Display the value of an expression. c Continue running your program (after stopping, e.g. at a breakpoint). next Execute next program line (after stopping); step over any function calls in the line. edit [file:]function look at the program line where it is presently stopped. list [file:]function type the text of the program in the vicinity of where it is presently stopped. step Execute next program line (after stopping); step into any function calls in the line. help [name] Show information about GDB command name, or general information about using GDB. quit exit Exit from GDB. For full details on GDB, see Using GDB: A Guide to the GNU Source-Level Debugger, by Richard M. Stallman and Roland H. Pesch. The same text is available online as the \"gdb\" entry in the \"info\" program. Any arguments other than options specify an executable file and core file (or process ID); that is, the first argument encountered with no associated option flag is equivalent to a --se option, and the second, if any, is equivalent to a -c option if it's the name of a file. Many options have both long and abbreviated forms; both are shown here. The long forms are also recognized if you truncate them, so long as enough of the option is present to be unambiguous. The abbreviated forms are shown here with - and long forms are shown with -- to reflect how they are shown in --help. However, GDB recognizes all of the following conventions for most options: \"--option=value\" \"--option value\" \"-option=value\" \"-option value\" \"--o=value\" \"--o value\" \"-o=value\" \"-o value\" All the options and command line arguments you give are processed in sequential order. The order makes a difference when the -x option is used. --help -h List all options, with brief explanations. --symbols=file -s file Read symbol table from file. --write Enable writing into executable and core files. --exec=file -e file Use file as the executable file to execute when appropriate, and for examining pure data in conjunction with a core dump. --se=file Read symbol table from file and use it as the executable file. --core=file -c file Use file as a core dump to examine. --command=file -x file Execute GDB commands from file. --eval-command=command -ex command Execute given GDB command. --init-eval-command=command -iex Execute GDB command before loading the inferior. --directory=directory -d directory Add directory to the path to search for source files. --nh Do not execute commands from ~/.config/gdb/gdbinit, ~/.gdbinit, ~/.config/gdb/gdbearlyinit, or ~/.gdbearlyinit --nx -n Do not execute commands from any .gdbinit or .gdbearlyinit initialization files. --quiet --silent -q \"Quiet\". Do not print the introductory and copyright messages. These messages are also suppressed in batch mode. --batch Run in batch mode. Exit with status 0 after processing all the command files specified with -x (and .gdbinit, if not inhibited). Exit with nonzero status if an error occurs in executing the GDB commands in the command files. Batch mode may be useful for running GDB as a filter, for example to download and run a program on another computer; in order to make this more useful, the message Program exited normally. (which is ordinarily issued whenever a program running under GDB control terminates) is not issued when running in batch mode. --batch-silent Run in batch mode, just like --batch, but totally silent. All GDB output is supressed (stderr is unaffected). This is much quieter than --silent and would be useless for an interactive session. This is particularly useful when using targets that give Loading section messages, for example. Note that targets that give their output via GDB, as opposed to writing directly to \"stdout\", will also be made silent. --args prog [arglist] Change interpretation of command line so that arguments following this option are passed as arguments to the inferior. As an example, take the following command: gdb ./a.out -q It would start GDB with -q, not printing the introductory message. On the other hand, using: gdb --args ./a.out -q starts GDB with the introductory message, and passes the option to the inferior. --pid=pid Attach GDB to an already running program, with the PID pid. --tui Open the terminal user interface. --readnow Read all symbols from the given symfile on the first access. --readnever Do not read symbol files. --return-child-result GDB's exit code will be the same as the child's exit code. --configuration Print details about GDB configuration and then exit. --version Print version information and then exit. --cd=directory Run GDB using directory as its working directory, instead of the current directory. --data-directory=directory -D Run GDB using directory as its data directory. The data directory is where GDB searches for its auxiliary files. --fullname -f Emacs sets this option when it runs GDB as a subprocess. It tells GDB to output the full file name and line number in a standard, recognizable fashion each time a stack frame is displayed (which includes each time the program stops). This recognizable format looks like two \\032 characters, followed by the file name, line number and character position separated by colons, and a newline. The Emacs-to-GDB interface program uses the two \\032 characters as a signal to display the source code for the frame. -b baudrate Set the line speed (baud rate or bits per second) of any serial interface used by GDB for remote debugging. -l timeout Set timeout, in seconds, for remote debugging. --tty=device Run using device for your program's standard input and output. "
  },
  {
    "command": "git-prune",
    "description": " Note In most cases, users should run git gc, which calls git prune. See the section \"NOTES\", below. This runs git fsck --unreachable using all the refs available in refs/, optionally with additional set of objects specified on the command line, and prunes all unpacked objects unreachable from any of these head objects from the object database. In addition, it prunes the unpacked objects that are also found in packs by running git prune-packed. It also removes entries from .git/shallow that are not reachable by any ref. Note that unreachable, packed objects will remain. If this is not desired, see git-repack(1). -n, --dry-run Do not remove anything; just report what it would remove. -v, --verbose Report all removed objects. --progress Show progress. --expire <time> Only expire loose objects older than <time>. -- Do not interpret any more arguments as options. <head>... In addition to objects reachable from any of our references, keep objects reachable from listed <head>s. "
  },
  {
    "command": "oomctl",
    "description": " oomctl may be used to get information about the various contexts read in by the systemd(1) userspace out-of-memory (OOM) killer, systemd-oomd(8). The following options are understood: -h, --help Print a short help text and exit. --version Print a short version string and exit. --no-pager Do not pipe output into a pager. "
  },
  {
    "command": "git-config",
    "description": " You can query/set/replace/unset options with this command. The name is actually the section and the key separated by a dot, and the value will be escaped. Multiple lines can be added to an option by using the --add option. If you want to update or unset an option which can occur on multiple lines, a value-pattern (which is an extended regular expression, unless the --fixed-value option is given) needs to be given. Only the existing values that match the pattern are updated or unset. If you want to handle the lines that do not match the pattern, just prepend a single exclamation mark in front (see also the section called \u201cEXAMPLES\u201d), but note that this only works when the --fixed-value option is not in use. The --type=<type> option instructs git config to ensure that incoming and outgoing values are canonicalize-able under the given <type>. If no --type=<type> is given, no canonicalization will be performed. Callers may unset an existing --type specifier with --no-type. When reading, the values are read from the system, global and repository local configuration files by default, and options --system, --global, --local, --worktree and --file <filename> can be used to tell the command to read from only that location (see the section called \u201cFILES\u201d). When writing, the new value is written to the repository local configuration file by default, and options --system, --global, --worktree, --file <filename> can be used to tell the command to write to that location (you can say --local but that is the default). This command will fail with non-zero status upon error. Some exit codes are: \u2022 The section or key is invalid (ret=1), \u2022 no section or name was provided (ret=2), \u2022 the config file is invalid (ret=3), \u2022 the config file cannot be written (ret=4), \u2022 you try to unset an option which does not exist (ret=5), \u2022 you try to unset/set an option for which multiple lines match (ret=5), or \u2022 you try to use an invalid regexp (ret=6). On success, the command returns the exit code 0. A list of all available configuration variables can be obtained using the git help --config command. --replace-all Default behavior is to replace at most one line. This replaces all lines matching the key (and optionally the value-pattern). --add Adds a new line to the option without altering any existing values. This is the same as providing ^$ as the value-pattern in --replace-all. --get Get the value for a given key (optionally filtered by a regex matching the value). Returns error code 1 if the key was not found and the last value if multiple key values were found. --get-all Like get, but returns all values for a multi-valued key. --get-regexp Like --get-all, but interprets the name as a regular expression and writes out the key names. Regular expression matching is currently case-sensitive and done against a canonicalized version of the key in which section and variable names are lowercased, but subsection names are not. --get-urlmatch <name> <URL> When given a two-part name section.key, the value for section.<URL>.key whose <URL> part matches the best to the given URL is returned (if no such key exists, the value for section.key is used as a fallback). When given just the section as name, do so for all the keys in the section and list them. Returns error code 1 if no value is found. --global For writing options: write to global ~/.gitconfig file rather than the repository .git/config, write to $XDG_CONFIG_HOME/git/config file if this file exists and the ~/.gitconfig file doesn\u2019t. For reading options: read only from global ~/.gitconfig and from $XDG_CONFIG_HOME/git/config rather than from all available files. See also the section called \u201cFILES\u201d. --system For writing options: write to system-wide $(prefix)/etc/gitconfig rather than the repository .git/config. For reading options: read only from system-wide $(prefix)/etc/gitconfig rather than from all available files. See also the section called \u201cFILES\u201d. --local For writing options: write to the repository .git/config file. This is the default behavior. For reading options: read only from the repository .git/config rather than from all available files. See also the section called \u201cFILES\u201d. --worktree Similar to --local except that $GIT_DIR/config.worktree is read from or written to if extensions.worktreeConfig is enabled. If not it\u2019s the same as --local. Note that $GIT_DIR is equal to $GIT_COMMON_DIR for the main working tree, but is of the form $GIT_DIR/worktrees/<id>/ for other working trees. See git-worktree(1) to learn how to enable extensions.worktreeConfig. -f <config-file>, --file <config-file> For writing options: write to the specified file rather than the repository .git/config. For reading options: read only from the specified file rather than from all available files. See also the section called \u201cFILES\u201d. --blob <blob> Similar to --file but use the given blob instead of a file. E.g. you can use master:.gitmodules to read values from the file .gitmodules in the master branch. See \"SPECIFYING REVISIONS\" section in gitrevisions(7) for a more complete list of ways to spell blob names. --remove-section Remove the given section from the configuration file. --rename-section Rename the given section to a new name. --unset Remove the line matching the key from config file. --unset-all Remove all lines matching the key from config file. -l, --list List all variables set in config file, along with their values. --fixed-value When used with the value-pattern argument, treat value-pattern as an exact string instead of a regular expression. This will restrict the name/value pairs that are matched to only those where the value is exactly equal to the value-pattern. --type <type> git config will ensure that any input or output is valid under the given type constraint(s), and will canonicalize outgoing values in <type>'s canonical form. Valid <type>'s include: \u2022 bool: canonicalize values as either \"true\" or \"false\". \u2022 int: canonicalize values as simple decimal numbers. An optional suffix of k, m, or g will cause the value to be multiplied by 1024, 1048576, or 1073741824 upon input. \u2022 bool-or-int: canonicalize according to either bool or int, as described above. \u2022 path: canonicalize by adding a leading ~ to the value of $HOME and ~user to the home directory for the specified user. This specifier has no effect when setting the value (but you can use git config section.variable ~/ from the command line to let your shell do the expansion.) \u2022 expiry-date: canonicalize by converting from a fixed or relative date-string to a timestamp. This specifier has no effect when setting the value. \u2022 color: When getting a value, canonicalize by converting to an ANSI color escape sequence. When setting a value, a sanity-check is performed to ensure that the given value is canonicalize-able as an ANSI color, but it is written as-is. --bool, --int, --bool-or-int, --path, --expiry-date Historical options for selecting a type specifier. Prefer instead --type (see above). --no-type Un-sets the previously set type specifier (if one was previously set). This option requests that git config not canonicalize the retrieved variable. --no-type has no effect without --type=<type> or --<type>. -z, --null For all options that output values and/or keys, always end values with the null character (instead of a newline). Use newline instead as a delimiter between key and value. This allows for secure parsing of the output without getting confused e.g. by values that contain line breaks. --name-only Output only the names of config variables for --list or --get-regexp. --show-origin Augment the output of all queried config options with the origin type (file, standard input, blob, command line) and the actual origin (config file path, ref, or blob id if applicable). --show-scope Similar to --show-origin in that it augments the output of all queried config options with the scope of that value (worktree, local, global, system, command). --get-colorbool <name> [<stdout-is-tty>] Find the color setting for <name> (e.g. color.diff) and output \"true\" or \"false\". <stdout-is-tty> should be either \"true\" or \"false\", and is taken into account when configuration says \"auto\". If <stdout-is-tty> is missing, then checks the standard output of the command itself, and exits with status 0 if color is to be used, or exits with status 1 otherwise. When the color setting for name is undefined, the command uses color.ui as fallback. --get-color <name> [<default>] Find the color configured for name (e.g. color.diff.new) and output it as the ANSI color escape sequence to the standard output. The optional default parameter is used instead, if there is no color configured for name. --type=color [--default=<default>] is preferred over --get-color (but note that --get-color will omit the trailing newline printed by --type=color). -e, --edit Opens an editor to modify the specified config file; either --system, --global, or repository (default). --[no-]includes Respect include.* directives in config files when looking up values. Defaults to off when a specific file is given (e.g., using --file, --global, etc) and on when searching all config files. --default <value> When using --get, and the requested variable is not found, behave as if <value> were the value assigned to the that variable. "
  },
  {
    "command": "git-merge-base",
    "description": " git merge-base finds best common ancestor(s) between two commits to use in a three-way merge. One common ancestor is better than another common ancestor if the latter is an ancestor of the former. A common ancestor that does not have any better common ancestor is a best common ancestor, i.e. a merge base. Note that there can be more than one merge base for a pair of commits. -a, --all Output all merge bases for the commits, instead of just one. "
  },
  {
    "command": "pwd",
    "description": " The pwd utility shall write to standard output an absolute pathname of the current working directory, which does not contain the filenames dot or dot-dot. The pwd utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported by the implementation: -L If the PWD environment variable contains an absolute pathname of the current directory and the pathname does not contain any components that are dot or dot-dot, pwd shall write this pathname to standard output, except that if the PWD environment variable is longer than {PATH_MAX} bytes including the terminating null, it is unspecified whether pwd writes this pathname to standard output or behaves as if the -P option had been specified. Otherwise, the -L option shall behave as the -P option. -P The pathname written to standard output shall not contain any components that refer to files of type symbolic link. If there are multiple pathnames that the pwd utility could write to standard output, one beginning with a single <slash> character and one or more beginning with two <slash> characters, then it shall write the pathname beginning with a single <slash> character. The pathname shall not contain any unnecessary <slash> characters after the leading one or two <slash> characters. If both -L and -P are specified, the last one shall apply. If neither -L nor -P is specified, the pwd utility shall behave as if -L had been specified. "
  },
  {
    "command": "git-unpack-file",
    "description": " Creates a file holding the contents of the blob specified by sha1. It returns the name of the temporary file in the following format: .merge_file_XXXXX <blob> Must be a blob id "
  },
  {
    "command": "git-fsck",
    "description": " Verifies the connectivity and validity of the objects in the database. <object> An object to treat as the head of an unreachability trace. If no objects are given, git fsck defaults to using the index file, all SHA-1 references in refs namespace, and all reflogs (unless --no-reflogs is given) as heads. --unreachable Print out objects that exist but that aren\u2019t reachable from any of the reference nodes. --[no-]dangling Print objects that exist but that are never directly used (default). --no-dangling can be used to omit this information from the output. --root Report root nodes. --tags Report tags. --cache Consider any object recorded in the index also as a head node for an unreachability trace. --no-reflogs Do not consider commits that are referenced only by an entry in a reflog to be reachable. This option is meant only to search for commits that used to be in a ref, but now aren\u2019t, but are still in that corresponding reflog. --full Check not just objects in GIT_OBJECT_DIRECTORY ($GIT_DIR/objects), but also the ones found in alternate object pools listed in GIT_ALTERNATE_OBJECT_DIRECTORIES or $GIT_DIR/objects/info/alternates, and in packed Git archives found in $GIT_DIR/objects/pack and corresponding pack subdirectories in alternate object pools. This is now default; you can turn it off with --no-full. --connectivity-only Check only the connectivity of reachable objects, making sure that any objects referenced by a reachable tag, commit, or tree is present. This speeds up the operation by avoiding reading blobs entirely (though it does still check that referenced blobs exist). This will detect corruption in commits and trees, but not do any semantic checks (e.g., for format errors). Corruption in blob objects will not be detected at all. Unreachable tags, commits, and trees will also be accessed to find the tips of dangling segments of history. Use --no-dangling if you don\u2019t care about this output and want to speed it up further. --strict Enable more strict checking, namely to catch a file mode recorded with g+w bit set, which was created by older versions of Git. Existing repositories, including the Linux kernel, Git itself, and sparse repository have old objects that triggers this check, but it is recommended to check new projects with this flag. --verbose Be chatty. --lost-found Write dangling objects into .git/lost-found/commit/ or .git/lost-found/other/, depending on type. If the object is a blob, the contents are written into the file, rather than its object name. --name-objects When displaying names of reachable objects, in addition to the SHA-1 also display a name that describes how they are reachable, compatible with git-rev-parse(1), e.g. HEAD@{1234567890}~25^2:src/. --[no-]progress Progress status is reported on the standard error stream by default when it is attached to a terminal, unless --no-progress or --verbose is specified. --progress forces progress status even if the standard error stream is not directed to a terminal. "
  },
  {
    "command": "chgrp",
    "description": " The chgrp utility shall set the group ID of the file named by each file operand to the group ID specified by the group operand. For each file operand, or, if the -R option is used, each file encountered while walking the directory trees specified by the file operands, the chgrp utility shall perform actions equivalent to the chown() function defined in the System Interfaces volume of POSIX.1\u20102017, called with the following arguments: * The file operand shall be used as the path argument. * The user ID of the file shall be used as the owner argument. * The specified group ID shall be used as the group argument. Unless chgrp is invoked by a process with appropriate privileges, the set-user-ID and set-group-ID bits of a regular file shall be cleared upon successful completion; the set-user-ID and set- group-ID bits of other file types may be cleared. The chgrp utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported by the implementation: -h For each file operand that names a file of type symbolic link, chgrp shall attempt to set the group ID of the symbolic link instead of the file referenced by the symbolic link. -H If the -R option is specified and a symbolic link referencing a file of type directory is specified on the command line, chgrp shall change the group of the directory referenced by the symbolic link and all files in the file hierarchy below it. -L If the -R option is specified and a symbolic link referencing a file of type directory is specified on the command line or encountered during the traversal of a file hierarchy, chgrp shall change the group of the directory referenced by the symbolic link and all files in the file hierarchy below it. -P If the -R option is specified and a symbolic link is specified on the command line or encountered during the traversal of a file hierarchy, chgrp shall change the group ID of the symbolic link. The chgrp utility shall not follow the symbolic link to any other part of the file hierarchy. -R Recursively change file group IDs. For each file operand that names a directory, chgrp shall change the group of the directory and all files in the file hierarchy below it. Unless a -H, -L, or -P option is specified, it is unspecified which of these options will be used as the default. Specifying more than one of the mutually-exclusive options -H, -L, and -P shall not be considered an error. The last option specified shall determine the behavior of the utility. "
  },
  {
    "command": "free",
    "description": " free displays the total amount of free and used physical and swap memory in the system, as well as the buffers and caches used by the kernel. The information is gathered by parsing /proc/meminfo. The displayed columns are: total Total usable memory (MemTotal and SwapTotal in /proc/meminfo). This includes the physical and swap memory minus a few reserved bits and kernel binary code. used Used or unavailable memory (calculated as total - available) free Unused memory (MemFree and SwapFree in /proc/meminfo) shared Memory used (mostly) by tmpfs (Shmem in /proc/meminfo) buffers Memory used by kernel buffers (Buffers in /proc/meminfo) cache Memory used by the page cache and slabs (Cached and SReclaimable in /proc/meminfo) buff/cache Sum of buffers and cache available Estimation of how much memory is available for starting new applications, without swapping. Unlike the data provided by the cache or free fields, this field takes into account page cache and also that not all reclaimable memory slabs will be reclaimed due to items being in use (MemAvailable in /proc/meminfo, available on kernels 3.14, emulated on kernels 2.6.27+, otherwise the same as free) -b, --bytes Display the amount of memory in bytes. -k, --kibi Display the amount of memory in kibibytes. This is the default. -m, --mebi Display the amount of memory in mebibytes. -g, --gibi Display the amount of memory in gibibytes. --tebi Display the amount of memory in tebibytes. --pebi Display the amount of memory in pebibytes. --kilo Display the amount of memory in kilobytes. Implies --si. --mega Display the amount of memory in megabytes. Implies --si. --giga Display the amount of memory in gigabytes. Implies --si. --tera Display the amount of memory in terabytes. Implies --si. --peta Display the amount of memory in petabytes. Implies --si. -h, --human Show all output fields automatically scaled to shortest three digit unit and display the units of print out. Following units are used. B = bytes Ki = kibibyte Mi = mebibyte Gi = gibibyte Ti = tebibyte Pi = pebibyte If unit is missing, and you have exbibyte of RAM or swap, the number is in tebibytes and columns might not be aligned with header. -w, --wide Switch to the wide mode. The wide mode produces lines longer than 80 characters. In this mode buffers and cache are reported in two separate columns. -c, --count count Display the result count times. Requires the -s option. -l, --lohi Show detailed low and high memory statistics. -L, --line Show output on a single line, often used with the -s option to show memory statistics repeatedly. -s, --seconds delay Continuously display the result delay seconds apart. You may actually specify any floating point number for delay using either . or , for decimal point. usleep(3) is used for microsecond resolution delay times. --si Use kilo, mega, giga etc (power of 1000) instead of kibi, mebi, gibi (power of 1024). -t, --total Display a line showing the column totals. -v, --committed Display a line showing the memory commit limit and amount of committed/uncommitted memory. The total column on this line will display the memory commit limit. This line is relevant if memory overcommit is disabled. --help Print help. -V, --version Display version information. "
  },
  {
    "command": "id",
    "description": " If no user operand is provided, the id utility shall write the user and group IDs and the corresponding user and group names of the invoking process to standard output. If the effective and real IDs do not match, both shall be written. If multiple groups are supported by the underlying system (see the description of {NGROUPS_MAX} in the System Interfaces volume of POSIX.1\u20102017), the supplementary group affiliations of the invoking process shall also be written. If a user operand is provided and the process has appropriate privileges, the user and group IDs of the selected user shall be written. In this case, effective IDs shall be assumed to be identical to real IDs. If the selected user has more than one allowable group membership listed in the group database, these shall be written in the same manner as the supplementary groups described in the preceding paragraph. The id utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -G Output all different group IDs (effective, real, and supplementary) only, using the format \"%u\\n\". If there is more than one distinct group affiliation, output each such affiliation, using the format \" %u\", before the <newline> is output. -g Output only the effective group ID, using the format \"%u\\n\". -n Output the name in the format \"%s\" instead of the numeric ID using the format \"%u\". -r Output the real ID instead of the effective ID. -u Output only the effective user ID, using the format \"%u\\n\". "
  },
  {
    "command": "readelf",
    "description": " readelf displays information about one or more ELF format object files. The options control what particular information to display. elffile... are the object files to be examined. 32-bit and 64-bit ELF files are supported, as are archives containing ELF files. This program performs a similar function to objdump but it goes into more detail and it exists independently of the BFD library, so if there is a bug in BFD then readelf will not be affected. The long and short forms of options, shown here as alternatives, are equivalent. At least one option besides -v or -H must be given. -a --all Equivalent to specifying --file-header, --program-headers, --sections, --symbols, --relocs, --dynamic, --notes, --version-info, --arch-specific, --unwind, --section-groups and --histogram. Note - this option does not enable --use-dynamic itself, so if that option is not present on the command line then dynamic symbols and dynamic relocs will not be displayed. -h --file-header Displays the information contained in the ELF header at the start of the file. -l --program-headers --segments Displays the information contained in the file's segment headers, if it has any. --quiet Suppress \"no symbols\" diagnostic. -S --sections --section-headers Displays the information contained in the file's section headers, if it has any. -g --section-groups Displays the information contained in the file's section groups, if it has any. -t --section-details Displays the detailed section information. Implies -S. -s --symbols --syms Displays the entries in symbol table section of the file, if it has one. If a symbol has version information associated with it then this is displayed as well. The version string is displayed as a suffix to the symbol name, preceded by an @ character. For example foo@VER_1. If the version is the default version to be used when resolving unversioned references to the symbol then it is displayed as a suffix preceded by two @ characters. For example foo@@VER_2. --dyn-syms Displays the entries in dynamic symbol table section of the file, if it has one. The output format is the same as the format used by the --syms option. --lto-syms Displays the contents of any LTO symbol tables in the file. --sym-base=[0|8|10|16] Forces the size field of the symbol table to use the given base. Any unrecognized options will be treated as 0. --sym-base=0 represents the default and legacy behaviour. This will output sizes as decimal for numbers less than 100000. For sizes 100000 and greater hexadecimal notation will be used with a 0x prefix. --sym-base=8 will give the symbol sizes in octal. --sym-base=10 will always give the symbol sizes in decimal. --sym-base=16 will always give the symbol sizes in hexadecimal with a 0x prefix. -C --demangle[=style] Decode (demangle) low-level symbol names into user-level names. This makes C++ function names readable. Different compilers have different mangling styles. The optional demangling style argument can be used to choose an appropriate demangling style for your compiler. --no-demangle Do not demangle low-level symbol names. This is the default. --recurse-limit --no-recurse-limit --recursion-limit --no-recursion-limit Enables or disables a limit on the amount of recursion performed whilst demangling strings. Since the name mangling formats allow for an infinite level of recursion it is possible to create strings whose decoding will exhaust the amount of stack space available on the host machine, triggering a memory fault. The limit tries to prevent this from happening by restricting recursion to 2048 levels of nesting. The default is for this limit to be enabled, but disabling it may be necessary in order to demangle truly complicated names. Note however that if the recursion limit is disabled then stack exhaustion is possible and any bug reports about such an event will be rejected. -U [d|i|l|e|x|h] --unicode=[default|invalid|locale|escape|hex|highlight] Controls the display of non-ASCII characters in identifier names. The default (--unicode=locale or --unicode=default) is to treat them as multibyte characters and display them in the current locale. All other versions of this option treat the bytes as UTF-8 encoded values and attempt to interpret them. If they cannot be interpreted or if the --unicode=invalid option is used then they are displayed as a sequence of hex bytes, encloses in curly parethesis characters. Using the --unicode=escape option will display the characters as as unicode escape sequences (\\uxxxx). Using the --unicode=hex will display the characters as hex byte sequences enclosed between angle brackets. Using the --unicode=highlight will display the characters as unicode escape sequences but it will also highlighted them in red, assuming that colouring is supported by the output device. The colouring is intended to draw attention to the presence of unicode sequences when they might not be expected. -e --headers Display all the headers in the file. Equivalent to -h -l -S. -n --notes Displays the contents of the NOTE segments and/or sections, if any. -r --relocs Displays the contents of the file's relocation section, if it has one. -u --unwind Displays the contents of the file's unwind section, if it has one. Only the unwind sections for IA64 ELF files, as well as ARM unwind tables (\".ARM.exidx\" / \".ARM.extab\") are currently supported. If support is not yet implemented for your architecture you could try dumping the contents of the .eh_frames section using the --debug-dump=frames or --debug-dump=frames-interp options. -d --dynamic Displays the contents of the file's dynamic section, if it has one. -V --version-info Displays the contents of the version sections in the file, it they exist. -A --arch-specific Displays architecture-specific information in the file, if there is any. -D --use-dynamic When displaying symbols, this option makes readelf use the symbol hash tables in the file's dynamic section, rather than the symbol table sections. When displaying relocations, this option makes readelf display the dynamic relocations rather than the static relocations. -L --lint --enable-checks Displays warning messages about possible problems with the file(s) being examined. If used on its own then all of the contents of the file(s) will be examined. If used with one of the dumping options then the warning messages will only be produced for the things being displayed. -x <number or name> --hex-dump=<number or name> Displays the contents of the indicated section as a hexadecimal bytes. A number identifies a particular section by index in the section table; any other string identifies all sections with that name in the object file. -R <number or name> --relocated-dump=<number or name> Displays the contents of the indicated section as a hexadecimal bytes. A number identifies a particular section by index in the section table; any other string identifies all sections with that name in the object file. The contents of the section will be relocated before they are displayed. -p <number or name> --string-dump=<number or name> Displays the contents of the indicated section as printable strings. A number identifies a particular section by index in the section table; any other string identifies all sections with that name in the object file. -z --decompress Requests that the section(s) being dumped by x, R or p options are decompressed before being displayed. If the section(s) are not compressed then they are displayed as is. -c --archive-index Displays the file symbol index information contained in the header part of binary archives. Performs the same function as the t command to ar, but without using the BFD library. -w[lLiaprmfFsOoRtUuTgAckK] --debug-dump[=rawline,=decodedline,=info,=abbrev,=pubnames,=aranges,=macro,=frames,=frames-interp,=str,=str-offsets,=loc,=Ranges,=pubtypes,=trace_info,=trace_abbrev,=trace_aranges,=gdb_index,=addr,=cu_index,=links,=follow-links] Displays the contents of the DWARF debug sections in the file, if any are present. Compressed debug sections are automatically decompressed (temporarily) before they are displayed. If one or more of the optional letters or words follows the switch then only those type(s) of data will be dumped. The letters and words refer to the following information: \"a\" \"=abbrev\" Displays the contents of the .debug_abbrev section. \"A\" \"=addr\" Displays the contents of the .debug_addr section. \"c\" \"=cu_index\" Displays the contents of the .debug_cu_index and/or .debug_tu_index sections. \"f\" \"=frames\" Display the raw contents of a .debug_frame section. \"F\" \"=frames-interp\" Display the interpreted contents of a .debug_frame section. \"g\" \"=gdb_index\" Displays the contents of the .gdb_index and/or .debug_names sections. \"i\" \"=info\" Displays the contents of the .debug_info section. Note: the output from this option can also be restricted by the use of the --dwarf-depth and --dwarf-start options. \"k\" \"=links\" Displays the contents of the .gnu_debuglink, .gnu_debugaltlink and .debug_sup sections, if any of them are present. Also displays any links to separate dwarf object files (dwo), if they are specified by the DW_AT_GNU_dwo_name or DW_AT_dwo_name attributes in the .debug_info section. \"K\" \"=follow-links\" Display the contents of any selected debug sections that are found in linked, separate debug info file(s). This can result in multiple versions of the same debug section being displayed if it exists in more than one file. In addition, when displaying DWARF attributes, if a form is found that references the separate debug info file, then the referenced contents will also be displayed. Note - in some distributions this option is enabled by default. It can be disabled via the N debug option. The default can be chosen when configuring the binutils via the --enable-follow-debug-links=yes or --enable-follow-debug-links=no options. If these are not used then the default is to enable the following of debug links. Note - if support for the debuginfod protocol was enabled when the binutils were built then this option will also include an attempt to contact any debuginfod servers mentioned in the DEBUGINFOD_URLS environment variable. This could take some time to resolve. This behaviour can be disabled via the =do-not-use-debuginfod debug option. \"N\" \"=no-follow-links\" Disables the following of links to separate debug info files. \"D\" \"=use-debuginfod\" Enables contacting debuginfod servers if there is a need to follow debug links. This is the default behaviour. \"E\" \"=do-not-use-debuginfod\" Disables contacting debuginfod servers when there is a need to follow debug links. \"l\" \"=rawline\" Displays the contents of the .debug_line section in a raw format. \"L\" \"=decodedline\" Displays the interpreted contents of the .debug_line section. \"m\" \"=macro\" Displays the contents of the .debug_macro and/or .debug_macinfo sections. \"o\" \"=loc\" Displays the contents of the .debug_loc and/or .debug_loclists sections. \"O\" \"=str-offsets\" Displays the contents of the .debug_str_offsets section. \"p\" \"=pubnames\" Displays the contents of the .debug_pubnames and/or .debug_gnu_pubnames sections. \"r\" \"=aranges\" Displays the contents of the .debug_aranges section. \"R\" \"=Ranges\" Displays the contents of the .debug_ranges and/or .debug_rnglists sections. \"s\" \"=str\" Displays the contents of the .debug_str, .debug_line_str and/or .debug_str_offsets sections. \"t\" \"=pubtype\" Displays the contents of the .debug_pubtypes and/or .debug_gnu_pubtypes sections. \"T\" \"=trace_aranges\" Displays the contents of the .trace_aranges section. \"u\" \"=trace_abbrev\" Displays the contents of the .trace_abbrev section. \"U\" \"=trace_info\" Displays the contents of the .trace_info section. Note: displaying the contents of .debug_static_funcs, .debug_static_vars and debug_weaknames sections is not currently supported. --dwarf-depth=n Limit the dump of the \".debug_info\" section to n children. This is only useful with --debug-dump=info. The default is to print all DIEs; the special value 0 for n will also have this effect. With a non-zero value for n, DIEs at or deeper than n levels will not be printed. The range for n is zero-based. --dwarf-start=n Print only DIEs beginning with the DIE numbered n. This is only useful with --debug-dump=info. If specified, this option will suppress printing of any header information and all DIEs before the DIE numbered n. Only siblings and children of the specified DIE will be printed. This can be used in conjunction with --dwarf-depth. -P --process-links Display the contents of non-debug sections found in separate debuginfo files that are linked to the main file. This option automatically implies the -wK option, and only sections requested by other command line options will be displayed. --ctf[=section] Display the contents of the specified CTF section. CTF sections themselves contain many subsections, all of which are displayed in order. By default, display the name of the section named .ctf, which is the name emitted by ld. --ctf-parent=member If the CTF section contains ambiguously-defined types, it will consist of an archive of many CTF dictionaries, all inheriting from one dictionary containing unambiguous types. This member is by default named .ctf, like the section containing it, but it is possible to change this name using the \"ctf_link_set_memb_name_changer\" function at link time. When looking at CTF archives that have been created by a linker that uses the name changer to rename the parent archive member, --ctf-parent can be used to specify the name used for the parent. --ctf-symbols=section --ctf-strings=section Specify the name of another section from which the CTF file can inherit strings and symbols. By default, the \".symtab\" and its linked string table are used. If either of --ctf-symbols or --ctf-strings is specified, the other must be specified as well. -I --histogram Display a histogram of bucket list lengths when displaying the contents of the symbol tables. -v --version Display the version number of readelf. -W --wide Don't break output lines to fit into 80 columns. By default readelf breaks section header and segment listing lines for 64-bit ELF files, so that they fit into 80 columns. This option causes readelf to print each section header resp. each segment one a single line, which is far more readable on terminals wider than 80 columns. -T --silent-truncation Normally when readelf is displaying a symbol name, and it has to truncate the name to fit into an 80 column display, it will add a suffix of \"[...]\" to the name. This command line option disables this behaviour, allowing 5 more characters of the name to be displayed and restoring the old behaviour of readelf (prior to release 2.35). -H --help Display the command-line options understood by readelf. @file Read command-line options from file. The options read are inserted in place of the original @file option. If file does not exist, or cannot be read, then the option will be treated literally, and not removed. Options in file are separated by whitespace. A whitespace character may be included in an option by surrounding the entire option in either single or double quotes. Any character (including a backslash) may be included by prefixing the character to be included with a backslash. The file may itself contain additional @file options; any such options will be processed recursively. "
  },
  {
    "command": "ld",
    "description": " ld combines a number of object and archive files, relocates their data and ties up symbol references. Usually the last step in compiling a program is to run ld. ld accepts Linker Command Language files written in a superset of AT&T's Link Editor Command Language syntax, to provide explicit and total control over the linking process. This man page does not describe the command language; see the ld entry in \"info\" for full details on the command language and on other aspects of the GNU linker. This version of ld uses the general purpose BFD libraries to operate on object files. This allows ld to read, combine, and write object files in many different formats---for example, COFF or \"a.out\". Different formats may be linked together to produce any available kind of object file. Aside from its flexibility, the GNU linker is more helpful than other linkers in providing diagnostic information. Many linkers abandon execution immediately upon encountering an error; whenever possible, ld continues executing, allowing you to identify other errors (or, in some cases, to get an output file in spite of the error). The GNU linker ld is meant to cover a broad range of situations, and to be as compatible as possible with other linkers. As a result, you have many choices to control its behavior. The linker supports a plethora of command-line options, but in actual practice few of them are used in any particular context. For instance, a frequent use of ld is to link standard Unix object files on a standard, supported Unix system. On such a system, to link a file \"hello.o\": ld -o <output> /lib/crt0.o hello.o -lc This tells ld to produce a file called output as the result of linking the file \"/lib/crt0.o\" with \"hello.o\" and the library \"libc.a\", which will come from the standard search directories. (See the discussion of the -l option below.) Some of the command-line options to ld may be specified at any point in the command line. However, options which refer to files, such as -l or -T, cause the file to be read at the point at which the option appears in the command line, relative to the object files and other file options. Repeating non-file options with a different argument will either have no further effect, or override prior occurrences (those further to the left on the command line) of that option. Options which may be meaningfully specified more than once are noted in the descriptions below. Non-option arguments are object files or archives which are to be linked together. They may follow, precede, or be mixed in with command-line options, except that an object file argument may not be placed between an option and its argument. Usually the linker is invoked with at least one object file, but you can specify other forms of binary input files using -l, -R, and the script command language. If no binary input files at all are specified, the linker does not produce any output, and issues the message No input files. If the linker cannot recognize the format of an object file, it will assume that it is a linker script. A script specified in this way augments the main linker script used for the link (either the default linker script or the one specified by using -T). This feature permits the linker to link against a file which appears to be an object or an archive, but actually merely defines some symbol values, or uses \"INPUT\" or \"GROUP\" to load other objects. Specifying a script in this way merely augments the main linker script, with the extra commands placed after the main script; use the -T option to replace the default linker script entirely, but note the effect of the \"INSERT\" command. For options whose names are a single letter, option arguments must either follow the option letter without intervening whitespace, or be given as separate arguments immediately following the option that requires them. For options whose names are multiple letters, either one dash or two can precede the option name; for example, -trace-symbol and --trace-symbol are equivalent. Note---there is one exception to this rule. Multiple letter options that start with a lower case 'o' can only be preceded by two dashes. This is to reduce confusion with the -o option. So for example -omagic sets the output file name to magic whereas --omagic sets the NMAGIC flag on the output. Arguments to multiple-letter options must either be separated from the option name by an equals sign, or be given as separate arguments immediately following the option that requires them. For example, --trace-symbol foo and --trace-symbol=foo are equivalent. Unique abbreviations of the names of multiple-letter options are accepted. Note---if the linker is being invoked indirectly, via a compiler driver (e.g. gcc) then all the linker command-line options should be prefixed by -Wl, (or whatever is appropriate for the particular compiler driver) like this: gcc -Wl,--start-group foo.o bar.o -Wl,--end-group This is important, because otherwise the compiler driver program may silently drop the linker options, resulting in a bad link. Confusion may also arise when passing options that require values through a driver, as the use of a space between option and argument acts as a separator, and causes the driver to pass only the option to the linker and the argument to the compiler. In this case, it is simplest to use the joined forms of both single- and multiple-letter options, such as: gcc foo.o bar.o -Wl,-eENTRY -Wl,-Map=a.map Here is a table of the generic command-line switches accepted by the GNU linker: @file Read command-line options from file. The options read are inserted in place of the original @file option. If file does not exist, or cannot be read, then the option will be treated literally, and not removed. Options in file are separated by whitespace. A whitespace character may be included in an option by surrounding the entire option in either single or double quotes. Any character (including a backslash) may be included by prefixing the character to be included with a backslash. The file may itself contain additional @file options; any such options will be processed recursively. -a keyword This option is supported for HP/UX compatibility. The keyword argument must be one of the strings archive, shared, or default. -aarchive is functionally equivalent to -Bstatic, and the other two keywords are functionally equivalent to -Bdynamic. This option may be used any number of times. --audit AUDITLIB Adds AUDITLIB to the \"DT_AUDIT\" entry of the dynamic section. AUDITLIB is not checked for existence, nor will it use the DT_SONAME specified in the library. If specified multiple times \"DT_AUDIT\" will contain a colon separated list of audit interfaces to use. If the linker finds an object with an audit entry while searching for shared libraries, it will add a corresponding \"DT_DEPAUDIT\" entry in the output file. This option is only meaningful on ELF platforms supporting the rtld-audit interface. -b input-format --format=input-format ld may be configured to support more than one kind of object file. If your ld is configured this way, you can use the -b option to specify the binary format for input object files that follow this option on the command line. Even when ld is configured to support alternative object formats, you don't usually need to specify this, as ld should be configured to expect as a default input format the most usual format on each machine. input-format is a text string, the name of a particular format supported by the BFD libraries. (You can list the available binary formats with objdump -i.) You may want to use this option if you are linking files with an unusual binary format. You can also use -b to switch formats explicitly (when linking object files of different formats), by including -b input-format before each group of object files in a particular format. The default format is taken from the environment variable \"GNUTARGET\". You can also define the input format from a script, using the command \"TARGET\"; -c MRI-commandfile --mri-script=MRI-commandfile For compatibility with linkers produced by MRI, ld accepts script files written in an alternate, restricted command language, described in the MRI Compatible Script Files section of GNU ld documentation. Introduce MRI script files with the option -c; use the -T option to run linker scripts written in the general-purpose ld scripting language. If MRI-cmdfile does not exist, ld looks for it in the directories specified by any -L options. -d -dc -dp These three options are equivalent; multiple forms are supported for compatibility with other linkers. They assign space to common symbols even if a relocatable output file is specified (with -r). The script command \"FORCE_COMMON_ALLOCATION\" has the same effect. --depaudit AUDITLIB -P AUDITLIB Adds AUDITLIB to the \"DT_DEPAUDIT\" entry of the dynamic section. AUDITLIB is not checked for existence, nor will it use the DT_SONAME specified in the library. If specified multiple times \"DT_DEPAUDIT\" will contain a colon separated list of audit interfaces to use. This option is only meaningful on ELF platforms supporting the rtld-audit interface. The -P option is provided for Solaris compatibility. --enable-non-contiguous-regions This option avoids generating an error if an input section does not fit a matching output section. The linker tries to allocate the input section to subseque nt matching output sections, and generates an error only if no output section is large enough. This is useful when several non-contiguous memory regions are available and the input section does not require a particular one. The order in which input sections are evaluated does not change, for instance: MEMORY { MEM1 (rwx) : ORIGIN : 0x1000, LENGTH = 0x14 MEM2 (rwx) : ORIGIN : 0x1000, LENGTH = 0x40 MEM3 (rwx) : ORIGIN : 0x2000, LENGTH = 0x40 } SECTIONS { mem1 : { *(.data.*); } > MEM1 mem2 : { *(.data.*); } > MEM2 mem3 : { *(.data.*); } > MEM2 } with input sections: .data.1: size 8 .data.2: size 0x10 .data.3: size 4 results in .data.1 affected to mem1, and .data.2 and .data.3 affected to mem2, even though .data.3 would fit in mem3. This option is incompatible with INSERT statements because it changes the way input sections are mapped to output sections. --enable-non-contiguous-regions-warnings This option enables warnings when \"--enable-non-contiguous-regions\" allows possibly unexpected matches in sections mapping, potentially leading to silently discarding a section instead of failing because it does not fit any output region. -e entry --entry=entry Use entry as the explicit symbol for beginning execution of your program, rather than the default entry point. If there is no symbol named entry, the linker will try to parse entry as a number, and use that as the entry address (the number will be interpreted in base 10; you may use a leading 0x for base 16, or a leading 0 for base 8). --exclude-libs lib,lib,... Specifies a list of archive libraries from which symbols should not be automatically exported. The library names may be delimited by commas or colons. Specifying \"--exclude-libs ALL\" excludes symbols in all archive libraries from automatic export. This option is available only for the i386 PE targeted port of the linker and for ELF targeted ports. For i386 PE, symbols explicitly listed in a .def file are still exported, regardless of this option. For ELF targeted ports, symbols affected by this option will be treated as hidden. --exclude-modules-for-implib module,module,... Specifies a list of object files or archive members, from which symbols should not be automatically exported, but which should be copied wholesale into the import library being generated during the link. The module names may be delimited by commas or colons, and must match exactly the filenames used by ld to open the files; for archive members, this is simply the member name, but for object files the name listed must include and match precisely any path used to specify the input file on the linker's command-line. This option is available only for the i386 PE targeted port of the linker. Symbols explicitly listed in a .def file are still exported, regardless of this option. -E --export-dynamic --no-export-dynamic When creating a dynamically linked executable, using the -E option or the --export-dynamic option causes the linker to add all symbols to the dynamic symbol table. The dynamic symbol table is the set of symbols which are visible from dynamic objects at run time. If you do not use either of these options (or use the --no-export-dynamic option to restore the default behavior), the dynamic symbol table will normally contain only those symbols which are referenced by some dynamic object mentioned in the link. If you use \"dlopen\" to load a dynamic object which needs to refer back to the symbols defined by the program, rather than some other dynamic object, then you will probably need to use this option when linking the program itself. You can also use the dynamic list to control what symbols should be added to the dynamic symbol table if the output format supports it. See the description of --dynamic-list. Note that this option is specific to ELF targeted ports. PE targets support a similar function to export all symbols from a DLL or EXE; see the description of --export-all-symbols below. --export-dynamic-symbol=glob When creating a dynamically linked executable, symbols matching glob will be added to the dynamic symbol table. When creating a shared library, references to symbols matching glob will not be bound to the definitions within the shared library. This option is a no-op when creating a shared library and -Bsymbolic or --dynamic-list are not specified. This option is only meaningful on ELF platforms which support shared libraries. --export-dynamic-symbol-list=file Specify a --export-dynamic-symbol for each pattern in the file. The format of the file is the same as the version node without scope and node name. See VERSION for more information. -EB Link big-endian objects. This affects the default output format. -EL Link little-endian objects. This affects the default output format. -f name --auxiliary=name When creating an ELF shared object, set the internal DT_AUXILIARY field to the specified name. This tells the dynamic linker that the symbol table of the shared object should be used as an auxiliary filter on the symbol table of the shared object name. If you later link a program against this filter object, then, when you run the program, the dynamic linker will see the DT_AUXILIARY field. If the dynamic linker resolves any symbols from the filter object, it will first check whether there is a definition in the shared object name. If there is one, it will be used instead of the definition in the filter object. The shared object name need not exist. Thus the shared object name may be used to provide an alternative implementation of certain functions, perhaps for debugging or for machine-specific performance. This option may be specified more than once. The DT_AUXILIARY entries will be created in the order in which they appear on the command line. -F name --filter=name When creating an ELF shared object, set the internal DT_FILTER field to the specified name. This tells the dynamic linker that the symbol table of the shared object which is being created should be used as a filter on the symbol table of the shared object name. If you later link a program against this filter object, then, when you run the program, the dynamic linker will see the DT_FILTER field. The dynamic linker will resolve symbols according to the symbol table of the filter object as usual, but it will actually link to the definitions found in the shared object name. Thus the filter object can be used to select a subset of the symbols provided by the object name. Some older linkers used the -F option throughout a compilation toolchain for specifying object-file format for both input and output object files. The GNU linker uses other mechanisms for this purpose: the -b, --format, --oformat options, the \"TARGET\" command in linker scripts, and the \"GNUTARGET\" environment variable. The GNU linker will ignore the -F option when not creating an ELF shared object. -fini=name When creating an ELF executable or shared object, call NAME when the executable or shared object is unloaded, by setting DT_FINI to the address of the function. By default, the linker uses \"_fini\" as the function to call. -g Ignored. Provided for compatibility with other tools. -G value --gpsize=value Set the maximum size of objects to be optimized using the GP register to size. This is only meaningful for object file formats such as MIPS ELF that support putting large and small objects into different sections. This is ignored for other object file formats. -h name -soname=name When creating an ELF shared object, set the internal DT_SONAME field to the specified name. When an executable is linked with a shared object which has a DT_SONAME field, then when the executable is run the dynamic linker will attempt to load the shared object specified by the DT_SONAME field rather than using the file name given to the linker. -i Perform an incremental link (same as option -r). -init=name When creating an ELF executable or shared object, call NAME when the executable or shared object is loaded, by setting DT_INIT to the address of the function. By default, the linker uses \"_init\" as the function to call. -l namespec --library=namespec Add the archive or object file specified by namespec to the list of files to link. This option may be used any number of times. If namespec is of the form :filename, ld will search the library path for a file called filename, otherwise it will search the library path for a file called libnamespec.a. On systems which support shared libraries, ld may also search for files other than libnamespec.a. Specifically, on ELF and SunOS systems, ld will search a directory for a library called libnamespec.so before searching for one called libnamespec.a. (By convention, a \".so\" extension indicates a shared library.) Note that this behavior does not apply to :filename, which always specifies a file called filename. The linker will search an archive only once, at the location where it is specified on the command line. If the archive defines a symbol which was undefined in some object which appeared before the archive on the command line, the linker will include the appropriate file(s) from the archive. However, an undefined symbol in an object appearing later on the command line will not cause the linker to search the archive again. See the -( option for a way to force the linker to search archives multiple times. You may list the same archive multiple times on the command line. This type of archive searching is standard for Unix linkers. However, if you are using ld on AIX, note that it is different from the behaviour of the AIX linker. -L searchdir --library-path=searchdir Add path searchdir to the list of paths that ld will search for archive libraries and ld control scripts. You may use this option any number of times. The directories are searched in the order in which they are specified on the command line. Directories specified on the command line are searched before the default directories. All -L options apply to all -l options, regardless of the order in which the options appear. -L options do not affect how ld searches for a linker script unless -T option is specified. If searchdir begins with \"=\" or $SYSROOT, then this prefix will be replaced by the sysroot prefix, controlled by the --sysroot option, or specified when the linker is configured. The default set of paths searched (without being specified with -L) depends on which emulation mode ld is using, and in some cases also on how it was configured. The paths can also be specified in a link script with the \"SEARCH_DIR\" command. Directories specified this way are searched at the point in which the linker script appears in the command line. -m emulation Emulate the emulation linker. You can list the available emulations with the --verbose or -V options. If the -m option is not used, the emulation is taken from the \"LDEMULATION\" environment variable, if that is defined. Otherwise, the default emulation depends upon how the linker was configured. -M --print-map Print a link map to the standard output. A link map provides information about the link, including the following: \u2022 Where object files are mapped into memory. \u2022 How common symbols are allocated. \u2022 All archive members included in the link, with a mention of the symbol which caused the archive member to be brought in. \u2022 The values assigned to symbols. Note - symbols whose values are computed by an expression which involves a reference to a previous value of the same symbol may not have correct result displayed in the link map. This is because the linker discards intermediate results and only retains the final value of an expression. Under such circumstances the linker will display the final value enclosed by square brackets. Thus for example a linker script containing: foo = 1 foo = foo * 4 foo = foo + 8 will produce the following output in the link map if the -M option is used: 0x00000001 foo = 0x1 [0x0000000c] foo = (foo * 0x4) [0x0000000c] foo = (foo + 0x8) See Expressions for more information about expressions in linker scripts. \u2022 How GNU properties are merged. When the linker merges input .note.gnu.property sections into one output .note.gnu.property section, some properties are removed or updated. These actions are reported in the link map. For example: Removed property 0xc0000002 to merge foo.o (0x1) and bar.o (not found) This indicates that property 0xc0000002 is removed from output when merging properties in foo.o, whose property 0xc0000002 value is 0x1, and bar.o, which doesn't have property 0xc0000002. Updated property 0xc0010001 (0x1) to merge foo.o (0x1) and bar.o (0x1) This indicates that property 0xc0010001 value is updated to 0x1 in output when merging properties in foo.o, whose 0xc0010001 property value is 0x1, and bar.o, whose 0xc0010001 property value is 0x1. --print-map-discarded --no-print-map-discarded Print (or do not print) the list of discarded and garbage collected sections in the link map. Enabled by default. -n --nmagic Turn off page alignment of sections, and disable linking against shared libraries. If the output format supports Unix style magic numbers, mark the output as \"NMAGIC\". -N --omagic Set the text and data sections to be readable and writable. Also, do not page-align the data segment, and disable linking against shared libraries. If the output format supports Unix style magic numbers, mark the output as \"OMAGIC\". Note: Although a writable text section is allowed for PE-COFF targets, it does not conform to the format specification published by Microsoft. --no-omagic This option negates most of the effects of the -N option. It sets the text section to be read-only, and forces the data segment to be page-aligned. Note - this option does not enable linking against shared libraries. Use -Bdynamic for this. -o output --output=output Use output as the name for the program produced by ld; if this option is not specified, the name a.out is used by default. The script command \"OUTPUT\" can also specify the output file name. --dependency-file=depfile Write a dependency file to depfile. This file contains a rule suitable for \"make\" describing the output file and all the input files that were read to produce it. The output is similar to the compiler's output with -M -MP. Note that there is no option like the compiler's -MM, to exclude \"system files\" (which is not a well-specified concept in the linker, unlike \"system headers\" in the compiler). So the output from --dependency-file is always specific to the exact state of the installation where it was produced, and should not be copied into distributed makefiles without careful editing. -O level If level is a numeric values greater than zero ld optimizes the output. This might take significantly longer and therefore probably should only be enabled for the final binary. At the moment this option only affects ELF shared library generation. Future releases of the linker may make more use of this option. Also currently there is no difference in the linker's behaviour for different non-zero values of this option. Again this may change with future releases. -plugin name Involve a plugin in the linking process. The name parameter is the absolute filename of the plugin. Usually this parameter is automatically added by the complier, when using link time optimization, but users can also add their own plugins if they so wish. Note that the location of the compiler originated plugins is different from the place where the ar, nm and ranlib programs search for their plugins. In order for those commands to make use of a compiler based plugin it must first be copied into the ${libdir}/bfd-plugins directory. All gcc based linker plugins are backward compatible, so it is sufficient to just copy in the newest one. --push-state The --push-state allows one to preserve the current state of the flags which govern the input file handling so that they can all be restored with one corresponding --pop-state option. The option which are covered are: -Bdynamic, -Bstatic, -dn, -dy, -call_shared, -non_shared, -static, -N, -n, --whole-archive, --no-whole-archive, -r, -Ur, --copy-dt-needed-entries, --no-copy-dt-needed-entries, --as-needed, --no-as-needed, and -a. One target for this option are specifications for pkg-config. When used with the --libs option all possibly needed libraries are listed and then possibly linked with all the time. It is better to return something as follows: -Wl,--push-state,--as-needed -libone -libtwo -Wl,--pop-state --pop-state Undoes the effect of --push-state, restores the previous values of the flags governing input file handling. -q --emit-relocs Leave relocation sections and contents in fully linked executables. Post link analysis and optimization tools may need this information in order to perform correct modifications of executables. This results in larger executables. This option is currently only supported on ELF platforms. --force-dynamic Force the output file to have dynamic sections. This option is specific to VxWorks targets. -r --relocatable Generate relocatable output---i.e., generate an output file that can in turn serve as input to ld. This is often called partial linking. As a side effect, in environments that support standard Unix magic numbers, this option also sets the output file's magic number to \"OMAGIC\". If this option is not specified, an absolute file is produced. When linking C++ programs, this option will not resolve references to constructors; to do that, use -Ur. When an input file does not have the same format as the output file, partial linking is only supported if that input file does not contain any relocations. Different output formats can have further restrictions; for example some \"a.out\"-based formats do not support partial linking with input files in other formats at all. This option does the same thing as -i. -R filename --just-symbols=filename Read symbol names and their addresses from filename, but do not relocate it or include it in the output. This allows your output file to refer symbolically to absolute locations of memory defined in other programs. You may use this option more than once. For compatibility with other ELF linkers, if the -R option is followed by a directory name, rather than a file name, it is treated as the -rpath option. -s --strip-all Omit all symbol information from the output file. -S --strip-debug Omit debugger symbol information (but not all symbols) from the output file. --strip-discarded --no-strip-discarded Omit (or do not omit) global symbols defined in discarded sections. Enabled by default. -t --trace Print the names of the input files as ld processes them. If -t is given twice then members within archives are also printed. -t output is useful to generate a list of all the object files and scripts involved in linking, for example, when packaging files for a linker bug report. -T scriptfile --script=scriptfile Use scriptfile as the linker script. This script replaces ld's default linker script (rather than adding to it), so commandfile must specify everything necessary to describe the output file. If scriptfile does not exist in the current directory, \"ld\" looks for it in the directories specified by any preceding -L options. Multiple -T options accumulate. -dT scriptfile --default-script=scriptfile Use scriptfile as the default linker script. This option is similar to the --script option except that processing of the script is delayed until after the rest of the command line has been processed. This allows options placed after the --default-script option on the command line to affect the behaviour of the linker script, which can be important when the linker command line cannot be directly controlled by the user. (eg because the command line is being constructed by another tool, such as gcc). -u symbol --undefined=symbol Force symbol to be entered in the output file as an undefined symbol. Doing this may, for example, trigger linking of additional modules from standard libraries. -u may be repeated with different option arguments to enter additional undefined symbols. This option is equivalent to the \"EXTERN\" linker script command. If this option is being used to force additional modules to be pulled into the link, and if it is an error for the symbol to remain undefined, then the option --require-defined should be used instead. --require-defined=symbol Require that symbol is defined in the output file. This option is the same as option --undefined except that if symbol is not defined in the output file then the linker will issue an error and exit. The same effect can be achieved in a linker script by using \"EXTERN\", \"ASSERT\" and \"DEFINED\" together. This option can be used multiple times to require additional symbols. -Ur For anything other than C++ programs, this option is equivalent to -r: it generates relocatable output---i.e., an output file that can in turn serve as input to ld. When linking C++ programs, -Ur does resolve references to constructors, unlike -r. It does not work to use -Ur on files that were themselves linked with -Ur; once the constructor table has been built, it cannot be added to. Use -Ur only for the last partial link, and -r for the others. --orphan-handling=MODE Control how orphan sections are handled. An orphan section is one not specifically mentioned in a linker script. MODE can have any of the following values: \"place\" Orphan sections are placed into a suitable output section following the strategy described in Orphan Sections. The option --unique also affects how sections are placed. \"discard\" All orphan sections are discarded, by placing them in the /DISCARD/ section. \"warn\" The linker will place the orphan section as for \"place\" and also issue a warning. \"error\" The linker will exit with an error if any orphan section is found. The default if --orphan-handling is not given is \"place\". --unique[=SECTION] Creates a separate output section for every input section matching SECTION, or if the optional wildcard SECTION argument is missing, for every orphan input section. An orphan section is one not specifically mentioned in a linker script. You may use this option multiple times on the command line; It prevents the normal merging of input sections with the same name, overriding output section assignments in a linker script. -v --version -V Display the version number for ld. The -V option also lists the supported emulations. -x --discard-all Delete all local symbols. -X --discard-locals Delete all temporary local symbols. (These symbols start with system-specific local label prefixes, typically .L for ELF systems or L for traditional a.out systems.) -y symbol --trace-symbol=symbol Print the name of each linked file in which symbol appears. This option may be given any number of times. On many systems it is necessary to prepend an underscore. This option is useful when you have an undefined symbol in your link but don't know where the reference is coming from. -Y path Add path to the default library search path. This option exists for Solaris compatibility. -z keyword The recognized keywords are: call-nop=prefix-addr call-nop=suffix-nop call-nop=prefix-byte call-nop=suffix-byte Specify the 1-byte \"NOP\" padding when transforming indirect call to a locally defined function, foo, via its GOT slot. call-nop=prefix-addr generates \"0x67 call foo\". call-nop=suffix-nop generates \"call foo 0x90\". call-nop=prefix-byte generates \"byte call foo\". call-nop=suffix-byte generates \"call foo byte\". Supported for i386 and x86_64. cet-report=none cet-report=warning cet-report=error Specify how to report the missing GNU_PROPERTY_X86_FEATURE_1_IBT and GNU_PROPERTY_X86_FEATURE_1_SHSTK properties in input .note.gnu.property section. cet-report=none, which is the default, will make the linker not report missing properties in input files. cet-report=warning will make the linker issue a warning for missing properties in input files. cet-report=error will make the linker issue an error for missing properties in input files. Note that ibt will turn off the missing GNU_PROPERTY_X86_FEATURE_1_IBT property report and shstk will turn off the missing GNU_PROPERTY_X86_FEATURE_1_SHSTK property report. Supported for Linux/i386 and Linux/x86_64. combreloc nocombreloc Combine multiple dynamic relocation sections and sort to improve dynamic symbol lookup caching. Do not do this if nocombreloc. common nocommon Generate common symbols with STT_COMMON type during a relocatable link. Use STT_OBJECT type if nocommon. common-page-size=value Set the page size most commonly used to value. Memory image layout will be optimized to minimize memory pages if the system is using pages of this size. defs Report unresolved symbol references from regular object files. This is done even if the linker is creating a non-symbolic shared library. This option is the inverse of -z undefs. dynamic-undefined-weak nodynamic-undefined-weak Make undefined weak symbols dynamic when building a dynamic object, if they are referenced from a regular object file and not forced local by symbol visibility or versioning. Do not make them dynamic if nodynamic- undefined-weak. If neither option is given, a target may default to either option being in force, or make some other selection of undefined weak symbols dynamic. Not all targets support these options. execstack Marks the object as requiring executable stack. global This option is only meaningful when building a shared object. It makes the symbols defined by this shared object available for symbol resolution of subsequently loaded libraries. globalaudit This option is only meaningful when building a dynamic executable. This option marks the executable as requiring global auditing by setting the \"DF_1_GLOBAUDIT\" bit in the \"DT_FLAGS_1\" dynamic tag. Global auditing requires that any auditing library defined via the --depaudit or -P command-line options be run for all dynamic objects loaded by the application. ibtplt Generate Intel Indirect Branch Tracking (IBT) enabled PLT entries. Supported for Linux/i386 and Linux/x86_64. ibt Generate GNU_PROPERTY_X86_FEATURE_1_IBT in .note.gnu.property section to indicate compatibility with IBT. This also implies ibtplt. Supported for Linux/i386 and Linux/x86_64. indirect-extern-access noindirect-extern-access Generate GNU_PROPERTY_1_NEEDED_INDIRECT_EXTERN_ACCESS in .note.gnu.property section to indicate that object file requires canonical function pointers and cannot be used with copy relocation. This option also implies noextern- protected-data and nocopyreloc. Supported for i386 and x86-64. noindirect-extern-access removes GNU_PROPERTY_1_NEEDED_INDIRECT_EXTERN_ACCESS from .note.gnu.property section. initfirst This option is only meaningful when building a shared object. It marks the object so that its runtime initialization will occur before the runtime initialization of any other objects brought into the process at the same time. Similarly the runtime finalization of the object will occur after the runtime finalization of any other objects. interpose Specify that the dynamic loader should modify its symbol search order so that symbols in this shared library interpose all other shared libraries not so marked. unique nounique When generating a shared library or other dynamically loadable ELF object mark it as one that should (by default) only ever be loaded once, and only in the main namespace (when using \"dlmopen\"). This is primarily used to mark fundamental libraries such as libc, libpthread et al which do not usually function correctly unless they are the sole instances of themselves. This behaviour can be overridden by the \"dlmopen\" caller and does not apply to certain loading mechanisms (such as audit libraries). lam-u48 Generate GNU_PROPERTY_X86_FEATURE_1_LAM_U48 in .note.gnu.property section to indicate compatibility with Intel LAM_U48. Supported for Linux/x86_64. lam-u57 Generate GNU_PROPERTY_X86_FEATURE_1_LAM_U57 in .note.gnu.property section to indicate compatibility with Intel LAM_U57. Supported for Linux/x86_64. lam-u48-report=none lam-u48-report=warning lam-u48-report=error Specify how to report the missing GNU_PROPERTY_X86_FEATURE_1_LAM_U48 property in input .note.gnu.property section. lam-u48-report=none, which is the default, will make the linker not report missing properties in input files. lam-u48-report=warning will make the linker issue a warning for missing properties in input files. lam-u48-report=error will make the linker issue an error for missing properties in input files. Supported for Linux/x86_64. lam-u57-report=none lam-u57-report=warning lam-u57-report=error Specify how to report the missing GNU_PROPERTY_X86_FEATURE_1_LAM_U57 property in input .note.gnu.property section. lam-u57-report=none, which is the default, will make the linker not report missing properties in input files. lam-u57-report=warning will make the linker issue a warning for missing properties in input files. lam-u57-report=error will make the linker issue an error for missing properties in input files. Supported for Linux/x86_64. lam-report=none lam-report=warning lam-report=error Specify how to report the missing GNU_PROPERTY_X86_FEATURE_1_LAM_U48 and GNU_PROPERTY_X86_FEATURE_1_LAM_U57 properties in input .note.gnu.property section. lam-report=none, which is the default, will make the linker not report missing properties in input files. lam-report=warning will make the linker issue a warning for missing properties in input files. lam-report=error will make the linker issue an error for missing properties in input files. Supported for Linux/x86_64. lazy When generating an executable or shared library, mark it to tell the dynamic linker to defer function call resolution to the point when the function is called (lazy binding), rather than at load time. Lazy binding is the default. loadfltr Specify that the object's filters be processed immediately at runtime. max-page-size=value Set the maximum memory page size supported to value. muldefs Allow multiple definitions. nocopyreloc Disable linker generated .dynbss variables used in place of variables defined in shared libraries. May result in dynamic text relocations. nodefaultlib Specify that the dynamic loader search for dependencies of this object should ignore any default library search paths. nodelete Specify that the object shouldn't be unloaded at runtime. nodlopen Specify that the object is not available to \"dlopen\". nodump Specify that the object can not be dumped by \"dldump\". noexecstack Marks the object as not requiring executable stack. noextern-protected-data Don't treat protected data symbols as external when building a shared library. This option overrides the linker backend default. It can be used to work around incorrect relocations against protected data symbols generated by compiler. Updates on protected data symbols by another module aren't visible to the resulting shared library. Supported for i386 and x86-64. noreloc-overflow Disable relocation overflow check. This can be used to disable relocation overflow check if there will be no dynamic relocation overflow at run-time. Supported for x86_64. now When generating an executable or shared library, mark it to tell the dynamic linker to resolve all symbols when the program is started, or when the shared library is loaded by dlopen, instead of deferring function call resolution to the point when the function is first called. origin Specify that the object requires $ORIGIN handling in paths. pack-relative-relocs nopack-relative-relocs Generate compact relative relocation in position- independent executable and shared library. It adds \"DT_RELR\", \"DT_RELRSZ\" and \"DT_RELRENT\" entries to the dynamic section. It is ignored when building position- dependent executable and relocatable output. nopack- relative-relocs is the default, which disables compact relative relocation. When linked against the GNU C Library, a GLIBC_ABI_DT_RELR symbol version dependency on the shared C Library is added to the output. Supported for i386 and x86-64. relro norelro Create an ELF \"PT_GNU_RELRO\" segment header in the object. This specifies a memory segment that should be made read-only after relocation, if supported. Specifying common-page-size smaller than the system page size will render this protection ineffective. Don't create an ELF \"PT_GNU_RELRO\" segment if norelro. report-relative-reloc Report dynamic relative relocations generated by linker. Supported for Linux/i386 and Linux/x86_64. separate-code noseparate-code Create separate code \"PT_LOAD\" segment header in the object. This specifies a memory segment that should contain only instructions and must be in wholly disjoint pages from any other data. Don't create separate code \"PT_LOAD\" segment if noseparate-code is used. shstk Generate GNU_PROPERTY_X86_FEATURE_1_SHSTK in .note.gnu.property section to indicate compatibility with Intel Shadow Stack. Supported for Linux/i386 and Linux/x86_64. stack-size=value Specify a stack size for an ELF \"PT_GNU_STACK\" segment. Specifying zero will override any default non-zero sized \"PT_GNU_STACK\" segment creation. start-stop-gc nostart-stop-gc When --gc-sections is in effect, a reference from a retained section to \"__start_SECNAME\" or \"__stop_SECNAME\" causes all input sections named \"SECNAME\" to also be retained, if \"SECNAME\" is representable as a C identifier and either \"__start_SECNAME\" or \"__stop_SECNAME\" is synthesized by the linker. -z start-stop-gc disables this effect, allowing sections to be garbage collected as if the special synthesized symbols were not defined. -z start-stop-gc has no effect on a definition of \"__start_SECNAME\" or \"__stop_SECNAME\" in an object file or linker script. Such a definition will prevent the linker providing a synthesized \"__start_SECNAME\" or \"__stop_SECNAME\" respectively, and therefore the special treatment by garbage collection for those references. start-stop-visibility=value Specify the ELF symbol visibility for synthesized \"__start_SECNAME\" and \"__stop_SECNAME\" symbols. value must be exactly default, internal, hidden, or protected. If no -z start-stop-visibility option is given, protected is used for compatibility with historical practice. However, it's highly recommended to use -z start-stop-visibility=hidden in new programs and shared libraries so that these symbols are not exported between shared objects, which is not usually what's intended. text notext textoff Report an error if DT_TEXTREL is set, i.e., if the position-independent or shared object has dynamic relocations in read-only sections. Don't report an error if notext or textoff. undefs Do not report unresolved symbol references from regular object files, either when creating an executable, or when creating a shared library. This option is the inverse of -z defs. unique-symbol nounique-symbol Avoid duplicated local symbol names in the symbol string table. Append \".\"number\"\" to duplicated local symbol names if unique-symbol is used. nounique-symbol is the default. x86-64-baseline x86-64-v2 x86-64-v3 x86-64-v4 Specify the x86-64 ISA level needed in .note.gnu.property section. x86-64-baseline generates \"GNU_PROPERTY_X86_ISA_1_BASELINE\". x86-64-v2 generates \"GNU_PROPERTY_X86_ISA_1_V2\". x86-64-v3 generates \"GNU_PROPERTY_X86_ISA_1_V3\". x86-64-v4 generates \"GNU_PROPERTY_X86_ISA_1_V4\". Supported for Linux/i386 and Linux/x86_64. Other keywords are ignored for Solaris compatibility. -( archives -) --start-group archives --end-group The archives should be a list of archive files. They may be either explicit file names, or -l options. The specified archives are searched repeatedly until no new undefined references are created. Normally, an archive is searched only once in the order that it is specified on the command line. If a symbol in that archive is needed to resolve an undefined symbol referred to by an object in an archive that appears later on the command line, the linker would not be able to resolve that reference. By grouping the archives, they will all be searched repeatedly until all possible references are resolved. Using this option has a significant performance cost. It is best to use it only when there are unavoidable circular references between two or more archives. --accept-unknown-input-arch --no-accept-unknown-input-arch Tells the linker to accept input files whose architecture cannot be recognised. The assumption is that the user knows what they are doing and deliberately wants to link in these unknown input files. This was the default behaviour of the linker, before release 2.14. The default behaviour from release 2.14 onwards is to reject such input files, and so the --accept-unknown-input-arch option has been added to restore the old behaviour. --as-needed --no-as-needed This option affects ELF DT_NEEDED tags for dynamic libraries mentioned on the command line after the --as-needed option. Normally the linker will add a DT_NEEDED tag for each dynamic library mentioned on the command line, regardless of whether the library is actually needed or not. --as-needed causes a DT_NEEDED tag to only be emitted for a library that at that point in the link satisfies a non-weak undefined symbol reference from a regular object file or, if the library is not found in the DT_NEEDED lists of other needed libraries, a non-weak undefined symbol reference from another needed dynamic library. Object files or libraries appearing on the command line after the library in question do not affect whether the library is seen as needed. This is similar to the rules for extraction of object files from archives. --no-as-needed restores the default behaviour. Note: On Linux based systems the --as-needed option also has an affect on the behaviour of the --rpath and --rpath-link options. See the description of --rpath-link for more details. --add-needed --no-add-needed These two options have been deprecated because of the similarity of their names to the --as-needed and --no-as-needed options. They have been replaced by --copy-dt-needed-entries and --no-copy-dt-needed-entries. -assert keyword This option is ignored for SunOS compatibility. -Bdynamic -dy -call_shared Link against dynamic libraries. This is only meaningful on platforms for which shared libraries are supported. This option is normally the default on such platforms. The different variants of this option are for compatibility with various systems. You may use this option multiple times on the command line: it affects library searching for -l options which follow it. -Bgroup Set the \"DF_1_GROUP\" flag in the \"DT_FLAGS_1\" entry in the dynamic section. This causes the runtime linker to handle lookups in this object and its dependencies to be performed only inside the group. --unresolved-symbols=report-all is implied. This option is only meaningful on ELF platforms which support shared libraries. -Bstatic -dn -non_shared -static Do not link against shared libraries. This is only meaningful on platforms for which shared libraries are supported. The different variants of this option are for compatibility with various systems. You may use this option multiple times on the command line: it affects library searching for -l options which follow it. This option also implies --unresolved-symbols=report-all. This option can be used with -shared. Doing so means that a shared library is being created but that all of the library's external references must be resolved by pulling in entries from static libraries. -Bsymbolic When creating a shared library, bind references to global symbols to the definition within the shared library, if any. Normally, it is possible for a program linked against a shared library to override the definition within the shared library. This option is only meaningful on ELF platforms which support shared libraries. -Bsymbolic-functions When creating a shared library, bind references to global function symbols to the definition within the shared library, if any. This option is only meaningful on ELF platforms which support shared libraries. -Bno-symbolic This option can cancel previously specified -Bsymbolic and -Bsymbolic-functions. --dynamic-list=dynamic-list-file Specify the name of a dynamic list file to the linker. This is typically used when creating shared libraries to specify a list of global symbols whose references shouldn't be bound to the definition within the shared library, or creating dynamically linked executables to specify a list of symbols which should be added to the symbol table in the executable. This option is only meaningful on ELF platforms which support shared libraries. The format of the dynamic list is the same as the version node without scope and node name. See VERSION for more information. --dynamic-list-data Include all global data symbols to the dynamic list. --dynamic-list-cpp-new Provide the builtin dynamic list for C++ operator new and delete. It is mainly useful for building shared libstdc++. --dynamic-list-cpp-typeinfo Provide the builtin dynamic list for C++ runtime type identification. --check-sections --no-check-sections Asks the linker not to check section addresses after they have been assigned to see if there are any overlaps. Normally the linker will perform this check, and if it finds any overlaps it will produce suitable error messages. The linker does know about, and does make allowances for sections in overlays. The default behaviour can be restored by using the command-line switch --check-sections. Section overlap is not usually checked for relocatable links. You can force checking in that case by using the --check-sections option. --copy-dt-needed-entries --no-copy-dt-needed-entries This option affects the treatment of dynamic libraries referred to by DT_NEEDED tags inside ELF dynamic libraries mentioned on the command line. Normally the linker won't add a DT_NEEDED tag to the output binary for each library mentioned in a DT_NEEDED tag in an input dynamic library. With --copy-dt-needed-entries specified on the command line however any dynamic libraries that follow it will have their DT_NEEDED entries added. The default behaviour can be restored with --no-copy-dt-needed-entries. This option also has an effect on the resolution of symbols in dynamic libraries. With --copy-dt-needed-entries dynamic libraries mentioned on the command line will be recursively searched, following their DT_NEEDED tags to other libraries, in order to resolve symbols required by the output binary. With the default setting however the searching of dynamic libraries that follow it will stop with the dynamic library itself. No DT_NEEDED links will be traversed to resolve symbols. --cref Output a cross reference table. If a linker map file is being generated, the cross reference table is printed to the map file. Otherwise, it is printed on the standard output. The format of the table is intentionally simple, so that it may be easily processed by a script if necessary. The symbols are printed out, sorted by name. For each symbol, a list of file names is given. If the symbol is defined, the first file listed is the location of the definition. If the symbol is defined as a common value then any files where this happens appear next. Finally any files that reference the symbol are listed. --ctf-variables --no-ctf-variables The CTF debuginfo format supports a section which encodes the names and types of variables found in the program which do not appear in any symbol table. These variables clearly cannot be looked up by address by conventional debuggers, so the space used for their types and names is usually wasted: the types are usually small but the names are often not. --ctf-variables causes the generation of such a section. The default behaviour can be restored with --no-ctf-variables. --ctf-share-types=method Adjust the method used to share types between translation units in CTF. share-unconflicted Put all types that do not have ambiguous definitions into the shared dictionary, where debuggers can easily access them, even if they only occur in one translation unit. This is the default. share-duplicated Put only types that occur in multiple translation units into the shared dictionary: types with only one definition go into per-translation-unit dictionaries. Types with ambiguous definitions in multiple translation units always go into per-translation-unit dictionaries. This tends to make the CTF larger, but may reduce the amount of CTF in the shared dictionary. For very large projects this may speed up opening the CTF and save memory in the CTF consumer at runtime. --no-define-common This option inhibits the assignment of addresses to common symbols. The script command \"INHIBIT_COMMON_ALLOCATION\" has the same effect. The --no-define-common option allows decoupling the decision to assign addresses to Common symbols from the choice of the output file type; otherwise a non-Relocatable output type forces assigning addresses to Common symbols. Using --no-define-common allows Common symbols that are referenced from a shared library to be assigned addresses only in the main program. This eliminates the unused duplicate space in the shared library, and also prevents any possible confusion over resolving to the wrong duplicate when there are many dynamic modules with specialized search paths for runtime symbol resolution. --force-group-allocation This option causes the linker to place section group members like normal input sections, and to delete the section groups. This is the default behaviour for a final link but this option can be used to change the behaviour of a relocatable link (-r). The script command \"FORCE_GROUP_ALLOCATION\" has the same effect. --defsym=symbol=expression Create a global symbol in the output file, containing the absolute address given by expression. You may use this option as many times as necessary to define multiple symbols in the command line. A limited form of arithmetic is supported for the expression in this context: you may give a hexadecimal constant or the name of an existing symbol, or use \"+\" and \"-\" to add or subtract hexadecimal constants or symbols. If you need more elaborate expressions, consider using the linker command language from a script. Note: there should be no white space between symbol, the equals sign (\"=\"), and expression. The linker processes --defsym arguments and -T arguments in order, placing --defsym before -T will define the symbol before the linker script from -T is processed, while placing --defsym after -T will define the symbol after the linker script has been processed. This difference has consequences for expressions within the linker script that use the --defsym symbols, which order is correct will depend on what you are trying to achieve. --demangle[=style] --no-demangle These options control whether to demangle symbol names in error messages and other output. When the linker is told to demangle, it tries to present symbol names in a readable fashion: it strips leading underscores if they are used by the object file format, and converts C++ mangled symbol names into user readable names. Different compilers have different mangling styles. The optional demangling style argument can be used to choose an appropriate demangling style for your compiler. The linker will demangle by default unless the environment variable COLLECT_NO_DEMANGLE is set. These options may be used to override the default. -Ifile --dynamic-linker=file Set the name of the dynamic linker. This is only meaningful when generating dynamically linked ELF executables. The default dynamic linker is normally correct; don't use this unless you know what you are doing. --no-dynamic-linker When producing an executable file, omit the request for a dynamic linker to be used at load-time. This is only meaningful for ELF executables that contain dynamic relocations, and usually requires entry point code that is capable of processing these relocations. --embedded-relocs This option is similar to the --emit-relocs option except that the relocs are stored in a target-specific section. This option is only supported by the BFIN, CR16 and M68K targets. --disable-multiple-abs-defs Do not allow multiple definitions with symbols included in filename invoked by -R or --just-symbols --fatal-warnings --no-fatal-warnings Treat all warnings as errors. The default behaviour can be restored with the option --no-fatal-warnings. -w --no-warnings Do not display any warning or error messages. This overrides --fatal-warnings if it has been enabled. This option can be used when it is known that the output binary will not work, but there is still a need to create it. --force-exe-suffix Make sure that an output file has a .exe suffix. If a successfully built fully linked output file does not have a \".exe\" or \".dll\" suffix, this option forces the linker to copy the output file to one of the same name with a \".exe\" suffix. This option is useful when using unmodified Unix makefiles on a Microsoft Windows host, since some versions of Windows won't run an image unless it ends in a \".exe\" suffix. --gc-sections --no-gc-sections Enable garbage collection of unused input sections. It is ignored on targets that do not support this option. The default behaviour (of not performing this garbage collection) can be restored by specifying --no-gc-sections on the command line. Note that garbage collection for COFF and PE format targets is supported, but the implementation is currently considered to be experimental. --gc-sections decides which input sections are used by examining symbols and relocations. The section containing the entry symbol and all sections containing symbols undefined on the command-line will be kept, as will sections containing symbols referenced by dynamic objects. Note that when building shared libraries, the linker must assume that any visible symbol is referenced. Once this initial set of sections has been determined, the linker recursively marks as used any section referenced by their relocations. See --entry, --undefined, and --gc-keep-exported. This option can be set when doing a partial link (enabled with option -r). In this case the root of symbols kept must be explicitly specified either by one of the options --entry, --undefined, or --gc-keep-exported or by a \"ENTRY\" command in the linker script. As a GNU extension, ELF input sections marked with the \"SHF_GNU_RETAIN\" flag will not be garbage collected. --print-gc-sections --no-print-gc-sections List all sections removed by garbage collection. The listing is printed on stderr. This option is only effective if garbage collection has been enabled via the --gc-sections) option. The default behaviour (of not listing the sections that are removed) can be restored by specifying --no-print-gc-sections on the command line. --gc-keep-exported When --gc-sections is enabled, this option prevents garbage collection of unused input sections that contain global symbols having default or protected visibility. This option is intended to be used for executables where unreferenced sections would otherwise be garbage collected regardless of the external visibility of contained symbols. Note that this option has no effect when linking shared objects since it is already the default behaviour. This option is only supported for ELF format targets. --print-output-format Print the name of the default output format (perhaps influenced by other command-line options). This is the string that would appear in an \"OUTPUT_FORMAT\" linker script command. --print-memory-usage Print used size, total size and used size of memory regions created with the MEMORY command. This is useful on embedded targets to have a quick view of amount of free memory. The format of the output has one headline and one line per region. It is both human readable and easily parsable by tools. Here is an example of an output: Memory region Used Size Region Size %age Used ROM: 256 KB 1 MB 25.00% RAM: 32 B 2 GB 0.00% --help Print a summary of the command-line options on the standard output and exit. --target-help Print a summary of all target-specific options on the standard output and exit. -Map=mapfile Print a link map to the file mapfile. See the description of the -M option, above. If mapfile is just the character \"-\" then the map will be written to stdout. Specifying a directory as mapfile causes the linker map to be written as a file inside the directory. Normally name of the file inside the directory is computed as the basename of the output file with \".map\" appended. If however the special character \"%\" is used then this will be replaced by the full path of the output file. Additionally if there are any characters after the % symbol then \".map\" will no longer be appended. -o foo.exe -Map=bar [Creates ./bar] -o ../dir/foo.exe -Map=bar [Creates ./bar] -o foo.exe -Map=../dir [Creates ../dir/foo.exe.map] -o ../dir2/foo.exe -Map=../dir [Creates ../dir/foo.exe.map] -o foo.exe -Map=% [Creates ./foo.exe.map] -o ../dir/foo.exe -Map=% [Creates ../dir/foo.exe.map] -o foo.exe -Map=%.bar [Creates ./foo.exe.bar] -o ../dir/foo.exe -Map=%.bar [Creates ../dir/foo.exe.bar] -o ../dir2/foo.exe -Map=../dir/% [Creates ../dir/../dir2/foo.exe.map] -o ../dir2/foo.exe -Map=../dir/%.bar [Creates ../dir/../dir2/foo.exe.bar] It is an error to specify more than one \"%\" character. If the map file already exists then it will be overwritten by this operation. --no-keep-memory ld normally optimizes for speed over memory usage by caching the symbol tables of input files in memory. This option tells ld to instead optimize for memory usage, by rereading the symbol tables as necessary. This may be required if ld runs out of memory space while linking a large executable. --no-undefined -z defs Report unresolved symbol references from regular object files. This is done even if the linker is creating a non- symbolic shared library. The switch --[no-]allow-shlib-undefined controls the behaviour for reporting unresolved references found in shared libraries being linked in. The effects of this option can be reverted by using \"-z undefs\". --allow-multiple-definition -z muldefs Normally when a symbol is defined multiple times, the linker will report a fatal error. These options allow multiple definitions and the first definition will be used. --allow-shlib-undefined --no-allow-shlib-undefined Allows or disallows undefined symbols in shared libraries. This switch is similar to --no-undefined except that it determines the behaviour when the undefined symbols are in a shared library rather than a regular object file. It does not affect how undefined symbols in regular object files are handled. The default behaviour is to report errors for any undefined symbols referenced in shared libraries if the linker is being used to create an executable, but to allow them if the linker is being used to create a shared library. The reasons for allowing undefined symbol references in shared libraries specified at link time are that: \u2022 A shared library specified at link time may not be the same as the one that is available at load time, so the symbol might actually be resolvable at load time. \u2022 There are some operating systems, eg BeOS and HPPA, where undefined symbols in shared libraries are normal. The BeOS kernel for example patches shared libraries at load time to select whichever function is most appropriate for the current architecture. This is used, for example, to dynamically select an appropriate memset function. --error-handling-script=scriptname If this option is provided then the linker will invoke scriptname whenever an error is encountered. Currently however only two kinds of error are supported: missing symbols and missing libraries. Two arguments will be passed to script: the keyword \"undefined-symbol\" or `missing-lib\" and the name of the undefined symbol or missing library. The intention is that the script will provide suggestions to the user as to where the symbol or library might be found. After the script has finished then the normal linker error message will be displayed. The availability of this option is controlled by a configure time switch, so it may not be present in specific implementations. --no-undefined-version Normally when a symbol has an undefined version, the linker will ignore it. This option disallows symbols with undefined version and a fatal error will be issued instead. --default-symver Create and use a default symbol version (the soname) for unversioned exported symbols. --default-imported-symver Create and use a default symbol version (the soname) for unversioned imported symbols. --no-warn-mismatch Normally ld will give an error if you try to link together input files that are mismatched for some reason, perhaps because they have been compiled for different processors or for different endiannesses. This option tells ld that it should silently permit such possible errors. This option should only be used with care, in cases when you have taken some special action that ensures that the linker errors are inappropriate. --no-warn-search-mismatch Normally ld will give a warning if it finds an incompatible library during a library search. This option silences the warning. --no-whole-archive Turn off the effect of the --whole-archive option for subsequent archive files. --noinhibit-exec Retain the executable output file whenever it is still usable. Normally, the linker will not produce an output file if it encounters errors during the link process; it exits without writing an output file when it issues any error whatsoever. -nostdlib Only search library directories explicitly specified on the command line. Library directories specified in linker scripts (including linker scripts specified on the command line) are ignored. --oformat=output-format ld may be configured to support more than one kind of object file. If your ld is configured this way, you can use the --oformat option to specify the binary format for the output object file. Even when ld is configured to support alternative object formats, you don't usually need to specify this, as ld should be configured to produce as a default output format the most usual format on each machine. output- format is a text string, the name of a particular format supported by the BFD libraries. (You can list the available binary formats with objdump -i.) The script command \"OUTPUT_FORMAT\" can also specify the output format, but this option overrides it. --out-implib file Create an import library in file corresponding to the executable the linker is generating (eg. a DLL or ELF program). This import library (which should be called \"*.dll.a\" or \"*.a\" for DLLs) may be used to link clients against the generated executable; this behaviour makes it possible to skip a separate import library creation step (eg. \"dlltool\" for DLLs). This option is only available for the i386 PE and ELF targetted ports of the linker. -pie --pic-executable Create a position independent executable. This is currently only supported on ELF platforms. Position independent executables are similar to shared libraries in that they are relocated by the dynamic linker to the virtual address the OS chooses for them (which can vary between invocations). Like normal dynamically linked executables they can be executed and symbols defined in the executable cannot be overridden by shared libraries. -no-pie Create a position dependent executable. This is the default. -qmagic This option is ignored for Linux compatibility. -Qy This option is ignored for SVR4 compatibility. --relax --no-relax An option with machine dependent effects. This option is only supported on a few targets. On some platforms the --relax option performs target specific, global optimizations that become possible when the linker resolves addressing in the program, such as relaxing address modes, synthesizing new instructions, selecting shorter version of current instructions, and combining constant values. On some platforms these link time global optimizations may make symbolic debugging of the resulting executable impossible. This is known to be the case for the Matsushita MN10200 and MN10300 family of processors. On platforms where the feature is supported, the option --no-relax will disable it. On platforms where the feature is not supported, both --relax and --no-relax are accepted, but ignored. --retain-symbols-file=filename Retain only the symbols listed in the file filename, discarding all others. filename is simply a flat file, with one symbol name per line. This option is especially useful in environments (such as VxWorks) where a large global symbol table is accumulated gradually, to conserve run-time memory. --retain-symbols-file does not discard undefined symbols, or symbols needed for relocations. You may only specify --retain-symbols-file once in the command line. It overrides -s and -S. -rpath=dir Add a directory to the runtime library search path. This is used when linking an ELF executable with shared objects. All -rpath arguments are concatenated and passed to the runtime linker, which uses them to locate shared objects at runtime. The -rpath option is also used when locating shared objects which are needed by shared objects explicitly included in the link; see the description of the -rpath-link option. Searching -rpath in this way is only supported by native linkers and cross linkers which have been configured with the --with-sysroot option. If -rpath is not used when linking an ELF executable, the contents of the environment variable \"LD_RUN_PATH\" will be used if it is defined. The -rpath option may also be used on SunOS. By default, on SunOS, the linker will form a runtime search path out of all the -L options it is given. If a -rpath option is used, the runtime search path will be formed exclusively using the -rpath options, ignoring the -L options. This can be useful when using gcc, which adds many -L options which may be on NFS mounted file systems. For compatibility with other ELF linkers, if the -R option is followed by a directory name, rather than a file name, it is treated as the -rpath option. -rpath-link=dir When using ELF or SunOS, one shared library may require another. This happens when an \"ld -shared\" link includes a shared library as one of the input files. When the linker encounters such a dependency when doing a non-shared, non-relocatable link, it will automatically try to locate the required shared library and include it in the link, if it is not included explicitly. In such a case, the -rpath-link option specifies the first set of directories to search. The -rpath-link option may specify a sequence of directory names either by specifying a list of names separated by colons, or by appearing multiple times. The tokens $ORIGIN and $LIB can appear in these search directories. They will be replaced by the full path to the directory containing the program or shared object in the case of $ORIGIN and either lib - for 32-bit binaries - or lib64 - for 64-bit binaries - in the case of $LIB. The alternative form of these tokens - ${ORIGIN} and ${LIB} can also be used. The token $PLATFORM is not supported. This option should be used with caution as it overrides the search path that may have been hard compiled into a shared library. In such a case it is possible to use unintentionally a different search path than the runtime linker would do. The linker uses the following search paths to locate required shared libraries: 1. Any directories specified by -rpath-link options. 2. Any directories specified by -rpath options. The difference between -rpath and -rpath-link is that directories specified by -rpath options are included in the executable and used at runtime, whereas the -rpath-link option is only effective at link time. Searching -rpath in this way is only supported by native linkers and cross linkers which have been configured with the --with-sysroot option. 3. On an ELF system, for native linkers, if the -rpath and -rpath-link options were not used, search the contents of the environment variable \"LD_RUN_PATH\". 4. On SunOS, if the -rpath option was not used, search any directories specified using -L options. 5. For a native linker, search the contents of the environment variable \"LD_LIBRARY_PATH\". 6. For a native ELF linker, the directories in \"DT_RUNPATH\" or \"DT_RPATH\" of a shared library are searched for shared libraries needed by it. The \"DT_RPATH\" entries are ignored if \"DT_RUNPATH\" entries exist. 7. For a linker for a Linux system, if the file /etc/ld.so.conf exists, the list of directories found in that file. Note: the path to this file is prefixed with the \"sysroot\" value, if that is defined, and then any \"prefix\" string if the linker was configured with the --prefix=<path> option. 8. For a native linker on a FreeBSD system, any directories specified by the \"_PATH_ELF_HINTS\" macro defined in the elf-hints.h header file. 9. Any directories specified by a \"SEARCH_DIR\" command in a linker script given on the command line, including scripts specified by -T (but not -dT). 10. The default directories, normally /lib and /usr/lib. 11. Any directories specified by a plugin LDPT_SET_EXTRA_LIBRARY_PATH. 12. Any directories specified by a \"SEARCH_DIR\" command in a default linker script. Note however on Linux based systems there is an additional caveat: If the --as-needed option is active and a shared library is located which would normally satisfy the search and this library does not have DT_NEEDED tag for libc.so and there is a shared library later on in the set of search directories which also satisfies the search and this second shared library does have a DT_NEEDED tag for libc.so then the second library will be selected instead of the first. If the required shared library is not found, the linker will issue a warning and continue with the link. -shared -Bshareable Create a shared library. This is currently only supported on ELF, XCOFF and SunOS platforms. On SunOS, the linker will automatically create a shared library if the -e option is not used and there are undefined symbols in the link. --sort-common --sort-common=ascending --sort-common=descending This option tells ld to sort the common symbols by alignment in ascending or descending order when it places them in the appropriate output sections. The symbol alignments considered are sixteen-byte or larger, eight-byte, four-byte, two-byte, and one-byte. This is to prevent gaps between symbols due to alignment constraints. If no sorting order is specified, then descending order is assumed. --sort-section=name This option will apply \"SORT_BY_NAME\" to all wildcard section patterns in the linker script. --sort-section=alignment This option will apply \"SORT_BY_ALIGNMENT\" to all wildcard section patterns in the linker script. --spare-dynamic-tags=count This option specifies the number of empty slots to leave in the .dynamic section of ELF shared objects. Empty slots may be needed by post processing tools, such as the prelinker. The default is 5. --split-by-file[=size] Similar to --split-by-reloc but creates a new output section for each input file when size is reached. size defaults to a size of 1 if not given. --split-by-reloc[=count] Tries to creates extra sections in the output file so that no single output section in the file contains more than count relocations. This is useful when generating huge relocatable files for downloading into certain real time kernels with the COFF object file format; since COFF cannot represent more than 65535 relocations in a single section. Note that this will fail to work with object file formats which do not support arbitrary sections. The linker will not split up individual input sections for redistribution, so if a single input section contains more than count relocations one output section will contain that many relocations. count defaults to a value of 32768. --stats Compute and display statistics about the operation of the linker, such as execution time and memory usage. --sysroot=directory Use directory as the location of the sysroot, overriding the configure-time default. This option is only supported by linkers that were configured using --with-sysroot. --task-link This is used by COFF/PE based targets to create a task-linked object file where all of the global symbols have been converted to statics. --traditional-format For some targets, the output of ld is different in some ways from the output of some existing linker. This switch requests ld to use the traditional format instead. For example, on SunOS, ld combines duplicate entries in the symbol string table. This can reduce the size of an output file with full debugging information by over 30 percent. Unfortunately, the SunOS \"dbx\" program can not read the resulting program (\"gdb\" has no trouble). The --traditional-format switch tells ld to not combine duplicate entries. --section-start=sectionname=org Locate a section in the output file at the absolute address given by org. You may use this option as many times as necessary to locate multiple sections in the command line. org must be a single hexadecimal integer; for compatibility with other linkers, you may omit the leading 0x usually associated with hexadecimal values. Note: there should be no white space between sectionname, the equals sign (\"=\"), and org. -Tbss=org -Tdata=org -Ttext=org Same as --section-start, with \".bss\", \".data\" or \".text\" as the sectionname. -Ttext-segment=org When creating an ELF executable, it will set the address of the first byte of the text segment. -Trodata-segment=org When creating an ELF executable or shared object for a target where the read-only data is in its own segment separate from the executable text, it will set the address of the first byte of the read-only data segment. -Tldata-segment=org When creating an ELF executable or shared object for x86-64 medium memory model, it will set the address of the first byte of the ldata segment. --unresolved-symbols=method Determine how to handle unresolved symbols. There are four possible values for method: ignore-all Do not report any unresolved symbols. report-all Report all unresolved symbols. This is the default. ignore-in-object-files Report unresolved symbols that are contained in shared libraries, but ignore them if they come from regular object files. ignore-in-shared-libs Report unresolved symbols that come from regular object files, but ignore them if they come from shared libraries. This can be useful when creating a dynamic binary and it is known that all the shared libraries that it should be referencing are included on the linker's command line. The behaviour for shared libraries on their own can also be controlled by the --[no-]allow-shlib-undefined option. Normally the linker will generate an error message for each reported unresolved symbol but the option --warn-unresolved-symbols can change this to a warning. --dll-verbose --verbose[=NUMBER] Display the version number for ld and list the linker emulations supported. Display which input files can and cannot be opened. Display the linker script being used by the linker. If the optional NUMBER argument > 1, plugin symbol status will also be displayed. --version-script=version-scriptfile Specify the name of a version script to the linker. This is typically used when creating shared libraries to specify additional information about the version hierarchy for the library being created. This option is only fully supported on ELF platforms which support shared libraries; see VERSION. It is partially supported on PE platforms, which can use version scripts to filter symbol visibility in auto-export mode: any symbols marked local in the version script will not be exported. --warn-common Warn when a common symbol is combined with another common symbol or with a symbol definition. Unix linkers allow this somewhat sloppy practice, but linkers on some other operating systems do not. This option allows you to find potential problems from combining global symbols. Unfortunately, some C libraries use this practice, so you may get some warnings about symbols in the libraries as well as in your programs. There are three kinds of global symbols, illustrated here by C examples: int i = 1; A definition, which goes in the initialized data section of the output file. extern int i; An undefined reference, which does not allocate space. There must be either a definition or a common symbol for the variable somewhere. int i; A common symbol. If there are only (one or more) common symbols for a variable, it goes in the uninitialized data area of the output file. The linker merges multiple common symbols for the same variable into a single symbol. If they are of different sizes, it picks the largest size. The linker turns a common symbol into a declaration, if there is a definition of the same variable. The --warn-common option can produce five kinds of warnings. Each warning consists of a pair of lines: the first describes the symbol just encountered, and the second describes the previous symbol encountered with the same name. One or both of the two symbols will be a common symbol. 1. Turning a common symbol into a reference, because there is already a definition for the symbol. <file>(<section>): warning: common of `<symbol>' overridden by definition <file>(<section>): warning: defined here 2. Turning a common symbol into a reference, because a later definition for the symbol is encountered. This is the same as the previous case, except that the symbols are encountered in a different order. <file>(<section>): warning: definition of `<symbol>' overriding common <file>(<section>): warning: common is here 3. Merging a common symbol with a previous same-sized common symbol. <file>(<section>): warning: multiple common of `<symbol>' <file>(<section>): warning: previous common is here 4. Merging a common symbol with a previous larger common symbol. <file>(<section>): warning: common of `<symbol>' overridden by larger common <file>(<section>): warning: larger common is here 5. Merging a common symbol with a previous smaller common symbol. This is the same as the previous case, except that the symbols are encountered in a different order. <file>(<section>): warning: common of `<symbol>' overriding smaller common <file>(<section>): warning: smaller common is here --warn-constructors Warn if any global constructors are used. This is only useful for a few object file formats. For formats like COFF or ELF, the linker can not detect the use of global constructors. --warn-execstack --no-warn-execstack On ELF platforms this option controls how the linker generates warning messages when it creates an output file with an executable stack. By default the linker will not warn if the -z execstack command line option has been used, but this behaviour can be overridden by the --warn-execstack option. On the other hand the linker will normally warn if the stack is made executable because one or more of the input files need an execuable stack and neither of the -z execstack or -z noexecstack command line options have been specified. This warning can be disabled via the --no-warn-execstack option. Note: ELF format input files specify that they need an executable stack by having a .note.GNU-stack section with the executable bit set in its section flags. They can specify that they do not need an executable stack by having that section, but without the executable flag bit set. If an input file does not have a .note.GNU-stack section present then the default behaviour is target specific. For some targets, then absence of such a section implies that an executable stack is required. This is often a problem for hand crafted assembler files. --warn-multiple-gp Warn if multiple global pointer values are required in the output file. This is only meaningful for certain processors, such as the Alpha. Specifically, some processors put large- valued constants in a special section. A special register (the global pointer) points into the middle of this section, so that constants can be loaded efficiently via a base- register relative addressing mode. Since the offset in base- register relative mode is fixed and relatively small (e.g., 16 bits), this limits the maximum size of the constant pool. Thus, in large programs, it is often necessary to use multiple global pointer values in order to be able to address all possible constants. This option causes a warning to be issued whenever this case occurs. --warn-once Only warn once for each undefined symbol, rather than once per module which refers to it. --warn-rwx-segments --no-warn-rwx-segments Warn if the linker creates a loadable, non-zero sized segment that has all three of the read, write and execute permission flags set. Such a segment represents a potential security vulnerability. In addition warnings will be generated if a thread local storage segment is created with the execute permission flag set, regardless of whether or not it has the read and/or write flags set. These warnings are enabled by default. They can be disabled via the --no-warn-rwx-segments option and re-enabled via the --warn-rwx-segments option. --warn-section-align Warn if the address of an output section is changed because of alignment. Typically, the alignment will be set by an input section. The address will only be changed if it not explicitly specified; that is, if the \"SECTIONS\" command does not specify a start address for the section. --warn-textrel Warn if the linker adds DT_TEXTREL to a position-independent executable or shared object. --warn-alternate-em Warn if an object has alternate ELF machine code. --warn-unresolved-symbols If the linker is going to report an unresolved symbol (see the option --unresolved-symbols) it will normally generate an error. This option makes it generate a warning instead. --error-unresolved-symbols This restores the linker's default behaviour of generating errors when it is reporting unresolved symbols. --whole-archive For each archive mentioned on the command line after the --whole-archive option, include every object file in the archive in the link, rather than searching the archive for the required object files. This is normally used to turn an archive file into a shared library, forcing every object to be included in the resulting shared library. This option may be used more than once. Two notes when using this option from gcc: First, gcc doesn't know about this option, so you have to use -Wl,-whole-archive. Second, don't forget to use -Wl,-no-whole-archive after your list of archives, because gcc will add its own list of archives to your link and you may not want this flag to affect those as well. --wrap=symbol Use a wrapper function for symbol. Any undefined reference to symbol will be resolved to \"__wrap_symbol\". Any undefined reference to \"__real_symbol\" will be resolved to symbol. This can be used to provide a wrapper for a system function. The wrapper function should be called \"__wrap_symbol\". If it wishes to call the system function, it should call \"__real_symbol\". Here is a trivial example: void * __wrap_malloc (size_t c) { printf (\"malloc called with %zu\\n\", c); return __real_malloc (c); } If you link other code with this file using --wrap malloc, then all calls to \"malloc\" will call the function \"__wrap_malloc\" instead. The call to \"__real_malloc\" in \"__wrap_malloc\" will call the real \"malloc\" function. You may wish to provide a \"__real_malloc\" function as well, so that links without the --wrap option will succeed. If you do this, you should not put the definition of \"__real_malloc\" in the same file as \"__wrap_malloc\"; if you do, the assembler may resolve the call before the linker has a chance to wrap it to \"malloc\". Only undefined references are replaced by the linker. So, translation unit internal references to symbol are not resolved to \"__wrap_symbol\". In the next example, the call to \"f\" in \"g\" is not resolved to \"__wrap_f\". int f (void) { return 123; } int g (void) { return f(); } --eh-frame-hdr --no-eh-frame-hdr Request (--eh-frame-hdr) or suppress (--no-eh-frame-hdr) the creation of \".eh_frame_hdr\" section and ELF \"PT_GNU_EH_FRAME\" segment header. --no-ld-generated-unwind-info Request creation of \".eh_frame\" unwind info for linker generated code sections like PLT. This option is on by default if linker generated unwind info is supported. This option also controls the generation of \".sframe\" unwind info for linker generated code sections like PLT. --enable-new-dtags --disable-new-dtags This linker can create the new dynamic tags in ELF. But the older ELF systems may not understand them. If you specify --enable-new-dtags, the new dynamic tags will be created as needed and older dynamic tags will be omitted. If you specify --disable-new-dtags, no new dynamic tags will be created. By default, the new dynamic tags are not created. Note that those options are only available for ELF systems. --hash-size=number Set the default size of the linker's hash tables to a prime number close to number. Increasing this value can reduce the length of time it takes the linker to perform its tasks, at the expense of increasing the linker's memory requirements. Similarly reducing this value can reduce the memory requirements at the expense of speed. --hash-style=style Set the type of linker's hash table(s). style can be either \"sysv\" for classic ELF \".hash\" section, \"gnu\" for new style GNU \".gnu.hash\" section or \"both\" for both the classic ELF \".hash\" and new style GNU \".gnu.hash\" hash tables. The default depends upon how the linker was configured, but for most Linux based systems it will be \"both\". --compress-debug-sections=none --compress-debug-sections=zlib --compress-debug-sections=zlib-gnu --compress-debug-sections=zlib-gabi --compress-debug-sections=zstd On ELF platforms, these options control how DWARF debug sections are compressed using zlib. --compress-debug-sections=none doesn't compress DWARF debug sections. --compress-debug-sections=zlib-gnu compresses DWARF debug sections and renames them to begin with .zdebug instead of .debug. --compress-debug-sections=zlib-gabi also compresses DWARF debug sections, but rather than renaming them it sets the SHF_COMPRESSED flag in the sections' headers. The --compress-debug-sections=zlib option is an alias for --compress-debug-sections=zlib-gabi. --compress-debug-sections=zstd compresses DWARF debug sections using zstd. Note that this option overrides any compression in input debug sections, so if a binary is linked with --compress-debug-sections=none for example, then any compressed debug sections in input files will be uncompressed before they are copied into the output binary. The default compression behaviour varies depending upon the target involved and the configure options used to build the toolchain. The default can be determined by examining the output from the linker's --help option. --reduce-memory-overheads This option reduces memory requirements at ld runtime, at the expense of linking speed. This was introduced to select the old O(n^2) algorithm for link map file generation, rather than the new O(n) algorithm which uses about 40% more memory for symbol storage. Another effect of the switch is to set the default hash table size to 1021, which again saves memory at the cost of lengthening the linker's run time. This is not done however if the --hash-size switch has been used. The --reduce-memory-overheads switch may be also be used to enable other tradeoffs in future versions of the linker. --max-cache-size=size ld normally caches the relocation information and symbol tables of input files in memory with the unlimited size. This option sets the maximum cache size to size. --build-id --build-id=style Request the creation of a \".note.gnu.build-id\" ELF note section or a \".buildid\" COFF section. The contents of the note are unique bits identifying this linked file. style can be \"uuid\" to use 128 random bits, \"sha1\" to use a 160-bit SHA1 hash on the normative parts of the output contents, \"md5\" to use a 128-bit MD5 hash on the normative parts of the output contents, or \"0xhexstring\" to use a chosen bit string specified as an even number of hexadecimal digits (\"-\" and \":\" characters between digit pairs are ignored). If style is omitted, \"sha1\" is used. The \"md5\" and \"sha1\" styles produces an identifier that is always the same in an identical output file, but will be unique among all nonidentical output files. It is not intended to be compared as a checksum for the file's contents. A linked file may be changed later by other tools, but the build ID bit string identifying the original linked file does not change. Passing \"none\" for style disables the setting from any \"--build-id\" options earlier on the command line. --package-metadata=JSON Request the creation of a \".note.package\" ELF note section. The contents of the note are in JSON format, as per the package metadata specification. For more information see: https://systemd.io/ELF_PACKAGE_METADATA/ If the JSON argument is missing/empty then this will disable the creation of the metadata note, if one had been enabled by an earlier occurrence of the --package-metdata option. If the linker has been built with libjansson, then the JSON string will be validated. The i386 PE linker supports the -shared option, which causes the output to be a dynamically linked library (DLL) instead of a normal executable. You should name the output \"*.dll\" when you use this option. In addition, the linker fully supports the standard \"*.def\" files, which may be specified on the linker command line like an object file (in fact, it should precede archives it exports symbols from, to ensure that they get linked in, just like a normal object file). In addition to the options common to all targets, the i386 PE linker support additional command-line options that are specific to the i386 PE target. Options that take values may be separated from their values by either a space or an equals sign. --add-stdcall-alias If given, symbols with a stdcall suffix (@nn) will be exported as-is and also with the suffix stripped. [This option is specific to the i386 PE targeted port of the linker] --base-file file Use file as the name of a file in which to save the base addresses of all the relocations needed for generating DLLs with dlltool. [This is an i386 PE specific option] --dll Create a DLL instead of a regular executable. You may also use -shared or specify a \"LIBRARY\" in a given \".def\" file. [This option is specific to the i386 PE targeted port of the linker] --enable-long-section-names --disable-long-section-names The PE variants of the COFF object format add an extension that permits the use of section names longer than eight characters, the normal limit for COFF. By default, these names are only allowed in object files, as fully-linked executable images do not carry the COFF string table required to support the longer names. As a GNU extension, it is possible to allow their use in executable images as well, or to (probably pointlessly!) disallow it in object files, by using these two options. Executable images generated with these long section names are slightly non-standard, carrying as they do a string table, and may generate confusing output when examined with non-GNU PE-aware tools, such as file viewers and dumpers. However, GDB relies on the use of PE long section names to find Dwarf-2 debug information sections in an executable image at runtime, and so if neither option is specified on the command-line, ld will enable long section names, overriding the default and technically correct behaviour, when it finds the presence of debug information while linking an executable image and not stripping symbols. [This option is valid for all PE targeted ports of the linker] --enable-stdcall-fixup --disable-stdcall-fixup If the link finds a symbol that it cannot resolve, it will attempt to do \"fuzzy linking\" by looking for another defined symbol that differs only in the format of the symbol name (cdecl vs stdcall) and will resolve that symbol by linking to the match. For example, the undefined symbol \"_foo\" might be linked to the function \"_foo@12\", or the undefined symbol \"_bar@16\" might be linked to the function \"_bar\". When the linker does this, it prints a warning, since it normally should have failed to link, but sometimes import libraries generated from third-party dlls may need this feature to be usable. If you specify --enable-stdcall-fixup, this feature is fully enabled and warnings are not printed. If you specify --disable-stdcall-fixup, this feature is disabled and such mismatches are considered to be errors. [This option is specific to the i386 PE targeted port of the linker] --leading-underscore --no-leading-underscore For most targets default symbol-prefix is an underscore and is defined in target's description. By this option it is possible to disable/enable the default underscore symbol- prefix. --export-all-symbols If given, all global symbols in the objects used to build a DLL will be exported by the DLL. Note that this is the default if there otherwise wouldn't be any exported symbols. When symbols are explicitly exported via DEF files or implicitly exported via function attributes, the default is to not export anything else unless this option is given. Note that the symbols \"DllMain@12\", \"DllEntryPoint@0\", \"DllMainCRTStartup@12\", and \"impure_ptr\" will not be automatically exported. Also, symbols imported from other DLLs will not be re-exported, nor will symbols specifying the DLL's internal layout such as those beginning with \"_head_\" or ending with \"_iname\". In addition, no symbols from \"libgcc\", \"libstd++\", \"libmingw32\", or \"crtX.o\" will be exported. Symbols whose names begin with \"__rtti_\" or \"__builtin_\" will not be exported, to help with C++ DLLs. Finally, there is an extensive list of cygwin-private symbols that are not exported (obviously, this applies on when building DLLs for cygwin targets). These cygwin-excludes are: \"_cygwin_dll_entry@12\", \"_cygwin_crt0_common@8\", \"_cygwin_noncygwin_dll_entry@12\", \"_fmode\", \"_impure_ptr\", \"cygwin_attach_dll\", \"cygwin_premain0\", \"cygwin_premain1\", \"cygwin_premain2\", \"cygwin_premain3\", and \"environ\". [This option is specific to the i386 PE targeted port of the linker] --exclude-symbols symbol,symbol,... Specifies a list of symbols which should not be automatically exported. The symbol names may be delimited by commas or colons. [This option is specific to the i386 PE targeted port of the linker] --exclude-all-symbols Specifies no symbols should be automatically exported. [This option is specific to the i386 PE targeted port of the linker] --file-alignment Specify the file alignment. Sections in the file will always begin at file offsets which are multiples of this number. This defaults to 512. [This option is specific to the i386 PE targeted port of the linker] --heap reserve --heap reserve,commit Specify the number of bytes of memory to reserve (and optionally commit) to be used as heap for this program. The default is 1MB reserved, 4K committed. [This option is specific to the i386 PE targeted port of the linker] --image-base value Use value as the base address of your program or dll. This is the lowest memory location that will be used when your program or dll is loaded. To reduce the need to relocate and improve performance of your dlls, each should have a unique base address and not overlap any other dlls. The default is 0x400000 for executables, and 0x10000000 for dlls. [This option is specific to the i386 PE targeted port of the linker] --kill-at If given, the stdcall suffixes (@nn) will be stripped from symbols before they are exported. [This option is specific to the i386 PE targeted port of the linker] --large-address-aware If given, the appropriate bit in the \"Characteristics\" field of the COFF header is set to indicate that this executable supports virtual addresses greater than 2 gigabytes. This should be used in conjunction with the /3GB or /USERVA=value megabytes switch in the \"[operating systems]\" section of the BOOT.INI. Otherwise, this bit has no effect. [This option is specific to PE targeted ports of the linker] --disable-large-address-aware Reverts the effect of a previous --large-address-aware option. This is useful if --large-address-aware is always set by the compiler driver (e.g. Cygwin gcc) and the executable does not support virtual addresses greater than 2 gigabytes. [This option is specific to PE targeted ports of the linker] --major-image-version value Sets the major number of the \"image version\". Defaults to 1. [This option is specific to the i386 PE targeted port of the linker] --major-os-version value Sets the major number of the \"os version\". Defaults to 4. [This option is specific to the i386 PE targeted port of the linker] --major-subsystem-version value Sets the major number of the \"subsystem version\". Defaults to 4. [This option is specific to the i386 PE targeted port of the linker] --minor-image-version value Sets the minor number of the \"image version\". Defaults to 0. [This option is specific to the i386 PE targeted port of the linker] --minor-os-version value Sets the minor number of the \"os version\". Defaults to 0. [This option is specific to the i386 PE targeted port of the linker] --minor-subsystem-version value Sets the minor number of the \"subsystem version\". Defaults to 0. [This option is specific to the i386 PE targeted port of the linker] --output-def file The linker will create the file file which will contain a DEF file corresponding to the DLL the linker is generating. This DEF file (which should be called \"*.def\") may be used to create an import library with \"dlltool\" or may be used as a reference to automatically or implicitly exported symbols. [This option is specific to the i386 PE targeted port of the linker] --enable-auto-image-base --enable-auto-image-base=value Automatically choose the image base for DLLs, optionally starting with base value, unless one is specified using the \"--image-base\" argument. By using a hash generated from the dllname to create unique image bases for each DLL, in-memory collisions and relocations which can delay program execution are avoided. [This option is specific to the i386 PE targeted port of the linker] --disable-auto-image-base Do not automatically generate a unique image base. If there is no user-specified image base (\"--image-base\") then use the platform default. [This option is specific to the i386 PE targeted port of the linker] --dll-search-prefix string When linking dynamically to a dll without an import library, search for \"<string><basename>.dll\" in preference to \"lib<basename>.dll\". This behaviour allows easy distinction between DLLs built for the various \"subplatforms\": native, cygwin, uwin, pw, etc. For instance, cygwin DLLs typically use \"--dll-search-prefix=cyg\". [This option is specific to the i386 PE targeted port of the linker] --enable-auto-import Do sophisticated linking of \"_symbol\" to \"__imp__symbol\" for DATA imports from DLLs, thus making it possible to bypass the dllimport mechanism on the user side and to reference unmangled symbol names. [This option is specific to the i386 PE targeted port of the linker] The following remarks pertain to the original implementation of the feature and are obsolete nowadays for Cygwin and MinGW targets. Note: Use of the 'auto-import' extension will cause the text section of the image file to be made writable. This does not conform to the PE-COFF format specification published by Microsoft. Note - use of the 'auto-import' extension will also cause read only data which would normally be placed into the .rdata section to be placed into the .data section instead. This is in order to work around a problem with consts that is described here: http://www.cygwin.com/ml/cygwin/2004-09/msg01101.html Using 'auto-import' generally will 'just work' -- but sometimes you may see this message: \"variable '<var>' can't be auto-imported. Please read the documentation for ld's \"--enable-auto-import\" for details.\" This message occurs when some (sub)expression accesses an address ultimately given by the sum of two constants (Win32 import tables only allow one). Instances where this may occur include accesses to member fields of struct variables imported from a DLL, as well as using a constant index into an array variable imported from a DLL. Any multiword variable (arrays, structs, long long, etc) may trigger this error condition. However, regardless of the exact data type of the offending exported variable, ld will always detect it, issue the warning, and exit. There are several ways to address this difficulty, regardless of the data type of the exported variable: One way is to use --enable-runtime-pseudo-reloc switch. This leaves the task of adjusting references in your client code for runtime environment, so this method works only when runtime environment supports this feature. A second solution is to force one of the 'constants' to be a variable -- that is, unknown and un-optimizable at compile time. For arrays, there are two possibilities: a) make the indexee (the array's address) a variable, or b) make the 'constant' index a variable. Thus: extern type extern_array[]; extern_array[1] --> { volatile type *t=extern_array; t[1] } or extern type extern_array[]; extern_array[1] --> { volatile int t=1; extern_array[t] } For structs (and most other multiword data types) the only option is to make the struct itself (or the long long, or the ...) variable: extern struct s extern_struct; extern_struct.field --> { volatile struct s *t=&extern_struct; t->field } or extern long long extern_ll; extern_ll --> { volatile long long * local_ll=&extern_ll; *local_ll } A third method of dealing with this difficulty is to abandon 'auto-import' for the offending symbol and mark it with \"__declspec(dllimport)\". However, in practice that requires using compile-time #defines to indicate whether you are building a DLL, building client code that will link to the DLL, or merely building/linking to a static library. In making the choice between the various methods of resolving the 'direct address with constant offset' problem, you should consider typical real-world usage: Original: --foo.h extern int arr[]; --foo.c #include \"foo.h\" void main(int argc, char **argv){ printf(\"%d\\n\",arr[1]); } Solution 1: --foo.h extern int arr[]; --foo.c #include \"foo.h\" void main(int argc, char **argv){ /* This workaround is for win32 and cygwin; do not \"optimize\" */ volatile int *parr = arr; printf(\"%d\\n\",parr[1]); } Solution 2: --foo.h /* Note: auto-export is assumed (no __declspec(dllexport)) */ #if (defined(_WIN32) || defined(__CYGWIN__)) && \\ !(defined(FOO_BUILD_DLL) || defined(FOO_STATIC)) #define FOO_IMPORT __declspec(dllimport) #else #define FOO_IMPORT #endif extern FOO_IMPORT int arr[]; --foo.c #include \"foo.h\" void main(int argc, char **argv){ printf(\"%d\\n\",arr[1]); } A fourth way to avoid this problem is to re-code your library to use a functional interface rather than a data interface for the offending variables (e.g. set_foo() and get_foo() accessor functions). --disable-auto-import Do not attempt to do sophisticated linking of \"_symbol\" to \"__imp__symbol\" for DATA imports from DLLs. [This option is specific to the i386 PE targeted port of the linker] --enable-runtime-pseudo-reloc If your code contains expressions described in --enable-auto-import section, that is, DATA imports from DLL with non-zero offset, this switch will create a vector of 'runtime pseudo relocations' which can be used by runtime environment to adjust references to such data in your client code. [This option is specific to the i386 PE targeted port of the linker] --disable-runtime-pseudo-reloc Do not create pseudo relocations for non-zero offset DATA imports from DLLs. [This option is specific to the i386 PE targeted port of the linker] --enable-extra-pe-debug Show additional debug info related to auto-import symbol thunking. [This option is specific to the i386 PE targeted port of the linker] --section-alignment Sets the section alignment. Sections in memory will always begin at addresses which are a multiple of this number. Defaults to 0x1000. [This option is specific to the i386 PE targeted port of the linker] --stack reserve --stack reserve,commit Specify the number of bytes of memory to reserve (and optionally commit) to be used as stack for this program. The default is 2MB reserved, 4K committed. [This option is specific to the i386 PE targeted port of the linker] --subsystem which --subsystem which:major --subsystem which:major.minor Specifies the subsystem under which your program will execute. The legal values for which are \"native\", \"windows\", \"console\", \"posix\", and \"xbox\". You may optionally set the subsystem version also. Numeric values are also accepted for which. [This option is specific to the i386 PE targeted port of the linker] The following options set flags in the \"DllCharacteristics\" field of the PE file header: [These options are specific to PE targeted ports of the linker] --high-entropy-va --disable-high-entropy-va Image is compatible with 64-bit address space layout randomization (ASLR). This option is enabled by default for 64-bit PE images. This option also implies --dynamicbase and --enable-reloc-section. --dynamicbase --disable-dynamicbase The image base address may be relocated using address space layout randomization (ASLR). This feature was introduced with MS Windows Vista for i386 PE targets. This option is enabled by default but can be disabled via the --disable-dynamicbase option. This option also implies --enable-reloc-section. --forceinteg --disable-forceinteg Code integrity checks are enforced. This option is disabled by default. --nxcompat --disable-nxcompat The image is compatible with the Data Execution Prevention. This feature was introduced with MS Windows XP SP2 for i386 PE targets. The option is enabled by default. --no-isolation --disable-no-isolation Although the image understands isolation, do not isolate the image. This option is disabled by default. --no-seh --disable-no-seh The image does not use SEH. No SE handler may be called from this image. This option is disabled by default. --no-bind --disable-no-bind Do not bind this image. This option is disabled by default. --wdmdriver --disable-wdmdriver The driver uses the MS Windows Driver Model. This option is disabled by default. --tsaware --disable-tsaware The image is Terminal Server aware. This option is disabled by default. --insert-timestamp --no-insert-timestamp Insert a real timestamp into the image. This is the default behaviour as it matches legacy code and it means that the image will work with other, proprietary tools. The problem with this default is that it will result in slightly different images being produced each time the same sources are linked. The option --no-insert-timestamp can be used to insert a zero value for the timestamp, this ensuring that binaries produced from identical sources will compare identically. --enable-reloc-section --disable-reloc-section Create the base relocation table, which is necessary if the image is loaded at a different image base than specified in the PE header. This option is enabled by default. The C6X uClinux target uses a binary format called DSBT to support shared libraries. Each shared library in the system needs to have a unique index; all executables use an index of 0. --dsbt-size size This option sets the number of entries in the DSBT of the current executable or shared library to size. The default is to create a table with 64 entries. --dsbt-index index This option sets the DSBT index of the current executable or shared library to index. The default is 0, which is appropriate for generating executables. If a shared library is generated with a DSBT index of 0, the \"R_C6000_DSBT_INDEX\" relocs are copied into the output file. The --no-merge-exidx-entries switch disables the merging of adjacent exidx entries in frame unwind info. --branch-stub This option enables linker branch relaxation by inserting branch stub sections when needed to extend the range of branches. This option is usually not required since C-SKY supports branch and call instructions that can access the full memory range and branch relaxation is normally handled by the compiler or assembler. --stub-group-size=N This option allows finer control of linker branch stub creation. It sets the maximum size of a group of input sections that can be handled by one stub section. A negative value of N locates stub sections after their branches, while a positive value allows stub sections to appear either before or after the branches. Values of 1 or -1 indicate that the linker should choose suitable defaults. The 68HC11 and 68HC12 linkers support specific options to control the memory bank switching mapping and trampoline code generation. --no-trampoline This option disables the generation of trampoline. By default a trampoline is generated for each far function which is called using a \"jsr\" instruction (this happens when a pointer to a far function is taken). --bank-window name This option indicates to the linker the name of the memory region in the MEMORY specification that describes the memory bank window. The definition of such region is then used by the linker to compute paging and addresses within the memory window. The following options are supported to control handling of GOT generation when linking for 68K targets. --got=type This option tells the linker which GOT generation scheme to use. type should be one of single, negative, multigot or target. For more information refer to the Info entry for ld. The following options are supported to control microMIPS instruction generation and branch relocation checks for ISA mode transitions when linking for MIPS targets. --insn32 --no-insn32 These options control the choice of microMIPS instructions used in code generated by the linker, such as that in the PLT or lazy binding stubs, or in relaxation. If --insn32 is used, then the linker only uses 32-bit instruction encodings. By default or if --no-insn32 is used, all instruction encodings are used, including 16-bit ones where possible. --ignore-branch-isa --no-ignore-branch-isa These options control branch relocation checks for invalid ISA mode transitions. If --ignore-branch-isa is used, then the linker accepts any branch relocations and any ISA mode transition required is lost in relocation calculation, except for some cases of \"BAL\" instructions which meet relaxation conditions and are converted to equivalent \"JALX\" instructions as the associated relocation is calculated. By default or if --no-ignore-branch-isa is used a check is made causing the loss of an ISA mode transition to produce an error. --compact-branches --no-compact-branches These options control the generation of compact instructions by the linker in the PLT entries for MIPS R6. For the pdp11-aout target, three variants of the output format can be produced as selected by the following options. The default variant for pdp11-aout is the --omagic option, whereas for other targets --nmagic is the default. The --imagic option is defined only for the pdp11-aout target, while the others are described here as they apply to the pdp11-aout target. -N --omagic Mark the output as \"OMAGIC\" (0407) in the a.out header to indicate that the text segment is not to be write-protected and shared. Since the text and data sections are both readable and writable, the data section is allocated immediately contiguous after the text segment. This is the oldest format for PDP11 executable programs and is the default for ld on PDP11 Unix systems from the beginning through 2.11BSD. -n --nmagic Mark the output as \"NMAGIC\" (0410) in the a.out header to indicate that when the output file is executed, the text portion will be read-only and shareable among all processes executing the same file. This involves moving the data areas up to the first possible 8K byte page boundary following the end of the text. This option creates a pure executable format. -z --imagic Mark the output as \"IMAGIC\" (0411) in the a.out header to indicate that when the output file is executed, the program text and data areas will be loaded into separate address spaces using the split instruction and data space feature of the memory management unit in larger models of the PDP11. This doubles the address space available to the program. The text segment is again pure, write-protected, and shareable. The only difference in the output format between this option and the others, besides the magic number, is that both the text and data sections start at location 0. The -z option selected this format in 2.11BSD. This option creates a separate executable format. --no-omagic Equivalent to --nmagic for pdp11-aout. "
  },
  {
    "command": "git-commit",
    "description": " Create a new commit containing the current contents of the index and the given log message describing the changes. The new commit is a direct child of HEAD, usually the tip of the current branch, and the branch is updated to point to it (unless no branch is associated with the working tree, in which case HEAD is \"detached\" as described in git-checkout(1)). The content to be committed can be specified in several ways: 1. by using git-add(1) to incrementally \"add\" changes to the index before using the commit command (Note: even modified files must be \"added\"); 2. by using git-rm(1) to remove files from the working tree and the index, again before using the commit command; 3. by listing files as arguments to the commit command (without --interactive or --patch switch), in which case the commit will ignore changes staged in the index, and instead record the current content of the listed files (which must already be known to Git); 4. by using the -a switch with the commit command to automatically \"add\" changes from all known files (i.e. all files that are already listed in the index) and to automatically \"rm\" files in the index that have been removed from the working tree, and then perform the actual commit; 5. by using the --interactive or --patch switches with the commit command to decide one by one which files or hunks should be part of the commit in addition to contents in the index, before finalizing the operation. See the \u201cInteractive Mode\u201d section of git-add(1) to learn how to operate these modes. The --dry-run option can be used to obtain a summary of what is included by any of the above for the next commit by giving the same set of parameters (options and paths). If you make a commit and then find a mistake immediately after that, you can recover from it with git reset. -a, --all Tell the command to automatically stage files that have been modified and deleted, but new files you have not told Git about are not affected. -p, --patch Use the interactive patch selection interface to choose which changes to commit. See git-add(1) for details. -C <commit>, --reuse-message=<commit> Take an existing commit object, and reuse the log message and the authorship information (including the timestamp) when creating the commit. -c <commit>, --reedit-message=<commit> Like -C, but with -c the editor is invoked, so that the user can further edit the commit message. --fixup=[(amend|reword):]<commit> Create a new commit which \"fixes up\" <commit> when applied with git rebase --autosquash. Plain --fixup=<commit> creates a \"fixup!\" commit which changes the content of <commit> but leaves its log message untouched. --fixup=amend:<commit> is similar but creates an \"amend!\" commit which also replaces the log message of <commit> with the log message of the \"amend!\" commit. --fixup=reword:<commit> creates an \"amend!\" commit which replaces the log message of <commit> with its own log message but makes no changes to the content of <commit>. The commit created by plain --fixup=<commit> has a subject composed of \"fixup!\" followed by the subject line from <commit>, and is recognized specially by git rebase --autosquash. The -m option may be used to supplement the log message of the created commit, but the additional commentary will be thrown away once the \"fixup!\" commit is squashed into <commit> by git rebase --autosquash. The commit created by --fixup=amend:<commit> is similar but its subject is instead prefixed with \"amend!\". The log message of <commit> is copied into the log message of the \"amend!\" commit and opened in an editor so it can be refined. When git rebase --autosquash squashes the \"amend!\" commit into <commit>, the log message of <commit> is replaced by the refined log message from the \"amend!\" commit. It is an error for the \"amend!\" commit\u2019s log message to be empty unless --allow-empty-message is specified. --fixup=reword:<commit> is shorthand for --fixup=amend:<commit> --only. It creates an \"amend!\" commit with only a log message (ignoring any changes staged in the index). When squashed by git rebase --autosquash, it replaces the log message of <commit> without making any other changes. Neither \"fixup!\" nor \"amend!\" commits change authorship of <commit> when applied by git rebase --autosquash. See git-rebase(1) for details. --squash=<commit> Construct a commit message for use with rebase --autosquash. The commit message subject line is taken from the specified commit with a prefix of \"squash! \". Can be used with additional commit message options (-m/-c/-C/-F). See git-rebase(1) for details. --reset-author When used with -C/-c/--amend options, or when committing after a conflicting cherry-pick, declare that the authorship of the resulting commit now belongs to the committer. This also renews the author timestamp. --short When doing a dry-run, give the output in the short-format. See git-status(1) for details. Implies --dry-run. --branch Show the branch and tracking info even in short-format. --porcelain When doing a dry-run, give the output in a porcelain-ready format. See git-status(1) for details. Implies --dry-run. --long When doing a dry-run, give the output in the long-format. Implies --dry-run. -z, --null When showing short or porcelain status output, print the filename verbatim and terminate the entries with NUL, instead of LF. If no format is given, implies the --porcelain output format. Without the -z option, filenames with \"unusual\" characters are quoted as explained for the configuration variable core.quotePath (see git-config(1)). -F <file>, --file=<file> Take the commit message from the given file. Use - to read the message from the standard input. --author=<author> Override the commit author. Specify an explicit author using the standard A U Thor <author@example.com> format. Otherwise <author> is assumed to be a pattern and is used to search for an existing commit by that author (i.e. rev-list --all -i --author=<author>); the commit author is then copied from the first such commit found. --date=<date> Override the author date used in the commit. -m <msg>, --message=<msg> Use the given <msg> as the commit message. If multiple -m options are given, their values are concatenated as separate paragraphs. The -m option is mutually exclusive with -c, -C, and -F. -t <file>, --template=<file> When editing the commit message, start the editor with the contents in the given file. The commit.template configuration variable is often used to give this option implicitly to the command. This mechanism can be used by projects that want to guide participants with some hints on what to write in the message in what order. If the user exits the editor without editing the message, the commit is aborted. This has no effect when a message is given by other means, e.g. with the -m or -F options. -s, --signoff, --no-signoff Add a Signed-off-by trailer by the committer at the end of the commit log message. The meaning of a signoff depends on the project to which you\u2019re committing. For example, it may certify that the committer has the rights to submit the work under the project\u2019s license or agrees to some contributor representation, such as a Developer Certificate of Origin. (See http://developercertificate.org for the one used by the Linux kernel and Git projects.) Consult the documentation or leadership of the project to which you\u2019re contributing to understand how the signoffs are used in that project. The --no-signoff option can be used to countermand an earlier --signoff option on the command line. --trailer <token>[(=|:)<value>] Specify a (<token>, <value>) pair that should be applied as a trailer. (e.g. git commit --trailer \"Signed-off-by:C O Mitter \\ <committer@example.com>\" --trailer \"Helped-by:C O Mitter \\ <committer@example.com>\" will add the \"Signed-off-by\" trailer and the \"Helped-by\" trailer to the commit message.) The trailer.* configuration variables (\u2010 git-interpret-trailers(1)) can be used to define if a duplicated trailer is omitted, where in the run of trailers each trailer would appear, and other details. -n, --[no-]verify By default, the pre-commit and commit-msg hooks are run. When any of --no-verify or -n is given, these are bypassed. See also githooks(5). --allow-empty Usually recording a commit that has the exact same tree as its sole parent commit is a mistake, and the command prevents you from making such a commit. This option bypasses the safety, and is primarily for use by foreign SCM interface scripts. --allow-empty-message Like --allow-empty this command is primarily for use by foreign SCM interface scripts. It allows you to create a commit with an empty commit message without using plumbing commands like git-commit-tree(1). --cleanup=<mode> This option determines how the supplied commit message should be cleaned up before committing. The <mode> can be strip, whitespace, verbatim, scissors or default. strip Strip leading and trailing empty lines, trailing whitespace, commentary and collapse consecutive empty lines. whitespace Same as strip except #commentary is not removed. verbatim Do not change the message at all. scissors Same as whitespace except that everything from (and including) the line found below is truncated, if the message is to be edited. \"#\" can be customized with core.commentChar. # ------------------------ >8 ------------------------ default Same as strip if the message is to be edited. Otherwise whitespace. The default can be changed by the commit.cleanup configuration variable (see git-config(1)). -e, --edit The message taken from file with -F, command line with -m, and from commit object with -C are usually used as the commit log message unmodified. This option lets you further edit the message taken from these sources. --no-edit Use the selected commit message without launching an editor. For example, git commit --amend --no-edit amends a commit without changing its commit message. --amend Replace the tip of the current branch by creating a new commit. The recorded tree is prepared as usual (including the effect of the -i and -o options and explicit pathspec), and the message from the original commit is used as the starting point, instead of an empty message, when no other message is specified from the command line via options such as -m, -F, -c, etc. The new commit has the same parents and author as the current one (the --reset-author option can countermand this). It is a rough equivalent for: $ git reset --soft HEAD^ $ ... do something else to come up with the right tree ... $ git commit -c ORIG_HEAD but can be used to amend a merge commit. You should understand the implications of rewriting history if you amend a commit that has already been published. (See the \"RECOVERING FROM UPSTREAM REBASE\" section in git-rebase(1).) --no-post-rewrite Bypass the post-rewrite hook. -i, --include Before making a commit out of staged contents so far, stage the contents of paths given on the command line as well. This is usually not what you want unless you are concluding a conflicted merge. -o, --only Make a commit by taking the updated working tree contents of the paths specified on the command line, disregarding any contents that have been staged for other paths. This is the default mode of operation of git commit if any paths are given on the command line, in which case this option can be omitted. If this option is specified together with --amend, then no paths need to be specified, which can be used to amend the last commit without committing changes that have already been staged. If used together with --allow-empty paths are also not required, and an empty commit will be created. --pathspec-from-file=<file> Pathspec is passed in <file> instead of commandline args. If <file> is exactly - then standard input is used. Pathspec elements are separated by LF or CR/LF. Pathspec elements can be quoted as explained for the configuration variable core.quotePath (see git-config(1)). See also --pathspec-file-nul and global --literal-pathspecs. --pathspec-file-nul Only meaningful with --pathspec-from-file. Pathspec elements are separated with NUL character and all other characters are taken literally (including newlines and quotes). -u[<mode>], --untracked-files[=<mode>] Show untracked files. The mode parameter is optional (defaults to all), and is used to specify the handling of untracked files; when -u is not used, the default is normal, i.e. show untracked files and directories. The possible options are: \u2022 no - Show no untracked files \u2022 normal - Shows untracked files and directories \u2022 all - Also shows individual files in untracked directories. The default can be changed using the status.showUntrackedFiles configuration variable documented in git-config(1). -v, --verbose Show unified diff between the HEAD commit and what would be committed at the bottom of the commit message template to help the user describe the commit by reminding what changes the commit has. Note that this diff output doesn\u2019t have its lines prefixed with #. This diff will not be a part of the commit message. See the commit.verbose configuration variable in git-config(1). If specified twice, show in addition the unified diff between what would be committed and the worktree files, i.e. the unstaged changes to tracked files. -q, --quiet Suppress commit summary message. --dry-run Do not create a commit, but show a list of paths that are to be committed, paths with local changes that will be left uncommitted and paths that are untracked. --status Include the output of git-status(1) in the commit message template when using an editor to prepare the commit message. Defaults to on, but can be used to override configuration variable commit.status. --no-status Do not include the output of git-status(1) in the commit message template when using an editor to prepare the default commit message. -S[<keyid>], --gpg-sign[=<keyid>], --no-gpg-sign GPG-sign commits. The keyid argument is optional and defaults to the committer identity; if specified, it must be stuck to the option without a space. --no-gpg-sign is useful to countermand both commit.gpgSign configuration variable, and earlier --gpg-sign. -- Do not interpret any more arguments as options. <pathspec>... When pathspec is given on the command line, commit the contents of the files that match the pathspec without recording the changes already added to the index. The contents of these files are also staged for the next commit on top of what have been staged before. For more details, see the pathspec entry in gitglossary(7). "
  },
  {
    "command": "xargs",
    "description": " The xargs utility shall construct a command line consisting of the utility and argument operands specified followed by as many arguments read in sequence from standard input as fit in length and number constraints specified by the options. The xargs utility shall then invoke the constructed command line and wait for its completion. This sequence shall be repeated until one of the following occurs: * An end-of-file condition is detected on standard input. * An argument consisting of just the logical end-of-file string (see the -E eofstr option) is found on standard input after double-quote processing, <apostrophe> processing, and <backslash>-escape processing (see next paragraph). All arguments up to but not including the argument consisting of just the logical end-of-file string shall be used as arguments in constructed command lines. * An invocation of a constructed command line returns an exit status of 255. The application shall ensure that arguments in the standard input are separated by unquoted <blank> characters, unescaped <blank> characters, or <newline> characters. A string of zero or more non-double-quote ('\"') characters and non-<newline> characters can be quoted by enclosing them in double-quotes. A string of zero or more non-<apostrophe> ('\\'') characters and non-<newline> characters can be quoted by enclosing them in <apostrophe> characters. Any unquoted character can be escaped by preceding it with a <backslash>. The utility named by utility shall be executed one or more times until the end-of-file is reached or the logical end-of file string is found. The results are unspecified if the utility named by utility attempts to read from its standard input. The generated command line length shall be the sum of the size in bytes of the utility name and each argument treated as strings, including a null byte terminator for each of these strings. The xargs utility shall limit the command line length such that when the command line is invoked, the combined argument and environment lists (see the exec family of functions in the System Interfaces volume of POSIX.1\u20102017) shall not exceed {ARG_MAX}-2048 bytes. Within this constraint, if neither the -n nor the -s option is specified, the default command line length shall be at least {LINE_MAX}. The xargs utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported: -E eofstr Use eofstr as the logical end-of-file string. If -E is not specified, it is unspecified whether the logical end-of-file string is the <underscore> character ('_') or the end-of-file string capability is disabled. When eofstr is the null string, the logical end-of-file string capability shall be disabled and <underscore> characters shall be taken literally. -I replstr Insert mode: utility is executed for each logical line from standard input. Arguments in the standard input shall be separated only by unescaped <newline> characters, not by <blank> characters. Any unquoted unescaped <blank> characters at the beginning of each line shall be ignored. The resulting argument shall be inserted in arguments in place of each occurrence of replstr. At least five arguments in arguments can each contain one or more instances of replstr. Each of these constructed arguments cannot grow larger than an implementation-defined limit greater than or equal to 255 bytes. Option -x shall be forced on. -L number The utility shall be executed for each non-empty number lines of arguments from standard input. The last invocation of utility shall be with fewer lines of arguments if fewer than number remain. A line is considered to end with the first <newline> unless the last character of the line is an unescaped <blank>; a trailing unescaped <blank> signals continuation to the next non-empty line, inclusive. -n number Invoke utility using as many standard input arguments as possible, up to number (a positive decimal integer) arguments maximum. Fewer arguments shall be used if: * The command line length accumulated exceeds the size specified by the -s option (or {LINE_MAX} if there is no -s option). * The last iteration has fewer than number, but not zero, operands remaining. -p Prompt mode: the user is asked whether to execute utility at each invocation. Trace mode (-t) is turned on to write the command instance to be executed, followed by a prompt to standard error. An affirmative response read from /dev/tty shall execute the command; otherwise, that particular invocation of utility shall be skipped. -s size Invoke utility using as many standard input arguments as possible yielding a command line length less than size (a positive decimal integer) bytes. Fewer arguments shall be used if: * The total number of arguments exceeds that specified by the -n option. * The total number of lines exceeds that specified by the -L option. * End-of-file is encountered on standard input before size bytes are accumulated. Values of size up to at least {LINE_MAX} bytes shall be supported, provided that the constraints specified in the DESCRIPTION are met. It shall not be considered an error if a value larger than that supported by the implementation or exceeding the constraints specified in the DESCRIPTION is given; xargs shall use the largest value it supports within the constraints. -t Enable trace mode. Each generated command line shall be written to standard error just prior to invocation. -x Terminate if a constructed command line will not fit in the implied or specified size (see the -s option above). "
  },
  {
    "command": "stty",
    "description": " Print or change terminal characteristics. Mandatory arguments to long options are mandatory for short options too. -a, --all print all current settings in human-readable form -g, --save print all current settings in a stty-readable form -F, --file=DEVICE open and use the specified DEVICE instead of stdin --help display this help and exit --version output version information and exit Optional - before SETTING indicates negation. An * marks non-POSIX settings. The underlying system defines which settings are available. Special characters: * discard CHAR CHAR will toggle discarding of output eof CHAR CHAR will send an end of file (terminate the input) eol CHAR CHAR will end the line * eol2 CHAR alternate CHAR for ending the line erase CHAR CHAR will erase the last character typed intr CHAR CHAR will send an interrupt signal kill CHAR CHAR will erase the current line * lnext CHAR CHAR will enter the next character quoted quit CHAR CHAR will send a quit signal * rprnt CHAR CHAR will redraw the current line start CHAR CHAR will restart the output after stopping it stop CHAR CHAR will stop the output susp CHAR CHAR will send a terminal stop signal * swtch CHAR CHAR will switch to a different shell layer * werase CHAR CHAR will erase the last word typed Special settings: N set the input and output speeds to N bauds * cols N tell the kernel that the terminal has N columns * columns N same as cols N * [-]drain wait for transmission before applying settings (on by default) ispeed N set the input speed to N * line N use line discipline N min N with -icanon, set N characters minimum for a completed read ospeed N set the output speed to N * rows N tell the kernel that the terminal has N rows * size print the number of rows and columns according to the kernel speed print the terminal speed time N with -icanon, set read timeout of N tenths of a second Control settings: [-]clocal disable modem control signals [-]cread allow input to be received * [-]crtscts enable RTS/CTS handshaking csN set character size to N bits, N in [5..8] [-]cstopb use two stop bits per character (one with '-') [-]hup send a hangup signal when the last process closes the tty [-]hupcl same as [-]hup [-]parenb generate parity bit in output and expect parity bit in input [-]parodd set odd parity (or even parity with '-') * [-]cmspar use \"stick\" (mark/space) parity Input settings: [-]brkint breaks cause an interrupt signal [-]icrnl translate carriage return to newline [-]ignbrk ignore break characters [-]igncr ignore carriage return [-]ignpar ignore characters with parity errors * [-]imaxbel beep and do not flush a full input buffer on a character [-]inlcr translate newline to carriage return [-]inpck enable input parity checking [-]istrip clear high (8th) bit of input characters * [-]iutf8 assume input characters are UTF-8 encoded * [-]iuclc translate uppercase characters to lowercase * [-]ixany let any character restart output, not only start character [-]ixoff enable sending of start/stop characters [-]ixon enable XON/XOFF flow control [-]parmrk mark parity errors (with a 255-0-character sequence) [-]tandem same as [-]ixoff Output settings: * bsN backspace delay style, N in [0..1] * crN carriage return delay style, N in [0..3] * ffN form feed delay style, N in [0..1] * nlN newline delay style, N in [0..1] * [-]ocrnl translate carriage return to newline * [-]ofdel use delete characters for fill instead of NUL characters * [-]ofill use fill (padding) characters instead of timing for delays * [-]olcuc translate lowercase characters to uppercase * [-]onlcr translate newline to carriage return-newline * [-]onlret newline performs a carriage return * [-]onocr do not print carriage returns in the first column [-]opost postprocess output * tabN horizontal tab delay style, N in [0..3] * tabs same as tab0 * -tabs same as tab3 * vtN vertical tab delay style, N in [0..1] Local settings: [-]crterase echo erase characters as backspace-space-backspace * crtkill kill all line by obeying the echoprt and echoe settings * -crtkill kill all line by obeying the echoctl and echok settings * [-]ctlecho echo control characters in hat notation ('^c') [-]echo echo input characters * [-]echoctl same as [-]ctlecho [-]echoe same as [-]crterase [-]echok echo a newline after a kill character * [-]echoke same as [-]crtkill [-]echonl echo newline even if not echoing other characters * [-]echoprt echo erased characters backward, between '\\' and '/' * [-]extproc enable \"LINEMODE\"; useful with high latency links * [-]flusho discard output [-]icanon enable special characters: erase, kill, werase, rprnt [-]iexten enable non-POSIX special characters [-]isig enable interrupt, quit, and suspend special characters [-]noflsh disable flushing after interrupt and quit special characters * [-]prterase same as [-]echoprt * [-]tostop stop background jobs that try to write to the terminal * [-]xcase with icanon, escape with '\\' for uppercase characters Combination settings: * [-]LCASE same as [-]lcase cbreak same as -icanon -cbreak same as icanon cooked same as brkint ignpar istrip icrnl ixon opost isig icanon, eof and eol characters to their default values -cooked same as raw crt same as echoe echoctl echoke dec same as echoe echoctl echoke -ixany intr ^c erase 0177 kill ^u * [-]decctlq same as [-]ixany ek erase and kill characters to their default values evenp same as parenb -parodd cs7 -evenp same as -parenb cs8 * [-]lcase same as xcase iuclc olcuc litout same as -parenb -istrip -opost cs8 -litout same as parenb istrip opost cs7 nl same as -icrnl -onlcr -nl same as icrnl -inlcr -igncr onlcr -ocrnl -onlret oddp same as parenb parodd cs7 -oddp same as -parenb cs8 [-]parity same as [-]evenp pass8 same as -parenb -istrip cs8 -pass8 same as parenb istrip cs7 raw same as -ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr -icrnl -ixon -ixoff -icanon -opost -isig -iuclc -ixany -imaxbel -xcase min 1 time 0 -raw same as cooked sane same as cread -ignbrk brkint -inlcr -igncr icrnl icanon iexten echo echoe echok -echonl -noflsh -ixoff -iutf8 -iuclc -ixany imaxbel -xcase -olcuc -ocrnl opost -ofill onlcr -onocr -onlret nl0 cr0 tab0 bs0 vt0 ff0 isig -tostop -ofdel -echoprt echoctl echoke -extproc -flusho, all special characters to their default values Handle the tty line connected to standard input. Without arguments, prints baud rate, line discipline, and deviations from stty sane. In settings, CHAR is taken literally, or coded as in ^c, 0x37, 0177 or 127; special values ^- or undef used to disable special characters. "
  },
  {
    "command": "git-ls-files",
    "description": " This merges the file listing in the index with the actual working directory list, and shows different combinations of the two. One or more of the options below may be used to determine the files shown, and each file may be printed multiple times if there are multiple entries in the index or multiple statuses are applicable for the relevant file selection options. -c, --cached Show all files cached in Git\u2019s index, i.e. all tracked files. (This is the default if no -c/-s/-d/-o/-u/-k/-m/--resolve-undo options are specified.) -d, --deleted Show files with an unstaged deletion -m, --modified Show files with an unstaged modification (note that an unstaged deletion also counts as an unstaged modification) -o, --others Show other (i.e. untracked) files in the output -i, --ignored Show only ignored files in the output. Must be used with either an explicit -c or -o. When showing files in the index (i.e. when used with -c), print only those files matching an exclude pattern. When showing \"other\" files (i.e. when used with -o), show only those matched by an exclude pattern. Standard ignore rules are not automatically activated, therefore at least one of the --exclude* options is required. -s, --stage Show staged contents' mode bits, object name and stage number in the output. --directory If a whole directory is classified as \"other\", show just its name (with a trailing slash) and not its whole contents. Has no effect without -o/--others. --no-empty-directory Do not list empty directories. Has no effect without --directory. -u, --unmerged Show information about unmerged files in the output, but do not show any other tracked files (forces --stage, overrides --cached). -k, --killed Show untracked files on the filesystem that need to be removed due to file/directory conflicts for tracked files to be able to be written to the filesystem. --resolve-undo Show files having resolve-undo information in the index together with their resolve-undo information. (resolve-undo information is what is used to implement \"git checkout -m $PATH\", i.e. to recreate merge conflicts that were accidentally resolved) -z \\0 line termination on output and do not quote filenames. See OUTPUT below for more information. --deduplicate When only filenames are shown, suppress duplicates that may come from having multiple stages during a merge, or giving --deleted and --modified option at the same time. When any of the -t, --unmerged, or --stage option is in use, this option has no effect. -x <pattern>, --exclude=<pattern> Skip untracked files matching pattern. Note that pattern is a shell wildcard pattern. See EXCLUDE PATTERNS below for more information. -X <file>, --exclude-from=<file> Read exclude patterns from <file>; 1 per line. --exclude-per-directory=<file> Read additional exclude patterns that apply only to the directory and its subdirectories in <file>. Deprecated; use --exclude-standard instead. --exclude-standard Add the standard Git exclusions: .git/info/exclude, .gitignore in each directory, and the user\u2019s global exclusion file. --error-unmatch If any <file> does not appear in the index, treat this as an error (return 1). --with-tree=<tree-ish> When using --error-unmatch to expand the user supplied <file> (i.e. path pattern) arguments to paths, pretend that paths which were removed in the index since the named <tree-ish> are still present. Using this option with -s or -u options does not make any sense. -t Show status tags together with filenames. Note that for scripting purposes, git-status(1) --porcelain and git-diff-files(1) --name-status are almost always superior alternatives, and users should look at git-status(1) --short or git-diff(1) --name-status for more user-friendly alternatives. This option provides a reason for showing each filename, in the form of a status tag (which is followed by a space and then the filename). The status tags are all single characters from the following list: H tracked file that is not either unmerged or skip-worktree S tracked file that is skip-worktree M tracked file that is unmerged R tracked file with unstaged removal/deletion C tracked file with unstaged modification/change K untracked paths which are part of file/directory conflicts which prevent checking out tracked files ? untracked file U file with resolve-undo information -v Similar to -t, but use lowercase letters for files that are marked as assume unchanged (see git-update-index(1)). -f Similar to -t, but use lowercase letters for files that are marked as fsmonitor valid (see git-update-index(1)). --full-name When run from a subdirectory, the command usually outputs paths relative to the current directory. This option forces paths to be output relative to the project top directory. --recurse-submodules Recursively calls ls-files on each active submodule in the repository. Currently there is only support for the --cached and --stage modes. --abbrev[=<n>] Instead of showing the full 40-byte hexadecimal object lines, show the shortest prefix that is at least <n> hexdigits long that uniquely refers the object. Non default number of digits can be specified with --abbrev=<n>. --debug After each line that describes a file, add more data about its cache entry. This is intended to show as much information as possible for manual inspection; the exact format may change at any time. --eol Show <eolinfo> and <eolattr> of files. <eolinfo> is the file content identification used by Git when the \"text\" attribute is \"auto\" (or not set and core.autocrlf is not false). <eolinfo> is either \"-text\", \"none\", \"lf\", \"crlf\", \"mixed\" or \"\". \"\" means the file is not a regular file, it is not in the index or not accessible in the working tree. <eolattr> is the attribute that is used when checking out or committing, it is either \"\", \"-text\", \"text\", \"text=auto\", \"text eol=lf\", \"text eol=crlf\". Since Git 2.10 \"text=auto eol=lf\" and \"text=auto eol=crlf\" are supported. Both the <eolinfo> in the index (\"i/<eolinfo>\") and in the working tree (\"w/<eolinfo>\") are shown for regular files, followed by the (\"attr/<eolattr>\"). --sparse If the index is sparse, show the sparse directories without expanding to the contained files. Sparse directories will be shown with a trailing slash, such as \"x/\" for a sparse directory \"x\". --format=<format> A string that interpolates %(fieldname) from the result being shown. It also interpolates %% to %, and %xx where xx are hex digits interpolates to character with hex code xx; for example %00 interpolates to \\0 (NUL), %09 to \\t (TAB) and %0a to \\n (LF). --format cannot be combined with -s, -o, -k, -t, --resolve-undo and --eol. -- Do not interpret any more arguments as options. <file> Files to show. If no files are given all files which match the other specified criteria are shown. "
  },
  {
    "command": "shred",
    "description": " Overwrite the specified FILE(s) repeatedly, in order to make it harder for even very expensive hardware probing to recover the data. If FILE is -, shred standard output. Mandatory arguments to long options are mandatory for short options too. -f, --force change permissions to allow writing if necessary -n, --iterations=N overwrite N times instead of the default (3) --random-source=FILE get random bytes from FILE -s, --size=N shred this many bytes (suffixes like K, M, G accepted) -u deallocate and remove file after overwriting --remove[=HOW] like -u but give control on HOW to delete; See below -v, --verbose show progress -x, --exact do not round file sizes up to the next full block; this is the default for non-regular files -z, --zero add a final overwrite with zeros to hide shredding --help display this help and exit --version output version information and exit Delete FILE(s) if --remove (-u) is specified. The default is not to remove the files because it is common to operate on device files like /dev/hda, and those files usually should not be removed. The optional HOW parameter indicates how to remove a directory entry: 'unlink' => use a standard unlink call. 'wipe' => also first obfuscate bytes in the name. 'wipesync' => also sync each obfuscated byte to the device. The default mode is 'wipesync', but note it can be expensive. CAUTION: shred assumes the file system and hardware overwrite data in place. Although this is common, many platforms operate otherwise. Also, backups and mirrors may contain unremovable copies that will let a shredded file be recovered later. See the GNU coreutils manual for details. "
  },
  {
    "command": "tac",
    "description": " Write each FILE to standard output, last line first. With no FILE, or when FILE is -, read standard input. Mandatory arguments to long options are mandatory for short options too. -b, --before attach the separator before instead of after -r, --regex interpret the separator as a regular expression -s, --separator=STRING use STRING as the separator instead of newline --help display this help and exit --version output version information and exit "
  },
  {
    "command": "write",
    "description": " The write utility shall read lines from the standard input and write them to the terminal of the specified user. When first invoked, it shall write the message: Message from sender-login-id (sending-terminal) [date]... to user_name. When it has successfully completed the connection, the sender's terminal shall be alerted twice to indicate that what the sender is typing is being written to the recipient's terminal. If the recipient wants to reply, this can be accomplished by typing: write sender-login-id [sending-terminal] upon receipt of the initial message. Whenever a line of input as delimited by an NL, EOF, or EOL special character (see the Base Definitions volume of POSIX.1\u20102017, Chapter 11, General Terminal Interface) is accumulated while in canonical input mode, the accumulated data shall be written on the other user's terminal. Characters shall be processed as follows: * Typing <alert> shall write the <alert> character to the recipient's terminal. * Typing the erase and kill characters shall affect the sender's terminal in the manner described by the termios interface in the Base Definitions volume of POSIX.1\u20102017, Chapter 11, General Terminal Interface. * Typing the interrupt or end-of-file characters shall cause write to write an appropriate message (\"EOT\\n\" in the POSIX locale) to the recipient's terminal and exit. * Typing characters from LC_CTYPE classifications print or space shall cause those characters to be sent to the recipient's terminal. * When and only when the stty iexten local mode is enabled, the existence and processing of additional special control characters and multi-byte or single-byte functions is implementation-defined. * Typing other non-printable characters shall cause implementation-defined sequences of printable characters to be written to the recipient's terminal. To write to a user who is logged in more than once, the terminal argument can be used to indicate which terminal to write to; otherwise, the recipient's terminal is selected in an implementation-defined manner and an informational message is written to the sender's standard output, indicating which terminal was chosen. Permission to be a recipient of a write message can be denied or granted by use of the mesg utility. However, a user's privilege may further constrain the domain of accessibility of other users' terminals. The write utility shall fail when the user lacks appropriate privileges to perform the requested action. None. "
  },
  {
    "command": "git-ls-remote",
    "description": " Displays references available in a remote repository along with the associated commit IDs. -h, --heads, -t, --tags Limit to only refs/heads and refs/tags, respectively. These options are not mutually exclusive; when given both, references stored in refs/heads and refs/tags are displayed. Note that git ls-remote -h used without anything else on the command line gives help, consistent with other git subcommands. --refs Do not show peeled tags or pseudorefs like HEAD in the output. -q, --quiet Do not print remote URL to stderr. --upload-pack=<exec> Specify the full path of git-upload-pack on the remote host. This allows listing references from repositories accessed via SSH and where the SSH daemon does not use the PATH configured by the user. --exit-code Exit with status \"2\" when no matching refs are found in the remote repository. Usually the command exits with status \"0\" to indicate it successfully talked with the remote repository, whether it found any matching refs. --get-url Expand the URL of the given remote repository taking into account any \"url.<base>.insteadOf\" config setting (See git-config(1)) and exit without talking to the remote. --symref In addition to the object pointed by it, show the underlying ref pointed by it when showing a symbolic ref. Currently, upload-pack only shows the symref HEAD, so it will be the only one shown by ls-remote. --sort=<key> Sort based on the key given. Prefix - to sort in descending order of the value. Supports \"version:refname\" or \"v:refname\" (tag names are treated as versions). The \"version:refname\" sort order can also be affected by the \"versionsort.suffix\" configuration variable. See git-for-each-ref(1) for more sort options, but be aware keys like committerdate that require access to the objects themselves will not work for refs whose objects have not yet been fetched from the remote, and will give a missing object error. -o <option>, --server-option=<option> Transmit the given string to the server when communicating using protocol version 2. The given string must not contain a NUL or LF character. When multiple --server-option=<option> are given, they are all sent to the other side in the order listed on the command line. <repository> The \"remote\" repository to query. This parameter can be either a URL or the name of a remote (see the GIT URLS and REMOTES sections of git-fetch(1)). <patterns>... When unspecified, all references, after filtering done with --heads and --tags, are shown. When <patterns>... are specified, only references matching one or more of the given patterns are displayed. Each pattern is interpreted as a glob (see glob in gitglossary(7)) which is matched against the \"tail\" of a ref, starting either from the start of the ref (so a full name like refs/heads/foo matches) or from a slash separator (so bar matches refs/heads/bar but not refs/heads/foobar). "
  },
  {
    "command": "git-merge",
    "description": " Incorporates changes from the named commits (since the time their histories diverged from the current branch) into the current branch. This command is used by git pull to incorporate changes from another repository and can be used by hand to merge changes from one branch into another. Assume the following history exists and the current branch is \"master\": A---B---C topic / D---E---F---G master Then \"git merge topic\" will replay the changes made on the topic branch since it diverged from master (i.e., E) until its current commit (C) on top of master, and record the result in a new commit along with the names of the two parent commits and a log message from the user describing the changes. Before the operation, ORIG_HEAD is set to the tip of the current branch (C). A---B---C topic / \\ D---E---F---G---H master The second syntax (\"git merge --abort\") can only be run after the merge has resulted in conflicts. git merge --abort will abort the merge process and try to reconstruct the pre-merge state. However, if there were uncommitted changes when the merge started (and especially if those changes were further modified after the merge was started), git merge --abort will in some cases be unable to reconstruct the original (pre-merge) changes. Therefore: Warning: Running git merge with non-trivial uncommitted changes is discouraged: while possible, it may leave you in a state that is hard to back out of in the case of a conflict. The third syntax (\"git merge --continue\") can only be run after the merge has resulted in conflicts. --commit, --no-commit Perform the merge and commit the result. This option can be used to override --no-commit. With --no-commit perform the merge and stop just before creating a merge commit, to give the user a chance to inspect and further tweak the merge result before committing. Note that fast-forward updates do not create a merge commit and therefore there is no way to stop those merges with --no-commit. Thus, if you want to ensure your branch is not changed or updated by the merge command, use --no-ff with --no-commit. --edit, -e, --no-edit Invoke an editor before committing successful mechanical merge to further edit the auto-generated merge message, so that the user can explain and justify the merge. The --no-edit option can be used to accept the auto-generated message (this is generally discouraged). The --edit (or -e) option is still useful if you are giving a draft message with the -m option from the command line and want to edit it in the editor. Older scripts may depend on the historical behaviour of not allowing the user to edit the merge log message. They will see an editor opened when they run git merge. To make it easier to adjust such scripts to the updated behaviour, the environment variable GIT_MERGE_AUTOEDIT can be set to no at the beginning of them. --cleanup=<mode> This option determines how the merge message will be cleaned up before committing. See git-commit(1) for more details. In addition, if the <mode> is given a value of scissors, scissors will be appended to MERGE_MSG before being passed on to the commit machinery in the case of a merge conflict. --ff, --no-ff, --ff-only Specifies how a merge is handled when the merged-in history is already a descendant of the current history. --ff is the default unless merging an annotated (and possibly signed) tag that is not stored in its natural place in the refs/tags/ hierarchy, in which case --no-ff is assumed. With --ff, when possible resolve the merge as a fast-forward (only update the branch pointer to match the merged branch; do not create a merge commit). When not possible (when the merged-in history is not a descendant of the current history), create a merge commit. With --no-ff, create a merge commit in all cases, even when the merge could instead be resolved as a fast-forward. With --ff-only, resolve the merge as a fast-forward when possible. When not possible, refuse to merge and exit with a non-zero status. -S[<keyid>], --gpg-sign[=<keyid>], --no-gpg-sign GPG-sign the resulting merge commit. The keyid argument is optional and defaults to the committer identity; if specified, it must be stuck to the option without a space. --no-gpg-sign is useful to countermand both commit.gpgSign configuration variable, and earlier --gpg-sign. --log[=<n>], --no-log In addition to branch names, populate the log message with one-line descriptions from at most <n> actual commits that are being merged. See also git-fmt-merge-msg(1). With --no-log do not list one-line descriptions from the actual commits being merged. --signoff, --no-signoff Add a Signed-off-by trailer by the committer at the end of the commit log message. The meaning of a signoff depends on the project to which you\u2019re committing. For example, it may certify that the committer has the rights to submit the work under the project\u2019s license or agrees to some contributor representation, such as a Developer Certificate of Origin. (See http://developercertificate.org for the one used by the Linux kernel and Git projects.) Consult the documentation or leadership of the project to which you\u2019re contributing to understand how the signoffs are used in that project. The --no-signoff option can be used to countermand an earlier --signoff option on the command line. --stat, -n, --no-stat Show a diffstat at the end of the merge. The diffstat is also controlled by the configuration option merge.stat. With -n or --no-stat do not show a diffstat at the end of the merge. --squash, --no-squash Produce the working tree and index state as if a real merge happened (except for the merge information), but do not actually make a commit, move the HEAD, or record $GIT_DIR/MERGE_HEAD (to cause the next git commit command to create a merge commit). This allows you to create a single commit on top of the current branch whose effect is the same as merging another branch (or more in case of an octopus). With --no-squash perform the merge and commit the result. This option can be used to override --squash. With --squash, --commit is not allowed, and will fail. --[no-]verify By default, the pre-merge and commit-msg hooks are run. When --no-verify is given, these are bypassed. See also githooks(5). -s <strategy>, --strategy=<strategy> Use the given merge strategy; can be supplied more than once to specify them in the order they should be tried. If there is no -s option, a built-in list of strategies is used instead (ort when merging a single head, octopus otherwise). -X <option>, --strategy-option=<option> Pass merge strategy specific option through to the merge strategy. --verify-signatures, --no-verify-signatures Verify that the tip commit of the side branch being merged is signed with a valid key, i.e. a key that has a valid uid: in the default trust model, this means the signing key has been signed by a trusted key. If the tip commit of the side branch is not signed with a valid key, the merge is aborted. --summary, --no-summary Synonyms to --stat and --no-stat; these are deprecated and will be removed in the future. -q, --quiet Operate quietly. Implies --no-progress. -v, --verbose Be verbose. --progress, --no-progress Turn progress on/off explicitly. If neither is specified, progress is shown if standard error is connected to a terminal. Note that not all merge strategies may support progress reporting. --autostash, --no-autostash Automatically create a temporary stash entry before the operation begins, record it in the special ref MERGE_AUTOSTASH and apply it after the operation ends. This means that you can run the operation on a dirty worktree. However, use with care: the final stash application after a successful merge might result in non-trivial conflicts. --allow-unrelated-histories By default, git merge command refuses to merge histories that do not share a common ancestor. This option can be used to override this safety when merging histories of two projects that started their lives independently. As that is a very rare occasion, no configuration variable to enable this by default exists and will not be added. -m <msg> Set the commit message to be used for the merge commit (in case one is created). If --log is specified, a shortlog of the commits being merged will be appended to the specified message. The git fmt-merge-msg command can be used to give a good default for automated git merge invocations. The automated message can include the branch description. --into-name <branch> Prepare the default merge message as if merging to the branch <branch>, instead of the name of the real branch to which the merge is made. -F <file>, --file=<file> Read the commit message to be used for the merge commit (in case one is created). If --log is specified, a shortlog of the commits being merged will be appended to the specified message. --rerere-autoupdate, --no-rerere-autoupdate After the rerere mechanism reuses a recorded resolution on the current conflict to update the files in the working tree, allow it to also update the index with the result of resolution. --no-rerere-autoupdate is a good way to double-check what rerere did and catch potential mismerges, before committing the result to the index with a separate git add. --overwrite-ignore, --no-overwrite-ignore Silently overwrite ignored files from the merge result. This is the default behavior. Use --no-overwrite-ignore to abort. --abort Abort the current conflict resolution process, and try to reconstruct the pre-merge state. If an autostash entry is present, apply it to the worktree. If there were uncommitted worktree changes present when the merge started, git merge --abort will in some cases be unable to reconstruct these changes. It is therefore recommended to always commit or stash your changes before running git merge. git merge --abort is equivalent to git reset --merge when MERGE_HEAD is present unless MERGE_AUTOSTASH is also present in which case git merge --abort applies the stash entry to the worktree whereas git reset --merge will save the stashed changes in the stash list. --quit Forget about the current merge in progress. Leave the index and the working tree as-is. If MERGE_AUTOSTASH is present, the stash entry will be saved to the stash list. --continue After a git merge stops due to conflicts you can conclude the merge by running git merge --continue (see \"HOW TO RESOLVE CONFLICTS\" section below). <commit>... Commits, usually other branch heads, to merge into our branch. Specifying more than one commit will create a merge with more than two parents (affectionately called an Octopus merge). If no commit is given from the command line, merge the remote-tracking branches that the current branch is configured to use as its upstream. See also the configuration section of this manual page. When FETCH_HEAD (and no other commit) is specified, the branches recorded in the .git/FETCH_HEAD file by the previous invocation of git fetch for merging are merged to the current branch. "
  },
  {
    "command": "chown",
    "description": " The chown utility shall set the user ID of the file named by each file operand to the user ID specified by the owner operand. For each file operand, or, if the -R option is used, each file encountered while walking the directory trees specified by the file operands, the chown utility shall perform actions equivalent to the chown() function defined in the System Interfaces volume of POSIX.1\u20102017, called with the following arguments: 1. The file operand shall be used as the path argument. 2. The user ID indicated by the owner portion of the first operand shall be used as the owner argument. 3. If the group portion of the first operand is given, the group ID indicated by it shall be used as the group argument; otherwise, the group ownership shall not be changed. Unless chown is invoked by a process with appropriate privileges, the set-user-ID and set-group-ID bits of a regular file shall be cleared upon successful completion; the set-user-ID and set- group-ID bits of other file types may be cleared. The chown utility shall conform to the Base Definitions volume of POSIX.1\u20102017, Section 12.2, Utility Syntax Guidelines. The following options shall be supported by the implementation: -h For each file operand that names a file of type symbolic link, chown shall attempt to set the user ID of the symbolic link. If a group ID was specified, for each file operand that names a file of type symbolic link, chown shall attempt to set the group ID of the symbolic link. -H If the -R option is specified and a symbolic link referencing a file of type directory is specified on the command line, chown shall change the user ID (and group ID, if specified) of the directory referenced by the symbolic link and all files in the file hierarchy below it. -L If the -R option is specified and a symbolic link referencing a file of type directory is specified on the command line or encountered during the traversal of a file hierarchy, chown shall change the user ID (and group ID, if specified) of the directory referenced by the symbolic link and all files in the file hierarchy below it. -P If the -R option is specified and a symbolic link is specified on the command line or encountered during the traversal of a file hierarchy, chown shall change the owner ID (and group ID, if specified) of the symbolic link. The chown utility shall not follow the symbolic link to any other part of the file hierarchy. -R Recursively change file user and group IDs. For each file operand that names a directory, chown shall change the user ID (and group ID, if specified) of the directory and all files in the file hierarchy below it. Unless a -H, -L, or -P option is specified, it is unspecified which of these options will be used as the default. Specifying more than one of the mutually-exclusive options -H, -L, and -P shall not be considered an error. The last option specified shall determine the behavior of the utility. "
  },
  {
    "command": "sshfs",
    "description": " SSHFS allows you to mount a remote filesystem using SSH (more precisely, the SFTP subsystem). Most SSH servers support and enable this SFTP access by default, so SSHFS is very simple to use - there's nothing to do on the server-side. By default, file permissions are ignored by SSHFS. Any user that can access the filesystem will be able to perform any operation that the remote server permits - based on the credentials that were used to connect to the server. If this is undesired, local permission checking can be enabled with -o default_permissions. By default, only the mounting user will be able to access the filesystem. Access for other users can be enabled by passing -o allow_other. In this case you most likely also want to use -o default_permissions. It is recommended to run SSHFS as regular user (not as root). For this to work the mountpoint must be owned by the user. If username is omitted SSHFS will use the local username. If the directory is omitted, SSHFS will mount the (remote) home directory. If you need to enter a password sshfs will ask for it (actually it just runs ssh which ask for the password if needed). -o opt,[opt...] mount options, see below for details. A a variety of SSH options can be given here as well, see the manual pages for sftp(1) and ssh_config(5). -h, --help print help and exit. -V, --version print version information and exit. -d, --debug print debugging information. -p PORT equivalent to '-o port=PORT' -f do not daemonize, stay in foreground. -s Single threaded operation. -C equivalent to '-o compression=yes' -F ssh_configfile specifies alternative ssh configuration file -1 equivalent to '-o ssh_protocol=1' -o reconnect automatically reconnect to server if connection is interrupted. Attempts to access files that were opened before the reconnection will give errors and need to be re-opened. -o delay_connect Don't immediately connect to server, wait until mountpoint is first accessed. -o sshfs_sync synchronous writes. This will slow things down, but may be useful in some situations. -o no_readahead Only read exactly the data that was requested, instead of speculatively reading more to anticipate the next read request. -o sync_readdir synchronous readdir. This will slow things down, but may be useful in some situations. -o workaround=LIST Enable the specified workaround. See the Caveats section below for some additional information. Possible values are: rename Emulate overwriting an existing file by deleting and renaming. renamexdev Make rename fail with EXDEV instead of the default EPERM to allow moving files across remote filesystems. truncate Work around servers that don't support truncate by coping the whole file, truncating it locally, and sending it back. fstat Work around broken servers that don't support fstat() by using stat instead. buflimit Work around OpenSSH \"buffer fillup\" bug. createmode Work around broken servers that produce an error when passing a non-zero mode to create, by always passing a mode of 0. -o idmap=TYPE How to map remote UID/GIDs to local values. Possible values are: none no translation of the ID space (default). user map the UID/GID of the remote user to UID/GID of the mounting user. file translate UIDs/GIDs based upon the contents of --uidfile and --gidfile. -o uidfile=FILE file containing username:uid mappings for -o idmap=file -o gidfile=FILE file containing groupname:gid mappings for -o idmap=file -o nomap=TYPE with idmap=file, how to handle missing mappings: ignore don't do any re-mapping error return an error (default) -o ssh_command=CMD execute CMD instead of 'ssh' -o ssh_protocol=N ssh protocol to use (default: 2) -o sftp_server=SERV path to sftp server or subsystem (default: sftp) -o directport=PORT directly connect to PORT bypassing ssh -o passive communicate over stdin and stdout bypassing network. Useful for mounting local filesystem on the remote side. An example using dpipe command would be dpipe /usr/lib/openssh/sftp-server = ssh RemoteHostname sshfs :/directory/to/be/shared ~/mnt/src -o passive -o disable_hardlink With this option set, attempts to call link(2) will fail with error code ENOSYS. -o transform_symlinks transform absolute symlinks on remote side to relative symlinks. This means that if e.g. on the server side /foo/bar/com is a symlink to /foo/blub, SSHFS will transform the link target to ../blub on the client side. -o follow_symlinks follow symlinks on the server, i.e. present them as regular files on the client. If a symlink is dangling (i.e, the target does not exist) the behavior depends on the remote server - the entry may appear as a symlink on the client, or it may appear as a regular file that cannot be accessed. -o no_check_root don't check for existence of 'dir' on server -o password_stdin read password from stdin (only for pam_mount!) -o dir_cache=BOOL Enables (yes) or disables (no) the SSHFS directory cache. The directory cache holds the names of directory entries. Enabling it allows readdir(3) system calls to be processed without network access. -o dcache_max_size=N sets the maximum size of the directory cache. -o dcache_timeout=N sets timeout for directory cache in seconds. -o dcache_{stat,link,dir}_timeout=N sets separate timeout for {attributes, symlinks, names} in the directory cache. -o dcache_clean_interval=N sets the interval for automatic cleaning of the directory cache. -o dcache_min_clean_interval=N sets the interval for forced cleaning of the directory cache when full. -o direct_io This option disables the use of page cache (file content cache) in the kernel for this filesystem. This has several affects: 1. Each read() or write() system call will initiate one or more read or write operations, data will not be cached in the kernel. 2. The return value of the read() and write() system calls will correspond to the return values of the read and write operations. This is useful for example if the file size is not known in advance (before reading it). e.g. /proc filesystem -o max_conns=N sets the maximum number of simultaneous SSH connections to use. Each connection is established with a separate SSH process. The primary purpose of this feature is to improve the responsiveness of the file system during large file transfers. When using more than once connection, the password_stdin and passive options can not be used, and the buflimit workaround is not supported. In addition, SSHFS accepts several options common to all FUSE file systems. These are described in the mount.fuse manpage (look for \"general\", \"libfuse specific\", and \"high-level API\" options). "
  },
  {
    "command": "sleep",
    "description": " Pause for NUMBER seconds. SUFFIX may be 's' for seconds (the default), 'm' for minutes, 'h' for hours or 'd' for days. NUMBER need not be an integer. Given two or more arguments, pause for the amount of time specified by the sum of their values. --help display this help and exit --version output version information and exit "
  },
  {
    "command": "manpath",
    "description": " If $MANPATH is set, manpath will simply display its contents and issue a warning. If not, manpath will determine a suitable manual page hierarchy search path and display the results. The colon-delimited path is determined using information gained from the man-db configuration file \u2013 (/usr/local/etc/man_db.conf) and the user's environment. -q, --quiet Do not issue warnings. -d, --debug Print debugging information. -c, --catpath Produce a catpath as opposed to a manpath. Once the manpath is determined, each path element is converted to its relative catpath. -g, --global Produce a manpath consisting of all paths named as \"global\" within the man-db configuration file. -m system[,...], --systems=system[,...] If this system has access to other operating systems' manual hierarchies, this option can be used to include them in the output of manpath. To include NewOS's manual page hierarchies use the option -m NewOS. The system specified can be a combination of comma delimited operating system names. To include the native operating system's manual page hierarchies, the system name man must be included in the argument string. This option will override the $SYSTEM environment variable. -C file, --config-file=file Use this user configuration file rather than the default of ~/.manpath. -?, --help Print a help message and exit. --usage Print a short usage message and exit. -V, --version Display version information. "
  },
  {
    "command": "mv",
    "description": " Rename SOURCE to DEST, or move SOURCE(s) to DIRECTORY. Mandatory arguments to long options are mandatory for short options too. --backup[=CONTROL] make a backup of each existing destination file -b like --backup but does not accept an argument --debug explain how a file is copied. Implies -v -f, --force do not prompt before overwriting -i, --interactive prompt before overwrite -n, --no-clobber do not overwrite an existing file If you specify more than one of -i, -f, -n, only the final one takes effect. --no-copy do not copy if renaming fails --strip-trailing-slashes remove any trailing slashes from each SOURCE argument -S, --suffix=SUFFIX override the usual backup suffix -t, --target-directory=DIRECTORY move all SOURCE arguments into DIRECTORY -T, --no-target-directory treat DEST as a normal file --update[=UPDATE] control which existing files are updated; UPDATE={all,none,older(default)}. See below -u equivalent to --update[=older] -v, --verbose explain what is being done -Z, --context set SELinux security context of destination file to default type --help display this help and exit --version output version information and exit UPDATE controls which existing files in the destination are replaced. 'all' is the default operation when an --update option is not specified, and results in all existing files in the destination being replaced. 'none' is similar to the --no-clobber option, in that no files in the destination are replaced, but also skipped files do not induce a failure. 'older' is the default operation when --update is specified, and results in files being replaced if they're older than the corresponding source file. The backup suffix is '~', unless set with --suffix or SIMPLE_BACKUP_SUFFIX. The version control method may be selected via the --backup option or through the VERSION_CONTROL environment variable. Here are the values: none, off never make backups (even if --backup is given) numbered, t make numbered backups existing, nil numbered if numbered backups exist, simple otherwise simple, never always make simple backups "
  },
  {
    "command": "whereis",
    "description": " whereis locates the binary, source and manual files for the specified command names. The supplied names are first stripped of leading pathname components. Prefixes of s. resulting from use of source code control are also dealt with. whereis then attempts to locate the desired program in the standard Linux places, and in the places specified by $PATH and $MANPATH. The search restrictions (options -b, -m and -s) are cumulative and apply to the subsequent name patterns on the command line. Any new search restriction resets the search mask. For example, whereis -bm ls tr -m gcc searches for \"ls\" and \"tr\" binaries and man pages, and for \"gcc\" man pages only. The options -B, -M and -S reset search paths for the subsequent name patterns. For example, whereis -m ls -M /usr/share/man/man1 -f cal searches for \"ls\" man pages in all default paths, but for \"cal\" in the /usr/share/man/man1 directory only. -b Search for binaries. -m Search for manuals. -s Search for sources. -u Only show the command names that have unusual entries. A command is said to be unusual if it does not have just one entry of each explicitly requested type. Thus 'whereis -m -u *' asks for those files in the current directory which have no documentation file, or more than one. -B list Limit the places where whereis searches for binaries, by a whitespace-separated list of directories. -M list Limit the places where whereis searches for manuals and documentation in Info format, by a whitespace-separated list of directories. -S list Limit the places where whereis searches for sources, by a whitespace-separated list of directories. -f Terminates the directory list and signals the start of filenames. It must be used when any of the -B, -M, or -S options is used. -l Output the list of effective lookup paths that whereis is using. When none of -B, -M, or -S is specified, the option will output the hard-coded paths that the command was able to find on the system. -g Interpret the next names as a glob(7) patterns. whereis always compares only filenames (aka basename) and never complete path. Using directory names in the pattern has no effect. Don\u2019t forget that the shell interprets the pattern when specified on the command line without quotes. It\u2019s necessary to use quotes for the name, for example: whereis -g 'find*' -h, --help Display help text and exit. -V, --version Print version and exit. "
  },
  {
    "command": "git-daemon",
    "description": " A really simple TCP Git daemon that normally listens on port \"DEFAULT_GIT_PORT\" aka 9418. It waits for a connection asking for a service, and will serve that service if it is enabled. It verifies that the directory has the magic file \"git-daemon-export-ok\", and it will refuse to export any Git directory that hasn\u2019t explicitly been marked for export this way (unless the --export-all parameter is specified). If you pass some directory paths as git daemon arguments, the offers are limited to repositories within those directories. By default, only upload-pack service is enabled, which serves git fetch-pack and git ls-remote clients, which are invoked from git fetch, git pull, and git clone. This is ideally suited for read-only updates, i.e., pulling from Git repositories. An upload-archive also exists to serve git archive. --strict-paths Match paths exactly (i.e. don\u2019t allow \"/foo/repo\" when the real path is \"/foo/repo.git\" or \"/foo/repo/.git\") and don\u2019t do user-relative paths. git daemon will refuse to start when this option is enabled and no directory arguments are provided. --base-path=<path> Remap all the path requests as relative to the given path. This is sort of \"Git root\" - if you run git daemon with --base-path=/srv/git on example.com, then if you later try to pull git://example.com/hello.git, git daemon will interpret the path as /srv/git/hello.git. --base-path-relaxed If --base-path is enabled and repo lookup fails, with this option git daemon will attempt to lookup without prefixing the base path. This is useful for switching to --base-path usage, while still allowing the old paths. --interpolated-path=<pathtemplate> To support virtual hosting, an interpolated path template can be used to dynamically construct alternate paths. The template supports %H for the target hostname as supplied by the client but converted to all lowercase, %CH for the canonical hostname, %IP for the server\u2019s IP address, %P for the port number, and %D for the absolute path of the named repository. After interpolation, the path is validated against the directory list. --export-all Allow pulling from all directories that look like Git repositories (have the objects and refs subdirectories), even if they do not have the git-daemon-export-ok file. --inetd Have the server run as an inetd service. Implies --syslog (may be overridden with --log-destination=). Incompatible with --detach, --port, --listen, --user and --group options. --listen=<host_or_ipaddr> Listen on a specific IP address or hostname. IP addresses can be either an IPv4 address or an IPv6 address if supported. If IPv6 is not supported, then --listen=hostname is also not supported and --listen must be given an IPv4 address. Can be given more than once. Incompatible with --inetd option. --port=<n> Listen on an alternative port. Incompatible with --inetd option. --init-timeout=<n> Timeout (in seconds) between the moment the connection is established and the client request is received (typically a rather low value, since that should be basically immediate). --timeout=<n> Timeout (in seconds) for specific client sub-requests. This includes the time it takes for the server to process the sub-request and the time spent waiting for the next client\u2019s request. --max-connections=<n> Maximum number of concurrent clients, defaults to 32. Set it to zero for no limit. --syslog Short for --log-destination=syslog. --log-destination=<destination> Send log messages to the specified destination. Note that this option does not imply --verbose, thus by default only error conditions will be logged. The <destination> must be one of: stderr Write to standard error. Note that if --detach is specified, the process disconnects from the real standard error, making this destination effectively equivalent to none. syslog Write to syslog, using the git-daemon identifier. none Disable all logging. The default destination is syslog if --inetd or --detach is specified, otherwise stderr. --user-path, --user-path=<path> Allow ~user notation to be used in requests. When specified with no parameter, requests to git://host/~alice/foo is taken as a request to access foo repository in the home directory of user alice. If --user-path=path is specified, the same request is taken as a request to access path/foo repository in the home directory of user alice. --verbose Log details about the incoming connections and requested files. --reuseaddr Use SO_REUSEADDR when binding the listening socket. This allows the server to restart without waiting for old connections to time out. --detach Detach from the shell. Implies --syslog. --pid-file=<file> Save the process id in file. Ignored when the daemon is run under --inetd. --user=<user>, --group=<group> Change daemon\u2019s uid and gid before entering the service loop. When only --user is given without --group, the primary group ID for the user is used. The values of the option are given to getpwnam(3) and getgrnam(3) and numeric IDs are not supported. Giving these options is an error when used with --inetd; use the facility of inet daemon to achieve the same before spawning git daemon if needed. Like many programs that switch user id, the daemon does not reset environment variables such as $HOME when it runs git programs, e.g. upload-pack and receive-pack. When using this option, you may also want to set and export HOME to point at the home directory of <user> before starting the daemon, and make sure any Git configuration files in that directory are readable by <user>. --enable=<service>, --disable=<service> Enable/disable the service site-wide per default. Note that a service disabled site-wide can still be enabled per repository if it is marked overridable and the repository enables the service with a configuration item. --allow-override=<service>, --forbid-override=<service> Allow/forbid overriding the site-wide default with per repository configuration. By default, all the services may be overridden. --[no-]informative-errors When informative errors are turned on, git-daemon will report more verbose errors to the client, differentiating conditions like \"no such repository\" from \"repository not exported\". This is more convenient for clients, but may leak information about the existence of unexported repositories. When informative errors are not enabled, all errors report \"access denied\" to the client. The default is --no-informative-errors. --access-hook=<path> Every time a client connects, first run an external command specified by the <path> with service name (e.g. \"upload-pack\"), path to the repository, hostname (%H), canonical hostname (%CH), IP address (%IP), and TCP port (%P) as its command-line arguments. The external command can decide to decline the service by exiting with a non-zero status (or to allow it by exiting with a zero status). It can also look at the $REMOTE_ADDR and $REMOTE_PORT environment variables to learn about the requestor when making this decision. The external command can optionally write a single line to its standard output to be sent to the requestor as an error message when it declines the service. <directory> The remaining arguments provide a list of directories. If any directories are specified, then the git-daemon process will serve a requested directory only if it is contained in one of these directories. If --strict-paths is specified, then the requested directory must match one of these directories exactly. "
  }
]