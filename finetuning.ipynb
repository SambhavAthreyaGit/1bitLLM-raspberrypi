{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9181612,"sourceType":"datasetVersion","datasetId":5549583}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-15T20:26:04.499067Z","iopub.execute_input":"2024-08-15T20:26:04.500122Z","iopub.status.idle":"2024-08-15T20:26:04.512862Z","shell.execute_reply.started":"2024-08-15T20:26:04.500076Z","shell.execute_reply":"2024-08-15T20:26:04.511939Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/csvbashcommands/formatted_command_dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import GPTNeoForCausalLM, GPT2Tokenizer, Trainer, TrainingArguments\nfrom datasets import load_dataset, Dataset\n\n# Load tokenizer and model\ntokenizer = GPT2Tokenizer.from_pretrained('EleutherAI/gpt-neo-125M')\nmodel = GPTNeoForCausalLM.from_pretrained('EleutherAI/gpt-neo-125M')\n\nmodel.config.use_cache = False\n\n# Load your dataset\ndataset = load_dataset('csv', data_files='/kaggle/input/csvbashcommands/formatted_command_dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:42:50.565388Z","iopub.execute_input":"2024-08-15T20:42:50.566089Z","iopub.status.idle":"2024-08-15T20:42:51.731676Z","shell.execute_reply.started":"2024-08-15T20:42:50.566055Z","shell.execute_reply":"2024-08-15T20:42:51.730631Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\nmodel.config.pad_token_id = tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:42:53.271444Z","iopub.execute_input":"2024-08-15T20:42:53.271876Z","iopub.status.idle":"2024-08-15T20:42:53.279767Z","shell.execute_reply.started":"2024-08-15T20:42:53.271843Z","shell.execute_reply":"2024-08-15T20:42:53.278183Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(examples):\n    tokenized = tokenizer(examples['description'], padding='max_length', truncation=True, max_length=128)\n    tokenized['labels'] = tokenized['input_ids'].copy()\n    return tokenized","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:42:54.681040Z","iopub.execute_input":"2024-08-15T20:42:54.681991Z","iopub.status.idle":"2024-08-15T20:42:54.688215Z","shell.execute_reply.started":"2024-08-15T20:42:54.681958Z","shell.execute_reply":"2024-08-15T20:42:54.687237Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=dataset['train'].column_names)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:42:57.857325Z","iopub.execute_input":"2024-08-15T20:42:57.857758Z","iopub.status.idle":"2024-08-15T20:43:06.941107Z","shell.execute_reply.started":"2024-08-15T20:42:57.857725Z","shell.execute_reply":"2024-08-15T20:43:06.939862Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/481 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf812c848438429fb0e034f5dd40ad7b"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:43:08.551537Z","iopub.execute_input":"2024-08-15T20:43:08.552285Z","iopub.status.idle":"2024-08-15T20:43:08.558707Z","shell.execute_reply.started":"2024-08-15T20:43:08.552252Z","shell.execute_reply":"2024-08-15T20:43:08.557683Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=3,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    eval_strategy=\"steps\",\n    eval_steps=500,\n    save_steps=1000,\n    load_best_model_at_end=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:43:10.691911Z","iopub.execute_input":"2024-08-15T20:43:10.692300Z","iopub.status.idle":"2024-08-15T20:43:10.734403Z","shell.execute_reply.started":"2024-08-15T20:43:10.692271Z","shell.execute_reply":"2024-08-15T20:43:10.733462Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        outputs = model(**inputs)\n        loss = outputs.loss\n        return (loss, outputs) if return_outputs else loss\n\n# Use CustomTrainer instead of Trainer\ntrainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset['train'],\n    eval_dataset=tokenized_dataset['test'] if 'test' in tokenized_dataset else None,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:43:12.897372Z","iopub.execute_input":"2024-08-15T20:43:12.898322Z","iopub.status.idle":"2024-08-15T20:43:13.069597Z","shell.execute_reply.started":"2024-08-15T20:43:12.898284Z","shell.execute_reply":"2024-08-15T20:43:13.068453Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:43:15.552169Z","iopub.execute_input":"2024-08-15T20:43:15.552690Z","iopub.status.idle":"2024-08-15T20:43:56.405749Z","shell.execute_reply.started":"2024-08-15T20:43:15.552648Z","shell.execute_reply":"2024-08-15T20:43:56.404771Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='93' max='93' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [93/93 00:39, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=93, training_loss=3.4743970645371305, metrics={'train_runtime': 40.2776, 'train_samples_per_second': 35.826, 'train_steps_per_second': 2.309, 'total_flos': 94230460366848.0, 'train_loss': 3.4743970645371305, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained(\"./fine_tuned_gpt_neo\")\ntokenizer.save_pretrained(\"./fine_tuned_gpt_neo\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:45:02.121474Z","iopub.execute_input":"2024-08-15T20:45:02.121914Z","iopub.status.idle":"2024-08-15T20:45:03.374061Z","shell.execute_reply.started":"2024-08-15T20:45:02.121882Z","shell.execute_reply":"2024-08-15T20:45:03.372773Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_gpt_neo/tokenizer_config.json',\n './fine_tuned_gpt_neo/special_tokens_map.json',\n './fine_tuned_gpt_neo/vocab.json',\n './fine_tuned_gpt_neo/merges.txt',\n './fine_tuned_gpt_neo/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:45:14.885330Z","iopub.execute_input":"2024-08-15T20:45:14.885785Z","iopub.status.idle":"2024-08-15T20:45:29.374263Z","shell.execute_reply.started":"2024-08-15T20:45:14.885749Z","shell.execute_reply":"2024-08-15T20:45:29.373028Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.23.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.7.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import HfApi, Repository\nfrom transformers import GPTNeoForCausalLM, GPT2Tokenizer\n\nfrom huggingface_hub import login\nlogin()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:45:41.930833Z","iopub.execute_input":"2024-08-15T20:45:41.931740Z","iopub.status.idle":"2024-08-15T20:45:41.970795Z","shell.execute_reply.started":"2024-08-15T20:45:41.931705Z","shell.execute_reply":"2024-08-15T20:45:41.969305Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ad9c06eeb574ad0b1128484aa3e8c03"}},"metadata":{}}]},{"cell_type":"code","source":"model = GPTNeoForCausalLM.from_pretrained(\"./fine_tuned_gpt_neo\")\ntokenizer = GPT2Tokenizer.from_pretrained(\"./fine_tuned_gpt_neo\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:47:34.115413Z","iopub.execute_input":"2024-08-15T20:47:34.115875Z","iopub.status.idle":"2024-08-15T20:47:34.754187Z","shell.execute_reply.started":"2024-08-15T20:47:34.115841Z","shell.execute_reply":"2024-08-15T20:47:34.753015Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"repo_name = \"sambhav11/gpt-neo-bash-commands\"  # Change this to your desired name\napi = HfApi()\nrepo_url = api.create_repo(repo_name, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:48:21.224021Z","iopub.execute_input":"2024-08-15T20:48:21.224430Z","iopub.status.idle":"2024-08-15T20:48:21.590642Z","shell.execute_reply.started":"2024-08-15T20:48:21.224396Z","shell.execute_reply":"2024-08-15T20:48:21.589208Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model.push_to_hub(repo_name)\ntokenizer.push_to_hub(repo_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T20:48:29.365321Z","iopub.execute_input":"2024-08-15T20:48:29.365722Z","iopub.status.idle":"2024-08-15T20:48:46.830527Z","shell.execute_reply.started":"2024-08-15T20:48:29.365691Z","shell.execute_reply":"2024-08-15T20:48:46.829285Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d1acabaa9a2477f9cf6723377028c17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da17140e09644bdc82140e8e656ea394"}},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/sambhav11/gpt-neo-bash-commands/commit/dbdb531767918ab63b3465475f6597e473d05ff9', commit_message='Upload tokenizer', commit_description='', oid='dbdb531767918ab63b3465475f6597e473d05ff9', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}